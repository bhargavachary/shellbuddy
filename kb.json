[
  {
    "id": "gnu-001",
    "pattern": "^rm\\s+-rf\\s+/$",
    "cmd": "rm",
    "severity": "danger",
    "hint": "Never run 'rm -rf /' \u2014 it erases your entire filesystem.",
    "detail": "Running 'rm -rf /' recursively deletes all files and directories from the root, leading to irreversible data loss. Many modern systems block this, but not all. Always double-check your target path before using 'rm -rf'.",
    "tags": [
      "rm",
      "danger",
      "filesystem"
    ]
  },
  {
    "id": "gnu-002",
    "pattern": "^rm\\s+-rf\\s+--no-preserve-root\\s+/?$",
    "cmd": "rm",
    "severity": "danger",
    "hint": "Avoid '--no-preserve-root' with 'rm -rf /'; it disables safety checks.",
    "detail": "The '--no-preserve-root' flag disables the default safeguard that prevents 'rm -rf /' from running. This can destroy the entire system, including running processes and critical files. Use only in highly controlled, non-production environments.",
    "tags": [
      "rm",
      "danger",
      "root"
    ]
  },
  {
    "id": "gnu-003",
    "pattern": "^cp\\s+-r\\s+\\S+\\s+\\S+$",
    "cmd": "cp",
    "severity": "warn",
    "hint": "Use '-a' instead of '-r' to preserve permissions and links.",
    "detail": "The '-r' flag copies directories recursively but does not preserve file modes, ownership, timestamps, or symlinks. The '-a' (archive) flag preserves all attributes, making it safer for backups or migrations.",
    "tags": [
      "cp",
      "permissions",
      "archive"
    ]
  },
  {
    "id": "gnu-004",
    "pattern": "^cp\\s+.*--no-clobber.*",
    "cmd": "cp",
    "severity": "tip",
    "hint": "Use '--no-clobber' to avoid overwriting existing files.",
    "detail": "The '--no-clobber' flag skips files that already exist at the destination, preventing accidental overwrites. This is especially useful in scripts or when copying large sets of files.",
    "tags": [
      "cp",
      "safe",
      "overwrite"
    ]
  },
  {
    "id": "gnu-005",
    "pattern": "^mv\\s+.*\\s+/dev/null\\s*$",
    "cmd": "mv",
    "severity": "danger",
    "hint": "Moving files to /dev/null deletes them irreversibly.",
    "detail": "'mv' to /dev/null discards the source file without recovery. Unlike 'rm', this doesn't prompt for confirmation. Only use this pattern if you intend to permanently delete the file.",
    "tags": [
      "mv",
      "danger",
      "deletion"
    ]
  },
  {
    "id": "gnu-006",
    "pattern": "^find\\s+.*-exec\\s+rm\\s+\\{-\\}\\s*;.*$",
    "cmd": "find",
    "severity": "warn",
    "hint": "Use '+', not ';', with '-exec' for better performance.",
    "detail": "Using '-exec ... {} ;' spawns a new process for each match, which is slow for large trees. '-exec ... {} +' groups files and runs fewer commands, greatly improving speed.",
    "tags": [
      "find",
      "performance",
      "exec"
    ]
  },
  {
    "id": "gnu-007",
    "pattern": "^find\\s+.*-delete.*$",
    "cmd": "find",
    "severity": "danger",
    "hint": "Double-check 'find ... -delete'; it's irreversible.",
    "detail": "'-delete' removes files immediately as they are found, without prompting. If your find pattern is too broad, you may delete unintended files. Always test with '-print' first.",
    "tags": [
      "find",
      "danger",
      "delete"
    ]
  },
  {
    "id": "gnu-008",
    "pattern": "^find\\s+.*-exec\\s+rm\\s+.*$",
    "cmd": "find",
    "severity": "warn",
    "hint": "Test your 'find' pattern with '-print' before using '-exec rm'.",
    "detail": "A misconfigured 'find' command with '-exec rm' can delete more files than intended. Always validate your search results with '-print' to avoid accidental data loss.",
    "tags": [
      "find",
      "rm",
      "warn"
    ]
  },
  {
    "id": "gnu-009",
    "pattern": "^ls\\s+-lR.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use 'tree' for better recursive directory visualization.",
    "detail": "'ls -lR' lists files recursively but can be hard to read for deep trees. The 'tree' command provides a hierarchical, indented view, making structure clearer. Install 'tree' for improved readability.",
    "tags": [
      "ls",
      "upgrade",
      "tree"
    ]
  },
  {
    "id": "gnu-010",
    "pattern": "^ls\\s+--color=never.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use '--color=auto' to enable color only in terminals.",
    "detail": "'--color=never' disables color output, which can make file types harder to distinguish. '--color=auto' enables color only when outputting to a terminal, avoiding escape codes in scripts or pipes.",
    "tags": [
      "ls",
      "color",
      "output"
    ]
  },
  {
    "id": "gnu-011",
    "pattern": "^ls\\s+.*-S.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Combine '-lhS' to sort by size with human-readable units.",
    "detail": "'ls -S' sorts by file size, but output is in bytes by default. Adding '-lh' shows sizes in KB/MB/GB, making large files easier to spot at a glance.",
    "tags": [
      "ls",
      "sort",
      "human-readable"
    ]
  },
  {
    "id": "gnu-012",
    "pattern": "^cp\\s+.*-u.*$",
    "cmd": "cp",
    "severity": "tip",
    "hint": "Use '-u' to copy only newer files, saving time and I/O.",
    "detail": "'cp -u' copies files only if the source is newer than the destination or if the destination does not exist. This is efficient for incremental backups or syncing directories.",
    "tags": [
      "cp",
      "incremental",
      "performance"
    ]
  },
  {
    "id": "gnu-013",
    "pattern": "^cp\\s+.*--reflink=auto.*$",
    "cmd": "cp",
    "severity": "tip",
    "hint": "Use '--reflink=auto' for fast, space-saving copies on supported files...",
    "detail": "On filesystems like btrfs or XFS, '--reflink=auto' creates copy-on-write clones, saving disk space and time. Falls back to regular copying if unsupported. Useful for large files or VM images.",
    "tags": [
      "cp",
      "reflink",
      "performance"
    ]
  },
  {
    "id": "gnu-014",
    "pattern": "^mv\\s+.*-n.*$",
    "cmd": "mv",
    "severity": "tip",
    "hint": "Use '-n' to prevent overwriting existing files during move.",
    "detail": "'mv -n' (no-clobber) skips moving files if the destination exists, protecting against accidental data loss. Combine with '-i' for interactive confirmation.",
    "tags": [
      "mv",
      "safe",
      "overwrite"
    ]
  },
  {
    "id": "gnu-015",
    "pattern": "^mv\\s+.*-b.*$",
    "cmd": "mv",
    "severity": "tip",
    "hint": "Use '-b' to create backups of overwritten files.",
    "detail": "'mv -b' saves a backup of each existing destination file before overwriting, appending a '~' by default. This can prevent accidental data loss during batch renames or moves.",
    "tags": [
      "mv",
      "backup",
      "safe"
    ]
  },
  {
    "id": "gnu-016",
    "pattern": "^rm\\s+.*-i.*$",
    "cmd": "rm",
    "severity": "tip",
    "hint": "Use '-i' for interactive prompts before each file deletion.",
    "detail": "'rm -i' asks for confirmation before deleting each file, reducing the risk of accidental removal. For directories, use '-I' for a single prompt if more than three files are being deleted.",
    "tags": [
      "rm",
      "interactive",
      "safe"
    ]
  },
  {
    "id": "gnu-017",
    "pattern": "^find\\s+.*-iname\\s+.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-iname' for case-insensitive filename matching.",
    "detail": "'-iname' matches files regardless of case, which is useful on case-sensitive filesystems like ext4. This helps avoid missing files due to capitalization differences.",
    "tags": [
      "find",
      "case",
      "search"
    ]
  },
  {
    "id": "gnu-018",
    "pattern": "^find\\s+.*-type\\s+f.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-type f' to restrict matches to regular files.",
    "detail": "'-type f' ensures only regular files are matched, excluding directories, symlinks, and device files. This reduces false positives in scripts that expect files only.",
    "tags": [
      "find",
      "type",
      "files"
    ]
  },
  {
    "id": "gnu-019",
    "pattern": "^find\\s+.*-mtime\\s+-?\\d+.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-mtime' to find files modified N days ago.",
    "detail": "'-mtime N' finds files modified exactly N*24 hours ago. Use '+N' for older, '-N' for newer. This is precise for backup scripts or cleanup jobs.",
    "tags": [
      "find",
      "mtime",
      "dates"
    ]
  },
  {
    "id": "gnu-020",
    "pattern": "^find\\s+.*-print0.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-print0' with 'xargs -0' for filenames with spaces.",
    "detail": "'-print0' outputs a null character after each filename, allowing 'xargs -0' to safely handle files with spaces, newlines, or special characters.",
    "tags": [
      "find",
      "xargs",
      "spaces"
    ]
  },
  {
    "id": "gnu-021",
    "pattern": "^xargs\\s+.*$",
    "cmd": "xargs",
    "severity": "warn",
    "hint": "Use 'xargs -0' with null-separated input to avoid splitting errors.",
    "detail": "Without '-0', xargs splits on whitespace, which can break for filenames with spaces or newlines. Pair with 'find ... -print0' for robust scripting.",
    "tags": [
      "xargs",
      "find",
      "spaces"
    ]
  },
  {
    "id": "gnu-022",
    "pattern": "^sort\\s+.*-u.*$",
    "cmd": "sort",
    "severity": "tip",
    "hint": "Use 'sort -u' to sort and remove duplicates in one step.",
    "detail": "'sort -u' combines sorting and uniqueness, saving a pipeline step compared to 'sort | uniq'. It's faster and avoids subtle issues with unsorted input to 'uniq'.",
    "tags": [
      "sort",
      "uniq",
      "performance"
    ]
  },
  {
    "id": "gnu-023",
    "pattern": "^uniq\\s+.*$",
    "cmd": "uniq",
    "severity": "warn",
    "hint": "Remember: 'uniq' only removes adjacent duplicates. Sort input first.",
    "detail": "'uniq' only removes consecutive duplicate lines. If input isn't sorted, duplicates may remain. Use 'sort | uniq' for global uniqueness.",
    "tags": [
      "uniq",
      "sort",
      "duplicates"
    ]
  },
  {
    "id": "gnu-024",
    "pattern": "^sort\\s+.*-k\\s+\\d+.*$",
    "cmd": "sort",
    "severity": "tip",
    "hint": "Use '-k N' to sort by the Nth field (column).",
    "detail": "'-k N' tells sort to use the Nth whitespace-delimited field as the sort key. For CSV, combine with '-t,' to set the delimiter.",
    "tags": [
      "sort",
      "fields",
      "columns"
    ]
  },
  {
    "id": "gnu-025",
    "pattern": "^sort\\s+.*-n.*$",
    "cmd": "sort",
    "severity": "tip",
    "hint": "Use '-n' for numeric sort; otherwise, sort is lexicographic.",
    "detail": "'sort -n' interprets numbers properly, so 10 comes after 2. Without '-n', '10' sorts before '2' due to string comparison.",
    "tags": [
      "sort",
      "numeric",
      "lexicographic"
    ]
  },
  {
    "id": "gnu-026",
    "pattern": "^cut\\s+.*-d\\s+[^ ]+\\s+-f\\s+\\d+.*$",
    "cmd": "cut",
    "severity": "tip",
    "hint": "Use '-d' to set delimiter and '-f' to select fields.",
    "detail": "'cut -d DELIM -f N' extracts the Nth field using the specified delimiter. For tab-delimited files, use '-d \"\\t\"'.",
    "tags": [
      "cut",
      "fields",
      "delimiter"
    ]
  },
  {
    "id": "gnu-027",
    "pattern": "^cut\\s+.*-c\\s+\\d+.*$",
    "cmd": "cut",
    "severity": "tip",
    "hint": "Use '-c' to select character positions, not fields.",
    "detail": "'cut -c N' extracts the Nth character of each line. Useful for fixed-width data, but not for delimited text. Beware of multi-byte characters.",
    "tags": [
      "cut",
      "characters",
      "fields"
    ]
  },
  {
    "id": "gnu-028",
    "pattern": "^paste\\s+.*$",
    "cmd": "paste",
    "severity": "tip",
    "hint": "Use 'paste' to merge lines from multiple files side by side.",
    "detail": "'paste' combines lines from each file into tab-separated columns. Use '-d' to specify a different delimiter, e.g., '-d ,'.",
    "tags": [
      "paste",
      "merge",
      "columns"
    ]
  },
  {
    "id": "gnu-029",
    "pattern": "^tr\\s+.*[A-Z].*[a-z].*$",
    "cmd": "tr",
    "severity": "tip",
    "hint": "Use 'tr A-Z a-z' to convert uppercase to lowercase.",
    "detail": "'tr' performs character-by-character translation. 'tr A-Z a-z' lowercases input. Be aware: locale can affect character ranges; use 'LC_ALL=C' for predictable results.",
    "tags": [
      "tr",
      "case",
      "locale"
    ]
  },
  {
    "id": "gnu-030",
    "pattern": "^tr\\s+.*-d.*$",
    "cmd": "tr",
    "severity": "tip",
    "hint": "Use 'tr -d' to delete characters from input.",
    "detail": "'tr -d' removes all occurrences of specified characters. For example, 'tr -d \"\\n\"' removes newlines. Does not support regex; only character sets.",
    "tags": [
      "tr",
      "delete",
      "characters"
    ]
  },
  {
    "id": "gnu-031",
    "pattern": "^wc\\s+.*$",
    "cmd": "wc",
    "severity": "tip",
    "hint": "Use 'wc -l' to count lines, 'wc -w' for words, 'wc -c' for bytes.",
    "detail": "'wc' defaults to all counts. Use specific flags to get only lines, words, or bytes, which is faster and easier to parse in scripts.",
    "tags": [
      "wc",
      "count",
      "lines"
    ]
  },
  {
    "id": "gnu-032",
    "pattern": "^head\\s+.*-n\\s+\\d+.*$",
    "cmd": "head",
    "severity": "tip",
    "hint": "Use 'head -n N' to show the first N lines of a file.",
    "detail": "'head -n N' is more portable than legacy syntax like 'head -N'. Negative values show all but the last N lines. Useful for previews.",
    "tags": [
      "head",
      "lines",
      "preview"
    ]
  },
  {
    "id": "gnu-033",
    "pattern": "^tail\\s+.*-f.*$",
    "cmd": "tail",
    "severity": "tip",
    "hint": "Use 'tail -F' to follow files even after rotation.",
    "detail": "'tail -f' follows file growth, but stops if the file is rotated or replaced. '-F' retries if the file disappears, making it better for logs.",
    "tags": [
      "tail",
      "follow",
      "logs"
    ]
  },
  {
    "id": "gnu-034",
    "pattern": "^tee\\s+.*$",
    "cmd": "tee",
    "severity": "tip",
    "hint": "Use 'tee' to write output to a file and stdout simultaneously.",
    "detail": "'tee' is useful in pipelines to log output while still passing it downstream. Use '-a' to append instead of overwrite.",
    "tags": [
      "tee",
      "output",
      "pipeline"
    ]
  },
  {
    "id": "gnu-035",
    "pattern": "^stat\\s+.*$",
    "cmd": "stat",
    "severity": "tip",
    "hint": "Use 'stat -c' to customize output format for scripting.",
    "detail": "'stat -c' allows you to specify a format string, e.g., '%s' for size, '%y' for modification time. This is more script-friendly than the default verbose output.",
    "tags": [
      "stat",
      "format",
      "scripting"
    ]
  },
  {
    "id": "gnu-036",
    "pattern": "^chmod\\s+777\\s+.*$",
    "cmd": "chmod",
    "severity": "danger",
    "hint": "Avoid 'chmod 777'; it grants all permissions to everyone.",
    "detail": "'chmod 777' makes files or directories world-writable and executable, which is a major security risk. Use the least permissive mode necessary, such as '755' for directories or '644' for files.",
    "tags": [
      "chmod",
      "permissions",
      "security"
    ]
  },
  {
    "id": "gnu-037",
    "pattern": "^chmod\\s+.*-R.*$",
    "cmd": "chmod",
    "severity": "warn",
    "hint": "Be careful with 'chmod -R'; it changes all files recursively.",
    "detail": "'chmod -R' applies permissions to all files and subdirectories. This can break scripts or expose sensitive files if used on the wrong path. Always verify the target directory.",
    "tags": [
      "chmod",
      "recursive",
      "permissions"
    ]
  },
  {
    "id": "gnu-038",
    "pattern": "^chown\\s+.*:.*$",
    "cmd": "chown",
    "severity": "tip",
    "hint": "Use 'chown user:group' to set both owner and group in one command.",
    "detail": "'chown user:group file' changes both owner and group. Omitting user or group leaves that attribute unchanged. Useful for batch ownership fixes.",
    "tags": [
      "chown",
      "ownership",
      "group"
    ]
  },
  {
    "id": "gnu-039",
    "pattern": "^chown\\s+.*-R.*$",
    "cmd": "chown",
    "severity": "warn",
    "hint": "Use 'chown -R' carefully; it changes ownership recursively.",
    "detail": "'chown -R' affects all files and subdirectories, which can break permissions or system functionality if run on system directories. Always double-check the path.",
    "tags": [
      "chown",
      "recursive",
      "ownership"
    ]
  },
  {
    "id": "gnu-040",
    "pattern": "^chgrp\\s+.*-R.*$",
    "cmd": "chgrp",
    "severity": "warn",
    "hint": "Be cautious with 'chgrp -R'; it changes group recursively.",
    "detail": "'chgrp -R' changes group ownership for all files and subdirectories. This can affect access control and group quotas. Use with care, especially on shared directories.",
    "tags": [
      "chgrp",
      "recursive",
      "group"
    ]
  },
  {
    "id": "gnu-041",
    "pattern": "^ln\\s+-s\\s+.*$",
    "cmd": "ln",
    "severity": "tip",
    "hint": "Use 'ln -s' for symlinks; check relative vs. absolute paths.",
    "detail": "'ln -s' creates symbolic links. Relative paths are resolved from the link's location, not the current directory. Use absolute paths for portability.",
    "tags": [
      "ln",
      "symlink",
      "paths"
    ]
  },
  {
    "id": "gnu-042",
    "pattern": "^ln\\s+.*$",
    "cmd": "ln",
    "severity": "tip",
    "hint": "Use 'ln' without '-s' to create hard links.",
    "detail": "Hard links point to the same inode and are indistinguishable from the original file. They cannot span filesystems or link to directories (except as root).",
    "tags": [
      "ln",
      "hardlink",
      "filesystem"
    ]
  },
  {
    "id": "gnu-043",
    "pattern": "^dd\\s+.*$",
    "cmd": "dd",
    "severity": "danger",
    "hint": "Be extremely careful with 'dd'; wrong 'of=' can destroy data.",
    "detail": "'dd' writes raw data to the specified output file or device. A typo in 'of=' can overwrite disks or partitions without warning. Always triple-check device names.",
    "tags": [
      "dd",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "gnu-044",
    "pattern": "^dd\\s+.*if=.*of=.*$",
    "cmd": "dd",
    "severity": "tip",
    "hint": "Use 'status=progress' to monitor 'dd' in real time.",
    "detail": "'status=progress' shows ongoing transfer stats, which is crucial for large copies. Without it, 'dd' is silent until completion.",
    "tags": [
      "dd",
      "progress",
      "monitoring"
    ]
  },
  {
    "id": "gnu-045",
    "pattern": "^dd\\s+.*bs=\\d+[KMG]?\\s+.*$",
    "cmd": "dd",
    "severity": "tip",
    "hint": "Set 'bs' (block size) for optimal speed; try 'bs=1M' for large files.",
    "detail": "Larger block sizes (e.g., 'bs=1M') reduce system call overhead and speed up large transfers. For small files, use smaller 'bs' to avoid memory waste.",
    "tags": [
      "dd",
      "performance",
      "blocksize"
    ]
  },
  {
    "id": "gnu-046",
    "pattern": "^split\\s+.*-b\\s+\\d+[KMG]?\\s+.*$",
    "cmd": "split",
    "severity": "tip",
    "hint": "Use 'split -b SIZE' to split files by byte size.",
    "detail": "'split -b' divides files into chunks of specified size (e.g., '100M'). Useful for transferring large files over media with size limits.",
    "tags": [
      "split",
      "filesize",
      "chunks"
    ]
  },
  {
    "id": "gnu-047",
    "pattern": "^split\\s+.*-l\\s+\\d+.*$",
    "cmd": "split",
    "severity": "tip",
    "hint": "Use 'split -l N' to split files by number of lines.",
    "detail": "'split -l N' creates output files with N lines each. Useful for processing large logs or datasets in parallel.",
    "tags": [
      "split",
      "lines",
      "chunks"
    ]
  },
  {
    "id": "gnu-048",
    "pattern": "^ls\\s+.*-1.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use 'ls -1' for one file per line, ideal for scripting.",
    "detail": "'ls -1' outputs each filename on a separate line, making it easier to parse in scripts or with tools like 'xargs'.",
    "tags": [
      "ls",
      "scripting",
      "output"
    ]
  },
  {
    "id": "gnu-049",
    "pattern": "^ls\\s+.*-A.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use 'ls -A' to list all except '.' and '..'.",
    "detail": "'ls -A' shows hidden files but omits '.' and '..', reducing clutter compared to 'ls -a'. Useful for seeing dotfiles without navigation entries.",
    "tags": [
      "ls",
      "hidden",
      "dotfiles"
    ]
  },
  {
    "id": "gnu-050",
    "pattern": "^ls\\s+.*-d\\s+\\*/.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use 'ls -d */' to list only directories.",
    "detail": "'ls -d */' lists directories in the current path, not their contents. Useful for quickly seeing directory names without file clutter.",
    "tags": [
      "ls",
      "directories",
      "listing"
    ]
  },
  {
    "id": "gnu-051",
    "pattern": "^ls\\s+.*--group-directories-first.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use '--group-directories-first' to list directories before files.",
    "detail": "This flag makes navigation easier by grouping directories at the top of the listing. Not all systems enable this by default.",
    "tags": [
      "ls",
      "directories",
      "navigation"
    ]
  },
  {
    "id": "gnu-052",
    "pattern": "^find\\s+.*-prune.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-prune' to exclude directories from 'find' traversal.",
    "detail": "'-prune' skips specified directories, improving performance and avoiding unwanted matches. Combine with '!' for exclusion logic.",
    "tags": [
      "find",
      "prune",
      "exclude"
    ]
  },
  {
    "id": "gnu-053",
    "pattern": "^find\\s+.*-empty.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-empty' to find empty files and directories.",
    "detail": "'-empty' matches files of zero size and directories with no entries. Useful for cleanup scripts or identifying unused space.",
    "tags": [
      "find",
      "empty",
      "cleanup"
    ]
  },
  {
    "id": "gnu-054",
    "pattern": "^find\\s+.*-size\\s+\\+?\\d+[ckMG]?\\s*.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-size' to find files by size, e.g., '-size +100M'.",
    "detail": "'-size' matches files of specified size. Use '+' for greater than, '-' for less than. Suffix with 'k', 'M', or 'G' for kilobytes, megabytes, or gigabytes.",
    "tags": [
      "find",
      "size",
      "files"
    ]
  },
  {
    "id": "gnu-055",
    "pattern": "^find\\s+.*-perm\\s+\\d+.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-perm' to find files with specific permissions.",
    "detail": "'-perm MODE' matches files with exact permissions. Use '/MODE' for any matching bits, '-MODE' for all specified bits set. Useful for finding world-writable files.",
    "tags": [
      "find",
      "permissions",
      "security"
    ]
  },
  {
    "id": "gnu-056",
    "pattern": "^find\\s+.*-user\\s+\\w+.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-user USER' to find files owned by a specific user.",
    "detail": "'-user USER' restricts matches to files owned by USER. Useful for quota checks, cleanup, or security audits.",
    "tags": [
      "find",
      "user",
      "ownership"
    ]
  },
  {
    "id": "gnu-057",
    "pattern": "^find\\s+.*-group\\s+\\w+.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-group GROUP' to find files owned by a specific group.",
    "detail": "'-group GROUP' restricts matches to files owned by GROUP. Useful for group-based cleanup or access control reviews.",
    "tags": [
      "find",
      "group",
      "ownership"
    ]
  },
  {
    "id": "gnu-058",
    "pattern": "^find\\s+.*-ls.*$",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use '-ls' to display detailed file info directly from 'find'.",
    "detail": "'-ls' outputs file details similar to 'ls -dils', including inode, size, and permissions. Useful for reporting or auditing without extra commands.",
    "tags": [
      "find",
      "ls",
      "details"
    ]
  },
  {
    "id": "gnu-059",
    "pattern": "^ls\\s+.*-h.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use '-h' for human-readable sizes (KB, MB, GB).",
    "detail": "'ls -lh' displays file sizes in human-friendly units, making it easier to spot large files compared to raw byte counts.",
    "tags": [
      "ls",
      "human-readable",
      "sizes"
    ]
  },
  {
    "id": "gnu-060",
    "pattern": "^ls\\s+.*-Z.*$",
    "cmd": "ls",
    "severity": "tip",
    "hint": "Use '-Z' to show SELinux security context labels.",
    "detail": "'ls -Z' displays SELinux labels for each file, which is essential for troubleshooting access issues on SELinux-enabled systems.",
    "tags": [
      "ls",
      "selinux",
      "security"
    ]
  },
  {
    "id": "text-001",
    "pattern": "^sed\\s+-i\\s+[^'\"].*",
    "cmd": "sed",
    "severity": "danger",
    "hint": "Always use -i'' or -i '' with sed -i for portability.",
    "detail": "GNU sed allows 'sed -i' without a backup extension, but BSD/macOS sed requires an argument (e.g., -i ''). Omitting this can delete data or fail silently on macOS. Always specify the backup extension explicitly for cross-platform scripts.",
    "tags": [
      "sed",
      "inplace",
      "cross-platform",
      "danger"
    ]
  },
  {
    "id": "text-002",
    "pattern": "^grep\\s+.*\\s--color=always",
    "cmd": "grep",
    "severity": "warn",
    "hint": "Use --color=auto instead of always to avoid polluting pipes.",
    "detail": "The --color=always flag forces ANSI color codes even when output is piped, which can break downstream tools or scripts expecting plain text. Use --color=auto to emit color only when outputting to a terminal.",
    "tags": [
      "grep",
      "color",
      "pipes",
      "warn"
    ]
  },
  {
    "id": "text-003",
    "pattern": "^awk\\s+.*\\$NF",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use awk '{print $(NF-1)}' for the second-to-last field.",
    "detail": "$NF prints the last field, but for penultimate fields use $(NF-1). This is useful for variable-width data where field count is not fixed. Remember, NF is the number of fields in the current record.",
    "tags": [
      "awk",
      "fields",
      "tip"
    ]
  },
  {
    "id": "text-004",
    "pattern": "^grep\\s+.*\\s-E\\s+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use egrep instead of grep -E for extended regex.",
    "detail": "'egrep' is equivalent to 'grep -E', but using the explicit flag is more portable and future-proof, as egrep is deprecated in some distributions. Prefer 'grep -E' for scripts.",
    "tags": [
      "grep",
      "egrep",
      "regex",
      "tip"
    ]
  },
  {
    "id": "text-005",
    "pattern": "^cut\\s+-f\\d+\\s+",
    "cmd": "cut",
    "severity": "warn",
    "hint": "Always specify -d with cut if the delimiter isn't TAB.",
    "detail": "By default, cut uses TAB as the field delimiter. If your data is comma- or space-separated, omitting -d can silently produce incorrect output. Always specify -d to match your data format.",
    "tags": [
      "cut",
      "delimiter",
      "warn"
    ]
  },
  {
    "id": "text-006",
    "pattern": "^tr\\s+.*\\s+[:upper:]\\s+[:lower:]",
    "cmd": "tr",
    "severity": "tip",
    "hint": "Use tr '[:upper:]' '[:lower:]' for locale-aware case conversion.",
    "detail": "Using character classes like '[:upper:]' and '[:lower:]' with tr ensures correct case conversion across locales, unlike hardcoding A-Z/a-z which may miss non-ASCII characters.",
    "tags": [
      "tr",
      "case",
      "locale",
      "tip"
    ]
  },
  {
    "id": "text-007",
    "pattern": "^sed\\s+.*\\s-s\\s+",
    "cmd": "sed",
    "severity": "tip",
    "hint": "Use -s to process each file separately with sed.",
    "detail": "The -s flag tells sed to treat each input file as a separate stream, resetting line numbers and pattern space. This is crucial when using scripts that depend on file boundaries.",
    "tags": [
      "sed",
      "files",
      "tip"
    ]
  },
  {
    "id": "text-008",
    "pattern": "^grep\\s+.*\\s-i\\s+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use -i for case-insensitive search with grep.",
    "detail": "The -i flag makes grep ignore case distinctions, which is essential for matching patterns regardless of capitalization. This is especially useful for user input or logs with inconsistent casing.",
    "tags": [
      "grep",
      "case",
      "tip"
    ]
  },
  {
    "id": "text-009",
    "pattern": "^awk\\s+.*\\s-F\\s+\"\\s*\\t\\s*\"",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use -F'\\t' for tab-delimited data in awk.",
    "detail": "Specifying -F'\\t' ensures awk splits fields on tabs, not spaces. This is critical for files like TSVs or outputs from 'cut' and 'column'.",
    "tags": [
      "awk",
      "delimiter",
      "tip"
    ]
  },
  {
    "id": "text-010",
    "pattern": "^grep\\s+.*\\s-r\\s+",
    "cmd": "grep",
    "severity": "upgrade",
    "hint": "Use ripgrep (rg) for faster recursive search than grep -r.",
    "detail": "ripgrep (rg) is significantly faster than grep -r, especially on large codebases, due to optimized file traversal and parallelism. It also respects .gitignore by default.",
    "tags": [
      "grep",
      "ripgrep",
      "performance",
      "upgrade"
    ]
  },
  {
    "id": "text-011",
    "pattern": "^sed\\s+.*\\s-e\\s+",
    "cmd": "sed",
    "severity": "tip",
    "hint": "Chain multiple -e scripts in sed for complex edits.",
    "detail": "Each -e flag allows you to specify a separate editing command. This is more readable and maintainable than combining multiple expressions with semicolons.",
    "tags": [
      "sed",
      "scripts",
      "tip"
    ]
  },
  {
    "id": "text-012",
    "pattern": "^awk\\s+.*\\s-v\\s+",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use -v to pass shell variables into awk scripts.",
    "detail": "The -v var=value flag allows you to safely pass shell variables into awk, avoiding quoting issues and injection vulnerabilities. This is preferable to using ENVIRON or string interpolation.",
    "tags": [
      "awk",
      "variables",
      "tip"
    ]
  },
  {
    "id": "text-013",
    "pattern": "^grep\\s+.*\\s--exclude-dir=",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --exclude-dir to skip directories in recursive grep.",
    "detail": "The --exclude-dir flag prevents grep from searching specified directories, improving performance and avoiding irrelevant matches. Useful for skipping .git, node_modules, or build directories.",
    "tags": [
      "grep",
      "performance",
      "tip"
    ]
  },
  {
    "id": "text-014",
    "pattern": "^cut\\s+-c\\s+\\d+-\\d+",
    "cmd": "cut",
    "severity": "warn",
    "hint": "cut -c operates on bytes, not characters; beware with UTF-8.",
    "detail": "The -c flag in cut selects byte positions, not Unicode characters. This can corrupt multibyte UTF-8 data, splitting characters. Use tools like awk or iconv for safe character-wise processing.",
    "tags": [
      "cut",
      "utf8",
      "warn"
    ]
  },
  {
    "id": "text-015",
    "pattern": "^jq\\s+.*\\s-r\\s+",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use -r to output raw strings from jq, not JSON-quoted.",
    "detail": "The -r (raw output) flag strips JSON quotes and escapes, making jq output suitable for shell scripts or piping into other tools. Without -r, jq emits JSON-encoded strings.",
    "tags": [
      "jq",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-016",
    "pattern": "^sed\\s+.*\\s-n\\s+p",
    "cmd": "sed",
    "severity": "tip",
    "hint": "Use -n with p to suppress default output in sed.",
    "detail": "The -n flag tells sed not to print lines by default. Use this with the p command to print only matching lines, avoiding duplicate output from implicit and explicit prints.",
    "tags": [
      "sed",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-017",
    "pattern": "^grep\\s+.*\\s--binary-files=without-match",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --binary-files=without-match to skip binaries in grep.",
    "detail": "This flag tells grep to assume binary files do not match, preventing binary output in the terminal and speeding up searches in mixed file trees.",
    "tags": [
      "grep",
      "binary",
      "tip"
    ]
  },
  {
    "id": "text-018",
    "pattern": "^awk\\s+.*\\s-F\\s+\"\\s*\\|\\s*\"",
    "cmd": "awk",
    "severity": "warn",
    "hint": "Escape | in awk -F: use -F'\\|' for literal pipe delimiter.",
    "detail": "In awk, -F'|' sets the field separator to a regex, so unescaped | means alternation. Use -F'\\|' to match a literal pipe character.",
    "tags": [
      "awk",
      "delimiter",
      "warn"
    ]
  },
  {
    "id": "text-019",
    "pattern": "^grep\\s+.*\\s--exclude=\\S+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --exclude to skip files by pattern in grep.",
    "detail": "The --exclude flag allows you to ignore files matching a glob pattern during recursive searches, improving speed and relevance. Combine with --exclude-dir for directories.",
    "tags": [
      "grep",
      "performance",
      "tip"
    ]
  },
  {
    "id": "text-020",
    "pattern": "^sed\\s+.*\\s-g\\s+",
    "cmd": "sed",
    "severity": "tip",
    "hint": "Use the g flag in sed s///g to replace all matches per line.",
    "detail": "Without the g flag, sed's s/// substitution replaces only the first match per line. Adding g ensures all occurrences are replaced.",
    "tags": [
      "sed",
      "replace",
      "tip"
    ]
  },
  {
    "id": "text-021",
    "pattern": "^jq\\s+.*\\s--slurp",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use --slurp to read all input as a single array in jq.",
    "detail": "The --slurp flag collects all input JSON objects into an array, enabling operations across the entire dataset, such as aggregation or sorting.",
    "tags": [
      "jq",
      "input",
      "tip"
    ]
  },
  {
    "id": "text-022",
    "pattern": "^grep\\s+.*\\s-z\\s+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use -z to search across NUL-separated records with grep.",
    "detail": "The -z flag treats input as NUL-separated, not newline-separated. This is essential when processing output from find -print0 or dealing with filenames containing newlines.",
    "tags": [
      "grep",
      "null",
      "tip"
    ]
  },
  {
    "id": "text-023",
    "pattern": "^awk\\s+.*\\s+ORS=",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Set ORS to control output record separator in awk.",
    "detail": "The ORS variable defines the output record separator. Setting ORS=\"\" removes newlines between records, useful for compact output or custom formatting.",
    "tags": [
      "awk",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-024",
    "pattern": "^column\\s+.*\\s-t\\s+",
    "cmd": "column",
    "severity": "tip",
    "hint": "Use -t to align columns into a table with column.",
    "detail": "The -t flag parses whitespace-delimited input and prints a neatly aligned table. This is ideal for improving readability of command output or logs.",
    "tags": [
      "column",
      "formatting",
      "tip"
    ]
  },
  {
    "id": "text-025",
    "pattern": "^jq\\s+.*\\s-c\\s+",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use -c for compact output in jq (one JSON object per line).",
    "detail": "The -c flag outputs each JSON object on a single line, making it easier to process with line-oriented tools like grep or awk.",
    "tags": [
      "jq",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-026",
    "pattern": "^grep\\s+.*\\s-P\\s+",
    "cmd": "grep",
    "severity": "warn",
    "hint": "grep -P (Perl regex) is not supported on all platforms.",
    "detail": "The -P flag enables Perl-compatible regex, but is not available in all grep builds (notably macOS/BSD). Scripts using -P may fail silently or with errors on those systems.",
    "tags": [
      "grep",
      "regex",
      "warn"
    ]
  },
  {
    "id": "text-027",
    "pattern": "^sed\\s+.*\\s-r\\s+",
    "cmd": "sed",
    "severity": "warn",
    "hint": "sed -r (extended regex) is not portable; use -E for BSD/macOS.",
    "detail": "GNU sed uses -r for extended regex, but BSD/macOS sed uses -E. For cross-platform scripts, prefer -E or detect the platform.",
    "tags": [
      "sed",
      "regex",
      "warn"
    ]
  },
  {
    "id": "text-028",
    "pattern": "^yq\\s+.*\\s-e\\s+",
    "cmd": "yq",
    "severity": "tip",
    "hint": "Use -e to exit non-zero if the yq expression returns false/null.",
    "detail": "The -e flag causes yq to exit with a non-zero status if the result is false or null, enabling robust error handling in scripts.",
    "tags": [
      "yq",
      "exit",
      "tip"
    ]
  },
  {
    "id": "text-029",
    "pattern": "^awk\\s+.*\\s+BEGIN\\s*\\{",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use BEGIN{...} in awk for initialization before input.",
    "detail": "The BEGIN block runs before any input is read, ideal for setting FS, OFS, or initializing variables. It executes only once per awk invocation.",
    "tags": [
      "awk",
      "init",
      "tip"
    ]
  },
  {
    "id": "text-030",
    "pattern": "^grep\\s+.*\\s-f\\s+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use -f to read patterns from a file with grep.",
    "detail": "The -f flag allows grep to read search patterns from a file, supporting complex or multi-line patterns without shell quoting issues.",
    "tags": [
      "grep",
      "patterns",
      "tip"
    ]
  },
  {
    "id": "text-031",
    "pattern": "^jq\\s+.*\\s--arg\\s+",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use --arg to safely pass shell variables into jq.",
    "detail": "--arg assigns a shell variable to a jq variable, avoiding injection and quoting problems. This is safer than interpolating variables directly into jq expressions.",
    "tags": [
      "jq",
      "variables",
      "tip"
    ]
  },
  {
    "id": "text-032",
    "pattern": "^sed\\s+.*\\s-.*w\\s+",
    "cmd": "sed",
    "severity": "tip",
    "hint": "Use the w command in sed to write output to a file.",
    "detail": "The w command appends matching lines to a file, allowing selective output without redirecting the entire stream. Useful for extracting data during in-place edits.",
    "tags": [
      "sed",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-033",
    "pattern": "^awk\\s+.*\\s+ORS=\"\"",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Set ORS=\"\" to print all output on one line in awk.",
    "detail": "Setting ORS (output record separator) to an empty string removes newlines between records, useful for producing compact output or custom formatting.",
    "tags": [
      "awk",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-034",
    "pattern": "^grep\\s+.*\\s-q\\s+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use -q for silent grep (exit code only, no output).",
    "detail": "The -q flag suppresses all output, making grep suitable for conditional logic in scripts based on its exit status.",
    "tags": [
      "grep",
      "quiet",
      "tip"
    ]
  },
  {
    "id": "text-035",
    "pattern": "^awk\\s+.*\\s+NF",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use 'awk 'NF'' to filter out blank lines.",
    "detail": "The built-in variable NF (number of fields) is zero for blank lines. 'awk NF' prints only non-empty lines, a concise alternative to grep -v '^$'.",
    "tags": [
      "awk",
      "filter",
      "tip"
    ]
  },
  {
    "id": "text-036",
    "pattern": "^jq\\s+.*\\s--sort-keys",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use --sort-keys to output JSON objects with sorted keys.",
    "detail": "The --sort-keys flag ensures consistent key ordering in output, which is useful for diffing or version control of JSON files.",
    "tags": [
      "jq",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-037",
    "pattern": "^grep\\s+.*\\s--line-buffered",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --line-buffered for real-time grep output in pipes.",
    "detail": "By default, grep buffers output, which can delay results in pipelines. --line-buffered flushes output after every line, improving responsiveness for monitoring or tailing logs.",
    "tags": [
      "grep",
      "buffering",
      "tip"
    ]
  },
  {
    "id": "text-038",
    "pattern": "^cut\\s+-d\\s+\"\\s*\\t\\s*\"",
    "cmd": "cut",
    "severity": "tip",
    "hint": "Use -d$'\\t' for literal tab delimiter with cut.",
    "detail": "In bash, -d$'\\t' sets the delimiter to a literal tab. Quoting '\\t' as a string passes backslash-t, not a real tab, which can silently fail.",
    "tags": [
      "cut",
      "delimiter",
      "tip"
    ]
  },
  {
    "id": "text-039",
    "pattern": "^tr\\s+.*\\s-d\\s+",
    "cmd": "tr",
    "severity": "tip",
    "hint": "Use tr -d to delete characters from input.",
    "detail": "The -d flag removes all occurrences of specified characters from the input stream, useful for stripping unwanted bytes or whitespace.",
    "tags": [
      "tr",
      "delete",
      "tip"
    ]
  },
  {
    "id": "text-040",
    "pattern": "^awk\\s+.*\\s+OFS=",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Set OFS to control output field separator in awk.",
    "detail": "OFS (output field separator) determines how fields are joined in output. Setting OFS=',' produces CSV-style output, for example.",
    "tags": [
      "awk",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-041",
    "pattern": "^datamash\\s+.*\\s-groupby\\s+",
    "cmd": "datamash",
    "severity": "tip",
    "hint": "Use groupby in datamash for grouped aggregations.",
    "detail": "The groupby operation allows datamash to compute statistics per group, similar to SQL's GROUP BY. Input must be sorted by the group key.",
    "tags": [
      "datamash",
      "groupby",
      "tip"
    ]
  },
  {
    "id": "text-042",
    "pattern": "^miller\\s+.*\\s-csv\\s+",
    "cmd": "miller",
    "severity": "upgrade",
    "hint": "Use Miller (mlr) for high-performance CSV/TSV/JSON processing.",
    "detail": "Miller (mlr) is a modern, streaming tool for manipulating structured text formats, outperforming awk/sed for CSV/TSV/JSON. It supports rich field selection, transformations, and statistics.",
    "tags": [
      "miller",
      "csv",
      "upgrade"
    ]
  },
  {
    "id": "text-043",
    "pattern": "^grep\\s+.*\\s--null",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --null to output NUL-separated filenames in grep.",
    "detail": "The --null flag outputs a NUL character after each filename, making grep output safe for filenames containing spaces or newlines. Useful with xargs -0.",
    "tags": [
      "grep",
      "null",
      "tip"
    ]
  },
  {
    "id": "text-044",
    "pattern": "^awk\\s+.*\\s+FS=\"\\s*\\t\\s*\"",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Set FS=\"\\t\" for tab-delimited input in awk.",
    "detail": "Setting FS (field separator) to '\\t' ensures correct parsing of tab-separated files, especially when input contains spaces within fields.",
    "tags": [
      "awk",
      "delimiter",
      "tip"
    ]
  },
  {
    "id": "text-045",
    "pattern": "^jq\\s+.*\\s--compact-output",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use --compact-output for single-line JSON in jq.",
    "detail": "The --compact-output flag is equivalent to -c, emitting each JSON object on one line. This is ideal for streaming or diffing JSON.",
    "tags": [
      "jq",
      "output",
      "tip"
    ]
  },
  {
    "id": "text-046",
    "pattern": "^yq\\s+.*\\s--inplace",
    "cmd": "yq",
    "severity": "tip",
    "hint": "Use --inplace to modify YAML files directly with yq.",
    "detail": "The --inplace flag edits files in place, similar to sed -i. Always back up important files before using in-place edits to prevent accidental data loss.",
    "tags": [
      "yq",
      "inplace",
      "tip"
    ]
  },
  {
    "id": "text-047",
    "pattern": "^grep\\s+.*\\s--files-without-match",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --files-without-match to list files with no matches.",
    "detail": "This flag lists only the filenames that do not contain the search pattern, useful for finding missing content or verifying exclusions.",
    "tags": [
      "grep",
      "files",
      "tip"
    ]
  },
  {
    "id": "text-048",
    "pattern": "^awk\\s+.*\\s+ENVIRON\\[",
    "cmd": "awk",
    "severity": "tip",
    "hint": "Use ENVIRON[] in awk to access environment variables.",
    "detail": "The ENVIRON associative array exposes environment variables inside awk scripts, enabling dynamic behavior based on the shell environment.",
    "tags": [
      "awk",
      "environment",
      "tip"
    ]
  },
  {
    "id": "text-049",
    "pattern": "^jq\\s+.*\\s--from-file",
    "cmd": "jq",
    "severity": "tip",
    "hint": "Use --from-file to load jq filters from a file.",
    "detail": "The --from-file flag allows complex jq filters to be stored and reused from external files, improving maintainability and avoiding shell quoting issues.",
    "tags": [
      "jq",
      "filters",
      "tip"
    ]
  },
  {
    "id": "text-050",
    "pattern": "^grep\\s+.*\\s--context=\\d+",
    "cmd": "grep",
    "severity": "tip",
    "hint": "Use --context=N to show N lines before and after matches.",
    "detail": "The --context flag prints N lines of leading and trailing context around each match, aiding in log analysis and debugging.",
    "tags": [
      "grep",
      "context",
      "tip"
    ]
  },
  {
    "id": "archive-001",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+/$",
    "cmd": "tar",
    "severity": "danger",
    "hint": "Avoid archiving root (/); this can destroy your system on extraction.",
    "detail": "Archiving '/' with 'tar -cf' creates an archive of the entire filesystem, including /dev, /proc, and /sys. Extracting such an archive with root privileges can overwrite critical system files, leading to irreversible damage. Always specify precise directories.",
    "tags": [
      "tar",
      "filesystem",
      "danger"
    ]
  },
  {
    "id": "archive-002",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+-C\\s+/",
    "cmd": "tar",
    "severity": "danger",
    "hint": "Extracting to / can overwrite system files. Use a safe target directory.",
    "detail": "Using 'tar -xvf <archive> -C /' as root can overwrite system binaries and configuration files, potentially rendering the system unbootable. Always extract archives to a non-root directory unless you are absolutely certain of the archive's contents.",
    "tags": [
      "tar",
      "extraction",
      "danger"
    ]
  },
  {
    "id": "archive-003",
    "pattern": "^tar\\s+-czf\\s+[^\\s]+\\s+.*",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Add -I pigz for much faster gzip compression on multicore CPUs.",
    "detail": "The default 'tar -czf' uses single-threaded gzip, which is slow on modern CPUs. Using 'tar -I pigz' leverages parallel compression, significantly speeding up the process. Ensure pigz is installed for this option.",
    "tags": [
      "tar",
      "performance",
      "gzip",
      "pigz"
    ]
  },
  {
    "id": "archive-004",
    "pattern": "^gzip\\s+-d\\s+[^\\s]+\\.gz",
    "cmd": "gzip",
    "severity": "warn",
    "hint": "gzip -d deletes the original .gz file after decompression.",
    "detail": "By default, 'gzip -d' decompresses and removes the .gz file. If you need to keep the compressed file, use 'gzip -dc' to output to stdout or copy the file first. This behavior is often overlooked and can lead to accidental data loss.",
    "tags": [
      "gzip",
      "decompression",
      "warn"
    ]
  },
  {
    "id": "archive-005",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--exclude=.*",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use multiple --exclude flags for complex patterns, not comma-separated.",
    "detail": "Each '--exclude' flag in tar only takes a single pattern. Comma-separated values are not recognized as multiple patterns and will be interpreted literally. Use repeated '--exclude' for each pattern to ensure correct exclusions.",
    "tags": [
      "tar",
      "exclude",
      "patterns"
    ]
  },
  {
    "id": "archive-006",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+--overwrite",
    "cmd": "tar",
    "severity": "warn",
    "hint": "Using --overwrite can silently replace existing files.",
    "detail": "'tar --overwrite' replaces files in the destination without prompting, which can lead to silent data loss if files differ. Consider using '--keep-old-files' to avoid overwriting or extract to a new directory for safety.",
    "tags": [
      "tar",
      "overwrite",
      "warn"
    ]
  },
  {
    "id": "archive-008",
    "pattern": "^bzip2\\s+-d\\s+[^\\s]+\\.bz2",
    "cmd": "bzip2",
    "severity": "warn",
    "hint": "bzip2 -d deletes the original .bz2 file after decompressing.",
    "detail": "Like gzip, 'bzip2 -d' removes the compressed file after decompression. To retain the original, use 'bzip2 -dc' to output to stdout or copy the file before decompressing.",
    "tags": [
      "bzip2",
      "decompression",
      "warn"
    ]
  },
  {
    "id": "archive-009",
    "pattern": "^tar\\s+-Jcf?\\s+[^\\s]+\\s+.*",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use -I pxz for parallel xz compression; it's much faster than -J.",
    "detail": "'tar -J' uses single-threaded xz, which is slow for large archives. 'tar -I pxz' uses all CPU cores for parallel compression, greatly reducing archive time. pxz must be installed separately.",
    "tags": [
      "tar",
      "xz",
      "performance",
      "pxz"
    ]
  },
  {
    "id": "archive-010",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+--strip-components=\\d+",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --strip-components=N to remove leading path elements on extraction.",
    "detail": "'--strip-components=N' removes N leading directories from file paths in the archive. This is useful for flattening directory structures or extracting only the files, but be careful not to strip too many components, which can result in missing files.",
    "tags": [
      "tar",
      "extraction",
      "paths"
    ]
  },
  {
    "id": "archive-011",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--numeric-owner",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --numeric-owner to preserve numeric UID/GID, not names.",
    "detail": "'--numeric-owner' stores user and group IDs instead of names. This is crucial when moving archives between systems with different user databases, ensuring correct ownership on extraction.",
    "tags": [
      "tar",
      "ownership",
      "backup"
    ]
  },
  {
    "id": "archive-012",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+--no-same-owner",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --no-same-owner when extracting as non-root to avoid errors.",
    "detail": "Without '--no-same-owner', tar tries to set file ownership to the original values, which fails for non-root users and can produce errors. This flag tells tar to use the current user's ownership instead.",
    "tags": [
      "tar",
      "ownership",
      "extraction"
    ]
  },
  {
    "id": "archive-013",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--atime-preserve",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --atime-preserve=system to avoid breaking backup tools.",
    "detail": "'--atime-preserve' can interfere with backup systems that rely on access times. '--atime-preserve=system' only preserves atime if supported, avoiding errors on filesystems that don't support it.",
    "tags": [
      "tar",
      "atime",
      "backup"
    ]
  },
  {
    "id": "archive-014",
    "pattern": "^tar\\s+-czf\\s+[^\\s]+\\s+--remove-files",
    "cmd": "tar",
    "severity": "danger",
    "hint": "tar --remove-files deletes source files after archiving.",
    "detail": "The '--remove-files' flag deletes each file after successfully adding it to the archive. If the archive operation fails partway, some files may be lost. Use with caution and always verify the archive before removing source files.",
    "tags": [
      "tar",
      "remove-files",
      "danger"
    ]
  },
  {
    "id": "archive-015",
    "pattern": "^gzip\\s+-[0-9]\\s+[^\\s]+",
    "cmd": "gzip",
    "severity": "tip",
    "hint": "Use gzip -1 for fastest or -9 for best compression.",
    "detail": "The compression level for gzip ranges from -1 (fastest, least compression) to -9 (slowest, best compression). The default is -6. Adjust the level based on your needs for speed vs. archive size.",
    "tags": [
      "gzip",
      "compression",
      "performance"
    ]
  },
  {
    "id": "archive-016",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--listed-incremental=.*",
    "cmd": "tar",
    "severity": "warn",
    "hint": "Incremental backups require consistent snapshot files.",
    "detail": "'--listed-incremental' creates incremental backups using a snapshot file. If the snapshot file is lost or corrupted, future incrementals may fail or miss changes. Always back up the snapshot file alongside your archives.",
    "tags": [
      "tar",
      "incremental",
      "backup",
      "warn"
    ]
  },
  {
    "id": "archive-017",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--no-same-permissions",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --no-same-permissions to extract files with current umask.",
    "detail": "'--no-same-permissions' tells tar to apply the current user's umask when extracting files, rather than preserving the original permissions. This is useful for restoring files to a new environment with different security requirements.",
    "tags": [
      "tar",
      "permissions",
      "umask"
    ]
  },
  {
    "id": "archive-018",
    "pattern": "^zip\\s+-r\\s+[^\\s]+\\s+.*",
    "cmd": "zip",
    "severity": "tip",
    "hint": "Add -9 for best compression or -0 for fastest with zip.",
    "detail": "'zip -r' recursively adds files, but the default compression is moderate. Use '-9' for maximum compression or '-0' for no compression (store only). This can significantly affect archive size and speed.",
    "tags": [
      "zip",
      "compression",
      "performance"
    ]
  },
  {
    "id": "archive-019",
    "pattern": "^unzip\\s+[^\\s]+\\s+-d\\s+/",
    "cmd": "unzip",
    "severity": "danger",
    "hint": "Extracting to / can overwrite system files. Use a safe directory.",
    "detail": "Unzipping archives directly to the root directory can overwrite critical system files and compromise system integrity. Always extract to a dedicated directory and review contents before moving files.",
    "tags": [
      "unzip",
      "extraction",
      "danger"
    ]
  },
  {
    "id": "archive-020",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--dereference",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --dereference to archive the target of symlinks, not the links.",
    "detail": "With '--dereference', tar archives the files symlinks point to, not the symlinks themselves. This is useful for creating complete backups, but be aware it can result in duplicate files if multiple symlinks point to the same target.",
    "tags": [
      "tar",
      "symlink",
      "backup"
    ]
  },
  {
    "id": "archive-021",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+--keep-old-files",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --keep-old-files to prevent overwriting existing files.",
    "detail": "'--keep-old-files' skips extraction of files that already exist, preserving the existing versions. This is safer than '--overwrite', especially when extracting archives from untrusted sources.",
    "tags": [
      "tar",
      "extraction",
      "files"
    ]
  },
  {
    "id": "archive-022",
    "pattern": "^lz4\\s+[^\\s]+",
    "cmd": "lz4",
    "severity": "upgrade",
    "hint": "lz4 is extremely fast; use for large data, logs, or backups.",
    "detail": "lz4 offers much faster compression and decompression than gzip or bzip2, with a reasonable compression ratio. It's ideal for large datasets, logs, or backup pipelines where speed is critical.",
    "tags": [
      "lz4",
      "compression",
      "upgrade"
    ]
  },
  {
    "id": "archive-023",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--one-file-system",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --one-file-system to avoid crossing filesystem boundaries.",
    "detail": "'--one-file-system' prevents tar from archiving files on other filesystems (e.g., NFS mounts or external drives). This is essential for focused backups and avoiding unexpected data in your archives.",
    "tags": [
      "tar",
      "filesystem",
      "backup"
    ]
  },
  {
    "id": "archive-024",
    "pattern": "^tar\\s+-xvf\\s+[^\\s]+\\s+--overwrite-dir",
    "cmd": "tar",
    "severity": "warn",
    "hint": "--overwrite-dir can change permissions on existing directories.",
    "detail": "'--overwrite-dir' causes tar to replace the permissions and ownership of existing directories with those stored in the archive. This can unintentionally weaken security or break applications relying on specific permissions.",
    "tags": [
      "tar",
      "permissions",
      "warn"
    ]
  },
  {
    "id": "archive-025",
    "pattern": "^7z\\s+x\\s+[^\\s]+",
    "cmd": "7z",
    "severity": "tip",
    "hint": "7z x preserves directory structure; use e to extract flat files.",
    "detail": "'7z x' extracts files with their full paths, recreating the directory tree. Use '7z e' to extract all files to the current directory without directories. This distinction is important for scripting and automation.",
    "tags": [
      "7z",
      "extraction",
      "paths"
    ]
  },
  {
    "id": "archive-026",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--ignore-failed-read",
    "cmd": "tar",
    "severity": "warn",
    "hint": "--ignore-failed-read skips unreadable files without error.",
    "detail": "With '--ignore-failed-read', tar silently skips files it can't read, which may result in incomplete backups. Always review tar's output or use '--warning=all' to catch missing files.",
    "tags": [
      "tar",
      "backup",
      "warn"
    ]
  },
  {
    "id": "archive-027",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--use-compress-program=([^\\s]+)",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --use-compress-program for custom compressors like zstd or lz4.",
    "detail": "'--use-compress-program' lets you specify any compression tool, e.g., 'tar --use-compress-program=zstd'. This enables cutting-edge compression algorithms not natively supported by tar.",
    "tags": [
      "tar",
      "compression",
      "custom"
    ]
  },
  {
    "id": "archive-028",
    "pattern": "^pigz\\s+-d\\s+[^\\s]+\\.gz",
    "cmd": "pigz",
    "severity": "tip",
    "hint": "pigz -d decompresses in parallel, much faster than gzip -d.",
    "detail": "pigz is a parallel implementation of gzip. Use 'pigz -d' for rapid decompression of large .gz files, especially on multicore systems. The interface is compatible with gzip.",
    "tags": [
      "pigz",
      "gzip",
      "performance"
    ]
  },
  {
    "id": "archive-029",
    "pattern": "^tar\\s+-cf\\s+[^\\s]+\\s+--no-recursion",
    "cmd": "tar",
    "severity": "tip",
    "hint": "Use --no-recursion to archive only listed directories, not contents.",
    "detail": "'--no-recursion' archives only the directory entries themselves, not their contents. This is useful for creating placeholder directory structures or when you want to avoid deep trees.",
    "tags": [
      "tar",
      "directories",
      "recursion"
    ]
  },
  {
    "id": "archive-030",
    "pattern": "^xz\\s+-d\\s+[^\\s]+\\.xz",
    "cmd": "xz",
    "severity": "warn",
    "hint": "xz -d deletes the original .xz file after decompression.",
    "detail": "Like gzip and bzip2, 'xz -d' removes the compressed file after decompressing. Use 'xz -dc' to keep the original, or copy the file first to avoid accidental data loss.",
    "tags": [
      "xz",
      "decompression",
      "warn"
    ]
  },
  {
    "id": "sysadmin-001",
    "pattern": "^systemctl\\s+restart\\s+.*",
    "cmd": "systemctl",
    "severity": "warn",
    "hint": "Use --no-block for non-blocking restarts in scripts.",
    "detail": "By default, 'systemctl restart' blocks until the unit is fully restarted. In automation or scripts, this can cause unexpected delays. Adding --no-block lets the command return immediately, and the restart continues in the background.",
    "tags": [
      "systemctl",
      "performance",
      "automation"
    ]
  },
  {
    "id": "sysadmin-002",
    "pattern": "^systemctl\\s+stop\\s+.*",
    "cmd": "systemctl",
    "severity": "warn",
    "hint": "Check dependencies; stopping units may halt critical services.",
    "detail": "Stopping a unit with systemctl can also stop dependent units due to dependency chains defined in unit files. Always review dependencies with 'systemctl list-dependencies <unit>' before stopping to avoid unintended outages.",
    "tags": [
      "systemctl",
      "dependencies",
      "service-management"
    ]
  },
  {
    "id": "sysadmin-003",
    "pattern": "^systemctl\\s+enable\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use --now to enable and start the service in one step.",
    "detail": "The --now flag combines enabling a service at boot and starting it immediately. This reduces the risk of forgetting to start the service after enabling, which is a common oversight.",
    "tags": [
      "systemctl",
      "service-management",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-004",
    "pattern": "^systemctl\\s+disable\\s+.*",
    "cmd": "systemctl",
    "severity": "warn",
    "hint": "Use --now to stop and disable the service together.",
    "detail": "Disabling a service only prevents it from starting at boot. If it's already running, it will continue until manually stopped. The --now flag ensures the service is both stopped and disabled in a single command.",
    "tags": [
      "systemctl",
      "service-management",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-005",
    "pattern": "^systemctl\\s+daemon-reload",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Always reload after editing unit files to apply changes.",
    "detail": "systemctl daemon-reload is required after modifying or adding unit files. Without it, systemd won't recognize changes, leading to confusion or outdated configurations being used.",
    "tags": [
      "systemctl",
      "unit-files",
      "configuration"
    ]
  },
  {
    "id": "sysadmin-006",
    "pattern": "^journalctl\\s*$",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Use -xe for recent logs with errors and context.",
    "detail": "The -xe flags show the end of the journal with extra context and error messages, making troubleshooting much faster. This is especially useful for debugging failed services.",
    "tags": [
      "journalctl",
      "logs",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-007",
    "pattern": "^journalctl\\s+--since=.*",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Combine --since and --until for precise log windows.",
    "detail": "Using both --since and --until narrows down log output to a specific time range, which is invaluable for incident analysis or tracking down issues within a known window.",
    "tags": [
      "journalctl",
      "logs",
      "time-filter"
    ]
  },
  {
    "id": "sysadmin-008",
    "pattern": "^journalctl\\s+--vacuum-time=.*",
    "cmd": "journalctl",
    "severity": "danger",
    "hint": "Vacuuming deletes logs permanently; double-check retention period.",
    "detail": "The --vacuum-time flag removes archived journal files older than the specified time. This operation is irreversible, and deleted logs cannot be recovered. Always verify retention requirements before running.",
    "tags": [
      "journalctl",
      "logs",
      "data-loss"
    ]
  },
  {
    "id": "sysadmin-009",
    "pattern": "^journalctl\\s+--vacuum-size=.*",
    "cmd": "journalctl",
    "severity": "danger",
    "hint": "Vacuuming by size may delete recent logs; confirm before running.",
    "detail": "When using --vacuum-size, journalctl deletes the oldest logs until the total size is below the specified limit. This can remove recent logs if the journal is large. Always check current usage with 'journalctl --disk-usage' first.",
    "tags": [
      "journalctl",
      "logs",
      "data-loss"
    ]
  },
  {
    "id": "sysadmin-010",
    "pattern": "^journalctl\\s+--rotate",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Rotate logs before backup to ensure all data is archived.",
    "detail": "The --rotate flag forces a rotation of the journal files, closing the current file and starting a new one. This ensures that all log data up to that point is written and can be safely backed up.",
    "tags": [
      "journalctl",
      "logs",
      "backup"
    ]
  },
  {
    "id": "sysadmin-011",
    "pattern": "^cron\\s+-e",
    "cmd": "cron",
    "severity": "warn",
    "hint": "Always specify full paths in crontab commands.",
    "detail": "Cron jobs run with a minimal environment, often lacking standard PATH variables. Using full paths to executables and files prevents silent failures due to missing binaries.",
    "tags": [
      "cron",
      "environment",
      "footgun"
    ]
  },
  {
    "id": "sysadmin-012",
    "pattern": "^crontab\\s+-e",
    "cmd": "crontab",
    "severity": "warn",
    "hint": "Check for duplicate or conflicting cron entries.",
    "detail": "Multiple cron entries for the same script can cause overlapping runs, race conditions, or resource contention. Review crontab carefully to avoid unintended consequences.",
    "tags": [
      "cron",
      "scheduling",
      "footgun"
    ]
  },
  {
    "id": "sysadmin-013",
    "pattern": "^crontab\\s+-r",
    "cmd": "crontab",
    "severity": "danger",
    "hint": "This deletes all cron jobs for the user with no confirmation.",
    "detail": "crontab -r removes the entire crontab for the current user without prompting. There is no undo. Always export with 'crontab -l > backup' before running.",
    "tags": [
      "cron",
      "data-loss",
      "danger"
    ]
  },
  {
    "id": "sysadmin-014",
    "pattern": "^crontab\\s+-l",
    "cmd": "crontab",
    "severity": "tip",
    "hint": "Redirect output to backup your crontab before editing.",
    "detail": "Before making changes, use 'crontab -l > crontab.bak' to save a copy. This allows for quick recovery if edits introduce errors or jobs are accidentally deleted.",
    "tags": [
      "cron",
      "backup",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-015",
    "pattern": "^at\\s+.*",
    "cmd": "at",
    "severity": "warn",
    "hint": "Check atd service is running or jobs will never execute.",
    "detail": "The 'at' command schedules jobs for later execution, but relies on the atd daemon. If atd is not running, jobs will be silently missed. Always verify with 'systemctl status atd'.",
    "tags": [
      "at",
      "scheduling",
      "footgun"
    ]
  },
  {
    "id": "sysadmin-016",
    "pattern": "^atq",
    "cmd": "atq",
    "severity": "tip",
    "hint": "Use atq to list pending jobs and their execution times.",
    "detail": "atq shows all scheduled 'at' jobs for the current user, including job IDs and times. This is essential for tracking and managing scheduled tasks.",
    "tags": [
      "at",
      "scheduling",
      "monitoring"
    ]
  },
  {
    "id": "sysadmin-017",
    "pattern": "^atrm\\s+\\d+",
    "cmd": "atrm",
    "severity": "tip",
    "hint": "Use atrm to remove scheduled jobs by their job number.",
    "detail": "atrm deletes 'at' jobs using the job number from atq. This is the only way to cancel pending at jobs before execution.",
    "tags": [
      "at",
      "scheduling",
      "management"
    ]
  },
  {
    "id": "sysadmin-018",
    "pattern": "^logrotate\\s+.*",
    "cmd": "logrotate",
    "severity": "warn",
    "hint": "Use -d for dry-run to preview logrotate actions.",
    "detail": "The -d flag shows what logrotate would do without making changes. This is crucial for verifying configuration changes and avoiding accidental log deletion or misrotation.",
    "tags": [
      "logrotate",
      "logs",
      "dry-run"
    ]
  },
  {
    "id": "sysadmin-019",
    "pattern": "^logrotate\\s+-f\\s+.*",
    "cmd": "logrotate",
    "severity": "danger",
    "hint": "Forcing rotation may delete logs; use with caution.",
    "detail": "The -f flag forces rotation even if logrotate thinks it's not needed. This can result in premature log deletion or overwriting, especially with misconfigured retention policies.",
    "tags": [
      "logrotate",
      "logs",
      "data-loss"
    ]
  },
  {
    "id": "sysadmin-020",
    "pattern": "^logrotate\\s+-s\\s+.*",
    "cmd": "logrotate",
    "severity": "tip",
    "hint": "Use -s to specify a custom state file for parallel runs.",
    "detail": "The -s flag lets you define a state file, which is useful when running multiple logrotate instances or testing new configurations without interfering with production state.",
    "tags": [
      "logrotate",
      "logs",
      "advanced"
    ]
  },
  {
    "id": "sysadmin-021",
    "pattern": "^ulimit\\s+-n\\s+\\d+",
    "cmd": "ulimit",
    "severity": "tip",
    "hint": "Increase open files limit for high-concurrency applications.",
    "detail": "The -n flag sets the maximum number of open file descriptors. Many servers (e.g., databases, web servers) require higher limits for optimal performance. Set in shell or /etc/security/limits.conf for persistency.",
    "tags": [
      "ulimit",
      "performance",
      "limits"
    ]
  },
  {
    "id": "sysadmin-022",
    "pattern": "^ulimit\\s+-a",
    "cmd": "ulimit",
    "severity": "tip",
    "hint": "Use -a to display all current resource limits.",
    "detail": "ulimit -a lists all resource limits for the current shell session, including file size, process count, and memory. This helps diagnose resource exhaustion issues.",
    "tags": [
      "ulimit",
      "diagnostics",
      "limits"
    ]
  },
  {
    "id": "sysadmin-023",
    "pattern": "^ulimit\\s+-c\\s+0",
    "cmd": "ulimit",
    "severity": "warn",
    "hint": "Setting core size to 0 disables core dumps for debugging.",
    "detail": "ulimit -c 0 prevents the creation of core dumps, which are vital for post-mortem debugging. Only set this in production if core dumps are not needed and disk space is a concern.",
    "tags": [
      "ulimit",
      "debugging",
      "core-dump"
    ]
  },
  {
    "id": "sysadmin-024",
    "pattern": "^sysctl\\s+-w\\s+.*",
    "cmd": "sysctl",
    "severity": "warn",
    "hint": "Changes with -w are temporary; use /etc/sysctl.conf for persistency.",
    "detail": "sysctl -w applies changes only until the next reboot. For persistent kernel parameter changes, edit /etc/sysctl.conf or drop files in /etc/sysctl.d/.",
    "tags": [
      "sysctl",
      "kernel",
      "configuration"
    ]
  },
  {
    "id": "sysadmin-025",
    "pattern": "^sysctl\\s+-p",
    "cmd": "sysctl",
    "severity": "tip",
    "hint": "Use -p to reload kernel parameters from sysctl.conf.",
    "detail": "sysctl -p reads and applies all settings from /etc/sysctl.conf. This is essential after editing the file to ensure changes take effect immediately.",
    "tags": [
      "sysctl",
      "kernel",
      "configuration"
    ]
  },
  {
    "id": "sysadmin-026",
    "pattern": "^sysctl\\s+.*",
    "cmd": "sysctl",
    "severity": "tip",
    "hint": "Query specific keys for quick checks, e.g., net.ipv4.ip_forward.",
    "detail": "sysctl allows querying individual kernel parameters, which is faster and less noisy than dumping all values. Use 'sysctl net.ipv4.ip_forward' for targeted checks.",
    "tags": [
      "sysctl",
      "kernel",
      "diagnostics"
    ]
  },
  {
    "id": "sysadmin-027",
    "pattern": "^dmesg\\s*$",
    "cmd": "dmesg",
    "severity": "tip",
    "hint": "Use -T to display human-readable timestamps.",
    "detail": "dmesg by default shows timestamps in seconds since boot, which can be hard to interpret. The -T flag converts these to local time, aiding in correlating events with logs.",
    "tags": [
      "dmesg",
      "logs",
      "usability"
    ]
  },
  {
    "id": "sysadmin-028",
    "pattern": "^dmesg\\s+-w",
    "cmd": "dmesg",
    "severity": "tip",
    "hint": "Use -w to watch kernel messages in real time.",
    "detail": "The -w flag makes dmesg follow new kernel messages as they arrive, similar to tail -f. This is invaluable for monitoring hardware events or debugging driver issues live.",
    "tags": [
      "dmesg",
      "monitoring",
      "kernel"
    ]
  },
  {
    "id": "sysadmin-029",
    "pattern": "^dmesg\\s+-C",
    "cmd": "dmesg",
    "severity": "danger",
    "hint": "Clearing the kernel ring buffer erases all current messages.",
    "detail": "dmesg -C wipes the entire kernel message buffer. This is irreversible and should only be done when absolutely necessary, such as before capturing new events for debugging.",
    "tags": [
      "dmesg",
      "logs",
      "data-loss"
    ]
  },
  {
    "id": "sysadmin-030",
    "pattern": "^uname\\s+-a",
    "cmd": "uname",
    "severity": "tip",
    "hint": "Use -a for all system info; combine with grep for specifics.",
    "detail": "uname -a outputs kernel name, version, and architecture. For scripts, pipe to grep for targeted queries, e.g., 'uname -a | grep SMP' to check for multi-processor support.",
    "tags": [
      "uname",
      "system-info",
      "diagnostics"
    ]
  },
  {
    "id": "sysadmin-031",
    "pattern": "^lsmod\\s*$",
    "cmd": "lsmod",
    "severity": "tip",
    "hint": "Use lsmod to list all loaded kernel modules.",
    "detail": "lsmod provides a snapshot of currently loaded kernel modules, their sizes, and usage counts. This is essential for troubleshooting hardware and driver issues.",
    "tags": [
      "lsmod",
      "kernel",
      "diagnostics"
    ]
  },
  {
    "id": "sysadmin-032",
    "pattern": "^modprobe\\s+.*",
    "cmd": "modprobe",
    "severity": "warn",
    "hint": "Use -n for dry-run to preview module dependencies.",
    "detail": "modprobe -n shows what would be done without loading or unloading modules. This helps prevent accidental removal or insertion of critical modules.",
    "tags": [
      "modprobe",
      "kernel",
      "dry-run"
    ]
  },
  {
    "id": "sysadmin-033",
    "pattern": "^modprobe\\s+-r\\s+.*",
    "cmd": "modprobe",
    "severity": "danger",
    "hint": "Removing modules can break devices or networking; confirm dependencies.",
    "detail": "modprobe -r unloads kernel modules, but dependencies may cause system instability or loss of network/storage. Always check with lsmod and modinfo before removing.",
    "tags": [
      "modprobe",
      "kernel",
      "danger"
    ]
  },
  {
    "id": "sysadmin-034",
    "pattern": "^modprobe\\s+.*\\s+--first-time",
    "cmd": "modprobe",
    "severity": "tip",
    "hint": "Use --first-time to load modules only if not already loaded.",
    "detail": "The --first-time flag prevents redundant module loading, which can reduce log noise and avoid unnecessary operations, especially in automation.",
    "tags": [
      "modprobe",
      "kernel",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-035",
    "pattern": "^update-alternatives\\s+--config\\s+.*",
    "cmd": "update-alternatives",
    "severity": "tip",
    "hint": "Use --display to review all alternatives before switching.",
    "detail": "update-alternatives --display shows all available versions and their priorities. This helps prevent accidental selection of outdated or unintended binaries.",
    "tags": [
      "update-alternatives",
      "configuration",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-036",
    "pattern": "^update-alternatives\\s+--remove\\s+.*",
    "cmd": "update-alternatives",
    "severity": "danger",
    "hint": "Removing alternatives may break scripts relying on symlinks.",
    "detail": "Removing an alternative deletes the symlink, which can cause scripts or services to fail if they depend on the managed path. Always check for dependencies before removal.",
    "tags": [
      "update-alternatives",
      "danger",
      "footgun"
    ]
  },
  {
    "id": "sysadmin-037",
    "pattern": "^update-alternatives\\s+--install\\s+.*",
    "cmd": "update-alternatives",
    "severity": "tip",
    "hint": "Set priority carefully to control default selection.",
    "detail": "The priority value determines which alternative is selected by default. Higher numbers take precedence. Misconfigured priorities can lead to unexpected binaries being used.",
    "tags": [
      "update-alternatives",
      "configuration",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-038",
    "pattern": "^systemctl\\s+mask\\s+.*",
    "cmd": "systemctl",
    "severity": "danger",
    "hint": "Masking disables a unit completely; even dependencies can't start it.",
    "detail": "systemctl mask symlinks a unit to /dev/null, making it impossible to start manually or as a dependency. This is stronger than disable and should be used with caution.",
    "tags": [
      "systemctl",
      "service-management",
      "danger"
    ]
  },
  {
    "id": "sysadmin-039",
    "pattern": "^systemctl\\s+unmask\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Unmask to re-enable units previously masked for troubleshooting.",
    "detail": "systemctl unmask removes the /dev/null symlink, restoring the unit's ability to be started. This is necessary after temporary masking for maintenance or debugging.",
    "tags": [
      "systemctl",
      "service-management",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-040",
    "pattern": "^systemctl\\s+is-enabled\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use is-enabled to check if a service starts at boot.",
    "detail": "systemctl is-enabled returns 'enabled', 'disabled', or 'static', indicating whether a unit is set to start automatically. This is useful for auditing system startup behavior.",
    "tags": [
      "systemctl",
      "auditing",
      "configuration"
    ]
  },
  {
    "id": "sysadmin-041",
    "pattern": "^systemctl\\s+is-active\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use is-active to check real-time service status in scripts.",
    "detail": "systemctl is-active returns 'active' or 'inactive', making it ideal for scripting health checks or conditional logic based on service state.",
    "tags": [
      "systemctl",
      "monitoring",
      "automation"
    ]
  },
  {
    "id": "sysadmin-042",
    "pattern": "^journalctl\\s+-u\\s+.*",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Filter logs by unit with -u for focused troubleshooting.",
    "detail": "The -u flag restricts output to a specific systemd unit, dramatically reducing noise and making it easier to diagnose service-specific issues.",
    "tags": [
      "journalctl",
      "logs",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-043",
    "pattern": "^journalctl\\s+--disk-usage",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Check journal disk usage before vacuuming or resizing.",
    "detail": "journalctl --disk-usage reports the total space used by journal logs. This helps inform retention and vacuuming decisions to avoid accidental log loss.",
    "tags": [
      "journalctl",
      "logs",
      "monitoring"
    ]
  },
  {
    "id": "sysadmin-044",
    "pattern": "^systemctl\\s+edit\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use edit to create drop-in overrides, not direct unit file edits.",
    "detail": "systemctl edit creates override files in /etc/systemd/system/<unit>.d/, preserving package-managed unit files. This is the recommended way to customize services without risking package conflicts.",
    "tags": [
      "systemctl",
      "configuration",
      "best-practice"
    ]
  },
  {
    "id": "sysadmin-045",
    "pattern": "^systemctl\\s+cat\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use cat to view full unit file with all overrides applied.",
    "detail": "systemctl cat displays the effective unit file, including drop-in overrides. This is essential for troubleshooting unexpected service behavior due to layered configuration.",
    "tags": [
      "systemctl",
      "configuration",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-046",
    "pattern": "^systemctl\\s+list-dependencies\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "List dependencies to understand service startup order.",
    "detail": "systemctl list-dependencies shows all units required by or ordering before/after the target unit. This helps diagnose boot issues and complex service relationships.",
    "tags": [
      "systemctl",
      "dependencies",
      "diagnostics"
    ]
  },
  {
    "id": "sysadmin-047",
    "pattern": "^systemctl\\s+show\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Use show to dump all unit properties for debugging.",
    "detail": "systemctl show outputs all properties of a unit, including environment, status, and dependencies. This is invaluable for deep troubleshooting and automation.",
    "tags": [
      "systemctl",
      "diagnostics",
      "automation"
    ]
  },
  {
    "id": "sysadmin-048",
    "pattern": "^systemctl\\s+list-units\\s+--failed",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "List only failed units to quickly spot issues.",
    "detail": "The --failed flag filters the unit list to only those in a failed state, making it easy to identify and address problems after boot or configuration changes.",
    "tags": [
      "systemctl",
      "monitoring",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-049",
    "pattern": "^systemctl\\s+reset-failed\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Reset failed state to allow service restarts after crash.",
    "detail": "systemctl reset-failed clears the failed state, which is required before restarting some units that have crashed or failed repeatedly. This avoids manual intervention in recovery scripts.",
    "tags": [
      "systemctl",
      "recovery",
      "automation"
    ]
  },
  {
    "id": "sysadmin-050",
    "pattern": "^journalctl\\s+--grep=.*",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Use --grep for fast, built-in log filtering.",
    "detail": "The --grep flag applies regex filtering at the journal level, which is more efficient than piping to grep and preserves log structure and colorization.",
    "tags": [
      "journalctl",
      "logs",
      "filtering"
    ]
  },
  {
    "id": "sysadmin-051",
    "pattern": "^systemctl\\s+set-environment\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Set environment variables for all services in current session.",
    "detail": "systemctl set-environment sets variables for the manager session, affecting all subsequently started units. Useful for temporary overrides without editing unit files.",
    "tags": [
      "systemctl",
      "environment",
      "advanced"
    ]
  },
  {
    "id": "sysadmin-052",
    "pattern": "^systemctl\\s+unset-environment\\s+.*",
    "cmd": "systemctl",
    "severity": "tip",
    "hint": "Unset environment variables previously set for systemd.",
    "detail": "systemctl unset-environment removes variables set with set-environment, restoring default behavior. This is important for cleaning up after temporary overrides.",
    "tags": [
      "systemctl",
      "environment",
      "advanced"
    ]
  },
  {
    "id": "sysadmin-053",
    "pattern": "^journalctl\\s+--user",
    "cmd": "journalctl",
    "severity": "tip",
    "hint": "Show logs for user services, not system-wide.",
    "detail": "The --user flag restricts journalctl output to the current user's session, which is essential for debugging user-level systemd services.",
    "tags": [
      "journalctl",
      "logs",
      "user-services"
    ]
  },
  {
    "id": "sysadmin-054",
    "pattern": "^systemctl\\s+reboot",
    "cmd": "systemctl",
    "severity": "danger",
    "hint": "Warn users before rebooting; may cause data loss.",
    "detail": "systemctl reboot immediately restarts the system, potentially interrupting users or services. Always notify users and ensure critical data is saved before rebooting.",
    "tags": [
      "systemctl",
      "danger",
      "shutdown"
    ]
  },
  {
    "id": "sysadmin-055",
    "pattern": "^systemctl\\s+poweroff",
    "cmd": "systemctl",
    "severity": "danger",
    "hint": "Warn users before shutdown; unsaved work will be lost.",
    "detail": "systemctl poweroff shuts down the system, which can cause data loss if users are not notified. Always check for active sessions and running services before powering off.",
    "tags": [
      "systemctl",
      "danger",
      "shutdown"
    ]
  },
  {
    "id": "sysadmin-056",
    "pattern": "^systemctl\\s+isolate\\s+.*",
    "cmd": "systemctl",
    "severity": "danger",
    "hint": "Isolating a target stops all other units; use with caution.",
    "detail": "systemctl isolate switches to the specified target, stopping all units not required by it. This can bring down networking or user sessions unexpectedly.",
    "tags": [
      "systemctl",
      "danger",
      "targets"
    ]
  },
  {
    "id": "sysadmin-057",
    "pattern": "^systemctl\\s+set-default\\s+.*",
    "cmd": "systemctl",
    "severity": "warn",
    "hint": "Set-default changes boot target; verify before applying.",
    "detail": "systemctl set-default alters the default systemd target (runlevel) for boot. Setting the wrong target can cause headless boots or missing services.",
    "tags": [
      "systemctl",
      "boot",
      "configuration"
    ]
  },
  {
    "id": "sysadmin-058",
    "pattern": "^logrotate\\s+-v\\s+.*",
    "cmd": "logrotate",
    "severity": "tip",
    "hint": "Use -v for verbose output to debug rotation issues.",
    "detail": "The -v flag prints detailed information about each log file processed, which helps identify misconfigurations or permission problems in logrotate setups.",
    "tags": [
      "logrotate",
      "logs",
      "debugging"
    ]
  },
  {
    "id": "sysadmin-059",
    "pattern": "^lsmod\\s+.*",
    "cmd": "lsmod",
    "severity": "tip",
    "hint": "Pipe to grep to quickly check if a module is loaded.",
    "detail": "lsmod | grep <module> is the fastest way to check if a specific kernel module is loaded, which is useful for troubleshooting hardware or driver issues.",
    "tags": [
      "lsmod",
      "kernel",
      "troubleshooting"
    ]
  },
  {
    "id": "sysadmin-060",
    "pattern": "^modprobe\\s+--show-depends\\s+.*",
    "cmd": "modprobe",
    "severity": "tip",
    "hint": "Show all dependencies before loading a module.",
    "detail": "The --show-depends flag lists all modules that would be loaded as dependencies, helping to anticipate side effects or conflicts before making changes.",
    "tags": [
      "modprobe",
      "kernel",
      "dependencies"
    ]
  },
  {
    "id": "process-001",
    "pattern": "^kill\\s+-9\\s+1(\\s|$)",
    "cmd": "kill",
    "severity": "danger",
    "hint": "Never send SIGKILL (-9) to PID 1. It can crash your system.",
    "detail": "PID 1 is the init/systemd process. Sending SIGKILL (-9) to PID 1 will not terminate it, but may destabilize or crash your entire system, leading to a kernel panic or forced reboot. Always verify the PID before using kill -9.",
    "tags": [
      "kill",
      "danger",
      "system"
    ]
  },
  {
    "id": "process-002",
    "pattern": "^killall\\s+-9\\s+.*",
    "cmd": "killall",
    "severity": "warn",
    "hint": "killall -9 can terminate all matching processes instantly. Double-che...",
    "detail": "killall -9 sends SIGKILL to all processes with the given name, bypassing cleanup routines. This can cause data loss or leave resources locked. Use killall without -9 first to allow graceful shutdown.",
    "tags": [
      "killall",
      "warn",
      "process"
    ]
  },
  {
    "id": "process-003",
    "pattern": "^ps\\s+-ef",
    "cmd": "ps",
    "severity": "tip",
    "hint": "Use 'ps aux' for BSD-style output and wider compatibility.",
    "detail": "The 'ps -ef' syntax is System V style and may not show all columns on BSD systems. 'ps aux' is portable across Linux and BSD, and displays more detailed information by default.",
    "tags": [
      "ps",
      "tip",
      "compatibility"
    ]
  },
  {
    "id": "process-004",
    "pattern": "^ps\\s+aux\\s+\\|\\s+grep\\s+",
    "cmd": "ps",
    "severity": "tip",
    "hint": "Use 'pgrep' instead of 'ps aux | grep' for cleaner process search.",
    "detail": "pgrep searches processes by name or pattern and returns matching PIDs directly, avoiding issues with grep matching itself or partial matches. It's more efficient and less error-prone.",
    "tags": [
      "ps",
      "pgrep",
      "upgrade"
    ]
  },
  {
    "id": "process-005",
    "pattern": "^kill\\s+\\d+\\s+\\d+",
    "cmd": "kill",
    "severity": "warn",
    "hint": "kill only accepts one PID at a time. Use kill with multiple PIDs or x...",
    "detail": "kill expects a list of PIDs, but some shells may interpret multiple arguments incorrectly. Use 'kill PID1 PID2' or 'xargs kill' for multiple processes. Always verify the list before execution.",
    "tags": [
      "kill",
      "warn",
      "syntax"
    ]
  },
  {
    "id": "process-006",
    "pattern": "^nohup\\s+.*\\s+&",
    "cmd": "nohup",
    "severity": "tip",
    "hint": "Redirect nohup output to a file to avoid nohup.out clutter.",
    "detail": "By default, nohup writes stdout and stderr to nohup.out in the current directory. Redirect output explicitly to a log file to keep directories clean and logs organized.",
    "tags": [
      "nohup",
      "tip",
      "output"
    ]
  },
  {
    "id": "process-007",
    "pattern": "^kill\\s+-1\\s+\\d+",
    "cmd": "kill",
    "severity": "warn",
    "hint": "kill -1 sends SIGHUP, not SIGKILL. Use -9 for force, -15 for graceful.",
    "detail": "SIGHUP (-1) is used to reload configuration or signal terminal hangup, not to terminate processes. Use SIGTERM (-15) for graceful shutdown, SIGKILL (-9) for forceful termination.",
    "tags": [
      "kill",
      "warn",
      "signals"
    ]
  },
  {
    "id": "process-008",
    "pattern": "^top\\s+-n\\s+1",
    "cmd": "top",
    "severity": "tip",
    "hint": "Use 'htop' for interactive, colorized, and sortable process lists.",
    "detail": "htop provides a more user-friendly, interactive interface than top, with colorized output, mouse support, and easier process management. It's available in most repositories.",
    "tags": [
      "top",
      "htop",
      "upgrade"
    ]
  },
  {
    "id": "process-009",
    "pattern": "^ps\\s+-A",
    "cmd": "ps",
    "severity": "tip",
    "hint": "Use 'ps -eo pid,cmd' for custom columns and scripting.",
    "detail": "The -A flag lists all processes, but custom output with -eo allows you to select only the columns you need, making parsing and automation easier.",
    "tags": [
      "ps",
      "tip",
      "scripting"
    ]
  },
  {
    "id": "process-010",
    "pattern": "^killall\\s+--user\\s+root",
    "cmd": "killall",
    "severity": "danger",
    "hint": "killall --user root can terminate critical system processes.",
    "detail": "Killing all processes owned by root may crash your system or make it unresponsive. Always target specific processes or use with extreme caution.",
    "tags": [
      "killall",
      "danger",
      "system"
    ]
  },
  {
    "id": "process-011",
    "pattern": "^nice\\s+-n\\s+-20\\s+",
    "cmd": "nice",
    "severity": "warn",
    "hint": "Only root can set negative nice values (higher priority).",
    "detail": "Setting a negative nice value increases process priority, but only the root user can do this. Non-root attempts will silently fail or default to 0.",
    "tags": [
      "nice",
      "warn",
      "permissions"
    ]
  },
  {
    "id": "process-012",
    "pattern": "^renice\\s+-n\\s+-20\\s+\\d+",
    "cmd": "renice",
    "severity": "warn",
    "hint": "renice -20 requires root privileges for higher priority.",
    "detail": "Only privileged users can decrease nice values (increase priority). Unprivileged attempts will fail with 'Permission denied' and not change process priority.",
    "tags": [
      "renice",
      "warn",
      "permissions"
    ]
  },
  {
    "id": "process-013",
    "pattern": "^strace\\s+.*\\s+2>&1",
    "cmd": "strace",
    "severity": "tip",
    "hint": "Use '-o file' to save strace output instead of redirecting.",
    "detail": "strace's -o flag writes output directly to a file, ensuring all output is captured, including early initialization messages that might be missed with shell redirection.",
    "tags": [
      "strace",
      "tip",
      "output"
    ]
  },
  {
    "id": "process-014",
    "pattern": "^ps\\s+-C\\s+",
    "cmd": "ps",
    "severity": "tip",
    "hint": "Use 'pgrep' for process name search; it's simpler and faster.",
    "detail": "ps -C matches command names, but pgrep is purpose-built for this and can output PIDs directly, making scripting and process management easier.",
    "tags": [
      "ps",
      "pgrep",
      "upgrade"
    ]
  },
  {
    "id": "process-015",
    "pattern": "^lsof\\s+-i",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "Use 'ss' for faster and more detailed socket information.",
    "detail": "lsof -i lists open network files, but 'ss' provides more detailed and faster socket statistics, including state, address, and process info.",
    "tags": [
      "lsof",
      "ss",
      "upgrade"
    ]
  },
  {
    "id": "process-016",
    "pattern": "^kill\\s+--signal\\s+SIGKILL\\s+\\d+",
    "cmd": "kill",
    "severity": "tip",
    "hint": "Use 'kill -9' as a shorthand for SIGKILL.",
    "detail": "The -9 flag is a shorthand for SIGKILL. Both forms are equivalent, but -9 is more concise and universally recognized in scripts and documentation.",
    "tags": [
      "kill",
      "tip",
      "signals"
    ]
  },
  {
    "id": "process-017",
    "pattern": "^nohup\\s+.*",
    "cmd": "nohup",
    "severity": "warn",
    "hint": "nohup does not detach from terminal; use '&' or disown for full backg...",
    "detail": "nohup ignores SIGHUP, but does not background the process. Use '&' to run in the background, or 'disown' to remove from shell job table for true detachment.",
    "tags": [
      "nohup",
      "warn",
      "background"
    ]
  },
  {
    "id": "process-018",
    "pattern": "^screen\\s+-ls",
    "cmd": "screen",
    "severity": "tip",
    "hint": "Use 'tmux' for modern terminal multiplexing and scripting.",
    "detail": "tmux is a modern alternative to screen, offering better scripting, session management, and configuration. It is widely adopted in DevOps workflows.",
    "tags": [
      "screen",
      "tmux",
      "upgrade"
    ]
  },
  {
    "id": "process-019",
    "pattern": "^kill\\s+-l",
    "cmd": "kill",
    "severity": "tip",
    "hint": "kill -l lists all signal names and numbers for reference.",
    "detail": "Use 'kill -l' to display all available signals. This is useful for scripting and understanding which signals are supported on your system.",
    "tags": [
      "kill",
      "tip",
      "signals"
    ]
  },
  {
    "id": "process-020",
    "pattern": "^ps\\s+-u\\s+root",
    "cmd": "ps",
    "severity": "tip",
    "hint": "Use 'ps -U root -u root u' for detailed user process info.",
    "detail": "Combining -U and -u with the 'u' format provides detailed user-oriented output, including CPU, memory, and process start time.",
    "tags": [
      "ps",
      "tip",
      "user"
    ]
  },
  {
    "id": "process-021",
    "pattern": "^jobs\\s+-l",
    "cmd": "jobs",
    "severity": "tip",
    "hint": "jobs -l shows process group IDs for advanced job control.",
    "detail": "The -l flag displays the process group ID (PGID) along with job information, which is useful for managing related background processes.",
    "tags": [
      "jobs",
      "tip",
      "jobcontrol"
    ]
  },
  {
    "id": "process-022",
    "pattern": "^fg\\s+%\\d+",
    "cmd": "fg",
    "severity": "tip",
    "hint": "Use 'fg' without arguments to bring last job to foreground.",
    "detail": "If no job specifier is given, 'fg' brings the most recently suspended or backgrounded job to the foreground. Use 'jobs' to list job numbers.",
    "tags": [
      "fg",
      "tip",
      "jobcontrol"
    ]
  },
  {
    "id": "process-023",
    "pattern": "^bg\\s+%\\d+",
    "cmd": "bg",
    "severity": "tip",
    "hint": "Use 'bg' to resume a stopped job in the background.",
    "detail": "The 'bg' command resumes a suspended job in the background. Use 'jobs' to find job numbers and manage multiple background tasks efficiently.",
    "tags": [
      "bg",
      "tip",
      "jobcontrol"
    ]
  },
  {
    "id": "process-024",
    "pattern": "^strace\\s+-f\\s+",
    "cmd": "strace",
    "severity": "tip",
    "hint": "strace -f traces child processes as well as the main process.",
    "detail": "The -f flag ensures that forked child processes are also traced, which is essential for debugging daemons or complex applications that spawn subprocesses.",
    "tags": [
      "strace",
      "tip",
      "debug"
    ]
  },
  {
    "id": "process-025",
    "pattern": "^lsof\\s+\\|\\s+grep\\s+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "Use 'lsof -c <name>' to filter by command name directly.",
    "detail": "The -c flag filters open files by command name, avoiding the need for grep and reducing the risk of matching unrelated processes.",
    "tags": [
      "lsof",
      "tip",
      "filter"
    ]
  },
  {
    "id": "process-026",
    "pattern": "^htop",
    "cmd": "htop",
    "severity": "tip",
    "hint": "Press F6 in htop to change sorting column interactively.",
    "detail": "htop allows dynamic sorting by CPU, memory, or other columns using the F6 key. This helps quickly identify resource-intensive processes.",
    "tags": [
      "htop",
      "tip",
      "performance"
    ]
  },
  {
    "id": "process-027",
    "pattern": "^ps\\s+-eo\\s+",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps -eo allows custom column selection for scripting and parsing.",
    "detail": "The -eo flag outputs user-specified columns, making it easier to script and automate process monitoring or reporting.",
    "tags": [
      "ps",
      "tip",
      "scripting"
    ]
  },
  {
    "id": "process-028",
    "pattern": "^killall\\s+.*\\s+--signal\\s+SIGKILL",
    "cmd": "killall",
    "severity": "warn",
    "hint": "killall --signal SIGKILL skips cleanup; prefer SIGTERM first.",
    "detail": "SIGKILL immediately terminates processes without allowing them to clean up resources. Use SIGTERM to allow graceful shutdown before resorting to SIGKILL.",
    "tags": [
      "killall",
      "warn",
      "signals"
    ]
  },
  {
    "id": "process-029",
    "pattern": "^strace\\s+-p\\s+\\d+",
    "cmd": "strace",
    "severity": "tip",
    "hint": "Attach strace to a running process with -p <PID> for live debugging.",
    "detail": "The -p flag lets you trace system calls of an already running process, which is invaluable for diagnosing issues without restarting the process.",
    "tags": [
      "strace",
      "tip",
      "debug"
    ]
  },
  {
    "id": "process-030",
    "pattern": "^lsof\\s+-p\\s+\\d+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -p <PID> shows all open files for a specific process.",
    "detail": "This is useful for debugging resource leaks or identifying files held open by a process. Combine with -a for more precise filtering.",
    "tags": [
      "lsof",
      "tip",
      "debug"
    ]
  },
  {
    "id": "process-031",
    "pattern": "^ps\\s+-o\\s+",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps -o lets you specify custom output columns for clarity.",
    "detail": "Custom columns help focus on relevant process attributes, improving readability and making parsing easier in scripts.",
    "tags": [
      "ps",
      "tip",
      "output"
    ]
  },
  {
    "id": "process-032",
    "pattern": "^kill\\s+--signal\\s+\\d+\\s+\\d+",
    "cmd": "kill",
    "severity": "warn",
    "hint": "kill --signal expects a signal name or number; check syntax.",
    "detail": "Incorrect signal specification can lead to no action or wrong signal sent. Always verify signal names/numbers with 'kill -l'.",
    "tags": [
      "kill",
      "warn",
      "signals"
    ]
  },
  {
    "id": "process-033",
    "pattern": "^renice\\s+\\d+\\s+-p\\s+\\d+",
    "cmd": "renice",
    "severity": "tip",
    "hint": "renice -p <PID> changes priority of a running process.",
    "detail": "This allows dynamic adjustment of process scheduling priority, which is useful for managing system load or troubleshooting performance issues.",
    "tags": [
      "renice",
      "tip",
      "performance"
    ]
  },
  {
    "id": "process-034",
    "pattern": "^strace\\s+-c\\s+",
    "cmd": "strace",
    "severity": "tip",
    "hint": "strace -c summarizes system call usage and timing.",
    "detail": "The -c flag provides a summary report of system calls, including counts and time spent, which is helpful for performance profiling.",
    "tags": [
      "strace",
      "tip",
      "profiling"
    ]
  },
  {
    "id": "process-035",
    "pattern": "^lsof\\s+-u\\s+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -u <user> lists files opened by a specific user.",
    "detail": "This is useful for tracking resource usage or troubleshooting user-specific issues. Combine with other filters for more precise results.",
    "tags": [
      "lsof",
      "tip",
      "user"
    ]
  },
  {
    "id": "process-036",
    "pattern": "^ps\\s+-axjf",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps -axjf shows process tree with parent-child relationships.",
    "detail": "The -j and -f flags together provide a full-format listing with job and parent info, useful for visualizing process hierarchies.",
    "tags": [
      "ps",
      "tip",
      "tree"
    ]
  },
  {
    "id": "process-037",
    "pattern": "^lsof\\s+-t\\s+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -t outputs only PIDs, ideal for scripting.",
    "detail": "The -t flag suppresses all fields except the PID, making it easy to use lsof output in scripts or with xargs.",
    "tags": [
      "lsof",
      "tip",
      "scripting"
    ]
  },
  {
    "id": "process-038",
    "pattern": "^killall\\s+--exact\\s+",
    "cmd": "killall",
    "severity": "tip",
    "hint": "killall --exact matches process names exactly, avoiding partial kills.",
    "detail": "This prevents accidental termination of similarly named processes. Always verify process names with 'ps' or 'pgrep' before using.",
    "tags": [
      "killall",
      "tip",
      "safety"
    ]
  },
  {
    "id": "process-039",
    "pattern": "^strace\\s+-e\\s+trace=",
    "cmd": "strace",
    "severity": "tip",
    "hint": "strace -e trace= limits tracing to specific syscall categories.",
    "detail": "This reduces noise and focuses debugging on relevant system calls, improving performance and clarity during analysis.",
    "tags": [
      "strace",
      "tip",
      "filter"
    ]
  },
  {
    "id": "process-040",
    "pattern": "^lsof\\s+-i:\\d+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -i:<port> shows processes listening on a specific port.",
    "detail": "This is useful for identifying which process is using a port, especially during network troubleshooting or service conflicts.",
    "tags": [
      "lsof",
      "tip",
      "network"
    ]
  },
  {
    "id": "process-041",
    "pattern": "^ps\\s+auxww",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps auxww shows full command lines without truncation.",
    "detail": "The extra 'w' flags ensure that long command lines are not cut off, which is essential for debugging complex processes.",
    "tags": [
      "ps",
      "tip",
      "output"
    ]
  },
  {
    "id": "process-042",
    "pattern": "^kill\\s+\\d+\\s*;\\s*kill\\s+\\d+",
    "cmd": "kill",
    "severity": "tip",
    "hint": "Use 'kill PID1 PID2' to send a signal to multiple PIDs at once.",
    "detail": "kill accepts multiple PIDs as arguments, making it more efficient than issuing separate commands for each process.",
    "tags": [
      "kill",
      "tip",
      "efficiency"
    ]
  },
  {
    "id": "process-043",
    "pattern": "^lsof\\s+-nP",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -nP disables DNS and port name resolution for speed.",
    "detail": "The -n and -P flags prevent lsof from resolving hostnames and port names, significantly speeding up output, especially on busy systems.",
    "tags": [
      "lsof",
      "tip",
      "performance"
    ]
  },
  {
    "id": "process-044",
    "pattern": "^strace\\s+-tt\\s+",
    "cmd": "strace",
    "severity": "tip",
    "hint": "strace -tt adds timestamps to each syscall for timing analysis.",
    "detail": "This is useful for correlating system call timing with application events or performance issues.",
    "tags": [
      "strace",
      "tip",
      "timing"
    ]
  },
  {
    "id": "process-045",
    "pattern": "^ps\\s+--forest",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps --forest visualizes process hierarchy as a tree.",
    "detail": "The --forest flag adds ASCII art to show parent-child relationships, making it easier to understand process ancestry and groupings.",
    "tags": [
      "ps",
      "tip",
      "tree"
    ]
  },
  {
    "id": "process-046",
    "pattern": "^lsof\\s+-c\\s+",
    "cmd": "lsof",
    "severity": "tip",
    "hint": "lsof -c <prefix> matches processes by command name prefix.",
    "detail": "This allows you to quickly filter open files by all processes starting with a given name, which is useful for grouped applications.",
    "tags": [
      "lsof",
      "tip",
      "filter"
    ]
  },
  {
    "id": "process-047",
    "pattern": "^strace\\s+-s\\s+\\d+",
    "cmd": "strace",
    "severity": "tip",
    "hint": "strace -s <len> increases the string print length in output.",
    "detail": "By default, strace truncates strings to 32 bytes. Use -s to capture longer strings, which is helpful for debugging arguments or data passed to syscalls.",
    "tags": [
      "strace",
      "tip",
      "output"
    ]
  },
  {
    "id": "process-048",
    "pattern": "^ltrace\\s+",
    "cmd": "ltrace",
    "severity": "tip",
    "hint": "ltrace traces library calls, complementing strace's syscalls.",
    "detail": "ltrace is useful for debugging dynamic linking or library-level issues, while strace focuses on kernel syscalls. Use both for comprehensive analysis.",
    "tags": [
      "ltrace",
      "strace",
      "tip"
    ]
  },
  {
    "id": "process-049",
    "pattern": "^ps\\s+-eo\\s+pid,ppid,cmd,stat",
    "cmd": "ps",
    "severity": "tip",
    "hint": "ps -eo pid,ppid,cmd,stat shows process state and ancestry.",
    "detail": "Including stat and ppid columns helps track process status and parentage, which is useful for troubleshooting zombies or orphans.",
    "tags": [
      "ps",
      "tip",
      "debug"
    ]
  },
  {
    "id": "process-050",
    "pattern": "^kill\\s+-0\\s+\\d+",
    "cmd": "kill",
    "severity": "tip",
    "hint": "kill -0 checks if a process exists without sending a signal.",
    "detail": "This is useful for scripts to test process liveness or permissions before attempting to send a real signal.",
    "tags": [
      "kill",
      "tip",
      "scripting"
    ]
  },
  {
    "id": "disk-001",
    "pattern": "^rm\\s+-rf\\s+/($|\\s+)",
    "cmd": "rm",
    "severity": "danger",
    "hint": "Never run 'rm -rf /'. This erases all files on the root filesystem.",
    "detail": "Running 'rm -rf /' will recursively and forcefully delete every file from the root directory, leading to complete data loss and system unbootability. Some systems may block this with a safety check, but not all. Always double-check your target path.",
    "tags": [
      "data-loss",
      "filesystem",
      "danger"
    ]
  },
  {
    "id": "disk-002",
    "pattern": "^mkfs\\s+.*(/dev/sd[a-z][0-9]?)",
    "cmd": "mkfs",
    "severity": "danger",
    "hint": "mkfs will irreversibly erase all data on the target device/partition.",
    "detail": "The mkfs command initializes a filesystem, overwriting all existing data on the specified device or partition. There is no undo; double-check the device (e.g., /dev/sda1) before proceeding. Consider using 'lsblk' to verify the target.",
    "tags": [
      "mkfs",
      "data-loss",
      "danger"
    ]
  },
  {
    "id": "disk-003",
    "pattern": "^fdisk\\s+/dev/sd[a-z]($|\\s+)",
    "cmd": "fdisk",
    "severity": "warn",
    "hint": "fdisk changes aren't saved until you write (w); quit (q) to discard.",
    "detail": "In fdisk, partition changes are staged in memory and only written to disk when you use the 'w' command. Exiting with 'q' will discard all changes. Always review your partition table before writing.",
    "tags": [
      "fdisk",
      "partition",
      "warn"
    ]
  },
  {
    "id": "disk-004",
    "pattern": "^mount\\s+(/dev/\\S+)\\s+(/\\S+)",
    "cmd": "mount",
    "severity": "warn",
    "hint": "Mounting over a non-empty directory hides its contents until unmount.",
    "detail": "If you mount a device over a directory that already contains files, those files become inaccessible until you unmount. This can lead to confusion or apparent data loss. Always check the mountpoint is empty before mounting.",
    "tags": [
      "mount",
      "filesystem",
      "warn"
    ]
  },
  {
    "id": "disk-005",
    "pattern": "^umount\\s+(/\\S+|/dev/\\S+)",
    "cmd": "umount",
    "severity": "warn",
    "hint": "umount fails if the target is busy; use 'lsof' or 'fuser' to debug.",
    "detail": "Unmounting a busy filesystem will fail with 'target is busy'. Use 'lsof +D <mountpoint>' or 'fuser -m <mountpoint>' to identify processes holding files open. Consider 'umount -l' (lazy) as a last resort.",
    "tags": [
      "umount",
      "busy",
      "warn"
    ]
  },
  {
    "id": "disk-006",
    "pattern": "^df($|\\s+)",
    "cmd": "df",
    "severity": "tip",
    "hint": "Use 'df -h' for human-readable sizes (e.g., GB, MB).",
    "detail": "By default, df reports sizes in 1K blocks, which can be hard to interpret. The '-h' flag displays sizes in human-readable units, making disk usage much easier to understand at a glance.",
    "tags": [
      "df",
      "usability",
      "tip"
    ]
  },
  {
    "id": "disk-007",
    "pattern": "^du($|\\s+)",
    "cmd": "du",
    "severity": "tip",
    "hint": "Use 'du -sh *' for a summary of directory sizes in current dir.",
    "detail": "The '-s' flag summarizes each argument, and '-h' makes the output human-readable. This combination is ideal for quickly assessing which directories are using the most space.",
    "tags": [
      "du",
      "usability",
      "tip"
    ]
  },
  {
    "id": "disk-008",
    "pattern": "^lsblk($|\\s+)",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Add '-f' to lsblk to show filesystem type and mountpoints.",
    "detail": "The '-f' (or '--fs') flag displays filesystem type, label, and UUID for each block device, which is invaluable for identifying disks and partitions before formatting or mounting.",
    "tags": [
      "lsblk",
      "filesystem",
      "tip"
    ]
  },
  {
    "id": "disk-009",
    "pattern": "^df\\s+-hT($|\\s+)",
    "cmd": "df",
    "severity": "tip",
    "hint": "The '-T' flag shows filesystem type in df output.",
    "detail": "Adding '-T' to df displays an extra column with the filesystem type (e.g., ext4, xfs, tmpfs), which helps distinguish between physical and virtual filesystems.",
    "tags": [
      "df",
      "filesystem",
      "tip"
    ]
  },
  {
    "id": "disk-010",
    "pattern": "^du\\s+-a($|\\s+)",
    "cmd": "du",
    "severity": "tip",
    "hint": "Use 'du -a' to include files as well as directories in output.",
    "detail": "By default, du only summarizes directories. The '-a' flag includes individual files, which is useful for finding large files within a directory tree.",
    "tags": [
      "du",
      "files",
      "tip"
    ]
  },
  {
    "id": "disk-011",
    "pattern": "^mount\\s+.*-o\\s+loop",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Use '-o loop' to mount ISO or image files as block devices.",
    "detail": "The 'loop' option allows you to mount a file (like an ISO or disk image) as if it were a block device. This is essential for working with images without burning them to physical media.",
    "tags": [
      "mount",
      "loop",
      "tip"
    ]
  },
  {
    "id": "disk-012",
    "pattern": "^fdisk\\s+-l($|\\s+)",
    "cmd": "fdisk",
    "severity": "tip",
    "hint": "Use 'fdisk -l' to list all disks and partitions with details.",
    "detail": "'fdisk -l' scans all block devices and prints partition tables, sizes, and types. It's a quick way to audit all attached storage before making changes.",
    "tags": [
      "fdisk",
      "audit",
      "tip"
    ]
  },
  {
    "id": "disk-013",
    "pattern": "^parted\\s+.*print($|\\s+)",
    "cmd": "parted",
    "severity": "tip",
    "hint": "Use 'parted <dev> print' for detailed partition info, including flags.",
    "detail": "The 'print' command in parted shows partition numbers, start/end sectors, sizes, types, and flags (like bootable). This is more detailed than fdisk for GPT disks.",
    "tags": [
      "parted",
      "partition",
      "tip"
    ]
  },
  {
    "id": "disk-014",
    "pattern": "^mount\\s+-a($|\\s+)",
    "cmd": "mount",
    "severity": "warn",
    "hint": "mount -a mounts all filesystems in /etc/fstab; check fstab first.",
    "detail": "The 'mount -a' command attempts to mount all filesystems listed in /etc/fstab. Errors or misconfigurations in fstab can cause failures or mount the wrong devices. Always review fstab before running.",
    "tags": [
      "mount",
      "fstab",
      "warn"
    ]
  },
  {
    "id": "disk-015",
    "pattern": "^umount\\s+-f\\s+(/\\S+|/dev/\\S+)",
    "cmd": "umount",
    "severity": "danger",
    "hint": "umount -f forcibly unmounts; can cause data loss or corruption.",
    "detail": "The '-f' flag forces unmount, even if the device is busy. This can leave open files in an inconsistent state and cause data loss, especially on network filesystems. Use only as a last resort.",
    "tags": [
      "umount",
      "force",
      "danger"
    ]
  },
  {
    "id": "disk-016",
    "pattern": "^lsblk\\s+-p($|\\s+)",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Add '-p' to lsblk to show full device paths (e.g., /dev/sda).",
    "detail": "The '-p' flag prints device names as absolute paths, which is useful for scripting and avoiding ambiguity when working with multiple disks.",
    "tags": [
      "lsblk",
      "scripting",
      "tip"
    ]
  },
  {
    "id": "disk-017",
    "pattern": "^df\\s+-i($|\\s+)",
    "cmd": "df",
    "severity": "tip",
    "hint": "Use 'df -i' to check inode usage, not just space usage.",
    "detail": "Filesystems can run out of inodes before running out of space, especially with many small files. 'df -i' shows inode usage and availability per filesystem.",
    "tags": [
      "df",
      "inode",
      "tip"
    ]
  },
  {
    "id": "disk-018",
    "pattern": "^du\\s+-d\\s+\\d+($|\\s+)",
    "cmd": "du",
    "severity": "tip",
    "hint": "Use 'du -d N' to limit directory depth in output.",
    "detail": "The '-d N' flag restricts du's output to directories at depth N or less, making it easier to summarize space usage in large directory trees.",
    "tags": [
      "du",
      "depth",
      "tip"
    ]
  },
  {
    "id": "disk-019",
    "pattern": "^mkfs\\s+.*-L\\s+\\S+",
    "cmd": "mkfs",
    "severity": "tip",
    "hint": "Use '-L <label>' to set a filesystem label during mkfs.",
    "detail": "Setting a label with '-L' makes it easier to identify filesystems in tools like lsblk, blkid, and mount. Labels are especially useful in multi-disk environments.",
    "tags": [
      "mkfs",
      "label",
      "tip"
    ]
  },
  {
    "id": "disk-020",
    "pattern": "^mount\\s+.*-o\\s+remount",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Use 'mount -o remount' to change mount options without unmounting.",
    "detail": "The 'remount' option allows you to alter mount flags (e.g., read-only, noatime) on a live filesystem without disrupting users or processes.",
    "tags": [
      "mount",
      "remount",
      "tip"
    ]
  },
  {
    "id": "disk-021",
    "pattern": "^lsblk\\s+-o\\s+",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Use 'lsblk -o <cols>' to customize output columns (e.g., UUID, LABEL).",
    "detail": "The '-o' flag lets you specify columns to display, such as NAME, SIZE, TYPE, MOUNTPOINT, UUID, and LABEL. This is invaluable for scripting and precise audits.",
    "tags": [
      "lsblk",
      "columns",
      "tip"
    ]
  },
  {
    "id": "disk-022",
    "pattern": "^iostat($|\\s+)",
    "cmd": "iostat",
    "severity": "tip",
    "hint": "Use 'iostat -x' for extended stats including utilization and queue size.",
    "detail": "The '-x' flag provides detailed per-device statistics, such as %util, await, and avgqu-sz, which are key for diagnosing disk bottlenecks.",
    "tags": [
      "iostat",
      "performance",
      "tip"
    ]
  },
  {
    "id": "disk-023",
    "pattern": "^iotop($|\\s+)",
    "cmd": "iotop",
    "severity": "tip",
    "hint": "Run iotop as root to see all processes and accurate I/O stats.",
    "detail": "Without root privileges, iotop may only show your own processes and incomplete I/O data. Use 'sudo iotop' for full visibility.",
    "tags": [
      "iotop",
      "permissions",
      "tip"
    ]
  },
  {
    "id": "disk-024",
    "pattern": "^smartctl\\s+-a\\s+(/dev/\\S+)",
    "cmd": "smartctl",
    "severity": "tip",
    "hint": "Use 'smartctl -a' for a full SMART report on disk health.",
    "detail": "The '-a' flag prints all available SMART data, including error logs, temperature, and self-test results. This is essential for preemptive disk failure detection.",
    "tags": [
      "smartctl",
      "health",
      "tip"
    ]
  },
  {
    "id": "disk-025",
    "pattern": "^smartctl\\s+-t\\s+short\\s+(/dev/\\S+)",
    "cmd": "smartctl",
    "severity": "tip",
    "hint": "Run 'smartctl -t short' to initiate a short self-test on a disk.",
    "detail": "A short self-test takes a few minutes and checks for common disk errors. Check the test result with 'smartctl -a' after completion.",
    "tags": [
      "smartctl",
      "test",
      "tip"
    ]
  },
  {
    "id": "disk-026",
    "pattern": "^mdadm\\s+--create($|\\s+)",
    "cmd": "mdadm",
    "severity": "danger",
    "hint": "mdadm --create overwrites data; double-check devices and options.",
    "detail": "Creating a new RAID array with mdadm will erase all data on the specified devices. Always back up important data and verify device names before proceeding.",
    "tags": [
      "mdadm",
      "raid",
      "danger"
    ]
  },
  {
    "id": "disk-027",
    "pattern": "^mdadm\\s+--assemble($|\\s+)",
    "cmd": "mdadm",
    "severity": "warn",
    "hint": "mdadm --assemble needs correct device order for RAID10/RAID0.",
    "detail": "For certain RAID levels (like RAID10 or RAID0), device order is critical. Assembling with the wrong order can result in data corruption or inaccessibility.",
    "tags": [
      "mdadm",
      "raid",
      "warn"
    ]
  },
  {
    "id": "disk-028",
    "pattern": "^mdadm\\s+--stop\\s+/dev/md\\d+",
    "cmd": "mdadm",
    "severity": "warn",
    "hint": "Stopping an active RAID device can cause service interruption.",
    "detail": "Running 'mdadm --stop' on a RAID device will make it inaccessible until reassembled. Ensure no filesystems are mounted and no services depend on the array before stopping.",
    "tags": [
      "mdadm",
      "raid",
      "warn"
    ]
  },
  {
    "id": "disk-029",
    "pattern": "^lvm\\s+vgextend($|\\s+)",
    "cmd": "lvm",
    "severity": "tip",
    "hint": "Use 'vgextend' to add new physical volumes to a volume group.",
    "detail": "The 'vgextend' command allows you to increase the storage capacity of a volume group by adding new physical volumes. This enables flexible, non-disruptive storage scaling.",
    "tags": [
      "lvm",
      "vg",
      "tip"
    ]
  },
  {
    "id": "disk-030",
    "pattern": "^lvextend\\s+.*--resizefs",
    "cmd": "lvextend",
    "severity": "tip",
    "hint": "Use '--resizefs' to auto-resize the filesystem after extending LV.",
    "detail": "The '--resizefs' flag (on some distros) automatically resizes the filesystem after logical volume extension, reducing manual steps and risk of mismatch.",
    "tags": [
      "lvm",
      "lv",
      "tip"
    ]
  },
  {
    "id": "disk-031",
    "pattern": "^lvremove\\s+(/dev/\\S+)",
    "cmd": "lvremove",
    "severity": "danger",
    "hint": "lvremove deletes a logical volume and all its data irreversibly.",
    "detail": "Removing a logical volume with lvremove destroys all data stored on it. There is no recovery unless you have backups or snapshots. Confirm the LV name carefully.",
    "tags": [
      "lvm",
      "lv",
      "danger"
    ]
  },
  {
    "id": "disk-032",
    "pattern": "^pvs($|\\s+)",
    "cmd": "pvs",
    "severity": "tip",
    "hint": "Use 'pvs -o+pv_used' to see used space per physical volume.",
    "detail": "The '-o+pv_used' option adds a column showing how much space is allocated on each physical volume, aiding in capacity planning.",
    "tags": [
      "lvm",
      "pvs",
      "tip"
    ]
  },
  {
    "id": "disk-033",
    "pattern": "^vgs($|\\s+)",
    "cmd": "vgs",
    "severity": "tip",
    "hint": "Use 'vgs -o+vg_free' to display free space in each volume group.",
    "detail": "The '-o+vg_free' flag adds a column for unallocated space, making it easy to see which VGs can be extended.",
    "tags": [
      "lvm",
      "vgs",
      "tip"
    ]
  },
  {
    "id": "disk-034",
    "pattern": "^lvs($|\\s+)",
    "cmd": "lvs",
    "severity": "tip",
    "hint": "Use 'lvs -a' to list all logical volumes, including hidden ones.",
    "detail": "The '-a' flag shows all LVs, including internal or hidden ones (such as snapshots), which are not shown by default. Useful for troubleshooting space issues.",
    "tags": [
      "lvm",
      "lvs",
      "tip"
    ]
  },
  {
    "id": "disk-035",
    "pattern": "^mkfs\\.ext4\\s+.*-E\\s+lazy_itable_init=0",
    "cmd": "mkfs.ext4",
    "severity": "tip",
    "hint": "Set '-E lazy_itable_init=0' for full inode table initialization.",
    "detail": "By default, mkfs.ext4 initializes inode tables lazily for speed. Disabling this with '-E lazy_itable_init=0' ensures all inode tables are zeroed immediately, which can be important for security or certain workloads.",
    "tags": [
      "mkfs",
      "ext4",
      "tip"
    ]
  },
  {
    "id": "disk-036",
    "pattern": "^mount\\s+.*-o\\s+noatime",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Use 'noatime' to reduce disk writes and improve performance.",
    "detail": "The 'noatime' mount option disables updating file access times on read, reducing unnecessary disk writes and improving performance, especially on SSDs and busy servers.",
    "tags": [
      "mount",
      "performance",
      "tip"
    ]
  },
  {
    "id": "disk-037",
    "pattern": "^du\\s+.*--exclude=.*",
    "cmd": "du",
    "severity": "tip",
    "hint": "Use '--exclude' to omit files/directories from du output.",
    "detail": "The '--exclude' flag allows you to skip specified files or directories, making it easier to focus on relevant data when analyzing disk usage.",
    "tags": [
      "du",
      "filter",
      "tip"
    ]
  },
  {
    "id": "disk-038",
    "pattern": "^lsblk\\s+.*-J",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Use '-J' to output lsblk results as JSON for scripting.",
    "detail": "The '-J' flag outputs lsblk data in JSON format, which is ideal for programmatic parsing and automation tasks.",
    "tags": [
      "lsblk",
      "json",
      "tip"
    ]
  },
  {
    "id": "disk-039",
    "pattern": "^findmnt($|\\s+)",
    "cmd": "findmnt",
    "severity": "upgrade",
    "hint": "Use 'findmnt' for modern, flexible mount info (better than mount/df).",
    "detail": "findmnt provides a tree view of all mounted filesystems, supports JSON output, and can filter by device, target, or source. It's more versatile than legacy 'mount' or 'df' for mount analysis.",
    "tags": [
      "findmnt",
      "upgrade",
      "mount"
    ]
  },
  {
    "id": "disk-040",
    "pattern": "^btrfs\\s+filesystem\\s+df\\s+(/\\S+)",
    "cmd": "btrfs",
    "severity": "tip",
    "hint": "Use 'btrfs filesystem df' for detailed space usage on Btrfs.",
    "detail": "This command shows how space is allocated for data, metadata, and system chunks, which is crucial for understanding Btrfs's unique allocation model.",
    "tags": [
      "btrfs",
      "filesystem",
      "tip"
    ]
  },
  {
    "id": "disk-041",
    "pattern": "^xfs_growfs\\s+(/\\S+)",
    "cmd": "xfs_growfs",
    "severity": "tip",
    "hint": "Use 'xfs_growfs' to expand an XFS filesystem online.",
    "detail": "xfs_growfs allows you to grow an XFS filesystem without unmounting, provided the underlying block device or LV has been extended. This is essential for minimal-downtime storage scaling.",
    "tags": [
      "xfs",
      "growfs",
      "tip"
    ]
  },
  {
    "id": "disk-042",
    "pattern": "^resize2fs\\s+(/dev/\\S+)",
    "cmd": "resize2fs",
    "severity": "tip",
    "hint": "Use 'resize2fs' after LV or partition resize to expand ext4/ext3.",
    "detail": "After increasing the size of a partition or logical volume, you must run 'resize2fs' to expand the filesystem and make new space available. It works online for ext4/ext3.",
    "tags": [
      "resize2fs",
      "ext4",
      "tip"
    ]
  },
  {
    "id": "disk-043",
    "pattern": "^mount\\s+.*-o\\s+ro",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Mount with '-o ro' for read-only access; useful for recovery.",
    "detail": "The 'ro' option mounts the filesystem read-only, preventing any writes. This is essential for forensic analysis or recovering data from damaged disks.",
    "tags": [
      "mount",
      "readonly",
      "tip"
    ]
  },
  {
    "id": "disk-044",
    "pattern": "^mount\\s+.*-o\\s+defaults",
    "cmd": "mount",
    "severity": "tip",
    "hint": "The 'defaults' option sets common mount flags; customize as needed.",
    "detail": "'defaults' includes rw, suid, dev, exec, auto, nouser, and async. For special needs (e.g., noatime, nodev), specify custom options instead.",
    "tags": [
      "mount",
      "defaults",
      "tip"
    ]
  },
  {
    "id": "disk-045",
    "pattern": "^mount\\s+.*-t\\s+tmpfs",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Use 'mount -t tmpfs' to create a RAM-backed temporary filesystem.",
    "detail": "tmpfs uses system RAM for storage, providing fast, ephemeral storage. Specify size with '-o size=1G' as needed. Data is lost on reboot.",
    "tags": [
      "mount",
      "tmpfs",
      "tip"
    ]
  },
  {
    "id": "disk-046",
    "pattern": "^mount\\s+.*-o\\s+discard",
    "cmd": "mount",
    "severity": "tip",
    "hint": "Use 'discard' for SSD TRIM support, but may impact performance.",
    "detail": "The 'discard' option enables TRIM on SSDs, allowing the OS to inform the device of unused blocks. On some SSDs, this can reduce performance; consider periodic fstrim instead.",
    "tags": [
      "mount",
      "ssd",
      "tip"
    ]
  },
  {
    "id": "disk-047",
    "pattern": "^lsblk\\s+.*-e\\s+7",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Use '-e 7' to exclude loop devices from lsblk output.",
    "detail": "The '-e' flag excludes devices by major number; 7 is for loop devices. This declutters output when many loop mounts are present (e.g., snaps, containers).",
    "tags": [
      "lsblk",
      "filter",
      "tip"
    ]
  },
  {
    "id": "disk-048",
    "pattern": "^du\\s+.*-x",
    "cmd": "du",
    "severity": "tip",
    "hint": "Use 'du -x' to stay within a single filesystem during scan.",
    "detail": "The '-x' flag prevents du from traversing directories on other filesystems (mountpoints), which is useful for analyzing usage of a specific partition.",
    "tags": [
      "du",
      "filesystem",
      "tip"
    ]
  },
  {
    "id": "disk-049",
    "pattern": "^lsblk\\s+.*-S",
    "cmd": "lsblk",
    "severity": "tip",
    "hint": "Use '-S' to list SCSI devices with model, vendor, and serial.",
    "detail": "The '-S' flag displays SCSI/SATA devices, showing hardware details like vendor, model, and serial number, which is useful for hardware inventory and troubleshooting.",
    "tags": [
      "lsblk",
      "hardware",
      "tip"
    ]
  },
  {
    "id": "disk-050",
    "pattern": "^find\\s+.*-size\\s+",
    "cmd": "find",
    "severity": "tip",
    "hint": "Use 'find -size +100M' to locate large files for cleanup.",
    "detail": "The '-size' flag lets you search for files by size. Use '+100M' for files over 100 MB. Combine with 'du' or 'xargs rm' for disk cleanup tasks.",
    "tags": [
      "find",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "users-001",
    "pattern": "^userdel\\s+-r\\s+root\\b",
    "cmd": "userdel",
    "severity": "danger",
    "hint": "Never delete the root user with userdel -r root.",
    "detail": "Deleting the root account with 'userdel -r root' will remove the superuser, potentially locking you out of system administration. Most distributions prevent this, but some misconfigurations or custom builds may allow it, causing irreversible system inaccessibility.",
    "tags": [
      "userdel",
      "root",
      "danger",
      "users"
    ]
  },
  {
    "id": "users-002",
    "pattern": "^useradd\\s+.*-u\\s+0\\b",
    "cmd": "useradd",
    "severity": "danger",
    "hint": "Avoid creating users with UID 0; only root should have UID 0.",
    "detail": "Assigning UID 0 to any user grants full root privileges, bypassing all user-based security. This is a critical security risk and can be exploited for privilege escalation. Always reserve UID 0 exclusively for the root account.",
    "tags": [
      "useradd",
      "uid",
      "security",
      "danger"
    ]
  },
  {
    "id": "users-003",
    "pattern": "^chmod\\s+-R\\s+777\\b",
    "cmd": "chmod",
    "severity": "danger",
    "hint": "Never recursively set permissions to 777; use least privilege.",
    "detail": "Running 'chmod -R 777' grants all users read, write, and execute access, which can lead to data tampering or accidental deletion. This is especially risky on web servers or shared directories. Use more restrictive permissions and only as needed.",
    "tags": [
      "chmod",
      "permissions",
      "danger",
      "recursion"
    ]
  },
  {
    "id": "users-004",
    "pattern": "^passwd\\s+--stdin\\s+\\w+",
    "cmd": "passwd",
    "severity": "warn",
    "hint": "Avoid using passwd --stdin; it exposes passwords to process list.",
    "detail": "The '--stdin' flag reads the password from standard input, which can be visible to other users via process inspection tools like 'ps'. Prefer interactive password setting or secure automation via tools like 'chpasswd' with proper permissions.",
    "tags": [
      "passwd",
      "stdin",
      "security",
      "warn"
    ]
  },
  {
    "id": "users-005",
    "pattern": "^sudo\\s+su\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "Use sudo -i for a root login shell instead of sudo su.",
    "detail": "'sudo su' spawns a new shell as root but may not preserve the environment as expected. 'sudo -i' simulates a full root login, loading root's environment and profile scripts, which is more predictable and secure.",
    "tags": [
      "sudo",
      "su",
      "shell",
      "tip"
    ]
  },
  {
    "id": "users-006",
    "pattern": "^chmod\\s+\\d{3,4}\\s+/",
    "cmd": "chmod",
    "severity": "danger",
    "hint": "Never change permissions of / or system dirs with chmod.",
    "detail": "Running chmod on / or system directories can break system functionality, causing boot failures or locking out users. Always double-check the target path before applying chmod, especially with absolute paths.",
    "tags": [
      "chmod",
      "filesystem",
      "danger",
      "permissions"
    ]
  },
  {
    "id": "users-007",
    "pattern": "^useradd\\s+.*-m\\b",
    "cmd": "useradd",
    "severity": "tip",
    "hint": "Use -m to create a home directory if not created by default.",
    "detail": "Some distributions do not create a home directory by default with useradd. The '-m' flag ensures a home directory is created, copying skeleton files from /etc/skel. Omitting it may result in login failures or missing user environments.",
    "tags": [
      "useradd",
      "home",
      "tip"
    ]
  },
  {
    "id": "users-008",
    "pattern": "^usermod\\s+-L\\s+root\\b",
    "cmd": "usermod",
    "severity": "danger",
    "hint": "Never lock the root account with usermod -L root.",
    "detail": "Locking the root account disables password-based root logins, which can prevent emergency recovery if sudo fails or no other admin accounts exist. Always ensure alternative privileged access before locking root.",
    "tags": [
      "usermod",
      "root",
      "danger",
      "lock"
    ]
  },
  {
    "id": "users-009",
    "pattern": "^passwd\\s+-d\\s+\\w+",
    "cmd": "passwd",
    "severity": "warn",
    "hint": "passwd -d deletes password, allowing empty password login.",
    "detail": "Using 'passwd -d' removes the password for the user, which may allow passwordless logins depending on PAM and SSH configuration. This can be a major security risk on multi-user or networked systems.",
    "tags": [
      "passwd",
      "security",
      "warn"
    ]
  },
  {
    "id": "users-010",
    "pattern": "^sudo\\s+-s\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "Use sudo -i for a full root login shell, not just -s.",
    "detail": "'sudo -s' starts a shell as root but does not load root's environment or profile scripts. 'sudo -i' simulates a login shell, ensuring environment variables and profiles are sourced for consistency.",
    "tags": [
      "sudo",
      "shell",
      "tip"
    ]
  },
  {
    "id": "users-011",
    "pattern": "^useradd\\s+.*-N\\b",
    "cmd": "useradd",
    "severity": "tip",
    "hint": "Use -N to prevent useradd from creating a group per user.",
    "detail": "By default, useradd may create a group with the same name as the user. The '-N' flag disables this, which is useful in environments where group management is handled separately or for legacy compatibility.",
    "tags": [
      "useradd",
      "groups",
      "tip"
    ]
  },
  {
    "id": "users-012",
    "pattern": "^chmod\\s+.*[0246][0246][0246]\\b",
    "cmd": "chmod",
    "severity": "warn",
    "hint": "Even permissions (e.g., 666) allow write without execute\u2014be careful.",
    "detail": "Permissions like 666 allow anyone to write to files but not execute them. This can be a security risk, especially for scripts or binaries. Always verify the required permissions and restrict write access where possible.",
    "tags": [
      "chmod",
      "permissions",
      "warn"
    ]
  },
  {
    "id": "users-013",
    "pattern": "^chown\\s+-R\\s+\\w+:\\w*\\s+/",
    "cmd": "chown",
    "severity": "danger",
    "hint": "Never recursively chown / or system dirs; restrict scope.",
    "detail": "Recursively changing ownership on / or system directories can break system services, daemons, and package management. Always specify the precise target directory and avoid running chown -R on system paths.",
    "tags": [
      "chown",
      "danger",
      "recursion"
    ]
  },
  {
    "id": "users-014",
    "pattern": "^chmod\\s+.*-R\\s+.*",
    "cmd": "chmod",
    "severity": "warn",
    "hint": "Be cautious with chmod -R; verify target path and permissions.",
    "detail": "Recursive chmod can unintentionally alter permissions on files and subdirectories, potentially exposing sensitive data or breaking applications. Always double-check the path and intended permission bits before running.",
    "tags": [
      "chmod",
      "permissions",
      "warn",
      "recursion"
    ]
  },
  {
    "id": "users-015",
    "pattern": "^useradd\\s+.*-e\\s+\\d{4}-\\d{2}-\\d{2}\\b",
    "cmd": "useradd",
    "severity": "tip",
    "hint": "Use -e to set account expiration date for temporary users.",
    "detail": "The '-e' flag sets an account expiration date in YYYY-MM-DD format. This is useful for contractors or temporary accounts, ensuring they are disabled automatically without manual intervention.",
    "tags": [
      "useradd",
      "expiration",
      "tip"
    ]
  },
  {
    "id": "users-016",
    "pattern": "^passwd\\s+-l\\s+root\\b",
    "cmd": "passwd",
    "severity": "danger",
    "hint": "Never lock the root password with passwd -l root.",
    "detail": "Locking the root password disables root logins, which can prevent system recovery if no other admin account is available. Always ensure alternative privileged access before locking root.",
    "tags": [
      "passwd",
      "root",
      "danger"
    ]
  },
  {
    "id": "users-017",
    "pattern": "^sudo\\s+.*-E\\b",
    "cmd": "sudo",
    "severity": "warn",
    "hint": "sudo -E preserves user environment; can leak sensitive vars.",
    "detail": "The '-E' flag passes the user's environment to the command, which may include sensitive variables like PATH, LD_LIBRARY_PATH, or credentials. This can introduce security risks if the environment is not sanitized.",
    "tags": [
      "sudo",
      "environment",
      "warn"
    ]
  },
  {
    "id": "users-018",
    "pattern": "^chmod\\s+.*\\+s\\b",
    "cmd": "chmod",
    "severity": "warn",
    "hint": "Setting the setuid/setgid bit can allow privilege escalation.",
    "detail": "The '+s' flag sets the setuid or setgid bit, causing executables to run with the file owner's privileges. This can be exploited if set on scripts or binaries with vulnerabilities. Only use on trusted binaries and review permissions regularly.",
    "tags": [
      "chmod",
      "setuid",
      "warn"
    ]
  },
  {
    "id": "users-019",
    "pattern": "^setfacl\\s+-m\\s+u:.*:rwx\\s+/",
    "cmd": "setfacl",
    "severity": "danger",
    "hint": "Never grant full ACL permissions recursively on /.",
    "detail": "Applying ACLs with full permissions to the root directory can expose the entire filesystem to unauthorized access. Always restrict ACL changes to specific directories and users.",
    "tags": [
      "setfacl",
      "acl",
      "danger"
    ]
  },
  {
    "id": "users-020",
    "pattern": "^umask\\s+000\\b",
    "cmd": "umask",
    "severity": "danger",
    "hint": "Never set umask to 000; files will be world-writable.",
    "detail": "A umask of 000 removes all default permission restrictions, causing all newly created files and directories to be readable and writable by any user. This is a severe security risk.",
    "tags": [
      "umask",
      "permissions",
      "danger"
    ]
  },
  {
    "id": "users-021",
    "pattern": "^chown\\s+.*:.*\\s+/",
    "cmd": "chown",
    "severity": "warn",
    "hint": "Avoid changing group ownership of / or system dirs.",
    "detail": "Changing group ownership on system directories can break service permissions and system integrity. Always target specific directories and verify group assignments before applying chown.",
    "tags": [
      "chown",
      "permissions",
      "warn"
    ]
  },
  {
    "id": "users-022",
    "pattern": "^sudo\\s+.*-u\\s+\\w+\\s+-i\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "sudo -u user -i simulates a full login shell for another user.",
    "detail": "The '-u user -i' combination runs a login shell as the specified user, loading their environment and profile scripts. This is useful for debugging user-specific issues or testing environment configurations.",
    "tags": [
      "sudo",
      "shell",
      "tip"
    ]
  },
  {
    "id": "users-023",
    "pattern": "^userdel\\s+.*-r\\s+\\w+",
    "cmd": "userdel",
    "severity": "warn",
    "hint": "userdel -r deletes home and mail; backup important data first.",
    "detail": "The '-r' flag removes the user's home directory and mail spool in addition to the account. Always ensure critical data is backed up before deleting users with this option.",
    "tags": [
      "userdel",
      "data loss",
      "warn"
    ]
  },
  {
    "id": "users-024",
    "pattern": "^chmod\\s+.*--reference=.*\\b",
    "cmd": "chmod",
    "severity": "tip",
    "hint": "Use --reference to copy permissions from another file.",
    "detail": "The '--reference=FILE' flag sets permissions to match those of the specified file, ensuring consistency across files or directories. This is useful for bulk permission corrections without manually specifying modes.",
    "tags": [
      "chmod",
      "permissions",
      "tip"
    ]
  },
  {
    "id": "users-025",
    "pattern": "^setfacl\\s+-b\\s+.*",
    "cmd": "setfacl",
    "severity": "warn",
    "hint": "setfacl -b removes all ACLs; verify before running.",
    "detail": "The '-b' flag removes all extended ACL entries from a file or directory, reverting to standard permissions. This can inadvertently revoke access for users or groups relying on ACLs.",
    "tags": [
      "setfacl",
      "acl",
      "warn"
    ]
  },
  {
    "id": "users-026",
    "pattern": "^chown\\s+.*--from=.*\\b",
    "cmd": "chown",
    "severity": "tip",
    "hint": "Use --from to conditionally change ownership only if matched.",
    "detail": "The '--from=CURRENT_OWNER:CURRENT_GROUP' flag changes ownership only if the file currently matches the specified owner and group. This prevents accidental ownership changes and is useful in scripts.",
    "tags": [
      "chown",
      "ownership",
      "tip"
    ]
  },
  {
    "id": "users-027",
    "pattern": "^chmod\\s+.*--preserve-root\\b",
    "cmd": "chmod",
    "severity": "tip",
    "hint": "Use --preserve-root to prevent chmod from acting on /.",
    "detail": "The '--preserve-root' flag protects against accidental permission changes on the root directory. This is especially important when running recursive operations as root.",
    "tags": [
      "chmod",
      "safety",
      "tip"
    ]
  },
  {
    "id": "users-028",
    "pattern": "^getfacl\\s+.*",
    "cmd": "getfacl",
    "severity": "tip",
    "hint": "Use getfacl to audit complex permissions and troubleshoot access.",
    "detail": "getfacl displays all ACL entries for files and directories, including default and extended permissions. This is essential for diagnosing access issues not explained by standard Unix permissions.",
    "tags": [
      "getfacl",
      "acl",
      "tip"
    ]
  },
  {
    "id": "users-029",
    "pattern": "^chmod\\s+.*-R\\s+.*\\s+--preserve-root\\b",
    "cmd": "chmod",
    "severity": "tip",
    "hint": "Combine -R with --preserve-root to avoid root directory changes.",
    "detail": "When running recursive chmod, '--preserve-root' ensures that the root directory is not affected, reducing the risk of catastrophic permission changes. Always use this flag in scripts or automation.",
    "tags": [
      "chmod",
      "recursion",
      "tip"
    ]
  },
  {
    "id": "users-030",
    "pattern": "^umask\\s+.*",
    "cmd": "umask",
    "severity": "tip",
    "hint": "Set umask to 027 for secure default file permissions.",
    "detail": "A umask of 027 ensures new files are not world-readable or writable, providing a good balance between usability and security. Adjust as needed for your environment's requirements.",
    "tags": [
      "umask",
      "permissions",
      "tip"
    ]
  },
  {
    "id": "users-031",
    "pattern": "^sudoedit\\s+.*",
    "cmd": "sudoedit",
    "severity": "tip",
    "hint": "Use sudoedit to safely edit files as root without shell access.",
    "detail": "sudoedit opens files with elevated privileges using the user's editor, without granting a root shell. This minimizes the risk of shell-based privilege escalation and logs the edit operation.",
    "tags": [
      "sudoedit",
      "security",
      "tip"
    ]
  },
  {
    "id": "users-032",
    "pattern": "^passwd\\s+-e\\s+\\w+",
    "cmd": "passwd",
    "severity": "tip",
    "hint": "passwd -e expires a password immediately, forcing reset.",
    "detail": "The '-e' flag marks the user's password as expired, requiring them to set a new password at next login. This is useful for onboarding or security resets.",
    "tags": [
      "passwd",
      "expiration",
      "tip"
    ]
  },
  {
    "id": "users-033",
    "pattern": "^usermod\\s+-a\\s+-G\\s+\\w+\\s+\\w+",
    "cmd": "usermod",
    "severity": "tip",
    "hint": "Always use -a with -G to append groups, not overwrite.",
    "detail": "Without '-a', the '-G' flag replaces all supplementary groups for the user. Always combine '-a' with '-G' to add the user to additional groups without removing existing memberships.",
    "tags": [
      "usermod",
      "groups",
      "tip"
    ]
  },
  {
    "id": "users-034",
    "pattern": "^chgrp\\s+-R\\s+\\w+\\s+/",
    "cmd": "chgrp",
    "severity": "danger",
    "hint": "Never recursively change group on / or system dirs.",
    "detail": "Recursively changing group ownership on system directories can break access for services and users. Always specify a safe target and avoid running chgrp -R on system paths.",
    "tags": [
      "chgrp",
      "danger",
      "recursion"
    ]
  },
  {
    "id": "users-035",
    "pattern": "^sudo\\s+visudo\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "Use visudo to safely edit the sudoers file with syntax checking.",
    "detail": "visudo locks the sudoers file and checks for syntax errors before saving changes, preventing misconfigurations that could lock out all sudo access. Always use visudo instead of editing /etc/sudoers directly.",
    "tags": [
      "sudo",
      "visudo",
      "tip"
    ]
  },
  {
    "id": "users-036",
    "pattern": "^setfacl\\s+-k\\s+.*",
    "cmd": "setfacl",
    "severity": "warn",
    "hint": "setfacl -k removes default ACLs; may affect new files.",
    "detail": "The '-k' flag deletes default ACLs, which control permissions for newly created files and directories. This can unintentionally restrict access for users or groups expecting inherited permissions.",
    "tags": [
      "setfacl",
      "acl",
      "warn"
    ]
  },
  {
    "id": "users-037",
    "pattern": "^passwd\\s+--status\\s+\\w+",
    "cmd": "passwd",
    "severity": "tip",
    "hint": "Use passwd --status to check account and password status.",
    "detail": "The '--status' flag displays the account's password state, including whether it is locked, expired, or has no password. Useful for auditing user accounts and troubleshooting login issues.",
    "tags": [
      "passwd",
      "audit",
      "tip"
    ]
  },
  {
    "id": "users-038",
    "pattern": "^sudo\\s+-l\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "Use sudo -l to list allowed commands for your user.",
    "detail": "'sudo -l' displays the commands and privileges granted to the current user, as defined in the sudoers file. This is useful for debugging permission issues or verifying sudo access.",
    "tags": [
      "sudo",
      "audit",
      "tip"
    ]
  },
  {
    "id": "users-039",
    "pattern": "^chmod\\s+.*-c\\b",
    "cmd": "chmod",
    "severity": "tip",
    "hint": "Use -c to show only files whose permissions actually change.",
    "detail": "The '-c' (changes) flag prints output only for files whose permissions are modified, reducing noise in scripts or bulk operations. Useful for tracking permission changes.",
    "tags": [
      "chmod",
      "output",
      "tip"
    ]
  },
  {
    "id": "users-040",
    "pattern": "^sudo\\s+.*-g\\s+\\w+\\b",
    "cmd": "sudo",
    "severity": "tip",
    "hint": "Use sudo -g to run commands with a different group ID.",
    "detail": "The '-g' flag allows you to specify a group to run the command as, which is useful for testing group-based permissions or running processes under specific group contexts.",
    "tags": [
      "sudo",
      "group",
      "tip"
    ]
  },
  {
    "id": "network-001",
    "pattern": "^curl\\s+-k(\\s|$)",
    "cmd": "curl",
    "severity": "danger",
    "hint": "Avoid using -k with curl; disables SSL certificate validation.",
    "detail": "The -k or --insecure flag tells curl to ignore SSL certificate validation, exposing you to man-in-the-middle attacks. Only use this in trusted, controlled environments. For production or sensitive data, always validate certificates.",
    "tags": [
      "curl",
      "ssl",
      "security"
    ]
  },
  {
    "id": "network-002",
    "pattern": "^wget\\s+--no-check-certificate(\\s|$)",
    "cmd": "wget",
    "severity": "danger",
    "hint": "Don't use --no-check-certificate unless absolutely necessary.",
    "detail": "The --no-check-certificate flag disables SSL/TLS certificate verification, making downloads vulnerable to interception. Use this only for internal or test servers, and never for production or sensitive data.",
    "tags": [
      "wget",
      "ssl",
      "security"
    ]
  },
  {
    "id": "network-003",
    "pattern": "^ssh\\s+.+@.+\\s+-o\\s+StrictHostKeyChecking=no",
    "cmd": "ssh",
    "severity": "danger",
    "hint": "Avoid StrictHostKeyChecking=no; exposes to MITM attacks.",
    "detail": "Disabling StrictHostKeyChecking means SSH will auto-accept any host key, making you vulnerable to man-in-the-middle attacks. Use this only for automation in trusted networks, and never for production logins.",
    "tags": [
      "ssh",
      "security",
      "automation"
    ]
  },
  {
    "id": "network-004",
    "pattern": "^scp\\s+.+\\s+.+",
    "cmd": "scp",
    "severity": "upgrade",
    "hint": "Use rsync or sftp instead of scp for secure, resumable transfers.",
    "detail": "scp does not support resuming interrupted transfers and has known security issues. rsync and sftp provide better performance, resume capability, and more robust error handling.",
    "tags": [
      "scp",
      "rsync",
      "sftp",
      "upgrade"
    ]
  },
  {
    "id": "network-005",
    "pattern": "^rsync\\s+.+\\s+.+",
    "cmd": "rsync",
    "severity": "tip",
    "hint": "Add -z to rsync for compression over slow links.",
    "detail": "The -z flag enables compression during transfer, significantly reducing bandwidth usage on slow or high-latency connections. This is especially useful for large files or many small files.",
    "tags": [
      "rsync",
      "performance",
      "compression"
    ]
  },
  {
    "id": "network-006",
    "pattern": "^rsync\\s+[^-]*$",
    "cmd": "rsync",
    "severity": "tip",
    "hint": "Use -a for archive mode to preserve permissions and timestamps.",
    "detail": "The -a (archive) flag combines several options to preserve symbolic links, permissions, ownership, and timestamps. It's the recommended default for most backup or mirroring tasks.",
    "tags": [
      "rsync",
      "permissions",
      "backup"
    ]
  },
  {
    "id": "network-007",
    "pattern": "^netstat\\s+",
    "cmd": "netstat",
    "severity": "upgrade",
    "hint": "Use ss instead of netstat for faster, more detailed output.",
    "detail": "ss is a modern replacement for netstat, providing more detailed socket statistics and faster execution. netstat is deprecated on many systems and may not show all socket states.",
    "tags": [
      "netstat",
      "ss",
      "upgrade"
    ]
  },
  {
    "id": "network-008",
    "pattern": "^ss\\s+",
    "cmd": "ss",
    "severity": "tip",
    "hint": "Use ss -tulwn to list all listening TCP/UDP ports with details.",
    "detail": "The -tulwn flags show TCP/UDP sockets, listening state, numeric addresses, and disables DNS lookups for speed. This is the most efficient way to audit open ports.",
    "tags": [
      "ss",
      "ports",
      "audit"
    ]
  },
  {
    "id": "network-009",
    "pattern": "^ifconfig\\s+",
    "cmd": "ifconfig",
    "severity": "upgrade",
    "hint": "Use ip addr instead of ifconfig; it's more modern and supported.",
    "detail": "ifconfig is deprecated on most Linux distributions. ip addr provides more detailed and accurate information about interfaces and supports modern networking features.",
    "tags": [
      "ifconfig",
      "ip",
      "upgrade"
    ]
  },
  {
    "id": "network-010",
    "pattern": "^route\\s+",
    "cmd": "route",
    "severity": "upgrade",
    "hint": "Use ip route instead of route for modern routing management.",
    "detail": "The ip route command replaces route, offering better syntax, more features, and compatibility with modern Linux networking stacks. route may not show all routing table entries on newer systems.",
    "tags": [
      "route",
      "ip",
      "upgrade"
    ]
  },
  {
    "id": "network-011",
    "pattern": "^dig\\s+",
    "cmd": "dig",
    "severity": "tip",
    "hint": "Use +short with dig for concise, script-friendly output.",
    "detail": "The +short flag outputs only the answer section, omitting headers and comments, making it ideal for scripting and quick lookups.",
    "tags": [
      "dig",
      "dns",
      "scripting"
    ]
  },
  {
    "id": "network-012",
    "pattern": "^nslookup\\s+",
    "cmd": "nslookup",
    "severity": "upgrade",
    "hint": "Use dig instead of nslookup for more detailed DNS queries.",
    "detail": "nslookup is deprecated and lacks many features present in dig, such as support for DNSSEC and advanced query options. dig is the preferred tool for DNS troubleshooting.",
    "tags": [
      "nslookup",
      "dig",
      "upgrade"
    ]
  },
  {
    "id": "network-013",
    "pattern": "^ping\\s+",
    "cmd": "ping",
    "severity": "tip",
    "hint": "Use -c to limit ping count and avoid endless output.",
    "detail": "By default, ping runs indefinitely on Linux. The -c flag lets you specify the number of packets to send, which is safer for scripting and prevents accidental flooding.",
    "tags": [
      "ping",
      "scripting",
      "safety"
    ]
  },
  {
    "id": "network-014",
    "pattern": "^traceroute\\s+",
    "cmd": "traceroute",
    "severity": "tip",
    "hint": "Use -I to force ICMP echo probes for firewall-friendly tracing.",
    "detail": "Some networks block UDP probes (the default for traceroute). The -I flag switches to ICMP, which is more likely to pass through firewalls and yield accurate results.",
    "tags": [
      "traceroute",
      "icmp",
      "firewall"
    ]
  },
  {
    "id": "network-015",
    "pattern": "^mtr\\s+",
    "cmd": "mtr",
    "severity": "tip",
    "hint": "Use -rw for report mode; suitable for non-interactive environments.",
    "detail": "The -rw flags make mtr run in report mode, printing results to stdout and exiting. This is ideal for automation or logging, as opposed to the default interactive mode.",
    "tags": [
      "mtr",
      "automation",
      "report"
    ]
  },
  {
    "id": "network-016",
    "pattern": "^nmap\\s+",
    "cmd": "nmap",
    "severity": "tip",
    "hint": "Add -T4 to nmap for faster scans on reliable networks.",
    "detail": "The -T4 timing template speeds up scanning by reducing wait times, suitable for local or trusted networks. Be cautious on unstable or remote networks, as this may cause packet loss or incomplete results.",
    "tags": [
      "nmap",
      "performance",
      "scanning"
    ]
  },
  {
    "id": "network-017",
    "pattern": "^nmap\\s+.+-A",
    "cmd": "nmap",
    "severity": "warn",
    "hint": "Avoid -A on production; enables intrusive scanning features.",
    "detail": "The -A flag enables OS detection, version detection, script scanning, and traceroute, which can be disruptive or trigger security alerts. Use with caution, especially against production systems.",
    "tags": [
      "nmap",
      "security",
      "intrusive"
    ]
  },
  {
    "id": "network-018",
    "pattern": "^tcpdump\\s+",
    "cmd": "tcpdump",
    "severity": "tip",
    "hint": "Use -n to disable DNS lookups for faster tcpdump output.",
    "detail": "The -n flag prevents tcpdump from resolving IP addresses to hostnames, significantly speeding up capture and reducing noise in logs, especially on busy networks.",
    "tags": [
      "tcpdump",
      "performance",
      "dns"
    ]
  },
  {
    "id": "network-019",
    "pattern": "^tcpdump\\s+.+-w\\s+.+",
    "cmd": "tcpdump",
    "severity": "warn",
    "hint": "Always use -U with -w to flush packets to disk in real time.",
    "detail": "By default, tcpdump buffers output when writing to a file with -w, risking data loss if interrupted. The -U flag forces packet data to be written immediately, improving reliability for long captures.",
    "tags": [
      "tcpdump",
      "capture",
      "reliability"
    ]
  },
  {
    "id": "network-020",
    "pattern": "^nc\\s+",
    "cmd": "nc",
    "severity": "tip",
    "hint": "Use -v for verbose output to debug connection issues.",
    "detail": "The -v flag provides detailed connection status, including errors and handshake progress, which is invaluable for debugging network connectivity problems.",
    "tags": [
      "nc",
      "debug",
      "connectivity"
    ]
  },
  {
    "id": "network-021",
    "pattern": "^nc\\s+.+-l(\\s|$)",
    "cmd": "nc",
    "severity": "warn",
    "hint": "Add -k to nc -l to keep listening after a client disconnects.",
    "detail": "Without -k, nc in listen mode (-l) will exit after a single connection. The -k flag keeps the listener running, making it suitable for repeated connections.",
    "tags": [
      "nc",
      "listen",
      "server"
    ]
  },
  {
    "id": "network-022",
    "pattern": "^socat\\s+",
    "cmd": "socat",
    "severity": "tip",
    "hint": "Use -d -d for double debug output in socat troubleshooting.",
    "detail": "The -d -d flags increase verbosity, showing detailed information about socket creation, data transfer, and errors. This is essential for diagnosing complex network relay setups.",
    "tags": [
      "socat",
      "debug",
      "troubleshooting"
    ]
  },
  {
    "id": "network-023",
    "pattern": "^curl\\s+.+--compressed",
    "cmd": "curl",
    "severity": "tip",
    "hint": "Use --compressed to request and handle compressed HTTP responses.",
    "detail": "The --compressed flag tells curl to send Accept-Encoding headers and automatically decompress responses. This reduces bandwidth and speeds up large downloads from servers supporting compression.",
    "tags": [
      "curl",
      "compression",
      "performance"
    ]
  },
  {
    "id": "network-024",
    "pattern": "^wget\\s+.+--mirror",
    "cmd": "wget",
    "severity": "tip",
    "hint": "Combine --mirror with --convert-links for offline browsing.",
    "detail": "The --convert-links flag rewrites links in downloaded HTML files to work locally, making mirrored sites fully navigable offline. This is essential for accurate site mirroring.",
    "tags": [
      "wget",
      "mirror",
      "offline"
    ]
  },
  {
    "id": "network-025",
    "pattern": "^ssh\\s+.+-A(\\s|$)",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Avoid -A unless needed; agent forwarding can leak credentials.",
    "detail": "Agent forwarding (-A) allows remote hosts to use your SSH keys, which can be hijacked if the remote host is compromised. Only use this with trusted hosts and never on shared or untrusted systems.",
    "tags": [
      "ssh",
      "security",
      "agent"
    ]
  },
  {
    "id": "network-026",
    "pattern": "^scp\\s+.+\\s+.+\\s+-r",
    "cmd": "scp",
    "severity": "tip",
    "hint": "Use -C with -r to compress recursive scp transfers.",
    "detail": "The -C flag enables compression, which can significantly speed up recursive directory transfers over slow links. This is especially effective for text-heavy directories.",
    "tags": [
      "scp",
      "compression",
      "performance"
    ]
  },
  {
    "id": "network-027",
    "pattern": "^rsync\\s+.+--delete",
    "cmd": "rsync",
    "severity": "danger",
    "hint": "Double-check --delete; it removes files not present in source.",
    "detail": "The --delete flag causes rsync to remove files from the destination that are not present in the source. This is irreversible and can lead to data loss if used incorrectly. Always test with --dry-run first.",
    "tags": [
      "rsync",
      "delete",
      "data-loss"
    ]
  },
  {
    "id": "network-028",
    "pattern": "^ip\\s+addr\\s+add\\s+.+",
    "cmd": "ip",
    "severity": "warn",
    "hint": "Changes with ip addr add are not persistent across reboots.",
    "detail": "ip addr add modifies the runtime interface configuration only. To make changes persistent, update your network configuration files or use your distribution's network manager.",
    "tags": [
      "ip",
      "networking",
      "persistence"
    ]
  },
  {
    "id": "network-029",
    "pattern": "^ping\\s+.+-f(\\s|$)",
    "cmd": "ping",
    "severity": "danger",
    "hint": "Avoid -f (flood) ping; can overwhelm networks and trigger alarms.",
    "detail": "The -f flag sends packets as fast as possible, which can saturate network links and is often interpreted as a denial-of-service attack. Use only for controlled testing on private networks.",
    "tags": [
      "ping",
      "flood",
      "danger"
    ]
  },
  {
    "id": "network-030",
    "pattern": "^traceroute\\s+.+-T(\\s|$)",
    "cmd": "traceroute",
    "severity": "tip",
    "hint": "Use -T for TCP probes to trace through firewalls.",
    "detail": "The -T flag sends TCP SYN packets, which are less likely to be blocked by firewalls than default UDP or ICMP probes. This helps trace routes to web servers and other TCP services.",
    "tags": [
      "traceroute",
      "tcp",
      "firewall"
    ]
  },
  {
    "id": "network-031",
    "pattern": "^nmap\\s+.+-Pn",
    "cmd": "nmap",
    "severity": "warn",
    "hint": "Using -Pn skips host discovery; may waste time on offline hosts.",
    "detail": "The -Pn flag disables host discovery, treating all targets as online. This can slow down scans significantly if many targets are unreachable. Use only when necessary, such as when ICMP is blocked.",
    "tags": [
      "nmap",
      "discovery",
      "performance"
    ]
  },
  {
    "id": "network-032",
    "pattern": "^tcpdump\\s+.+-s\\s+0",
    "cmd": "tcpdump",
    "severity": "tip",
    "hint": "Use -s 0 to capture full packets, not just headers.",
    "detail": "By default, tcpdump captures only the first 262144 bytes (or less, depending on version) of each packet. -s 0 ensures the entire packet is captured, which is necessary for deep protocol analysis.",
    "tags": [
      "tcpdump",
      "capture",
      "analysis"
    ]
  },
  {
    "id": "network-033",
    "pattern": "^nc\\s+.+-e\\s+",
    "cmd": "nc",
    "severity": "danger",
    "hint": "Never use -e with nc; it enables remote shell execution.",
    "detail": "The -e flag executes a program after connection, often used for reverse shells. This is a major security risk and is disabled in many netcat versions. Avoid using -e except in controlled, secure environments.",
    "tags": [
      "nc",
      "security",
      "shell"
    ]
  },
  {
    "id": "network-034",
    "pattern": "^socat\\s+.+OPENSSL:",
    "cmd": "socat",
    "severity": "warn",
    "hint": "Specify verify=1 for socat OPENSSL to enforce certificate checks.",
    "detail": "By default, socat's OPENSSL client does not verify server certificates, exposing you to MITM attacks. Add verify=1 to require certificate validation.",
    "tags": [
      "socat",
      "openssl",
      "security"
    ]
  },
  {
    "id": "network-035",
    "pattern": "^curl\\s+.+-L",
    "cmd": "curl",
    "severity": "tip",
    "hint": "Use -L to follow HTTP redirects automatically.",
    "detail": "The -L flag tells curl to follow HTTP 3xx redirects. Without it, curl will only fetch the initial response, which may not be the actual content you want.",
    "tags": [
      "curl",
      "redirect",
      "http"
    ]
  },
  {
    "id": "network-036",
    "pattern": "^wget\\s+.+-c",
    "cmd": "wget",
    "severity": "tip",
    "hint": "Use -c to resume interrupted wget downloads.",
    "detail": "The -c (continue) flag allows wget to resume partially downloaded files, saving bandwidth and time if a download is interrupted.",
    "tags": [
      "wget",
      "resume",
      "download"
    ]
  },
  {
    "id": "network-037",
    "pattern": "^ssh\\s+.+-X",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Avoid -X unless needed; X11 forwarding can be a security risk.",
    "detail": "X11 forwarding (-X) allows remote applications to display on your local machine, but can be exploited to capture keystrokes or access your X session. Use only with trusted hosts.",
    "tags": [
      "ssh",
      "x11",
      "security"
    ]
  },
  {
    "id": "network-038",
    "pattern": "^scp\\s+.+\\s+.+\\s+-P\\s+",
    "cmd": "scp",
    "severity": "tip",
    "hint": "Use -P (uppercase) for port; lowercase -p preserves timestamps.",
    "detail": "scp uses -P (uppercase) to specify the port, while -p (lowercase) preserves file timestamps and modes. Mixing these up can cause unexpected behavior.",
    "tags": [
      "scp",
      "port",
      "timestamp"
    ]
  },
  {
    "id": "network-039",
    "pattern": "^rsync\\s+.+--bwlimit=",
    "cmd": "rsync",
    "severity": "tip",
    "hint": "Set --bwlimit to throttle rsync and avoid saturating links.",
    "detail": "The --bwlimit flag limits the bandwidth used by rsync, which is useful when syncing over slow or shared connections to prevent network congestion.",
    "tags": [
      "rsync",
      "bandwidth",
      "performance"
    ]
  },
  {
    "id": "network-040",
    "pattern": "^ip\\s+link\\s+set\\s+.+\\s+down",
    "cmd": "ip",
    "severity": "warn",
    "hint": "ip link set down disables the interface immediately.",
    "detail": "Bringing an interface down with ip link set disables all traffic instantly, possibly breaking SSH or remote sessions. Ensure you have alternate access before running this on remote systems.",
    "tags": [
      "ip",
      "interface",
      "danger"
    ]
  },
  {
    "id": "network-041",
    "pattern": "^dig\\s+.+@8\\.8\\.8\\.8",
    "cmd": "dig",
    "severity": "tip",
    "hint": "Use @server syntax to query a specific DNS resolver.",
    "detail": "Specifying a DNS server with @ lets you test resolution from different points in the network, which is useful for troubleshooting DNS propagation or resolver issues.",
    "tags": [
      "dig",
      "dns",
      "resolver"
    ]
  },
  {
    "id": "network-042",
    "pattern": "^nslookup\\s+.+8\\.8\\.8\\.8",
    "cmd": "nslookup",
    "severity": "tip",
    "hint": "Specify a DNS server as the second argument for targeted queries.",
    "detail": "nslookup allows you to specify the DNS server after the hostname, which is useful for checking how different resolvers respond to the same query.",
    "tags": [
      "nslookup",
      "dns",
      "resolver"
    ]
  },
  {
    "id": "network-043",
    "pattern": "^ping\\s+.+-s\\s+\\d+",
    "cmd": "ping",
    "severity": "tip",
    "hint": "Use -s to set packet size for MTU/path testing.",
    "detail": "The -s flag sets the ICMP payload size, which helps diagnose MTU issues or test fragmentation on the network path.",
    "tags": [
      "ping",
      "mtu",
      "diagnostics"
    ]
  },
  {
    "id": "network-044",
    "pattern": "^traceroute\\s+.+-m\\s+\\d+",
    "cmd": "traceroute",
    "severity": "tip",
    "hint": "Use -m to limit max hops and speed up traceroute results.",
    "detail": "The -m flag sets the maximum TTL (hop count), reducing unnecessary probes and making traceroute faster when you know the approximate network distance.",
    "tags": [
      "traceroute",
      "ttl",
      "performance"
    ]
  },
  {
    "id": "network-045",
    "pattern": "^mtr\\s+.+--report-cycles\\s+\\d+",
    "cmd": "mtr",
    "severity": "tip",
    "hint": "Set --report-cycles for controlled, repeatable mtr reports.",
    "detail": "The --report-cycles flag specifies how many cycles to run before printing the report, making results more consistent and suitable for automated monitoring.",
    "tags": [
      "mtr",
      "report",
      "automation"
    ]
  },
  {
    "id": "network-046",
    "pattern": "^nmap\\s+.+-p-",
    "cmd": "nmap",
    "severity": "warn",
    "hint": "Using -p- scans all 65535 ports; can be slow and noisy.",
    "detail": "The -p- flag tells nmap to scan all possible TCP ports, which is time-consuming and may trigger security alerts. Use only when a full port scan is necessary.",
    "tags": [
      "nmap",
      "ports",
      "performance"
    ]
  },
  {
    "id": "network-047",
    "pattern": "^tcpdump\\s+.+-i\\s+any",
    "cmd": "tcpdump",
    "severity": "warn",
    "hint": "Capturing on -i any may miss VLAN or interface-specific traffic.",
    "detail": "The any pseudo-interface aggregates all interfaces but can miss certain traffic types, such as VLAN tags or interface-specific packets. For detailed analysis, capture on the specific interface.",
    "tags": [
      "tcpdump",
      "interface",
      "capture"
    ]
  },
  {
    "id": "network-048",
    "pattern": "^nc\\s+.+-zv",
    "cmd": "nc",
    "severity": "tip",
    "hint": "Use -zv for port scanning with verbose output.",
    "detail": "The -z flag enables scanning mode (no data sent), while -v gives verbose feedback. This is a quick way to check if ports are open without sending payloads.",
    "tags": [
      "nc",
      "scan",
      "ports"
    ]
  },
  {
    "id": "network-049",
    "pattern": "^socat\\s+.+UDP4-RECVFROM:",
    "cmd": "socat",
    "severity": "tip",
    "hint": "Use UDP4-RECVFROM for receiving UDP datagrams with source info.",
    "detail": "UDP4-RECVFROM allows socat to receive UDP packets and capture the sender's address, which is essential for building UDP relays or debugging source addresses.",
    "tags": [
      "socat",
      "udp",
      "debug"
    ]
  },
  {
    "id": "network-050",
    "pattern": "^curl\\s+.+--retry\\s+\\d+",
    "cmd": "curl",
    "severity": "tip",
    "hint": "Use --retry to automatically retry failed curl requests.",
    "detail": "The --retry flag tells curl to retry transient failures, such as network timeouts or HTTP 5xx errors, improving reliability in unstable environments.",
    "tags": [
      "curl",
      "retry",
      "reliability"
    ]
  },
  {
    "id": "network-051",
    "pattern": "^wget\\s+.+--limit-rate=",
    "cmd": "wget",
    "severity": "tip",
    "hint": "Set --limit-rate to throttle wget downloads and avoid congestion.",
    "detail": "The --limit-rate flag restricts download speed, preventing wget from saturating your network connection, which is useful when running multiple downloads or on shared links.",
    "tags": [
      "wget",
      "bandwidth",
      "performance"
    ]
  },
  {
    "id": "network-052",
    "pattern": "^ssh\\s+.+-C(\\s|$)",
    "cmd": "ssh",
    "severity": "tip",
    "hint": "Use -C to enable SSH compression over slow links.",
    "detail": "The -C flag compresses all data sent over the SSH connection, which can significantly improve performance on slow or high-latency networks, especially for text-heavy sessions.",
    "tags": [
      "ssh",
      "compression",
      "performance"
    ]
  },
  {
    "id": "network-053",
    "pattern": "^scp\\s+.+\\s+.+\\s+-o\\s+",
    "cmd": "scp",
    "severity": "tip",
    "hint": "Use -o to pass SSH options, e.g., -o ProxyJump for jump hosts.",
    "detail": "The -o flag lets you specify arbitrary SSH options, such as ProxyJump or IdentityFile, providing advanced control over scp's connection behavior.",
    "tags": [
      "scp",
      "ssh",
      "options"
    ]
  },
  {
    "id": "network-054",
    "pattern": "^rsync\\s+.+--dry-run",
    "cmd": "rsync",
    "severity": "tip",
    "hint": "Use --dry-run to preview changes before syncing with rsync.",
    "detail": "The --dry-run flag simulates the transfer, showing what would be copied or deleted without making any changes. This is essential for verifying complex sync operations.",
    "tags": [
      "rsync",
      "safety",
      "preview"
    ]
  },
  {
    "id": "network-055",
    "pattern": "^ip\\s+neigh\\s+flush\\s+all",
    "cmd": "ip",
    "severity": "warn",
    "hint": "ip neigh flush all clears ARP/neighbor cache immediately.",
    "detail": "Flushing the neighbor table can disrupt ongoing connections, especially in environments with static ARP entries or complex routing. Use with caution on production systems.",
    "tags": [
      "ip",
      "arp",
      "networking"
    ]
  },
  {
    "id": "network-056",
    "pattern": "^dig\\s+.+\\+trace",
    "cmd": "dig",
    "severity": "tip",
    "hint": "Use +trace to debug DNS resolution from root servers downward.",
    "detail": "The +trace flag makes dig follow the DNS resolution path from the root servers, showing each step. This is invaluable for diagnosing DNS propagation and delegation issues.",
    "tags": [
      "dig",
      "dns",
      "debug"
    ]
  },
  {
    "id": "network-057",
    "pattern": "^nmap\\s+.+-oX\\s+",
    "cmd": "nmap",
    "severity": "tip",
    "hint": "Use -oX for XML output; ideal for parsing and automation.",
    "detail": "The -oX flag outputs scan results in XML, making it easy to process with scripts or import into analysis tools. Combine with -oA for multiple formats.",
    "tags": [
      "nmap",
      "output",
      "automation"
    ]
  },
  {
    "id": "network-058",
    "pattern": "^tcpdump\\s+.+-G\\s+\\d+",
    "cmd": "tcpdump",
    "severity": "tip",
    "hint": "Use -G to rotate tcpdump output files by time interval.",
    "detail": "The -G flag tells tcpdump to create a new output file every N seconds, which is useful for long-term captures and managing disk space.",
    "tags": [
      "tcpdump",
      "rotation",
      "capture"
    ]
  },
  {
    "id": "network-059",
    "pattern": "^nc\\s+.+-6",
    "cmd": "nc",
    "severity": "tip",
    "hint": "Use -6 to force IPv6 connections with nc.",
    "detail": "The -6 flag ensures netcat uses IPv6, which is necessary when connecting to IPv6-only hosts or testing dual-stack configurations.",
    "tags": [
      "nc",
      "ipv6",
      "networking"
    ]
  },
  {
    "id": "network-060",
    "pattern": "^socat\\s+.+PTY,link=",
    "cmd": "socat",
    "severity": "tip",
    "hint": "Use PTY,link= to create virtual serial ports for testing.",
    "detail": "The PTY,link= option lets socat create a named pseudo-terminal device, which is useful for simulating serial devices or connecting legacy software in virtualized environments.",
    "tags": [
      "socat",
      "pty",
      "virtualization"
    ]
  },
  {
    "id": "security-001",
    "pattern": "^ssh\\s+.*-o\\s+StrictHostKeyChecking=no",
    "cmd": "ssh",
    "severity": "danger",
    "hint": "Never use -o StrictHostKeyChecking=no in production environments.",
    "detail": "Disabling StrictHostKeyChecking allows MITM attacks by accepting any host key without verification. This flag is only safe for automated testing or ephemeral infrastructure, never for persistent or sensitive connections.",
    "tags": [
      "ssh",
      "danger",
      "mitm",
      "auth"
    ]
  },
  {
    "id": "security-002",
    "pattern": "^chmod\\s+777\\s+",
    "cmd": "chmod",
    "severity": "danger",
    "hint": "Avoid chmod 777; use least-privilege permissions instead.",
    "detail": "Setting permissions to 777 grants read, write, and execute to everyone, creating a severe security risk. Always restrict permissions to the minimum required for functionality, and prefer group/user-specific access.",
    "tags": [
      "file-permissions",
      "danger",
      "chmod"
    ]
  },
  {
    "id": "security-003",
    "pattern": "^openssl\\s+genrsa(\\s|$)",
    "cmd": "openssl",
    "severity": "upgrade",
    "hint": "Use openssl genpkey instead of deprecated genrsa for new keys.",
    "detail": "The genrsa command is deprecated; genpkey supports modern algorithms and better defaults. For RSA keys, use 'openssl genpkey -algorithm RSA' to ensure future compatibility and improved security.",
    "tags": [
      "openssl",
      "upgrade",
      "crypto"
    ]
  },
  {
    "id": "security-004",
    "pattern": "^gpg\\s+--output\\s+.*--decrypt\\s+.*\\.gpg",
    "cmd": "gpg",
    "severity": "warn",
    "hint": "Pipe decrypted output to avoid writing secrets to disk.",
    "detail": "Writing decrypted secrets to disk can leave sensitive data exposed in filesystem or backups. Use piping (e.g., gpg --decrypt file.gpg | ...) to keep secrets in memory and reduce attack surface.",
    "tags": [
      "gpg",
      "warn",
      "secrets"
    ]
  },
  {
    "id": "security-005",
    "pattern": "^ssh\\s+.*-A(\\s|$)",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Avoid SSH agent forwarding (-A) unless absolutely necessary.",
    "detail": "SSH agent forwarding exposes your local keys to the remote host, which can be compromised or untrusted. Only use -A for trusted hosts and consider using ProxyJump or bastion hosts instead.",
    "tags": [
      "ssh",
      "warn",
      "agent-forwarding"
    ]
  },
  {
    "id": "security-006",
    "pattern": "^export\\s+.*=.*",
    "cmd": "export",
    "severity": "warn",
    "hint": "Never export secrets as environment variables in shared shells.",
    "detail": "Environment variables can be accessed by other processes or users on the same system, especially if /proc is world-readable. Use dedicated secrets management tools or files with restricted permissions.",
    "tags": [
      "env",
      "warn",
      "secrets"
    ]
  },
  {
    "id": "security-007",
    "pattern": "^iptables\\s+-F(\\s|$)",
    "cmd": "iptables",
    "severity": "danger",
    "hint": "Flushing all iptables rules can drop all firewall protections.",
    "detail": "The -F flag removes all rules in the selected chain or all chains, potentially exposing the system to all incoming and outgoing traffic. Always back up rules and apply changes incrementally.",
    "tags": [
      "iptables",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-008",
    "pattern": "^ufw\\s+disable",
    "cmd": "ufw",
    "severity": "danger",
    "hint": "Disabling UFW removes all firewall protections instantly.",
    "detail": "Running 'ufw disable' flushes all rules and leaves the host unprotected. Use 'ufw status' to check rules and only disable for troubleshooting with physical access.",
    "tags": [
      "ufw",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-009",
    "pattern": "^chmod\\s+.*\\s+/etc/passwd",
    "cmd": "chmod",
    "severity": "danger",
    "hint": "Never change permissions on /etc/passwd; system integrity risk.",
    "detail": "Altering /etc/passwd permissions can allow unauthorized edits or reading, breaking authentication and enabling privilege escalation. The file should be world-readable but only writable by root.",
    "tags": [
      "file-permissions",
      "danger",
      "auth"
    ]
  },
  {
    "id": "security-010",
    "pattern": "^gpg\\s+--import\\s+.*\\.asc",
    "cmd": "gpg",
    "severity": "warn",
    "hint": "Always verify imported keys with --fingerprint after import.",
    "detail": "Imported keys may be spoofed or tampered with. Use 'gpg --fingerprint <keyid>' to verify the key's authenticity before trusting it for encryption or signing.",
    "tags": [
      "gpg",
      "warn",
      "key-management"
    ]
  },
  {
    "id": "security-011",
    "pattern": "^ssh\\s+.*root@",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Avoid direct root SSH login; use sudo after connecting.",
    "detail": "Direct root login increases attack surface and audit complexity. Disable root SSH access in /etc/ssh/sshd_config with 'PermitRootLogin no' and use regular users with sudo.",
    "tags": [
      "ssh",
      "warn",
      "root"
    ]
  },
  {
    "id": "security-012",
    "pattern": "^openssl\\s+enc\\s+.*-d\\s+.*-in\\s+.*-out\\s+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Avoid writing decrypted files to disk; use piping instead.",
    "detail": "Decrypted files written to disk can be recovered from disk remnants or backups. Pipe output directly to consuming processes to minimize exposure.",
    "tags": [
      "openssl",
      "warn",
      "secrets"
    ]
  },
  {
    "id": "security-013",
    "pattern": "^fail2ban-client\\s+set\\s+.*\\s+unbanip\\s+",
    "cmd": "fail2ban-client",
    "severity": "warn",
    "hint": "Unbanning IPs can re-expose your system to attackers.",
    "detail": "Unbanning should be done with caution and only after verifying the IP is not malicious. Review logs and ban history before removing bans to avoid reintroducing threats.",
    "tags": [
      "fail2ban",
      "warn",
      "intrusion"
    ]
  },
  {
    "id": "security-014",
    "pattern": "^ssh\\s+.*-i\\s+.*\\.pem",
    "cmd": "ssh",
    "severity": "tip",
    "hint": "Set 600 permissions on private keys before using with -i.",
    "detail": "OpenSSH refuses to use private keys with overly permissive permissions. Use 'chmod 600 key.pem' to avoid 'unprotected private key file' errors and prevent key leaks.",
    "tags": [
      "ssh",
      "tip",
      "file-permissions"
    ]
  },
  {
    "id": "security-015",
    "pattern": "^nft\\s+add\\s+rule\\s+.*accept",
    "cmd": "nft",
    "severity": "warn",
    "hint": "Be specific with nftables accept rules to avoid open ports.",
    "detail": "Generic accept rules can unintentionally expose services. Always specify interface, source, and protocol to limit exposure and follow the principle of least privilege.",
    "tags": [
      "nftables",
      "warn",
      "firewall"
    ]
  },
  {
    "id": "security-016",
    "pattern": "^openssl\\s+req\\s+-new\\s+-x509\\s+.*-days\\s+([1-9]|[1-9][0-9])\\s",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Short certificate lifetimes (<90 days) can cause unexpected expiry.",
    "detail": "Certificates with very short validity periods may expire before renewal scripts run, causing outages. Use at least 90 days for automation and monitor expiry proactively.",
    "tags": [
      "openssl",
      "warn",
      "certificates"
    ]
  },
  {
    "id": "security-017",
    "pattern": "^auditctl\\s+-e\\s+0",
    "cmd": "auditctl",
    "severity": "danger",
    "hint": "Disabling auditd removes all security event logging.",
    "detail": "Setting auditd to disabled mode with '-e 0' stops all audit logging, making it impossible to detect or investigate breaches. Only disable for troubleshooting and re-enable immediately after.",
    "tags": [
      "auditd",
      "danger",
      "logging"
    ]
  },
  {
    "id": "security-018",
    "pattern": "^ssh-keygen\\s+-t\\s+dsa",
    "cmd": "ssh-keygen",
    "severity": "upgrade",
    "hint": "DSA keys are deprecated; use ed25519 or rsa for new keys.",
    "detail": "DSA (ssh-dss) keys are considered weak and are disabled by default in many OpenSSH versions. Prefer 'ssh-keygen -t ed25519' for modern, secure keys.",
    "tags": [
      "ssh",
      "upgrade",
      "crypto"
    ]
  },
  {
    "id": "security-019",
    "pattern": "^openssl\\s+enc\\s+.*-aes-128-cbc",
    "cmd": "openssl",
    "severity": "upgrade",
    "hint": "Use AES-256-GCM instead of AES-128-CBC for stronger encryption.",
    "detail": "CBC mode is vulnerable to padding oracle attacks and lacks authentication. GCM provides authenticated encryption and is recommended for new deployments.",
    "tags": [
      "openssl",
      "upgrade",
      "crypto"
    ]
  },
  {
    "id": "security-020",
    "pattern": "^ufw\\s+allow\\s+22/tcp",
    "cmd": "ufw",
    "severity": "tip",
    "hint": "Limit SSH access by IP or subnet with ufw for better security.",
    "detail": "Allowing SSH from all IPs increases brute-force risk. Use 'ufw allow from <trusted_ip> to any port 22 proto tcp' to restrict access to known sources.",
    "tags": [
      "ufw",
      "tip",
      "ssh"
    ]
  },
  {
    "id": "security-021",
    "pattern": "^cat\\s+.*\\.env",
    "cmd": "cat",
    "severity": "warn",
    "hint": "Avoid displaying .env files; secrets may leak to terminal logs.",
    "detail": "Terminals may log output or be visible to other users via process monitoring. Use 'grep' or 'less' with restricted access, and never cat secrets in shared environments.",
    "tags": [
      "env",
      "warn",
      "secrets"
    ]
  },
  {
    "id": "security-022",
    "pattern": "^iptables\\s+-P\\s+INPUT\\s+ACCEPT",
    "cmd": "iptables",
    "severity": "danger",
    "hint": "Setting default INPUT policy to ACCEPT exposes all ports.",
    "detail": "The default policy should be DROP or REJECT to enforce explicit allow rules. ACCEPT as default negates all firewall protections and invites attacks.",
    "tags": [
      "iptables",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-023",
    "pattern": "^gpg\\s+--symmetric\\s+.*--cipher-algo\\s+CAST5",
    "cmd": "gpg",
    "severity": "upgrade",
    "hint": "CAST5 is outdated; use AES256 for symmetric encryption.",
    "detail": "CAST5 is the default for legacy GPG but is considered weak by modern standards. Specify '--cipher-algo AES256' for stronger encryption.",
    "tags": [
      "gpg",
      "upgrade",
      "crypto"
    ]
  },
  {
    "id": "security-024",
    "pattern": "^ssh\\s+.*-C(\\s|$)",
    "cmd": "ssh",
    "severity": "tip",
    "hint": "Use -C for SSH compression only on slow links; can increase CPU use.",
    "detail": "Compression (-C) can help on slow networks but increases CPU usage and may leak information via compression side-channels. Avoid on fast, local networks.",
    "tags": [
      "ssh",
      "tip",
      "performance"
    ]
  },
  {
    "id": "security-025",
    "pattern": "^find\\s+.*-exec\\s+chmod\\s+777",
    "cmd": "find",
    "severity": "danger",
    "hint": "Never recursively set 777 permissions; restrict as needed.",
    "detail": "Recursively applying 777 permissions exposes all files to modification and execution by any user, risking privilege escalation and data loss.",
    "tags": [
      "file-permissions",
      "danger",
      "find"
    ]
  },
  {
    "id": "security-026",
    "pattern": "^openssl\\s+rand\\s+-hex\\s+([1-9]|[1-9][0-9])\\s",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use at least 32 bytes for cryptographic secrets with openssl rand.",
    "detail": "Short random values are easier to brute-force. For API keys or tokens, use 'openssl rand -hex 32' or more for sufficient entropy.",
    "tags": [
      "openssl",
      "tip",
      "secrets"
    ]
  },
  {
    "id": "security-027",
    "pattern": "^sudo\\s+chmod\\s+.*\\s+/etc/shadow",
    "cmd": "sudo",
    "severity": "danger",
    "hint": "Never change /etc/shadow permissions; critical for system security.",
    "detail": "/etc/shadow contains password hashes and must be readable only by root. Changing permissions can allow privilege escalation or credential theft.",
    "tags": [
      "file-permissions",
      "danger",
      "auth"
    ]
  },
  {
    "id": "security-028",
    "pattern": "^export\\s+AWS_SECRET_ACCESS_KEY=.*",
    "cmd": "export",
    "severity": "danger",
    "hint": "Never export AWS secrets in shell; use credential files.",
    "detail": "Shell history and environment leaks can expose cloud credentials. Use ~/.aws/credentials with correct permissions and avoid exporting secrets in interactive shells.",
    "tags": [
      "env",
      "danger",
      "cloud",
      "secrets"
    ]
  },
  {
    "id": "security-029",
    "pattern": "^ssh\\s+.*-o\\s+UserKnownHostsFile=/dev/null",
    "cmd": "ssh",
    "severity": "danger",
    "hint": "Never use UserKnownHostsFile=/dev/null; disables host verification.",
    "detail": "This disables SSH's host authenticity checks, making MITM attacks trivial. Always use the default known_hosts file for persistent infrastructure.",
    "tags": [
      "ssh",
      "danger",
      "mitm"
    ]
  },
  {
    "id": "security-030",
    "pattern": "^ufw\\s+reset",
    "cmd": "ufw",
    "severity": "danger",
    "hint": "ufw reset deletes all rules and disables firewall protection.",
    "detail": "This command removes all user-defined rules and disables UFW, exposing the system until rules are reapplied. Always backup rules before resetting.",
    "tags": [
      "ufw",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-031",
    "pattern": "^nft\\s+flush\\s+ruleset",
    "cmd": "nft",
    "severity": "danger",
    "hint": "Flushing nftables ruleset removes all firewall protections.",
    "detail": "This command deletes all tables, chains, and rules, leaving the host unprotected. Only use during maintenance with physical access.",
    "tags": [
      "nftables",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-032",
    "pattern": "^auditctl\\s+-D",
    "cmd": "auditctl",
    "severity": "danger",
    "hint": "auditctl -D deletes all audit rules; logging is disabled.",
    "detail": "Removing all audit rules prevents detection of unauthorized activity. Only clear rules when reloading a known-good policy, and never in production without backup.",
    "tags": [
      "auditd",
      "danger",
      "logging"
    ]
  },
  {
    "id": "security-033",
    "pattern": "^gpg\\s+--delete-secret-keys\\s+",
    "cmd": "gpg",
    "severity": "warn",
    "hint": "Deleting secret keys is irreversible; backup before removal.",
    "detail": "Once deleted, secret keys cannot be recovered unless previously exported. Always backup with 'gpg --export-secret-keys' before deletion.",
    "tags": [
      "gpg",
      "warn",
      "key-management"
    ]
  },
  {
    "id": "security-034",
    "pattern": "^iptables\\s+-A\\s+INPUT\\s+-j\\s+ACCEPT",
    "cmd": "iptables",
    "severity": "warn",
    "hint": "Avoid blanket ACCEPT rules; restrict by source and protocol.",
    "detail": "Unrestricted ACCEPT rules expose all services. Specify source IP, interface, and protocol to limit exposure and follow best practices.",
    "tags": [
      "iptables",
      "warn",
      "firewall"
    ]
  },
  {
    "id": "security-035",
    "pattern": "^openssl\\s+req\\s+-new\\s+-x509\\s+.*-nodes",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Using -nodes creates unencrypted private keys; store securely.",
    "detail": "The -nodes flag disables encryption of private keys, making them readable by anyone with file access. Only use for automation with strict file permissions.",
    "tags": [
      "openssl",
      "warn",
      "crypto"
    ]
  },
  {
    "id": "security-036",
    "pattern": "^ssh\\s+.*-o\\s+PasswordAuthentication=yes",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Enable public key authentication; avoid PasswordAuthentication=yes.",
    "detail": "Password authentication is more susceptible to brute-force attacks. Use key-based authentication and set 'PasswordAuthentication no' in sshd_config.",
    "tags": [
      "ssh",
      "warn",
      "auth"
    ]
  },
  {
    "id": "security-037",
    "pattern": "^find\\s+.*-exec\\s+chown\\s+root:root",
    "cmd": "find",
    "severity": "warn",
    "hint": "Changing ownership to root recursively can break applications.",
    "detail": "Files required by non-root users or services may become inaccessible, causing outages. Audit file ownership before recursive chown operations.",
    "tags": [
      "file-permissions",
      "warn",
      "find"
    ]
  },
  {
    "id": "security-038",
    "pattern": "^fail2ban-client\\s+set\\s+.*\\s+addignoreip\\s+0\\.0\\.0\\.0/0",
    "cmd": "fail2ban-client",
    "severity": "danger",
    "hint": "Ignoring all IPs disables fail2ban protection entirely.",
    "detail": "Adding 0.0.0.0/0 to ignore list means no IP will ever be banned, negating all intrusion prevention. Only ignore trusted management IPs.",
    "tags": [
      "fail2ban",
      "danger",
      "intrusion"
    ]
  },
  {
    "id": "security-039",
    "pattern": "^ssh\\s+.*-o\\s+LogLevel=DEBUG",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Avoid LogLevel=DEBUG in production; may leak sensitive info.",
    "detail": "DEBUG logging can expose keys, passwords, or internal network details in logs. Use INFO or VERBOSE only for troubleshooting, and sanitize logs after use.",
    "tags": [
      "ssh",
      "warn",
      "logging"
    ]
  },
  {
    "id": "security-040",
    "pattern": "^gpg\\s+--armor\\s+--export-secret-keys",
    "cmd": "gpg",
    "severity": "warn",
    "hint": "Exporting secret keys in ASCII armor is risky; encrypt exports.",
    "detail": "ASCII-armored secret keys are easily copied and imported. Always encrypt exported keys with a strong passphrase and store them securely.",
    "tags": [
      "gpg",
      "warn",
      "key-management"
    ]
  },
  {
    "id": "security-041",
    "pattern": "^openssl\\s+s_server\\s+.*-www",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "openssl s_server is for testing only; not for production use.",
    "detail": "The built-in web server lacks authentication, logging, and security controls. Use a real web server for production TLS endpoints.",
    "tags": [
      "openssl",
      "warn",
      "testing"
    ]
  },
  {
    "id": "security-042",
    "pattern": "^chmod\\s+.*\\s+/etc/ssh/sshd_config",
    "cmd": "chmod",
    "severity": "warn",
    "hint": "Changing sshd_config permissions can break SSH or expose secrets.",
    "detail": "sshd_config should be readable by root only. Overly permissive permissions can allow unauthorized edits or information disclosure.",
    "tags": [
      "file-permissions",
      "warn",
      "ssh"
    ]
  },
  {
    "id": "security-043",
    "pattern": "^ssh\\s+.*-o\\s+ProxyCommand=nc",
    "cmd": "ssh",
    "severity": "tip",
    "hint": "Use ProxyJump (-J) instead of ProxyCommand for modern SSH hops.",
    "detail": "ProxyJump simplifies multi-hop SSH and is more secure and maintainable than ProxyCommand with netcat. Use 'ssh -J user@jump host' for easier configuration.",
    "tags": [
      "ssh",
      "tip",
      "proxy"
    ]
  },
  {
    "id": "security-044",
    "pattern": "^openssl\\s+enc\\s+.*-md\\s+md5",
    "cmd": "openssl",
    "severity": "upgrade",
    "hint": "MD5 is insecure; use SHA-256 or better for message digests.",
    "detail": "MD5 is vulnerable to collision attacks and should not be used for cryptographic purposes. Specify '-md sha256' or higher for integrity.",
    "tags": [
      "openssl",
      "upgrade",
      "crypto"
    ]
  },
  {
    "id": "security-045",
    "pattern": "^ufw\\s+allow\\s+any",
    "cmd": "ufw",
    "severity": "danger",
    "hint": "ufw allow any opens all ports; restrict by port and protocol.",
    "detail": "Allowing 'any' traffic disables firewall protections. Always specify service, port, and protocol to minimize attack surface.",
    "tags": [
      "ufw",
      "danger",
      "firewall"
    ]
  },
  {
    "id": "security-046",
    "pattern": "^ssh\\s+.*-o\\s+PermitLocalCommand=yes",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "PermitLocalCommand can execute arbitrary code; disable unless needed.",
    "detail": "Enabling this option allows execution of local commands on SSH connection, which can be exploited if configuration files are compromised.",
    "tags": [
      "ssh",
      "warn",
      "config"
    ]
  },
  {
    "id": "security-047",
    "pattern": "^gpg\\s+--list-keys\\s+--with-colons",
    "cmd": "gpg",
    "severity": "tip",
    "hint": "Use --with-fingerprint to verify key authenticity programmatically.",
    "detail": "--with-colons is useful for scripting, but always include --with-fingerprint to check for key spoofing or MITM attacks.",
    "tags": [
      "gpg",
      "tip",
      "key-management"
    ]
  },
  {
    "id": "security-048",
    "pattern": "^iptables\\s+-A\\s+FORWARD\\s+-j\\s+ACCEPT",
    "cmd": "iptables",
    "severity": "warn",
    "hint": "Unrestricted FORWARD ACCEPT exposes internal networks.",
    "detail": "Allowing all forwarded packets can expose private networks to external threats. Restrict by source, destination, and protocol for proper segmentation.",
    "tags": [
      "iptables",
      "warn",
      "firewall"
    ]
  },
  {
    "id": "security-049",
    "pattern": "^ssh\\s+.*-o\\s+GSSAPIAuthentication=yes",
    "cmd": "ssh",
    "severity": "warn",
    "hint": "Disable GSSAPIAuthentication unless using Kerberos.",
    "detail": "GSSAPI can introduce authentication delays and attack surface if not used. Set 'GSSAPIAuthentication no' in sshd_config unless Kerberos is required.",
    "tags": [
      "ssh",
      "warn",
      "auth"
    ]
  },
  {
    "id": "security-050",
    "pattern": "^nft\\s+add\\s+rule\\s+.*ct\\s+state\\s+new,established,related\\s+accept",
    "cmd": "nft",
    "severity": "tip",
    "hint": "Limit nftables accept rules to required connection states only.",
    "detail": "Accepting all connection states can allow unwanted traffic. Specify only the states necessary for your application (e.g., new, established) to minimize exposure.",
    "tags": [
      "nftables",
      "tip",
      "firewall"
    ]
  },
  {
    "id": "tls-001",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-CAfile\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Always verify s_client exit code; handshake errors may not print.",
    "detail": "openssl s_client may return a zero exit code even if the handshake fails, especially with certain TLS errors. Always check the output for 'Verify return code' and not just rely on exit status. This can prevent silent trust failures.",
    "tags": [
      "openssl",
      "s_client",
      "tls",
      "debug"
    ]
  },
  {
    "id": "tls-002",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-showcerts",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -showcerts to display the full certificate chain.",
    "detail": "The -showcerts flag in s_client prints all certificates sent by the server, not just the leaf. This is essential for debugging incomplete chains or misconfigured intermediates, which can cause trust failures in clients.",
    "tags": [
      "openssl",
      "s_client",
      "certificates",
      "debug"
    ]
  },
  {
    "id": "tls-003",
    "pattern": "^openssl\\s+x509\\s+-in\\s+[^\\s]+\\s+-text\\s+-noout",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Add -purpose to check certificate's intended usages.",
    "detail": "The -purpose flag analyzes the certificate's EKU and basic constraints, showing if it's valid for server, client, or CA use. This helps catch misissued or misconfigured certs that pass basic parsing but fail in real deployments.",
    "tags": [
      "openssl",
      "x509",
      "inspection",
      "eku"
    ]
  },
  {
    "id": "tls-004",
    "pattern": "^openssl\\s+req\\s+-new\\s+-key\\s+[^\\s]+\\s+-out\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Use -nodes only if you want an unencrypted private key.",
    "detail": "The -nodes flag disables encryption on the private key output. This is dangerous for production keys, as the key will be stored unprotected. Only use for automation or ephemeral test keys, never for long-lived secrets.",
    "tags": [
      "openssl",
      "req",
      "private-key",
      "security"
    ]
  },
  {
    "id": "tls-005",
    "pattern": "^certbot\\s+certonly\\s+.*--standalone",
    "cmd": "certbot",
    "severity": "warn",
    "hint": "Standalone mode stops web servers on port 80/443; expect downtime.",
    "detail": "certbot --standalone launches its own server to complete the ACME challenge, requiring exclusive access to HTTP(S) ports. This can cause brief outages if a web server is running. Use --webroot or DNS challenge for zero-downtime renewals.",
    "tags": [
      "certbot",
      "acme",
      "renewal",
      "downtime"
    ]
  },
  {
    "id": "tls-006",
    "pattern": "^openssl\\s+x509\\s+-in\\s+[^\\s]+\\s+-noout\\s+-enddate",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -checkend <seconds> to test for imminent expiry.",
    "detail": "The -checkend flag lets you check if a certificate will expire within a given number of seconds. This is useful for scripting expiry monitoring and proactive renewal, avoiding service interruptions.",
    "tags": [
      "openssl",
      "x509",
      "expiry",
      "automation"
    ]
  },
  {
    "id": "tls-007",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-servername\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Always use -servername for SNI; many servers require it.",
    "detail": "Modern TLS servers often serve multiple certificates via SNI. Without -servername, s_client may receive a default or invalid certificate, leading to misleading results. Always specify the intended hostname.",
    "tags": [
      "openssl",
      "s_client",
      "sni",
      "debug"
    ]
  },
  {
    "id": "tls-008",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-tls1$",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Avoid forcing obsolete TLS versions; use -tls1_2 or higher.",
    "detail": "The -tls1 flag enables only TLS 1.0, which is deprecated and insecure. Many servers will reject such connections, and some OpenSSL builds may disable this flag. Prefer -tls1_2 or -tls1_3 for modern security.",
    "tags": [
      "openssl",
      "s_client",
      "tls",
      "security"
    ]
  },
  {
    "id": "tls-009",
    "pattern": "^openssl\\s+genrsa\\s+.*",
    "cmd": "openssl",
    "severity": "upgrade",
    "hint": "Use 'openssl genpkey' for modern key generation.",
    "detail": "genrsa is deprecated in favor of genpkey, which supports more algorithms and flexible parameterization. genpkey is the recommended method for generating RSA, EC, and other key types in current OpenSSL releases.",
    "tags": [
      "openssl",
      "keygen",
      "modern",
      "upgrade"
    ]
  },
  {
    "id": "tls-010",
    "pattern": "^cfssl\\s+sign\\s+.*",
    "cmd": "cfssl",
    "severity": "tip",
    "hint": "Use -remote to offload signing to a remote CFSSL signer.",
    "detail": "The -remote flag allows cfssl sign to delegate signing operations to a remote API endpoint, centralizing CA operations and improving security by keeping private keys off local machines.",
    "tags": [
      "cfssl",
      "sign",
      "ca",
      "remote"
    ]
  },
  {
    "id": "tls-011",
    "pattern": "^cfssl\\s+serve\\s+.*",
    "cmd": "cfssl",
    "severity": "warn",
    "hint": "cfssl serve exposes a signing API; restrict access with firewall.",
    "detail": "cfssl serve runs a REST API that can sign certificates if misconfigured. Always restrict access to trusted networks and use authentication to prevent unauthorized certificate issuance.",
    "tags": [
      "cfssl",
      "serve",
      "security",
      "api"
    ]
  },
  {
    "id": "tls-012",
    "pattern": "^step\\s+ca\\s+provisioner\\s+add\\s+.*--x509",
    "cmd": "step",
    "severity": "tip",
    "hint": "Use --x509 to enable X.509 provisioning for mTLS workflows.",
    "detail": "The --x509 flag allows a provisioner to issue X.509 certificates, enabling mutual TLS authentication. Without this, provisioners may only issue JWTs or SSH certificates, limiting use cases.",
    "tags": [
      "step-ca",
      "provisioner",
      "mtls",
      "x509"
    ]
  },
  {
    "id": "tls-013",
    "pattern": "^openssl\\s+verify\\s+-CAfile\\s+[^\\s]+\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "verify only checks chain validity, not revocation status.",
    "detail": "openssl verify confirms that a certificate chains to a trusted root but does not check CRL or OCSP revocation by default. Use -crl_check or -ocsp to ensure revoked certificates are detected.",
    "tags": [
      "openssl",
      "verify",
      "revocation",
      "crl",
      "ocsp"
    ]
  },
  {
    "id": "tls-014",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-crlf",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -crlf to send CRLF line endings for SMTP/POP3 debugging.",
    "detail": "Some protocols require CRLF line endings. The -crlf flag ensures that input lines sent to the server use CRLF, which is necessary for accurate debugging of protocols like SMTP and POP3 over TLS.",
    "tags": [
      "openssl",
      "s_client",
      "smtp",
      "debug"
    ]
  },
  {
    "id": "tls-015",
    "pattern": "^openssl\\s+req\\s+-x509\\s+-newkey\\s+[^\\s]+\\s+-keyout\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Without -days, self-signed certs default to 30 days validity.",
    "detail": "If -days is omitted, self-signed certificates created with req -x509 are valid for only 30 days. Always specify -days for the intended validity period to avoid unexpected expiry.",
    "tags": [
      "openssl",
      "req",
      "self-signed",
      "expiry"
    ]
  },
  {
    "id": "tls-016",
    "pattern": "^openssl\\s+x509\\s+-in\\s+[^\\s]+\\s+-text\\s+-noout\\s+-ext\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -ext to inspect specific certificate extensions.",
    "detail": "The -ext flag allows you to display only selected X.509 extensions, such as subjectAltName or keyUsage, making it easier to audit or debug specific certificate attributes.",
    "tags": [
      "openssl",
      "x509",
      "extensions",
      "inspection"
    ]
  },
  {
    "id": "tls-017",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-cipher\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Test server cipher support with -cipher <suite>.",
    "detail": "Specifying -cipher allows you to test if a server accepts a particular cipher suite. This is useful for verifying compliance with security policies or debugging handshake failures due to cipher mismatches.",
    "tags": [
      "openssl",
      "s_client",
      "cipher",
      "debug"
    ]
  },
  {
    "id": "tls-018",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-brief",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -brief for concise handshake summaries in OpenSSL 3.x+.",
    "detail": "The -brief flag, available in OpenSSL 3.x and later, reduces output to essential handshake details, making it easier to spot issues without sifting through verbose logs.",
    "tags": [
      "openssl",
      "s_client",
      "debug",
      "modern"
    ]
  },
  {
    "id": "tls-019",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-tls1_3",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -tls1_3 to force TLS 1.3 and test modern server configs.",
    "detail": "Forcing TLS 1.3 helps verify if a server supports the latest protocol version, which offers improved security and performance. Useful for compliance and regression testing.",
    "tags": [
      "openssl",
      "s_client",
      "tls1.3",
      "debug"
    ]
  },
  {
    "id": "tls-020",
    "pattern": "^certbot\\s+renew\\s+.*--force-renewal",
    "cmd": "certbot",
    "severity": "warn",
    "hint": "Avoid --force-renewal unless absolutely necessary.",
    "detail": "--force-renewal triggers renewal even if certificates are not near expiry. Overuse can hit CA rate limits or cause unnecessary downtime. Only use for testing or emergency re-issuance.",
    "tags": [
      "certbot",
      "renewal",
      "rate-limit",
      "warn"
    ]
  },
  {
    "id": "tls-021",
    "pattern": "^cfssl\\s+bundle\\s+-cert\\s+[^\\s]+\\s+-ca-bundle\\s+[^\\s]+",
    "cmd": "cfssl",
    "severity": "tip",
    "hint": "cfssl bundle checks chain completeness and trust roots.",
    "detail": "The bundle command validates that a certificate chains to a trusted root and includes all necessary intermediates. This is vital for preventing chain-related trust failures in browsers and clients.",
    "tags": [
      "cfssl",
      "bundle",
      "chain",
      "trust"
    ]
  },
  {
    "id": "tls-022",
    "pattern": "^openssl\\s+pkcs12\\s+-export\\s+-inkey\\s+[^\\s]+\\s+-in\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "warn",
    "hint": "Do not use empty export passwords; PKCS#12 files are sensitive.",
    "detail": "Exporting PKCS#12 bundles without a password leaves private keys unprotected. Always set a strong export password to prevent credential leakage if the file is exposed.",
    "tags": [
      "openssl",
      "pkcs12",
      "private-key",
      "security"
    ]
  },
  {
    "id": "tls-023",
    "pattern": "^openssl\\s+x509\\s+-in\\s+[^\\s]+\\s+-serial",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -issuer and -subject to correlate serials with CAs.",
    "detail": "Serial numbers alone are not unique globally; combining with issuer and subject helps identify the certificate's context, especially when managing multiple CAs.",
    "tags": [
      "openssl",
      "x509",
      "serial",
      "ca"
    ]
  },
  {
    "id": "tls-024",
    "pattern": "^step\\s+ca\\s+certificate\\s+.*--provisioner-password-file",
    "cmd": "step",
    "severity": "tip",
    "hint": "Store provisioner password files securely; avoid world-readable perms.",
    "detail": "Provisioner password files grant certificate issuance rights. Set permissions to 600 and restrict access to trusted users only, as compromise can lead to unauthorized certificate creation.",
    "tags": [
      "step-ca",
      "provisioner",
      "security"
    ]
  },
  {
    "id": "tls-025",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-prexit",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -prexit to display session info before closing connection.",
    "detail": "-prexit prints session details (like session ID and ticket) before closing, which is useful for debugging session resumption and ticket-based authentication issues.",
    "tags": [
      "openssl",
      "s_client",
      "session",
      "debug"
    ]
  },
  {
    "id": "tls-026",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-quiet",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -quiet to suppress handshake and verification output.",
    "detail": "The -quiet flag is useful for scripting or when only the application data is needed, as it suppresses most diagnostic output, making parsing easier.",
    "tags": [
      "openssl",
      "s_client",
      "debug",
      "automation"
    ]
  },
  {
    "id": "tls-027",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-status",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -status to request OCSP stapling from the server.",
    "detail": "The -status flag triggers an OCSP status request during handshake. If the server supports OCSP stapling, the response is shown, helping verify revocation status in real time.",
    "tags": [
      "openssl",
      "s_client",
      "ocsp",
      "debug"
    ]
  },
  {
    "id": "tls-028",
    "pattern": "^openssl\\s+req\\s+-new\\s+-key\\s+[^\\s]+\\s+-subj\\s+\"[^\"]*\"",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -subj to automate CSR creation without prompts.",
    "detail": "The -subj flag lets you specify the subject DN inline, enabling fully non-interactive CSR generation. This is essential for automation and CI/CD pipelines.",
    "tags": [
      "openssl",
      "req",
      "csr",
      "automation"
    ]
  },
  {
    "id": "tls-029",
    "pattern": "^openssl\\s+req\\s+-new\\s+-config\\s+[^\\s]+",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -config to specify custom extensions or SANs in CSRs.",
    "detail": "The -config flag allows you to include subjectAltName and other extensions, which are not prompted interactively. This is required for modern browsers and many server configurations.",
    "tags": [
      "openssl",
      "req",
      "csr",
      "san"
    ]
  },
  {
    "id": "tls-030",
    "pattern": "^openssl\\s+s_client\\s+-connect\\s+[^\\s]+\\s+-ign_eof",
    "cmd": "openssl",
    "severity": "tip",
    "hint": "Use -ign_eof to keep connection open after stdin closes.",
    "detail": "The -ign_eof flag prevents s_client from closing the connection when stdin closes, allowing for interactive debugging of protocols that expect persistent connections.",
    "tags": [
      "openssl",
      "s_client",
      "debug",
      "protocol"
    ]
  },
  {
    "id": "git-001",
    "pattern": "^git\\s+push\\s+--force(\\s|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Use --force-with-lease instead of --force to avoid overwriting others.",
    "detail": "Using 'git push --force' can overwrite commits on the remote, potentially deleting teammates' work. '--force-with-lease' checks for upstream changes before pushing, reducing the risk of accidental data loss. Always prefer '--force-with-lease' for safer force-pushes.",
    "tags": [
      "push",
      "safety",
      "collaboration"
    ]
  },
  {
    "id": "git-002",
    "pattern": "^git\\s+commit\\s+-a(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Remember -a skips untracked files; use 'git add' for new files.",
    "detail": "'git commit -a' stages and commits only modified and deleted files that are already tracked. Untracked files are ignored, which can lead to missing new files in commits. Always use 'git add' to include new files before committing.",
    "tags": [
      "commit",
      "staging",
      "untracked"
    ]
  },
  {
    "id": "git-003",
    "pattern": "^git\\s+merge\\s+--no-ff(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --no-ff to preserve branch history in merges.",
    "detail": "The '--no-ff' flag creates a merge commit even if a fast-forward is possible, making the branch structure explicit in history. This is useful for preserving context in feature branches, especially in collaborative workflows.",
    "tags": [
      "merge",
      "history",
      "workflow"
    ]
  },
  {
    "id": "git-004",
    "pattern": "^git\\s+pull(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use 'git pull --rebase' to avoid unnecessary merge commits.",
    "detail": "By default, 'git pull' performs a merge, which can clutter history with unnecessary merge commits. Using '--rebase' applies your local commits on top of the upstream changes, resulting in a cleaner, linear history. Configure with 'git config pull.rebase true' for consistency.",
    "tags": [
      "pull",
      "rebase",
      "history"
    ]
  },
  {
    "id": "git-005",
    "pattern": "^git\\s+add\\s+\\.",
    "cmd": "git",
    "severity": "warn",
    "hint": "Review staged changes with 'git status' before committing.",
    "detail": "'git add .' stages all changes in the current directory, including unintended files. This can lead to committing sensitive or unrelated files. Always check 'git status' before committing to verify what will be included.",
    "tags": [
      "add",
      "staging",
      "safety"
    ]
  },
  {
    "id": "git-006",
    "pattern": "^git\\s+commit\\s+-m\\s+\"?\\s*\"?$",
    "cmd": "git",
    "severity": "warn",
    "hint": "Avoid empty commit messages; provide a descriptive summary.",
    "detail": "Empty commit messages hinder understanding of project history and make debugging difficult. Always provide a concise, meaningful message summarizing the change. Some hooks or CI systems may reject empty messages.",
    "tags": [
      "commit",
      "message",
      "best-practice"
    ]
  },
  {
    "id": "git-007",
    "pattern": "^git\\s+rebase\\s+-i\\s+origin/",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use interactive rebase to squash or reorder commits before merging.",
    "detail": "Interactive rebasing ('-i') allows you to edit, squash, or reorder commits, producing a cleaner, more logical history. This is especially useful before merging a feature branch into main. Be cautious: rebasing rewrites history.",
    "tags": [
      "rebase",
      "history",
      "squash"
    ]
  },
  {
    "id": "git-008",
    "pattern": "^git\\s+stash\\s+pop(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use 'git stash apply' to keep stash after applying changes.",
    "detail": "'git stash pop' applies the latest stash and then deletes it. If a conflict occurs, the stash is still dropped, risking data loss. Use 'git stash apply' to apply changes without removing the stash, allowing recovery if needed.",
    "tags": [
      "stash",
      "safety",
      "conflict"
    ]
  },
  {
    "id": "git-009",
    "pattern": "^git\\s+fetch(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--prune' to remove deleted remote branches locally.",
    "detail": "'git fetch --prune' cleans up references to branches that have been deleted on the remote. This keeps your local repository tidy and prevents confusion from stale branch references. Set 'fetch.prune' to true for automatic pruning.",
    "tags": [
      "fetch",
      "prune",
      "maintenance"
    ]
  },
  {
    "id": "git-010",
    "pattern": "^git\\s+log(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--oneline --graph' for a concise, visual commit history.",
    "detail": "'git log --oneline --graph' provides a compact, visual representation of the commit history, making it easier to understand branching and merges. Combine with '--decorate' for branch/tag names.",
    "tags": [
      "log",
      "visualization",
      "history"
    ]
  },
  {
    "id": "git-011",
    "pattern": "^git\\s+diff(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--color-words' for word-level diff highlighting.",
    "detail": "'git diff --color-words' highlights changes at the word level, making it easier to spot small edits within lines. This is especially useful for prose or documentation changes.",
    "tags": [
      "diff",
      "visualization",
      "usability"
    ]
  },
  {
    "id": "git-012",
    "pattern": "^git\\s+blame(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '-w' to ignore whitespace when blaming lines.",
    "detail": "'git blame -w' ignores whitespace changes, attributing lines to the last non-whitespace edit. This helps avoid misleading blame results when code is reformatted.",
    "tags": [
      "blame",
      "whitespace",
      "history"
    ]
  },
  {
    "id": "git-013",
    "pattern": "^git\\s+tag\\s+-d\\s+",
    "cmd": "git",
    "severity": "warn",
    "hint": "Deleting a tag locally doesn't remove it from remotes.",
    "detail": "'git tag -d <tag>' deletes a tag only in your local repository. To remove it from remotes, use 'git push --delete <remote> <tag>'. Otherwise, the tag will persist for others.",
    "tags": [
      "tag",
      "delete",
      "remote"
    ]
  },
  {
    "id": "git-014",
    "pattern": "^git\\s+push\\s+--tags(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Pushing all tags may include unintended or test tags.",
    "detail": "'git push --tags' pushes all local tags to the remote, including those not meant for sharing. Review your tags with 'git tag' and push only the intended ones using 'git push <remote> <tag>' if necessary.",
    "tags": [
      "push",
      "tag",
      "review"
    ]
  },
  {
    "id": "git-015",
    "pattern": "^git\\s+checkout\\s+[^\\s]+(\\s|$)",
    "cmd": "git",
    "severity": "upgrade",
    "hint": "Use 'git switch' for branches and 'git restore' for files.",
    "detail": "'git checkout' is overloaded for both branch switching and file restoration. The newer 'git switch' and 'git restore' commands are more explicit and user-friendly, reducing accidental mistakes.",
    "tags": [
      "checkout",
      "switch",
      "restore"
    ]
  },
  {
    "id": "git-016",
    "pattern": "^git\\s+merge\\s+--squash(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Squash merges combine changes but don't record merge info.",
    "detail": "'git merge --squash' applies all changes from the branch as a single commit, but does not create a merge commit. The branch relationship is not recorded in history, which may impact traceability.",
    "tags": [
      "merge",
      "squash",
      "history"
    ]
  },
  {
    "id": "git-017",
    "pattern": "^git\\s+rebase\\s+--onto\\s+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --onto for advanced rebasing between arbitrary bases.",
    "detail": "'git rebase --onto <newbase> <upstream> <branch>' allows you to transplant a branch onto a new base, skipping certain commits. This is powerful for complex history rewriting and splitting feature branches.",
    "tags": [
      "rebase",
      "advanced",
      "history"
    ]
  },
  {
    "id": "git-018",
    "pattern": "^git\\s+reset\\s+--hard(\\s|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Hard reset discards all local changes irreversibly.",
    "detail": "'git reset --hard' resets the index and working tree to match the specified commit, deleting all uncommitted changes. This action cannot be undone unless you have backups or stashes.",
    "tags": [
      "reset",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "git-019",
    "pattern": "^git\\s+clean\\s+-fd(\\s|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Clean -fd deletes untracked files and directories permanently.",
    "detail": "'git clean -fd' removes all untracked files and directories in the working tree. There is no undo. Use 'git clean -nfd' to preview what will be deleted before running.",
    "tags": [
      "clean",
      "danger",
      "untracked"
    ]
  },
  {
    "id": "git-020",
    "pattern": "^git\\s+cherry-pick\\s+",
    "cmd": "git",
    "severity": "warn",
    "hint": "Cherry-picking can duplicate commits; check for conflicts.",
    "detail": "'git cherry-pick' applies commits from another branch onto your current branch. If the commits already exist in the target branch, this can create duplicate history and conflicts. Always review the commit graph before cherry-picking.",
    "tags": [
      "cherry-pick",
      "conflict",
      "history"
    ]
  },
  {
    "id": "git-021",
    "pattern": "^git\\s+rebase\\s+--skip(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Skipping a commit during rebase may drop important changes.",
    "detail": "'git rebase --skip' omits the current patch, which can result in lost changes if used unintentionally. Always check the reason for the conflict before skipping, and consider resolving instead.",
    "tags": [
      "rebase",
      "skip",
      "conflict"
    ]
  },
  {
    "id": "git-022",
    "pattern": "^git\\s+pull\\s+--rebase(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Set 'pull.rebase=true' to make rebase the default for pulls.",
    "detail": "Setting 'git config --global pull.rebase true' makes all pulls use rebase by default, ensuring a linear history and reducing merge commits. This is especially helpful in teams preferring rebased histories.",
    "tags": [
      "pull",
      "rebase",
      "config"
    ]
  },
  {
    "id": "git-023",
    "pattern": "^git\\s+log\\s+--stat(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--stat' to see file-level changes per commit.",
    "detail": "'git log --stat' shows a summary of file changes (insertions/deletions) for each commit, providing a quick overview of the impact of each change. Combine with '--oneline' for concise output.",
    "tags": [
      "log",
      "stat",
      "review"
    ]
  },
  {
    "id": "git-024",
    "pattern": "^git\\s+show\\s+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--stat' with 'git show' for commit file change summary.",
    "detail": "'git show --stat <commit>' displays the diff and a summary of files changed in the specified commit. This helps quickly assess the scope of a change without reading the full diff.",
    "tags": [
      "show",
      "stat",
      "review"
    ]
  },
  {
    "id": "git-025",
    "pattern": "^git\\s+add\\s+-p(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '-p' to stage changes interactively by hunk.",
    "detail": "'git add -p' lets you review and stage changes hunk by hunk, enabling precise commits and better history. This is invaluable for splitting large changes into logical commits.",
    "tags": [
      "add",
      "interactive",
      "staging"
    ]
  },
  {
    "id": "git-026",
    "pattern": "^git\\s+commit\\s+--amend(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Amending rewrites history; avoid on shared/public branches.",
    "detail": "'git commit --amend' replaces the last commit with a new one, rewriting history. If the commit has been pushed, amending can cause conflicts for collaborators. Use only on local or private branches.",
    "tags": [
      "commit",
      "amend",
      "history"
    ]
  },
  {
    "id": "git-027",
    "pattern": "^git\\s+push\\s+origin\\s+HEAD:main(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Pushing to main directly can overwrite remote history.",
    "detail": "Pushing HEAD to main may overwrite commits on the remote if your local history diverges. Always pull and review the remote branch before pushing directly to main.",
    "tags": [
      "push",
      "main",
      "history"
    ]
  },
  {
    "id": "git-028",
    "pattern": "^git\\s+merge\\s+--abort(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--abort' to safely exit a conflicted merge.",
    "detail": "'git merge --abort' resets the working tree to the pre-merge state, discarding all changes from the merge attempt. This is safer than manually resetting files after a conflict.",
    "tags": [
      "merge",
      "abort",
      "conflict"
    ]
  },
  {
    "id": "git-029",
    "pattern": "^git\\s+stash\\s+save(\\s|$)",
    "cmd": "git",
    "severity": "upgrade",
    "hint": "Use 'git stash push' instead of deprecated 'stash save'.",
    "detail": "'git stash save' is deprecated; 'git stash push' is the modern replacement, supporting more options and clearer syntax. Update scripts and habits to use 'push' for future compatibility.",
    "tags": [
      "stash",
      "upgrade",
      "deprecated"
    ]
  },
  {
    "id": "git-030",
    "pattern": "^git\\s+diff\\s+--cached(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--cached' to see staged changes only.",
    "detail": "'git diff --cached' shows differences between the index (staged changes) and the last commit. This helps verify exactly what will be committed, especially before a commit.",
    "tags": [
      "diff",
      "staged",
      "review"
    ]
  },
  {
    "id": "git-031",
    "pattern": "^git\\s+fetch\\s+--all(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Combine '--all' with '--prune' to clean up all remotes.",
    "detail": "'git fetch --all --prune' updates all remotes and removes references to deleted branches. This is essential for maintaining a clean repository when working with multiple remotes.",
    "tags": [
      "fetch",
      "prune",
      "remotes"
    ]
  },
  {
    "id": "git-032",
    "pattern": "^git\\s+reflog(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use 'reflog' to recover lost commits after reset or rebase.",
    "detail": "'git reflog' records updates to HEAD and branches, allowing you to recover commits lost due to reset, rebase, or checkout. This is a critical tool for undoing mistakes.",
    "tags": [
      "reflog",
      "recovery",
      "history"
    ]
  },
  {
    "id": "git-033",
    "pattern": "^git\\s+bisect(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Automate bisect with 'git bisect run <script>' for faster debugging.",
    "detail": "'git bisect run <script>' automates the bisection process by running a test script at each step, quickly identifying the commit that introduced a bug. This is much faster than manual marking.",
    "tags": [
      "bisect",
      "automation",
      "debugging"
    ]
  },
  {
    "id": "git-034",
    "pattern": "^git\\s+config\\s+--global\\s+user\\.email\\s+",
    "cmd": "git",
    "severity": "warn",
    "hint": "Global email affects all repos; use local config for per-project iden...",
    "detail": "Setting 'user.email' globally applies to all repositories, which may not be desirable if you use different emails for work and personal projects. Use 'git config user.email' in the repo to override.",
    "tags": [
      "config",
      "identity",
      "email"
    ]
  },
  {
    "id": "git-035",
    "pattern": "^git\\s+log\\s+--follow\\s+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--follow' to track file history across renames.",
    "detail": "'git log --follow <file>' shows the history of a file, including across renames. Without '--follow', history is truncated at the rename point.",
    "tags": [
      "log",
      "history",
      "rename"
    ]
  },
  {
    "id": "git-036",
    "pattern": "^git\\s+clone\\s+--depth=\\d+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Shallow clones save time and bandwidth for large repos.",
    "detail": "'git clone --depth=N' creates a shallow clone with only the last N commits, reducing download size and time. Be aware that some operations (like pushing or rebasing) are limited in shallow clones.",
    "tags": [
      "clone",
      "performance",
      "shallow"
    ]
  },
  {
    "id": "git-037",
    "pattern": "^git\\s+push\\s+--mirror(\\s|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Mirror push overwrites all refs on remote. Use with extreme caution.",
    "detail": "'git push --mirror' pushes all refs (branches, tags, etc.) and overwrites the remote to match the local repository exactly. This can delete branches and tags on the remote. Only use for full repo migrations.",
    "tags": [
      "push",
      "mirror",
      "danger"
    ]
  },
  {
    "id": "git-038",
    "pattern": "^git\\s+add\\s+--patch(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--patch' to interactively stage parts of files.",
    "detail": "'git add --patch' is an alias for '-p', allowing you to stage specific hunks within files. This is useful for splitting logical changes into separate commits.",
    "tags": [
      "add",
      "patch",
      "staging"
    ]
  },
  {
    "id": "git-039",
    "pattern": "^git\\s+commit\\s+--no-verify(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Skipping hooks may bypass important checks or formatting.",
    "detail": "'git commit --no-verify' skips pre-commit and commit-msg hooks, which may enforce code quality or formatting. Use only when you are certain the checks are unnecessary for the current commit.",
    "tags": [
      "commit",
      "hooks",
      "quality"
    ]
  },
  {
    "id": "git-040",
    "pattern": "^git\\s+push\\s+--set-upstream\\s+origin\\s+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Set upstream to enable simple 'git push' and 'git pull'.",
    "detail": "'git push --set-upstream origin <branch>' configures the local branch to track the remote, allowing future pushes and pulls without specifying the remote and branch names.",
    "tags": [
      "push",
      "upstream",
      "tracking"
    ]
  },
  {
    "id": "git-041",
    "pattern": "^git\\s+merge\\s+--strategy=ours(\\s|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "'ours' strategy ignores all changes from the other branch.",
    "detail": "'git merge --strategy=ours' resolves all conflicts in favor of the current branch, discarding changes from the merged branch. This can hide important changes if used carelessly.",
    "tags": [
      "merge",
      "strategy",
      "conflict"
    ]
  },
  {
    "id": "git-042",
    "pattern": "^git\\s+rebase\\s+--interactive(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Interactive rebase allows editing, squashing, and reordering commits.",
    "detail": "'git rebase --interactive' (or '-i') opens an editor to let you pick, squash, or reorder commits, enabling a clean and logical commit history before merging.",
    "tags": [
      "rebase",
      "interactive",
      "history"
    ]
  },
  {
    "id": "git-043",
    "pattern": "^git\\s+log\\s+--pretty=oneline(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--oneline' for compact commit logs.",
    "detail": "'git log --oneline' is a shorthand for '--pretty=oneline --abbrev-commit', providing a concise view of commit history. Useful for quick overviews.",
    "tags": [
      "log",
      "oneline",
      "review"
    ]
  },
  {
    "id": "git-044",
    "pattern": "^git\\s+diff\\s+--name-only(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--name-only' to list changed files without showing diffs.",
    "detail": "'git diff --name-only' lists only the names of changed files, which is useful for scripting or quickly identifying affected files without reading the full diff.",
    "tags": [
      "diff",
      "files",
      "review"
    ]
  },
  {
    "id": "git-045",
    "pattern": "^git\\s+tag\\s+-a\\s+",
    "cmd": "git",
    "severity": "tip",
    "hint": "Annotated tags store metadata and are preferred for releases.",
    "detail": "'git tag -a <tag>' creates an annotated tag, storing the tagger name, date, and message. Annotated tags are recommended for releases and versioning, as they are stored as full objects in the repository.",
    "tags": [
      "tag",
      "annotated",
      "release"
    ]
  },
  {
    "id": "git-046",
    "pattern": "^git\\s+stash\\s+--include-untracked(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Include untracked files in stash with '-u' or '--include-untracked'.",
    "detail": "'git stash --include-untracked' (or '-u') stashes both tracked and untracked files, which is useful when you want a completely clean working directory. Untracked files are restored with 'stash pop/apply'.",
    "tags": [
      "stash",
      "untracked",
      "clean"
    ]
  },
  {
    "id": "git-047",
    "pattern": "^git\\s+fetch\\s+origin\\s+refs/pull/",
    "cmd": "git",
    "severity": "tip",
    "hint": "Fetch pull request refs directly for review or testing.",
    "detail": "On platforms like GitHub, 'git fetch origin refs/pull/ID/head:BRANCH' fetches a pull request as a local branch, allowing you to test or review PRs without merging.",
    "tags": [
      "fetch",
      "pull-request",
      "review"
    ]
  },
  {
    "id": "git-048",
    "pattern": "^git\\s+commit\\s+--allow-empty(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--allow-empty' to create a commit with no changes.",
    "detail": "'git commit --allow-empty' creates a commit even if there are no staged changes. This can be useful for marking milestones, triggering CI, or documenting events.",
    "tags": [
      "commit",
      "empty",
      "milestone"
    ]
  },
  {
    "id": "git-049",
    "pattern": "^git\\s+log\\s+--grep=",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--grep' to search commit messages for keywords.",
    "detail": "'git log --grep=<pattern>' filters commit logs by message content, making it easier to find specific changes or references. Combine with '--author' or '--oneline' for more targeted searches.",
    "tags": [
      "log",
      "search",
      "grep"
    ]
  },
  {
    "id": "git-050",
    "pattern": "^git\\s+push\\s+--dry-run(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--dry-run' to preview what would be pushed.",
    "detail": "'git push --dry-run' shows which commits and refs would be pushed, without actually updating the remote. This is useful for verifying push effects before making changes.",
    "tags": [
      "push",
      "dry-run",
      "preview"
    ]
  },
  {
    "id": "git-051",
    "pattern": "^git\\s+merge\\s+--no-commit(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--no-commit' to review or modify the merge before committing.",
    "detail": "'git merge --no-commit' performs the merge but leaves changes staged, allowing you to review, test, or further modify the result before finalizing the commit.",
    "tags": [
      "merge",
      "review",
      "staging"
    ]
  },
  {
    "id": "git-052",
    "pattern": "^git\\s+reset\\s+--soft(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Soft reset moves HEAD but keeps changes staged.",
    "detail": "'git reset --soft <commit>' moves HEAD to the specified commit but leaves all changes staged. This is useful for combining commits or reworking recent history without losing work.",
    "tags": [
      "reset",
      "soft",
      "history"
    ]
  },
  {
    "id": "git-053",
    "pattern": "^git\\s+stash\\s+list(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use 'stash list' to view all stashed changes with messages.",
    "detail": "'git stash list' shows all stashes, including their messages and commit references. Use descriptive messages when stashing for easier retrieval later.",
    "tags": [
      "stash",
      "list",
      "review"
    ]
  },
  {
    "id": "git-054",
    "pattern": "^git\\s+log\\s+--since=",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--since' to filter commits by date.",
    "detail": "'git log --since=<date>' shows commits newer than the specified date. Accepts flexible date formats (e.g., '2.weeks', 'yesterday'), aiding in time-based reviews.",
    "tags": [
      "log",
      "date",
      "filter"
    ]
  },
  {
    "id": "git-055",
    "pattern": "^git\\s+commit\\s+--fixup=",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--fixup' to prepare commits for autosquash rebasing.",
    "detail": "'git commit --fixup=<commit>' creates a commit marked for squashing into the target during an interactive rebase with '--autosquash'. This streamlines history cleanup before merging.",
    "tags": [
      "commit",
      "fixup",
      "rebase"
    ]
  },
  {
    "id": "git-056",
    "pattern": "^git\\s+rebase\\s+--autosquash(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Autosquash automatically moves fixup/squash commits during rebase.",
    "detail": "'git rebase --autosquash' automatically reorders and marks fixup/squash commits for squashing, reducing manual editing during interactive rebases. Combine with '--interactive' for best results.",
    "tags": [
      "rebase",
      "autosquash",
      "history"
    ]
  },
  {
    "id": "git-057",
    "pattern": "^git\\s+log\\s+--author=",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--author' to filter commits by contributor.",
    "detail": "'git log --author=<pattern>' limits log output to commits by a specific author. Useful for tracking individual contributions or code reviews.",
    "tags": [
      "log",
      "author",
      "filter"
    ]
  },
  {
    "id": "git-058",
    "pattern": "^git\\s+branch\\s+-D\\s+",
    "cmd": "git",
    "severity": "danger",
    "hint": "Branch deletion with '-D' is irreversible; use '-d' for safety.",
    "detail": "'git branch -D <branch>' forcibly deletes a branch, even if it has unmerged changes. Use '-d' to prevent deleting branches with unmerged commits, avoiding accidental data loss.",
    "tags": [
      "branch",
      "delete",
      "danger"
    ]
  },
  {
    "id": "git-059",
    "pattern": "^git\\s+rebase\\s+origin/",
    "cmd": "git",
    "severity": "warn",
    "hint": "Rebasing on remote branches rewrites local history; check for conflicts.",
    "detail": "'git rebase origin/<branch>' rewrites your local branch history atop the remote branch. This can cause conflicts if your branch diverged significantly. Always resolve conflicts carefully and avoid rebasing shared branches.",
    "tags": [
      "rebase",
      "remote",
      "conflict"
    ]
  },
  {
    "id": "git-060",
    "pattern": "^git\\s+log\\s+--decorate(\\s|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use '--decorate' to show branch and tag names in logs.",
    "detail": "'git log --decorate' annotates commits with branch and tag names, making it easier to understand the commit's context in the repository. Combine with '--oneline' and '--graph' for a comprehensive overview.",
    "tags": [
      "log",
      "decorate",
      "visualization"
    ]
  },
  {
    "id": "git-advanced-001",
    "pattern": "^git\\s+filter-branch(\\s+|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Use git filter-repo instead of filter-branch for rewriting history.",
    "detail": "git filter-branch is deprecated and error-prone for history rewriting. It can corrupt repositories or leave orphaned refs, especially with complex filters. The official recommendation is to use git filter-repo, which is faster, safer, and better maintained.",
    "tags": [
      "history",
      "rewrite",
      "deprecated",
      "filter-repo",
      "danger"
    ]
  },
  {
    "id": "git-advanced-002",
    "pattern": "^git\\s+push\\s+--force(\\s+|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Use --force-with-lease to avoid overwriting others' work.",
    "detail": "--force overwrites remote history unconditionally, risking data loss if others have pushed. --force-with-lease checks that your local view matches the remote before pushing, reducing the risk of accidentally deleting others' commits.",
    "tags": [
      "push",
      "force",
      "history",
      "danger"
    ]
  },
  {
    "id": "git-advanced-003",
    "pattern": "^git\\s+submodule\\s+update(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Add --init to initialize new submodules after clone.",
    "detail": "git submodule update alone does not initialize new submodules. Use git submodule update --init to ensure all submodules are initialized and checked out, especially after cloning a repository with submodules.",
    "tags": [
      "submodule",
      "init",
      "clone",
      "warn"
    ]
  },
  {
    "id": "git-advanced-004",
    "pattern": "^git\\s+worktree\\s+add(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --no-checkout to avoid unnecessary checkout for CI or scripting.",
    "detail": "The --no-checkout flag creates a new worktree without checking out files, which can save time and disk I/O in automation scenarios. This is useful for scripts or CI pipelines where you only need the worktree structure.",
    "tags": [
      "worktree",
      "checkout",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-005",
    "pattern": "^git\\s+archive(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --format=tar.gz for compressed archives directly.",
    "detail": "git archive supports --format=tar.gz (with recent Git) to create compressed tarballs in one step, avoiding the need for a separate gzip process. This is more efficient and reduces intermediate files.",
    "tags": [
      "archive",
      "compression",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-006",
    "pattern": "^git\\s+reflog\\s+expire(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use --expire-unreachable=now to prune unreachable reflog entries.",
    "detail": "By default, git reflog expire only prunes entries older than the default expiry. Use --expire-unreachable=now to aggressively clean up unreachable reflog entries, which is critical before garbage collection in sensitive environments.",
    "tags": [
      "reflog",
      "expire",
      "gc",
      "warn"
    ]
  },
  {
    "id": "git-advanced-007",
    "pattern": "^git\\s+subtree\\s+split(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use --rejoin to avoid duplicate commits when splitting repeatedly.",
    "detail": "When splitting a subtree multiple times, omitting --rejoin can cause duplicate commits and history divergence. The --rejoin flag ensures the split branch is merged back, maintaining a clean history.",
    "tags": [
      "subtree",
      "split",
      "history",
      "warn"
    ]
  },
  {
    "id": "git-advanced-008",
    "pattern": "^git\\s+bundle\\s+create(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Specify refs explicitly to avoid incomplete bundles.",
    "detail": "If you omit explicit refs when creating a bundle, only the current HEAD is included. For full repository backups or transfers, specify all relevant branches and tags to ensure completeness.",
    "tags": [
      "bundle",
      "backup",
      "refs",
      "tip"
    ]
  },
  {
    "id": "git-advanced-009",
    "pattern": "^git\\s+clone\\s+--filter=blob:none(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use partial clone to save bandwidth for large repos.",
    "detail": "The --filter=blob:none flag enables partial clone, downloading only tree and commit objects initially. This is ideal for large repositories where you don't need all file contents immediately, significantly reducing clone time and bandwidth.",
    "tags": [
      "clone",
      "partial",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-010",
    "pattern": "^git\\s+sparse-checkout\\s+init(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Enable cone mode for simpler sparse-checkout patterns.",
    "detail": "Cone mode, enabled by default in recent Git, simplifies sparse-checkout patterns to directory prefixes, making it easier and faster to manage large monorepos. Use git sparse-checkout init --cone for compatibility.",
    "tags": [
      "sparse-checkout",
      "performance",
      "monorepo",
      "tip"
    ]
  },
  {
    "id": "git-advanced-011",
    "pattern": "^git\\s+submodule\\s+update\\s+--remote(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Check submodule branch tracking to avoid unexpected updates.",
    "detail": "git submodule update --remote fetches the latest commit from the tracked branch, which may not match the superproject's intended state. Always verify the branch configured in .gitmodules and .git/config to prevent silent drift.",
    "tags": [
      "submodule",
      "remote",
      "branch",
      "warn"
    ]
  },
  {
    "id": "git-advanced-012",
    "pattern": "^git\\s+worktree\\s+prune(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Prune to clean up stale worktree references after manual deletion.",
    "detail": "If you manually delete a worktree directory, git worktree prune removes stale references from the repository, preventing errors and confusion when adding new worktrees. This keeps the worktree list accurate.",
    "tags": [
      "worktree",
      "prune",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "git-advanced-013",
    "pattern": "^git\\s+reflog\\s+delete(\\s+|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Deleting reflog entries is irreversible; backup first.",
    "detail": "git reflog delete removes reflog entries permanently, making it impossible to recover previous states referenced only in the reflog. Always ensure you have backups or have pushed important commits before deleting.",
    "tags": [
      "reflog",
      "delete",
      "danger",
      "irreversible"
    ]
  },
  {
    "id": "git-advanced-014",
    "pattern": "^git\\s+archive\\s+--format=zip(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --prefix to add a directory prefix inside the archive.",
    "detail": "The --prefix option adds a directory prefix to all files in the archive, making extraction cleaner and avoiding file collisions when unpacking multiple archives into the same directory.",
    "tags": [
      "archive",
      "zip",
      "prefix",
      "tip"
    ]
  },
  {
    "id": "git-advanced-015",
    "pattern": "^git\\s+submodule\\s+deinit(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Remove submodule directories manually after deinit.",
    "detail": "git submodule deinit only removes the submodule's configuration, not its working directory. You must manually delete the submodule directory to fully remove it from your filesystem.",
    "tags": [
      "submodule",
      "deinit",
      "cleanup",
      "warn"
    ]
  },
  {
    "id": "git-advanced-016",
    "pattern": "^git\\s+worktree\\s+add\\s+--detach(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Detached worktrees are not associated with a branch; handle with care.",
    "detail": "Adding a worktree in detached HEAD mode means changes won't be associated with a branch, making it easy to lose work if not explicitly committed and referenced. Always check HEAD state before making changes.",
    "tags": [
      "worktree",
      "detached",
      "warn"
    ]
  },
  {
    "id": "git-advanced-017",
    "pattern": "^git\\s+filter-branch\\s+--tree-filter(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --index-filter for faster history rewriting.",
    "detail": "--tree-filter runs a shell command for every checked-out commit, which is slow. --index-filter operates directly on the index, dramatically improving performance for large repositories.",
    "tags": [
      "filter-branch",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-018",
    "pattern": "^git\\s+subtree\\s+add(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use --squash to avoid polluting history with subtree commits.",
    "detail": "The --squash flag combines all subtree commits into a single commit, keeping your main repository history clean and avoiding unnecessary complexity from the subtree's commit history.",
    "tags": [
      "subtree",
      "add",
      "squash",
      "warn"
    ]
  },
  {
    "id": "git-advanced-019",
    "pattern": "^git\\s+bundle\\s+verify(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Always verify bundles before using them for clone or fetch.",
    "detail": "git bundle verify checks the integrity and completeness of a bundle file, ensuring all required objects and refs are present. This prevents partial or corrupted restores.",
    "tags": [
      "bundle",
      "verify",
      "integrity",
      "tip"
    ]
  },
  {
    "id": "git-advanced-020",
    "pattern": "^git\\s+clone\\s+--depth=1(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --single-branch to avoid fetching unnecessary refs.",
    "detail": "By default, a shallow clone with --depth=1 still fetches all branches' refs. Adding --single-branch limits the clone to the specified branch, reducing bandwidth and storage.",
    "tags": [
      "clone",
      "shallow",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-021",
    "pattern": "^git\\s+rerere\\s+enabled(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Enable rerere to auto-resolve repeated merge conflicts.",
    "detail": "git rerere records how you resolve conflicts and can automatically apply the same resolution in future merges or rebases, saving time in repetitive workflows. Enable with git config rerere.enabled true.",
    "tags": [
      "rerere",
      "merge",
      "conflict",
      "tip"
    ]
  },
  {
    "id": "git-advanced-022",
    "pattern": "^git\\s+submodule\\s+sync(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Run sync after changing submodule URLs or branches.",
    "detail": "git submodule sync updates local configuration to match .gitmodules, ensuring correct URLs and branch tracking after changes. This avoids confusion and fetch errors when submodule remotes change.",
    "tags": [
      "submodule",
      "sync",
      "configuration",
      "tip"
    ]
  },
  {
    "id": "git-advanced-023",
    "pattern": "^git\\s+worktree\\s+list(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Check for locked or prunable worktrees before adding new ones.",
    "detail": "git worktree list shows all active and locked worktrees. Stale or locked worktrees can prevent new ones from being added for the same branch. Prune or unlock as needed.",
    "tags": [
      "worktree",
      "list",
      "tip"
    ]
  },
  {
    "id": "git-advanced-024",
    "pattern": "^git\\s+reflog(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use reflog to recover lost commits after a reset or rebase.",
    "detail": "git reflog tracks all changes to HEAD and branch tips, allowing you to recover commits even after a hard reset or rebase. Use git reflog to find the commit hash and git reset to restore.",
    "tags": [
      "reflog",
      "recovery",
      "tip"
    ]
  },
  {
    "id": "git-advanced-025",
    "pattern": "^git\\s+archive\\s+--remote=(\\S+)(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Remote archive requires upload-archive enabled on the server.",
    "detail": "git archive --remote relies on the server supporting the upload-archive service, which is disabled by default on many servers for security reasons. Always verify server configuration before relying on this feature.",
    "tags": [
      "archive",
      "remote",
      "server",
      "warn"
    ]
  },
  {
    "id": "git-advanced-026",
    "pattern": "^git\\s+submodule\\s+foreach(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --recursive to run commands in nested submodules.",
    "detail": "By default, git submodule foreach only iterates over top-level submodules. Adding --recursive ensures the command is executed in all nested submodules, which is crucial for complex dependency trees.",
    "tags": [
      "submodule",
      "foreach",
      "recursive",
      "tip"
    ]
  },
  {
    "id": "git-advanced-027",
    "pattern": "^git\\s+worktree\\s+add\\s+--orphan(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Orphan worktrees start with no history; commits are isolated.",
    "detail": "Creating a worktree with --orphan starts a new branch with no parent commits. This is useful for gh-pages or documentation branches, but beware: commits here are not connected to existing history.",
    "tags": [
      "worktree",
      "orphan",
      "history",
      "warn"
    ]
  },
  {
    "id": "git-advanced-028",
    "pattern": "^git\\s+filter-branch\\s+--prune-empty(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --prune-empty to remove empty commits after filtering.",
    "detail": "When rewriting history, --prune-empty removes commits that become empty due to filtering, keeping the new history clean and concise. This avoids clutter from meaningless commits.",
    "tags": [
      "filter-branch",
      "prune-empty",
      "tip"
    ]
  },
  {
    "id": "git-advanced-029",
    "pattern": "^git\\s+subtree\\s+pull(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Use --squash to avoid merging full subtree history.",
    "detail": "Without --squash, git subtree pull merges the entire history of the subtree, which can clutter your main repository's log. --squash condenses the changes into a single commit.",
    "tags": [
      "subtree",
      "pull",
      "squash",
      "warn"
    ]
  },
  {
    "id": "git-advanced-030",
    "pattern": "^git\\s+bundle\\s+create\\s+.*--all(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Bundle with --all includes all refs, possibly leaking sensitive branc...",
    "detail": "Using --all when creating a bundle includes every ref in the repository, including private or experimental branches. Always review included refs before sharing bundles.",
    "tags": [
      "bundle",
      "all",
      "privacy",
      "warn"
    ]
  },
  {
    "id": "git-advanced-031",
    "pattern": "^git\\s+clone\\s+--filter=blob:none\\s+--depth=1(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Combine partial and shallow clone for minimal initial checkout.",
    "detail": "Using both --filter=blob:none and --depth=1 results in a minimal clone, fetching only the latest commit metadata and no file contents. This is ideal for CI or quick inspections of large repositories.",
    "tags": [
      "clone",
      "partial",
      "shallow",
      "performance",
      "tip"
    ]
  },
  {
    "id": "git-advanced-032",
    "pattern": "^git\\s+rerere\\s+gc(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Run rerere gc to clean up obsolete conflict resolutions.",
    "detail": "git rerere gc removes stale or unused conflict resolution records, keeping the rerere database small and relevant. This is useful in long-lived repositories with many merges.",
    "tags": [
      "rerere",
      "gc",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "git-advanced-033",
    "pattern": "^git\\s+hook(s)?(\\s+|$)",
    "cmd": "git",
    "severity": "upgrade",
    "hint": "Use core.hooksPath to share hooks across repositories.",
    "detail": "Setting core.hooksPath in your config allows you to maintain hooks in a central directory, making it easier to share and update hooks across multiple repositories. This is more maintainable than per-repo .git/hooks.",
    "tags": [
      "hooks",
      "configuration",
      "upgrade"
    ]
  },
  {
    "id": "git-advanced-034",
    "pattern": "^git\\s+submodule\\s+update\\s+--merge(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Conflicts in submodules require manual resolution.",
    "detail": "Using --merge with submodule update attempts to merge submodule changes, but conflicts are not automatically resolved and require manual intervention. Always check submodule status after merging.",
    "tags": [
      "submodule",
      "merge",
      "conflict",
      "warn"
    ]
  },
  {
    "id": "git-advanced-035",
    "pattern": "^git\\s+archive\\s+--output=(\\S+)(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Specify --format to match the output file extension.",
    "detail": "When using --output, git does not infer the archive format from the file extension. Always specify --format=tar or --format=zip to avoid mismatched or unreadable archives.",
    "tags": [
      "archive",
      "output",
      "format",
      "tip"
    ]
  },
  {
    "id": "git-advanced-036",
    "pattern": "^git\\s+submodule\\s+status(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "A leading '-' means the submodule is not initialized.",
    "detail": "git submodule status shows a '-' at the start of the line for submodules that are not initialized. This is a quick way to check submodule health after cloning or updating.",
    "tags": [
      "submodule",
      "status",
      "tip"
    ]
  },
  {
    "id": "git-advanced-037",
    "pattern": "^git\\s+worktree\\s+add\\s+.*-b\\s+(\\S+)(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use -b to create and check out a new branch in the worktree.",
    "detail": "The -b flag creates a new branch and checks it out in the new worktree, avoiding conflicts with existing branches and enabling parallel feature development.",
    "tags": [
      "worktree",
      "branch",
      "tip"
    ]
  },
  {
    "id": "git-advanced-038",
    "pattern": "^git\\s+filter-branch\\s+--force(\\s+|$)",
    "cmd": "git",
    "severity": "danger",
    "hint": "Force overwrites rewritten refs; backup before proceeding.",
    "detail": "The --force flag causes filter-branch to overwrite refs even if they exist, which can destroy previous history. Always backup or push important branches before using --force.",
    "tags": [
      "filter-branch",
      "force",
      "danger"
    ]
  },
  {
    "id": "git-advanced-039",
    "pattern": "^git\\s+submodule\\s+add(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Always commit .gitmodules and submodule directory after adding.",
    "detail": "After adding a submodule, both .gitmodules and the submodule directory must be committed to ensure other users can clone and initialize the submodule correctly. Omitting either causes confusion and broken checkouts.",
    "tags": [
      "submodule",
      "add",
      "commit",
      "warn"
    ]
  },
  {
    "id": "git-advanced-040",
    "pattern": "^git\\s+archive\\s+--prefix=(\\S+)(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Prefix should end with '/' to create a directory in the archive.",
    "detail": "If the prefix does not end with a slash, files will be prefixed but not placed in a directory, potentially leading to clutter or collisions when extracting.",
    "tags": [
      "archive",
      "prefix",
      "tip"
    ]
  },
  {
    "id": "git-advanced-041",
    "pattern": "^git\\s+bundle\\s+create\\s+.*HEAD(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "HEAD may not include all branches; specify refs for completeness.",
    "detail": "Creating a bundle with only HEAD includes only the current branch. For full backups or transfers, specify all relevant refs to avoid missing branches or tags.",
    "tags": [
      "bundle",
      "HEAD",
      "refs",
      "warn"
    ]
  },
  {
    "id": "git-advanced-042",
    "pattern": "^git\\s+rerere\\s+forget(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use rerere forget to remove specific conflict resolutions.",
    "detail": "rerere forget removes a recorded resolution for a specific conflict, allowing you to handle future conflicts differently. This is useful if a previous resolution is no longer appropriate.",
    "tags": [
      "rerere",
      "forget",
      "conflict",
      "tip"
    ]
  },
  {
    "id": "git-advanced-043",
    "pattern": "^git\\s+sparse-checkout\\s+set(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use set to quickly switch sparse-checkout patterns.",
    "detail": "git sparse-checkout set replaces the current sparse-checkout patterns atomically, making it easy to switch working directory subsets in monorepos without manual edits.",
    "tags": [
      "sparse-checkout",
      "set",
      "tip"
    ]
  },
  {
    "id": "git-advanced-044",
    "pattern": "^git\\s+submodule\\s+update\\s+--recursive(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Always use --recursive for nested submodules.",
    "detail": "Nested submodules are not updated unless --recursive is specified. This ensures all dependencies are initialized and updated, preventing build failures in projects with deep submodule trees.",
    "tags": [
      "submodule",
      "recursive",
      "tip"
    ]
  },
  {
    "id": "git-advanced-045",
    "pattern": "^git\\s+worktree\\s+remove(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Remove worktree only after committing or stashing changes.",
    "detail": "Removing a worktree with uncommitted changes will result in data loss. Always commit or stash changes before removing a worktree to prevent accidental loss.",
    "tags": [
      "worktree",
      "remove",
      "warn"
    ]
  },
  {
    "id": "git-advanced-046",
    "pattern": "^git\\s+filter-branch\\s+--subdirectory-filter(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --subdirectory-filter to extract project history cleanly.",
    "detail": "The --subdirectory-filter flag rewrites history to only include a specific subdirectory, making it easy to split out a project. This is more efficient than manual filtering.",
    "tags": [
      "filter-branch",
      "subdirectory-filter",
      "tip"
    ]
  },
  {
    "id": "git-advanced-047",
    "pattern": "^git\\s+submodule\\s+absorbgitdirs(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Absorb submodule .git dirs for easier migration or backup.",
    "detail": "absorbgitdirs moves submodule .git directories into the superproject's .git/modules, simplifying repository structure and making migration or backup more straightforward.",
    "tags": [
      "submodule",
      "absorbgitdirs",
      "tip"
    ]
  },
  {
    "id": "git-advanced-048",
    "pattern": "^git\\s+worktree\\s+lock(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Lock worktrees to prevent accidental deletion or modification.",
    "detail": "git worktree lock marks a worktree as locked, preventing removal or modification until explicitly unlocked. This is useful for protecting important or long-lived worktrees.",
    "tags": [
      "worktree",
      "lock",
      "tip"
    ]
  },
  {
    "id": "git-advanced-049",
    "pattern": "^git\\s+subtree\\s+push(\\s+|$)",
    "cmd": "git",
    "severity": "warn",
    "hint": "Subtree push rewrites remote history; coordinate with collaborators.",
    "detail": "git subtree push can rewrite the remote branch's history, potentially overwriting changes made by others. Always communicate with your team before pushing subtree splits.",
    "tags": [
      "subtree",
      "push",
      "history",
      "warn"
    ]
  },
  {
    "id": "git-advanced-050",
    "pattern": "^git\\s+clone\\s+--filter=tree:0(\\s+|$)",
    "cmd": "git",
    "severity": "tip",
    "hint": "Use --filter=tree:0 to fetch only commit objects for analysis.",
    "detail": "The --filter=tree:0 option in partial clone fetches only commit objects, omitting all tree and blob data. This is useful for repository analysis or statistics without needing file contents.",
    "tags": [
      "clone",
      "partial",
      "performance",
      "tip"
    ]
  },
  {
    "id": "python-pkg-001",
    "pattern": "^pip\\s+install\\s+-r\\s+requirements.txt\\s*$",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Use --require-hashes with -r for reproducible installs.",
    "detail": "Without --require-hashes, pip can silently install newer or malicious packages if requirements.txt is modified upstream. --require-hashes enforces exact package hashes, preventing tampering and ensuring deterministic builds.",
    "tags": [
      "pip",
      "security",
      "reproducibility"
    ]
  },
  {
    "id": "python-pkg-002",
    "pattern": "^pip\\s+install\\s+.*--user.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Avoid --user inside virtual environments; it breaks isolation.",
    "detail": "Using --user inside a virtualenv installs packages to the user site directory, bypassing the virtualenv and causing unpredictable import behavior. Always omit --user when a venv is active.",
    "tags": [
      "pip",
      "virtualenv",
      "isolation"
    ]
  },
  {
    "id": "python-pkg-003",
    "pattern": "^pip\\s+install\\s+.*--upgrade\\s+pip.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Upgrading pip globally can break system Python or OS tools.",
    "detail": "Upgrading pip outside a virtualenv may overwrite the system pip, potentially breaking OS package management or other Python tools. Use a virtualenv or your OS package manager for upgrades.",
    "tags": [
      "pip",
      "system",
      "virtualenv"
    ]
  },
  {
    "id": "python-pkg-004",
    "pattern": "^pip\\s+install\\s+.*-e\\s+\\.",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use -e . for editable installs during development.",
    "detail": "Editable installs link your source code directly into the environment, so changes are reflected immediately. This is ideal for local development, but avoid in production as it can lead to unexpected behavior if files are modified.",
    "tags": [
      "pip",
      "development",
      "editable"
    ]
  },
  {
    "id": "python-pkg-005",
    "pattern": "^pip\\s+freeze\\s*$",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use pip freeze > requirements.txt to capture exact versions.",
    "detail": "pip freeze outputs all installed packages with their versions, suitable for requirements.txt. This ensures others can replicate your environment exactly, avoiding version drift.",
    "tags": [
      "pip",
      "requirements",
      "reproducibility"
    ]
  },
  {
    "id": "python-pkg-006",
    "pattern": "^pip\\s+install\\s+.*--no-cache-dir.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --no-cache-dir to save disk space in CI/CD pipelines.",
    "detail": "The --no-cache-dir flag prevents pip from storing downloaded packages, reducing disk usage. This is especially useful in ephemeral environments like CI/CD runners where caching is unnecessary.",
    "tags": [
      "pip",
      "ci",
      "performance"
    ]
  },
  {
    "id": "python-pkg-007",
    "pattern": "^pip\\s+install\\s+.*--pre.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Using --pre may install unstable pre-release packages.",
    "detail": "The --pre flag allows pip to install pre-release and development versions, which may be unstable or incompatible. Use this only when you specifically need to test or develop against pre-release software.",
    "tags": [
      "pip",
      "stability",
      "pre-release"
    ]
  },
  {
    "id": "python-pkg-008",
    "pattern": "^pip\\s+install\\s+.*--no-deps.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Using --no-deps skips dependency installation; resolve manually.",
    "detail": "The --no-deps flag tells pip not to install dependencies, which can lead to missing packages and runtime errors. Only use this if you are certain all dependencies are already installed.",
    "tags": [
      "pip",
      "dependencies",
      "footgun"
    ]
  },
  {
    "id": "python-pkg-009",
    "pattern": "^pip\\s+install\\s+.*--force-reinstall.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --force-reinstall to overwrite broken or corrupted installs.",
    "detail": "If a package is corrupted or partially installed, --force-reinstall ensures a clean reinstallation. This can resolve issues where pip refuses to reinstall an already-present package.",
    "tags": [
      "pip",
      "reinstall",
      "troubleshooting"
    ]
  },
  {
    "id": "python-pkg-010",
    "pattern": "^pip\\s+install\\s+.*--find-links=.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --find-links to point pip at local or custom package indexes.",
    "detail": "The --find-links option allows pip to search additional directories or URLs for packages, useful for internal mirrors or offline installs. It complements --index-url but does not replace it.",
    "tags": [
      "pip",
      "mirrors",
      "offline"
    ]
  },
  {
    "id": "python-pkg-011",
    "pattern": "^pip\\s+install\\s+.*--trusted-host=.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Avoid --trusted-host unless absolutely necessary; it's a security risk.",
    "detail": "Using --trusted-host disables SSL verification for the specified host, exposing you to man-in-the-middle attacks. Prefer configuring proper certificates or using secure indexes.",
    "tags": [
      "pip",
      "security",
      "ssl"
    ]
  },
  {
    "id": "python-pkg-012",
    "pattern": "^pip\\s+install\\s+.*--extra-index-url=.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --extra-index-url to add private package repositories.",
    "detail": "This flag lets pip search additional package indexes after PyPI. It's useful for organizations hosting private packages, but order matters: PyPI is always searched first unless --index-url is overridden.",
    "tags": [
      "pip",
      "private",
      "repositories"
    ]
  },
  {
    "id": "python-pkg-013",
    "pattern": "^pip\\s+install\\s+.*--proxy=.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --proxy to route pip traffic through a proxy server.",
    "detail": "The --proxy flag supports HTTP(S) proxies, including authentication. This is essential in restricted or corporate networks, but ensure credentials are protected and not logged.",
    "tags": [
      "pip",
      "proxy",
      "network"
    ]
  },
  {
    "id": "python-pkg-014",
    "pattern": "^pip\\s+install\\s+.*--no-binary\\s+all.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --no-binary all to force source builds for all packages.",
    "detail": "This flag ensures pip builds everything from source, which is useful for debugging or when binary wheels are unavailable. Be aware this can significantly slow down installs and may require build dependencies.",
    "tags": [
      "pip",
      "source",
      "build"
    ]
  },
  {
    "id": "python-pkg-015",
    "pattern": "^pip\\s+install\\s+.*--upgrade-strategy\\s+eager.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --upgrade-strategy eager to update all dependencies.",
    "detail": "The default strategy is 'only-if-needed', which upgrades only direct dependencies. 'eager' upgrades all dependencies to the newest versions, which can help resolve conflicts but may introduce incompatibilities.",
    "tags": [
      "pip",
      "dependencies",
      "upgrade"
    ]
  },
  {
    "id": "python-pkg-016",
    "pattern": "^pip\\s+install\\s+.*--break-system-packages.*",
    "cmd": "pip",
    "severity": "danger",
    "hint": "Avoid --break-system-packages; it can corrupt system Python installs.",
    "detail": "This flag allows pip to install into system-managed Python environments, potentially overwriting or breaking OS-provided packages. Use only in isolated containers or virtual environments.",
    "tags": [
      "pip",
      "system",
      "danger"
    ]
  },
  {
    "id": "python-pkg-017",
    "pattern": "^python\\s+-m\\s+venv\\s+.*",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use python -m venv for built-in, cross-platform virtualenvs.",
    "detail": "python -m venv is the standard way to create virtual environments in Python 3.3+, avoiding external dependencies. It ensures consistent behavior across platforms, but lacks some advanced features of the virtualenv package.",
    "tags": [
      "venv",
      "virtualenv",
      "isolation"
    ]
  },
  {
    "id": "python-pkg-018",
    "pattern": "^virtualenv\\s+.*",
    "cmd": "virtualenv",
    "severity": "upgrade",
    "hint": "Prefer python -m venv over virtualenv for most use cases.",
    "detail": "python -m venv is included in Python 3.3+ and is sufficient for most workflows. virtualenv is still useful for older Python versions or advanced features, but adds extra dependencies.",
    "tags": [
      "virtualenv",
      "venv",
      "upgrade"
    ]
  },
  {
    "id": "python-pkg-019",
    "pattern": "^pip\\s+install\\s+.*-c\\s+constraints.txt.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use -c constraints.txt to pin indirect dependency versions.",
    "detail": "Constraints files allow you to specify versions for dependencies not directly listed in requirements.txt, ensuring consistent indirect dependency resolution across environments.",
    "tags": [
      "pip",
      "constraints",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-020",
    "pattern": "^pip\\s+install\\s+.*--editable\\s+.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Editable installs require a setup.py or pyproject.toml with [project].",
    "detail": "If the project lacks the correct metadata file, pip will fail or install incorrectly. For PEP 517/518 builds, ensure pyproject.toml has a [project] section and build-backend defined.",
    "tags": [
      "pip",
      "editable",
      "pyproject.toml"
    ]
  },
  {
    "id": "python-pkg-021",
    "pattern": "^pip\\s+install\\s+.*--root=.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Using --root installs packages outside sys.path; use with care.",
    "detail": "The --root option changes the root directory for installation, which can break imports if sys.path is not updated accordingly. Intended for packaging or system image builds, not normal development.",
    "tags": [
      "pip",
      "install",
      "sys.path"
    ]
  },
  {
    "id": "python-pkg-022",
    "pattern": "^conda\\s+install\\s+.*pip.*",
    "cmd": "conda",
    "severity": "warn",
    "hint": "Mixing pip and conda can cause dependency conflicts.",
    "detail": "Conda and pip manage dependencies differently. Installing pip packages in a conda environment can lead to unsatisfiable dependencies or broken environments. Prefer conda packages when available.",
    "tags": [
      "conda",
      "pip",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-023",
    "pattern": "^conda\\s+update\\s+-all.*",
    "cmd": "conda",
    "severity": "warn",
    "hint": "conda update -all may break environments; review changes first.",
    "detail": "Updating all packages can introduce incompatibilities or remove packages due to dependency resolution. Use conda update <package> for targeted upgrades, and always review the proposed changes.",
    "tags": [
      "conda",
      "update",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-024",
    "pattern": "^conda\\s+create\\s+-n\\s+.*python=.*",
    "cmd": "conda",
    "severity": "tip",
    "hint": "Pin Python version in conda envs for reproducibility.",
    "detail": "Specifying python=3.x ensures the environment uses the intended interpreter version, avoiding accidental upgrades or incompatibilities with dependencies.",
    "tags": [
      "conda",
      "env",
      "python-version"
    ]
  },
  {
    "id": "python-pkg-025",
    "pattern": "^conda\\s+env\\s+export.*",
    "cmd": "conda",
    "severity": "tip",
    "hint": "Use conda env export > env.yml to capture full environment state.",
    "detail": "This command exports all packages, including pip-installed ones, ensuring others can recreate the environment exactly. Useful for sharing or deploying consistent setups.",
    "tags": [
      "conda",
      "env",
      "reproducibility"
    ]
  },
  {
    "id": "python-pkg-026",
    "pattern": "^poetry\\s+add\\s+.*",
    "cmd": "poetry",
    "severity": "tip",
    "hint": "Use poetry add --dev for development-only dependencies.",
    "detail": "The --dev flag ensures packages are only installed in development environments, keeping production deployments lean and secure. These are listed under [tool.poetry.dev-dependencies] in pyproject.toml.",
    "tags": [
      "poetry",
      "dev",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-027",
    "pattern": "^poetry\\s+install\\s+.*--no-root.*",
    "cmd": "poetry",
    "severity": "tip",
    "hint": "Use --no-root to skip installing the current project package.",
    "detail": "This is useful for CI pipelines or when you only want to install dependencies, not the project itself. It avoids polluting the environment with local code during testing.",
    "tags": [
      "poetry",
      "install",
      "ci"
    ]
  },
  {
    "id": "python-pkg-028",
    "pattern": "^poetry\\s+lock\\s+--no-update.*",
    "cmd": "poetry",
    "severity": "tip",
    "hint": "Use --no-update to regenerate poetry.lock without changing versions.",
    "detail": "This command refreshes the lock file to match pyproject.toml constraints, but does not update dependency versions. Useful after editing only metadata or resolving merge conflicts.",
    "tags": [
      "poetry",
      "lock",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-029",
    "pattern": "^poetry\\s+publish\\s+.*--build.*",
    "cmd": "poetry",
    "severity": "tip",
    "hint": "Use --build to ensure a fresh build before publishing.",
    "detail": "The --build flag creates a new distribution before uploading, ensuring the published package matches the latest source. Without it, Poetry may reuse an outdated build.",
    "tags": [
      "poetry",
      "publish",
      "build"
    ]
  },
  {
    "id": "python-pkg-030",
    "pattern": "^uv\\s+pip\\s+install\\s+.*",
    "cmd": "uv",
    "severity": "upgrade",
    "hint": "uv pip is a drop-in, much faster replacement for pip.",
    "detail": "uv pip leverages Rust for significant speed improvements, especially in dependency resolution and installation. It is compatible with most pip workflows and supports requirements.txt files.",
    "tags": [
      "uv",
      "pip",
      "performance"
    ]
  },
  {
    "id": "python-pkg-031",
    "pattern": "^pdm\\s+install\\s+.*--prod.*",
    "cmd": "pdm",
    "severity": "tip",
    "hint": "Use --prod to install only production dependencies.",
    "detail": "This flag skips dev dependencies, reducing attack surface and install time for production deployments. It reads from pyproject.toml's [project.dependencies] section.",
    "tags": [
      "pdm",
      "install",
      "production"
    ]
  },
  {
    "id": "python-pkg-032",
    "pattern": "^hatch\\s+env\\s+create\\s+.*",
    "cmd": "hatch",
    "severity": "tip",
    "hint": "Use hatch env create for isolated, reproducible dev environments.",
    "detail": "Hatch environments are fully isolated and defined in pyproject.toml, supporting matrix builds and custom dependencies. This prevents global pollution and ensures consistent local setups.",
    "tags": [
      "hatch",
      "env",
      "isolation"
    ]
  },
  {
    "id": "python-pkg-033",
    "pattern": "^pip\\s+install\\s+.*--use-deprecated=legacy-resolver.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Avoid legacy-resolver; it may produce broken or inconsistent installs.",
    "detail": "The legacy resolver ignores dependency conflicts and can result in environments with incompatible packages. Use the default resolver for safer, more predictable dependency management.",
    "tags": [
      "pip",
      "resolver",
      "dependencies"
    ]
  },
  {
    "id": "python-pkg-034",
    "pattern": "^pip\\s+install\\s+.*--target=.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --target to install packages into a specific directory.",
    "detail": "This is useful for building zipapps, AWS Lambda, or custom deployment bundles. Remember to add the target directory to PYTHONPATH so Python can find the packages.",
    "tags": [
      "pip",
      "target",
      "deployment"
    ]
  },
  {
    "id": "python-pkg-035",
    "pattern": "^pip\\s+install\\s+.*--no-build-isolation.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Disabling build isolation can cause inconsistent builds.",
    "detail": "Build isolation ensures that build dependencies are installed in a temporary environment, avoiding contamination from the current environment. Disabling it may lead to subtle, hard-to-debug build errors.",
    "tags": [
      "pip",
      "build",
      "isolation"
    ]
  },
  {
    "id": "python-pkg-036",
    "pattern": "^pip\\s+install\\s+.*--compile.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Use --compile to generate .pyc files for faster startup.",
    "detail": "This flag precompiles Python files to bytecode during installation, reducing import time at runtime. Useful for performance-critical deployments or embedded systems.",
    "tags": [
      "pip",
      "performance",
      "compile"
    ]
  },
  {
    "id": "python-pkg-037",
    "pattern": "^pip\\s+install\\s+.*--no-warn-script-location.*",
    "cmd": "pip",
    "severity": "warn",
    "hint": "Suppressing script location warnings may hide PATH issues.",
    "detail": "If scripts are installed outside your PATH, you may not be able to run them. Pay attention to these warnings to ensure installed CLI tools are accessible.",
    "tags": [
      "pip",
      "scripts",
      "path"
    ]
  },
  {
    "id": "python-pkg-038",
    "pattern": "^pip\\s+install\\s+.*--retries=\\d+.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Increase --retries for flaky network connections.",
    "detail": "The default is 5 retries. Raising this can help in unreliable networks, but may mask persistent connectivity or index issues. Combine with --timeout for best results.",
    "tags": [
      "pip",
      "network",
      "retries"
    ]
  },
  {
    "id": "python-pkg-039",
    "pattern": "^pip\\s+install\\s+.*--timeout=\\d+.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Increase --timeout for slow or high-latency networks.",
    "detail": "The default timeout is 15 seconds. Increasing this helps avoid failed installs in slow environments, especially when downloading large packages or using remote indexes.",
    "tags": [
      "pip",
      "network",
      "timeout"
    ]
  },
  {
    "id": "python-pkg-040",
    "pattern": "^pip\\s+install\\s+.*--progress-bar\\s+off.*",
    "cmd": "pip",
    "severity": "tip",
    "hint": "Disable progress bar in CI logs for cleaner output.",
    "detail": "The --progress-bar off flag prevents pip from printing progress bars, which can clutter CI logs or terminals that do not support ANSI control codes. Useful for automated builds and log parsing.",
    "tags": [
      "pip",
      "ci",
      "logging"
    ]
  },
  {
    "id": "python-dev-001",
    "pattern": "^black\\s+.+--fast",
    "cmd": "black",
    "severity": "warn",
    "hint": "Avoid --fast; it skips safety checks. Use --safe for reliability.",
    "detail": "The --fast flag disables Black's sanity checks, which can result in formatting files that may not parse correctly. Use --safe to ensure Black validates syntax before writing changes, especially in CI pipelines.",
    "tags": [
      "black",
      "formatting",
      "ci"
    ]
  },
  {
    "id": "python-dev-002",
    "pattern": "^pytest\\s+.+--maxfail=1",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --maxfail=1 for quick feedback on first test failure.",
    "detail": "The --maxfail flag stops the test run after a specified number of failures. Setting --maxfail=1 is useful for rapid iteration, especially in TDD, but remember to remove it for full test runs.",
    "tags": [
      "pytest",
      "testing",
      "productivity"
    ]
  },
  {
    "id": "python-dev-003",
    "pattern": "^pytest\\s+.+--tb=short",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --tb=short for concise tracebacks in noisy test suites.",
    "detail": "The --tb option controls traceback verbosity. --tb=short gives a compact output, making it easier to spot failures in large test suites. Combine with --maxfail for even faster debugging.",
    "tags": [
      "pytest",
      "testing",
      "output"
    ]
  },
  {
    "id": "python-dev-004",
    "pattern": "^pytest\\s+.+--disable-warnings",
    "cmd": "pytest",
    "severity": "warn",
    "hint": "Don't ignore warnings globally; fix or filter them explicitly.",
    "detail": "Using --disable-warnings can hide deprecation or runtime warnings that may break code in future Python versions. Prefer filtering specific warnings with --filterwarnings or fixing the root causes.",
    "tags": [
      "pytest",
      "testing",
      "warnings"
    ]
  },
  {
    "id": "python-dev-005",
    "pattern": "^mypy\\s+.+--ignore-missing-imports",
    "cmd": "mypy",
    "severity": "warn",
    "hint": "Avoid --ignore-missing-imports; it hides type errors in dependencies.",
    "detail": "This flag suppresses errors for missing stubs in imported modules, potentially masking real type issues. Instead, install type stubs (e.g., types-requests) or use per-module configuration in mypy.ini for finer control.",
    "tags": [
      "mypy",
      "typing",
      "dependencies"
    ]
  },
  {
    "id": "python-dev-006",
    "pattern": "^ruff\\s+.+--fix-only",
    "cmd": "ruff",
    "severity": "tip",
    "hint": "Use --fix-only to auto-fix issues without reporting new ones.",
    "detail": "The --fix-only flag applies automatic fixes but does not report new violations. This is useful in pre-commit hooks to avoid noisy output, but always run a full check before merging.",
    "tags": [
      "ruff",
      "linting",
      "pre-commit"
    ]
  },
  {
    "id": "python-dev-007",
    "pattern": "^pylint\\s+.+--disable=all",
    "cmd": "pylint",
    "severity": "danger",
    "hint": "Never use --disable=all; it disables all checks and defeats linting.",
    "detail": "Disabling all checks with --disable=all renders pylint ineffective. Instead, selectively disable specific checks using --disable=<msg-id> or configure disables in .pylintrc for granular control.",
    "tags": [
      "pylint",
      "linting",
      "config"
    ]
  },
  {
    "id": "python-dev-008",
    "pattern": "^pytest\\s+.+--capture=no",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --capture=no to see real-time stdout/stderr during tests.",
    "detail": "The --capture=no flag disables output capturing, allowing print statements and logs to appear immediately. This is helpful for debugging, but can clutter output in large suites.",
    "tags": [
      "pytest",
      "debugging",
      "output"
    ]
  },
  {
    "id": "python-dev-009",
    "pattern": "^coverage\\s+run\\s+.+--branch",
    "cmd": "coverage",
    "severity": "tip",
    "hint": "Use --branch to measure branch coverage, not just line coverage.",
    "detail": "The --branch flag tracks which code branches (if/else, try/except) are executed, providing deeper insight than line coverage alone. This helps catch untested logic paths.",
    "tags": [
      "coverage",
      "testing",
      "quality"
    ]
  },
  {
    "id": "python-dev-010",
    "pattern": "^pre-commit\\s+run\\s+.+--all-files",
    "cmd": "pre-commit",
    "severity": "tip",
    "hint": "Use --all-files to lint the entire repo, not just staged files.",
    "detail": "By default, pre-commit only checks staged files. The --all-files flag forces hooks to run on every file, ensuring consistent style and catching legacy issues.",
    "tags": [
      "pre-commit",
      "linting",
      "ci"
    ]
  },
  {
    "id": "python-dev-011",
    "pattern": "^tox\\s+.+--parallel",
    "cmd": "tox",
    "severity": "tip",
    "hint": "Use --parallel to run environments concurrently for faster CI.",
    "detail": "The --parallel flag allows tox to execute multiple environments in parallel, significantly reducing test suite run times on multicore systems. Monitor resource usage to avoid overloading CI runners.",
    "tags": [
      "tox",
      "testing",
      "performance"
    ]
  },
  {
    "id": "python-dev-012",
    "pattern": "^pytest\\s+.+-n\\s+\\d+",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use -n <N> (pytest-xdist) for parallel test execution.",
    "detail": "The -n flag from pytest-xdist distributes tests across N processes, speeding up large suites. Beware of shared state or filesystem dependencies between tests, which can cause flaky failures.",
    "tags": [
      "pytest",
      "performance",
      "parallel"
    ]
  },
  {
    "id": "python-dev-013",
    "pattern": "^pytest\\s+.+--lf",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --lf to rerun only the tests that failed last time.",
    "detail": "The --lf (last-failed) flag reruns only previously failing tests, accelerating feedback during debugging. Combine with --maxfail for even faster cycles.",
    "tags": [
      "pytest",
      "testing",
      "productivity"
    ]
  },
  {
    "id": "python-dev-014",
    "pattern": "^pytest\\s+.+--ff",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --ff to run last-failed tests first, then the rest.",
    "detail": "The --ff (failed-first) flag prioritizes previously failing tests, then runs the rest. This helps catch regressions early in large suites.",
    "tags": [
      "pytest",
      "testing",
      "productivity"
    ]
  },
  {
    "id": "python-dev-015",
    "pattern": "^pytest\\s+.+--durations=\\d+",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --durations=N to profile slowest tests and optimize performance.",
    "detail": "The --durations flag reports the N slowest tests, helping identify bottlenecks. Use this regularly to keep test suites fast and maintainable.",
    "tags": [
      "pytest",
      "performance",
      "profiling"
    ]
  },
  {
    "id": "python-dev-016",
    "pattern": "^pytest\\s+.+--exitfirst",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --exitfirst to stop on first failure for rapid feedback.",
    "detail": "The --exitfirst flag halts the test run after the first failure, useful for TDD or debugging. Combine with --maxfail for more granular control.",
    "tags": [
      "pytest",
      "testing",
      "productivity"
    ]
  },
  {
    "id": "python-dev-017",
    "pattern": "^ruff\\s+.+--select=ALL",
    "cmd": "ruff",
    "severity": "warn",
    "hint": "Avoid --select=ALL; it enables all rules, including unstable ones.",
    "detail": "Selecting ALL rules can introduce false positives and unstable checks. Instead, specify rule sets relevant to your codebase or use a ruff.toml config to fine-tune.",
    "tags": [
      "ruff",
      "linting",
      "config"
    ]
  },
  {
    "id": "python-dev-018",
    "pattern": "^black\\s+.+--diff",
    "cmd": "black",
    "severity": "tip",
    "hint": "Use --diff to preview changes without modifying files.",
    "detail": "The --diff flag outputs a unified diff of proposed changes, allowing review before applying formatting. Useful for code reviews or integrating into CI pipelines.",
    "tags": [
      "black",
      "formatting",
      "ci"
    ]
  },
  {
    "id": "python-dev-019",
    "pattern": "^mypy\\s+.+--strict",
    "cmd": "mypy",
    "severity": "tip",
    "hint": "Use --strict for comprehensive type checking in new projects.",
    "detail": "The --strict flag enables all optional type checks, catching subtle bugs early. For legacy code, incrementally enable strictness via mypy.ini to avoid overwhelming error output.",
    "tags": [
      "mypy",
      "typing",
      "quality"
    ]
  },
  {
    "id": "python-dev-020",
    "pattern": "^pylint\\s+.+--output-format=json",
    "cmd": "pylint",
    "severity": "tip",
    "hint": "Use --output-format=json for machine-readable lint results.",
    "detail": "JSON output is ideal for integrating pylint with CI/CD systems or custom dashboards. Parseable output enables automated reporting and trend analysis.",
    "tags": [
      "pylint",
      "linting",
      "ci"
    ]
  },
  {
    "id": "python-dev-021",
    "pattern": "^pytest\\s+.+--cov",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --cov to measure test coverage directly with pytest-cov.",
    "detail": "The --cov flag integrates coverage measurement into pytest runs. Specify modules or directories for granular reporting. Combine with --cov-report for HTML or XML output.",
    "tags": [
      "pytest",
      "coverage",
      "testing"
    ]
  },
  {
    "id": "python-dev-022",
    "pattern": "^coverage\\s+report\\s+.+--fail-under=\\d+",
    "cmd": "coverage",
    "severity": "tip",
    "hint": "Use --fail-under=N to enforce minimum coverage in CI.",
    "detail": "The --fail-under flag causes the command to exit nonzero if coverage is below N percent, enforcing quality gates in automated pipelines.",
    "tags": [
      "coverage",
      "testing",
      "ci"
    ]
  },
  {
    "id": "python-dev-023",
    "pattern": "^hypothesis\\s+run",
    "cmd": "hypothesis",
    "severity": "upgrade",
    "hint": "Hypothesis CLI is deprecated; use pytest with @given instead.",
    "detail": "Hypothesis CLI is no longer maintained. The recommended approach is to use the @given decorator with pytest for property-based testing, enabling better integration and reporting.",
    "tags": [
      "hypothesis",
      "pytest",
      "testing"
    ]
  },
  {
    "id": "python-dev-024",
    "pattern": "^tox\\s+.+--recreate",
    "cmd": "tox",
    "severity": "tip",
    "hint": "Use --recreate to force environment rebuilds after dependency changes.",
    "detail": "The --recreate flag deletes and rebuilds virtualenvs, ensuring dependency updates are applied. Use after modifying requirements or tox.ini to avoid stale environments.",
    "tags": [
      "tox",
      "env",
      "dependencies"
    ]
  },
  {
    "id": "python-dev-025",
    "pattern": "^pre-commit\\s+install\\s+--hook-type\\s+pre-push",
    "cmd": "pre-commit",
    "severity": "tip",
    "hint": "Use --hook-type pre-push to run hooks before git push.",
    "detail": "By default, pre-commit installs pre-commit hooks. Use --hook-type pre-push to enforce checks before pushing, catching issues missed at commit time.",
    "tags": [
      "pre-commit",
      "git",
      "hooks"
    ]
  },
  {
    "id": "python-dev-026",
    "pattern": "^py-spy\\s+record\\s+.+--flame",
    "cmd": "py-spy",
    "severity": "tip",
    "hint": "Use --flame to generate interactive flamegraphs for profiling.",
    "detail": "The --flame flag outputs a flamegraph SVG, visualizing call stacks and hotspots. This helps quickly identify performance bottlenecks in production or staging environments.",
    "tags": [
      "py-spy",
      "profiling",
      "performance"
    ]
  },
  {
    "id": "python-dev-027",
    "pattern": "^py-spy\\s+top\\s+.+--idle",
    "cmd": "py-spy",
    "severity": "tip",
    "hint": "Use --idle to include idle threads in py-spy top output.",
    "detail": "The --idle flag shows threads even when they're not running Python code, revealing bottlenecks due to I/O or GIL contention. Useful for diagnosing concurrency issues.",
    "tags": [
      "py-spy",
      "profiling",
      "threads"
    ]
  },
  {
    "id": "python-dev-028",
    "pattern": "^memray\\s+run\\s+.+--trace-python-allocators",
    "cmd": "memray",
    "severity": "tip",
    "hint": "Use --trace-python-allocators to track Python-level allocations.",
    "detail": "This flag enables tracking of Python object allocations, not just native memory. It helps pinpoint memory leaks in pure Python code, complementing native leak detection.",
    "tags": [
      "memray",
      "profiling",
      "memory"
    ]
  },
  {
    "id": "python-dev-029",
    "pattern": "^scalene\\s+.+--cpu-only",
    "cmd": "scalene",
    "severity": "tip",
    "hint": "Use --cpu-only to profile CPU time without memory overhead.",
    "detail": "The --cpu-only flag disables memory profiling, reducing overhead and focusing on CPU-bound performance issues. Ideal for quick profiling runs.",
    "tags": [
      "scalene",
      "profiling",
      "performance"
    ]
  },
  {
    "id": "python-dev-030",
    "pattern": "^scalene\\s+.+--reduced-profile",
    "cmd": "scalene",
    "severity": "tip",
    "hint": "Use --reduced-profile for faster, lower-overhead sampling.",
    "detail": "The --reduced-profile flag lowers sampling rates, reducing profiling overhead at the cost of some accuracy. Useful for profiling in production or on large codebases.",
    "tags": [
      "scalene",
      "profiling",
      "performance"
    ]
  },
  {
    "id": "python-dev-031",
    "pattern": "^pytest\\s+.+--import-mode=append",
    "cmd": "pytest",
    "severity": "warn",
    "hint": "Avoid --import-mode=append; prefer import-mode=importlib for isolation.",
    "detail": "The append mode can cause test pollution due to sys.path manipulation. Use importlib mode (pytest>=6.0) for better import isolation and fewer side effects.",
    "tags": [
      "pytest",
      "import",
      "isolation"
    ]
  },
  {
    "id": "python-dev-032",
    "pattern": "^pytest\\s+.+--confcutdir=\\S+",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --confcutdir to control which pytest config is loaded.",
    "detail": "The --confcutdir flag sets the directory where pytest stops searching for config files. This avoids accidentally loading configs from parent directories, ensuring test isolation.",
    "tags": [
      "pytest",
      "config",
      "isolation"
    ]
  },
  {
    "id": "python-dev-033",
    "pattern": "^pytest\\s+.+--random-order",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --random-order to detect hidden test dependencies.",
    "detail": "Randomizing test order can reveal inter-test dependencies and flaky tests. Use pytest-random-order or pytest-randomly plugins to enable this feature.",
    "tags": [
      "pytest",
      "testing",
      "flaky"
    ]
  },
  {
    "id": "python-dev-034",
    "pattern": "^black\\s+.+--line-length=\\d+",
    "cmd": "black",
    "severity": "tip",
    "hint": "Set --line-length to match project style; default is 88.",
    "detail": "Black defaults to 88 characters per line. Override with --line-length to match legacy code or team standards, but keep it consistent across the project.",
    "tags": [
      "black",
      "formatting",
      "style"
    ]
  },
  {
    "id": "python-dev-035",
    "pattern": "^ruff\\s+.+--show-source",
    "cmd": "ruff",
    "severity": "tip",
    "hint": "Use --show-source to display offending code lines in output.",
    "detail": "The --show-source flag prints the source line for each violation, making it easier to spot and fix issues directly from the CLI.",
    "tags": [
      "ruff",
      "linting",
      "output"
    ]
  },
  {
    "id": "python-dev-036",
    "pattern": "^mypy\\s+.+--cache-dir=\\S+",
    "cmd": "mypy",
    "severity": "tip",
    "hint": "Use --cache-dir to speed up repeated mypy runs in CI.",
    "detail": "Specifying a persistent cache directory allows mypy to reuse previous results, significantly speeding up type checking in continuous integration environments.",
    "tags": [
      "mypy",
      "performance",
      "ci"
    ]
  },
  {
    "id": "python-dev-037",
    "pattern": "^pylint\\s+.+--jobs=\\d+",
    "cmd": "pylint",
    "severity": "tip",
    "hint": "Use --jobs=N for parallel linting of multiple files.",
    "detail": "The --jobs flag enables parallel processing, reducing linting time on multicore systems. Useful for large codebases or CI pipelines.",
    "tags": [
      "pylint",
      "performance",
      "parallel"
    ]
  },
  {
    "id": "python-dev-038",
    "pattern": "^pytest\\s+.+--rootdir=\\S+",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --rootdir to explicitly set the project root for test discovery.",
    "detail": "Setting --rootdir ensures pytest discovers tests and config files from the correct directory, avoiding issues with nested or monorepo structures.",
    "tags": [
      "pytest",
      "config",
      "discovery"
    ]
  },
  {
    "id": "python-dev-039",
    "pattern": "^pre-commit\\s+autoupdate",
    "cmd": "pre-commit",
    "severity": "tip",
    "hint": "Run pre-commit autoupdate regularly to keep hooks up to date.",
    "detail": "The autoupdate command updates hook versions in .pre-commit-config.yaml, ensuring you benefit from bug fixes and security patches. Review diffs before committing.",
    "tags": [
      "pre-commit",
      "maintenance",
      "security"
    ]
  },
  {
    "id": "python-dev-040",
    "pattern": "^pytest\\s+.+--strict-markers",
    "cmd": "pytest",
    "severity": "tip",
    "hint": "Use --strict-markers to catch typos in custom pytest markers.",
    "detail": "The --strict-markers flag causes pytest to error on unknown markers, preventing silent test skips due to typos or misconfigurations in marker names.",
    "tags": [
      "pytest",
      "testing",
      "quality"
    ]
  },
  {
    "id": "jupyter-001",
    "pattern": "^jupyter\\s+notebook\\s+--no-browser",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Use --ip=0.0.0.0 for remote access, not just --no-browser.",
    "detail": "The --no-browser flag prevents the browser from opening but does not make the server accessible remotely. To bind to all interfaces for remote access, add --ip=0.0.0.0. Otherwise, the notebook will only listen on localhost.",
    "tags": [
      "notebook",
      "network",
      "remote"
    ]
  },
  {
    "id": "jupyter-002",
    "pattern": "^jupyter\\s+notebook\\s+--allow-root",
    "cmd": "jupyter",
    "severity": "danger",
    "hint": "Avoid running Jupyter as root; use a non-privileged user.",
    "detail": "Running Jupyter Notebook as root can expose your system to privilege escalation and security vulnerabilities. The --allow-root flag bypasses safety checks and should only be used in controlled, containerized environments.",
    "tags": [
      "notebook",
      "security",
      "root"
    ]
  },
  {
    "id": "jupyter-003",
    "pattern": "^jupyter\\s+notebook\\s+--NotebookApp\\.token='?'?''?'?",
    "cmd": "jupyter",
    "severity": "danger",
    "hint": "Never disable token auth in production; set a strong token.",
    "detail": "Setting --NotebookApp.token='' disables authentication, exposing the notebook server to anyone with network access. This is extremely risky on shared or public networks. Always use a strong token or password in production.",
    "tags": [
      "notebook",
      "security",
      "auth"
    ]
  },
  {
    "id": "jupyter-004",
    "pattern": "^jupyter\\s+notebook\\s+--port=8888",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Check if port 8888 is available; use --port-retries for fallback.",
    "detail": "Port 8888 is the default and may already be in use, causing the notebook server to fail to start. Use --port-retries to automatically try alternative ports if 8888 is unavailable.",
    "tags": [
      "notebook",
      "network",
      "port"
    ]
  },
  {
    "id": "jupyter-005",
    "pattern": "^jupyter\\s+notebook\\s+--notebook-dir=.+",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Set --notebook-dir to restrict file browser scope.",
    "detail": "Specifying --notebook-dir limits the file browser to a specific directory, improving security and reducing clutter. This is especially useful on shared systems or when serving notebooks from a project folder.",
    "tags": [
      "notebook",
      "filesystem",
      "security"
    ]
  },
  {
    "id": "jupyter-006",
    "pattern": "^jupyter\\s+lab\\s+--dev-mode",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Dev mode disables some security checks; avoid in production.",
    "detail": "The --dev-mode flag is intended for JupyterLab extension development and disables certain security features. Running in this mode in production can expose your server to vulnerabilities.",
    "tags": [
      "lab",
      "security",
      "dev"
    ]
  },
  {
    "id": "jupyter-007",
    "pattern": "^jupyter\\s+lab\\s+--watch",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use --watch for live extension reloads during development.",
    "detail": "The --watch flag enables hot-reloading of JupyterLab extensions, speeding up the development cycle. This is not needed for normal usage and can consume extra resources.",
    "tags": [
      "lab",
      "dev",
      "performance"
    ]
  },
  {
    "id": "jupyter-008",
    "pattern": "^jupyter\\s+lab\\s+--collaborative",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Enable --collaborative for real-time multi-user editing.",
    "detail": "The --collaborative flag activates JupyterLab's real-time collaboration features, allowing multiple users to edit notebooks simultaneously. This requires JupyterLab 3.1+ and may need additional configuration for production use.",
    "tags": [
      "lab",
      "collaboration",
      "feature"
    ]
  },
  {
    "id": "jupyter-009",
    "pattern": "^jupyter\\s+lab\\s+--SingleUserNotebookApp\\.default_url=.+",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Set default_url to open a specific notebook or dashboard on launch.",
    "detail": "The --SingleUserNotebookApp.default_url flag lets you specify the initial page, such as a notebook, dashboard, or file browser path. This improves user experience in multi-user or kiosk setups.",
    "tags": [
      "lab",
      "config",
      "usability"
    ]
  },
  {
    "id": "jupyter-010",
    "pattern": "^jupyter\\s+lab\\s+--no-browser",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Combine --no-browser with --ip=0.0.0.0 for remote access.",
    "detail": "Using --no-browser alone prevents the browser from opening but does not make the server accessible remotely. Add --ip=0.0.0.0 to bind to all interfaces for SSH tunneling or remote access.",
    "tags": [
      "lab",
      "network",
      "remote"
    ]
  },
  {
    "id": "jupyter-011",
    "pattern": "^jupyter\\s+lab\\s+extension\\s+install\\s+.+",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Restart JupyterLab after installing extensions for changes to apply.",
    "detail": "JupyterLab extensions often require a server restart to be fully loaded. Some extensions may not function correctly until the server is restarted, even if installation appears successful.",
    "tags": [
      "lab",
      "extension",
      "install"
    ]
  },
  {
    "id": "jupyter-012",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--execute",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Use --ExecutePreprocessor.timeout to avoid infinite execution.",
    "detail": "By default, nbconvert's --execute will wait indefinitely for cells to finish. Set --ExecutePreprocessor.timeout=N to limit execution time per cell and avoid hangs on long-running or stuck cells.",
    "tags": [
      "nbconvert",
      "execution",
      "timeout"
    ]
  },
  {
    "id": "jupyter-013",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--to\\s+notebook",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use --to notebook --inplace to overwrite the original notebook.",
    "detail": "The --inplace flag updates the notebook file in place, preserving metadata and outputs. Without --inplace, a new file is created, which can lead to confusion or version drift.",
    "tags": [
      "nbconvert",
      "notebook",
      "output"
    ]
  },
  {
    "id": "jupyter-014",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--clear-output",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Clear outputs before sharing notebooks for reproducibility.",
    "detail": "The --clear-output flag removes all cell outputs, making notebooks cleaner for version control and sharing. This helps avoid merge conflicts and ensures others see only the code, not stale results.",
    "tags": [
      "nbconvert",
      "output",
      "sharing"
    ]
  },
  {
    "id": "jupyter-015",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--to\\s+html",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use --template=lab for modern, responsive HTML exports.",
    "detail": "The --template=lab option produces a more visually appealing and mobile-friendly HTML output, matching the look of JupyterLab. This is preferable to the legacy default template for sharing results.",
    "tags": [
      "nbconvert",
      "html",
      "template"
    ]
  },
  {
    "id": "jupyter-016",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--stdout",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use --stdout to pipe nbconvert output directly to other tools.",
    "detail": "The --stdout flag writes the converted notebook to standard output, enabling chaining with other commands or tools. This is useful for automation and scripting in CI/CD pipelines.",
    "tags": [
      "nbconvert",
      "stdout",
      "automation"
    ]
  },
  {
    "id": "jupyter-017",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--to\\s+pdf",
    "cmd": "jupyter",
    "severity": "warn",
    "hint": "Ensure LaTeX is installed for PDF export; otherwise, export will fail.",
    "detail": "PDF export via nbconvert requires a full LaTeX installation (e.g., texlive). If LaTeX is missing, the conversion will silently fail or produce incomplete output. Check dependencies before exporting.",
    "tags": [
      "nbconvert",
      "pdf",
      "dependency"
    ]
  },
  {
    "id": "jupyter-018",
    "pattern": "^jupyter\\s+nbconvert\\s+.+--to\\s+script",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use --to script for quick Python script extraction from notebooks.",
    "detail": "The --to script option converts notebooks to .py files, preserving code cells as script blocks. This is useful for versioning or running code outside the notebook environment.",
    "tags": [
      "nbconvert",
      "script",
      "conversion"
    ]
  },
  {
    "id": "jupyter-019",
    "pattern": "^jupyter\\s+nbformat\\s+validate\\s+.+",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Validate notebook JSON structure before processing with tools.",
    "detail": "nbformat validate checks notebook files for schema compliance, catching issues that can cause downstream tools to fail. This is especially important before automated processing or sharing.",
    "tags": [
      "nbformat",
      "validate",
      "schema"
    ]
  },
  {
    "id": "jupyter-020",
    "pattern": "^jupyter\\s+nbformat\\s+convert\\s+.+",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use nbformat convert to upgrade/downgrade notebook formats.",
    "detail": "nbformat convert allows you to change the notebook version (e.g., v3 to v4), ensuring compatibility with different Jupyter environments. This is critical when collaborating across teams or legacy systems.",
    "tags": [
      "nbformat",
      "convert",
      "compatibility"
    ]
  },
  {
    "id": "jupyter-021",
    "pattern": "^papermill\\s+.+--parameters\\s+.+",
    "cmd": "papermill",
    "severity": "tip",
    "hint": "Use --parameters to inject variables for parameterized runs.",
    "detail": "Papermill's --parameters flag allows dynamic injection of variables into notebooks, enabling reproducible and automated parameter sweeps. This is essential for pipeline automation and experimentation.",
    "tags": [
      "papermill",
      "parameters",
      "automation"
    ]
  },
  {
    "id": "jupyter-022",
    "pattern": "^papermill\\s+.+--kernel\\s+.+",
    "cmd": "papermill",
    "severity": "warn",
    "hint": "Ensure the specified kernel exists; mismatches cause silent failures.",
    "detail": "If the kernel specified with --kernel does not exist or is misspelled, papermill may fail to execute the notebook without clear errors. Use jupyter kernelspec list to verify available kernels.",
    "tags": [
      "papermill",
      "kernel",
      "execution"
    ]
  },
  {
    "id": "jupyter-023",
    "pattern": "^nbstripout\\s+.+",
    "cmd": "nbstripout",
    "severity": "tip",
    "hint": "Use nbstripout to remove outputs before committing notebooks.",
    "detail": "nbstripout cleans output cells from notebooks, reducing merge conflicts and repository bloat. It can be installed as a git filter for automatic output removal on commit.",
    "tags": [
      "nbstripout",
      "git",
      "output"
    ]
  },
  {
    "id": "jupyter-024",
    "pattern": "^nbstripout\\s+install",
    "cmd": "nbstripout",
    "severity": "tip",
    "hint": "Run nbstripout install to enable output stripping for your repo.",
    "detail": "The install command sets up git hooks to automatically strip outputs from notebooks on commit, enforcing clean notebooks in version control. This is a best practice for collaborative projects.",
    "tags": [
      "nbstripout",
      "git",
      "hook"
    ]
  },
  {
    "id": "jupyter-025",
    "pattern": "^jupytext\\s+.+--to\\s+.+",
    "cmd": "jupytext",
    "severity": "upgrade",
    "hint": "Use jupytext for round-trip sync between .ipynb and .py/.md files.",
    "detail": "Jupytext enables seamless conversion between notebooks and plain text formats (Python, Markdown, Rmd), supporting round-trip editing and version control. This modern workflow replaces manual nbconvert scripts.",
    "tags": [
      "jupytext",
      "conversion",
      "upgrade"
    ]
  },
  {
    "id": "jupyter-026",
    "pattern": "^jupytext\\s+.+--sync",
    "cmd": "jupytext",
    "severity": "tip",
    "hint": "Use --sync to keep .ipynb and text files in sync automatically.",
    "detail": "The --sync flag ensures that changes in either the notebook or paired text file are reflected in both, preventing divergence and simplifying collaboration across editors.",
    "tags": [
      "jupytext",
      "sync",
      "collaboration"
    ]
  },
  {
    "id": "jupyter-027",
    "pattern": "^voila\\s+.+",
    "cmd": "voila",
    "severity": "upgrade",
    "hint": "Use voila to turn notebooks into interactive dashboards.",
    "detail": "Voila renders Jupyter notebooks as standalone web apps, hiding code cells and exposing only interactive widgets. This is a modern alternative to sharing raw notebooks for dashboards and demos.",
    "tags": [
      "voila",
      "dashboard",
      "upgrade"
    ]
  },
  {
    "id": "jupyter-028",
    "pattern": "^voila\\s+.+--no-browser",
    "cmd": "voila",
    "severity": "tip",
    "hint": "Combine --no-browser with --port and --ip for remote deployment.",
    "detail": "When deploying voila remotely, use --no-browser to prevent local browser launch, and specify --port and --ip=0.0.0.0 to bind the service for external access.",
    "tags": [
      "voila",
      "remote",
      "deployment"
    ]
  },
  {
    "id": "jupyter-029",
    "pattern": "^jupyter\\s+notebook\\s+list",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Use notebook list to find running servers and their tokens.",
    "detail": "The notebook list command shows URLs and tokens for all running Jupyter servers on the system, helping you recover access if you lose the browser tab or token.",
    "tags": [
      "notebook",
      "management",
      "token"
    ]
  },
  {
    "id": "jupyter-030",
    "pattern": "^jupyter\\s+lab\\s+--ResourceUseDisplay\\.track_cpu_percent=True",
    "cmd": "jupyter",
    "severity": "tip",
    "hint": "Enable ResourceUseDisplay to monitor CPU/memory in JupyterLab.",
    "detail": "The ResourceUseDisplay extension shows real-time CPU and memory usage in the JupyterLab status bar. This helps diagnose performance bottlenecks and runaway kernels.",
    "tags": [
      "lab",
      "resource",
      "monitoring"
    ]
  },
  {
    "id": "datascience-001",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*skiprows=0[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Avoid skiprows=0 in pandas.read_csv; it has no effect.",
    "detail": "Setting skiprows=0 in pandas.read_csv does nothing, but may mislead readers into thinking rows are skipped. Omitting skiprows is equivalent and clearer. This can cause confusion in data preprocessing scripts.",
    "tags": [
      "pandas",
      "csv",
      "parsing",
      "footgun"
    ]
  },
  {
    "id": "datascience-002",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*engine=['\"]python['\"][^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Avoid engine='python' in pandas.read_csv unless necessary.",
    "detail": "The 'python' engine in pandas.read_csv is much slower and less robust than the default 'c' engine. Only use it for exotic CSV dialects. For large files, this can drastically increase load times.",
    "tags": [
      "pandas",
      "csv",
      "performance",
      "engine"
    ]
  },
  {
    "id": "datascience-003",
    "pattern": "^python\\s+.*import\\s+pandas.*to_csv\\([^)]*index=True[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "to_csv(index=True) writes index column; check if needed.",
    "detail": "By default, pandas.DataFrame.to_csv writes the index as the first column. This can lead to duplicated or confusing columns when reloading the CSV. Set index=False unless you explicitly need the index.",
    "tags": [
      "pandas",
      "csv",
      "output",
      "index"
    ]
  },
  {
    "id": "datascience-004",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*dtype=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Explicit dtype=None disables type inference in pandas.read_csv.",
    "detail": "Setting dtype=None in pandas.read_csv disables automatic type inference, causing all columns to be read as objects. This can break downstream numeric operations and slow performance.",
    "tags": [
      "pandas",
      "csv",
      "dtype",
      "parsing"
    ]
  },
  {
    "id": "datascience-005",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*chunksize=\\d+[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use chunksize in read_csv for large files to avoid memory issues.",
    "detail": "The chunksize parameter in pandas.read_csv enables iteration over file chunks, reducing memory usage for large datasets. Each chunk is a DataFrame; process them in a loop for scalable ETL.",
    "tags": [
      "pandas",
      "csv",
      "memory",
      "chunksize"
    ]
  },
  {
    "id": "datascience-006",
    "pattern": "^python\\s+.*import\\s+numpy.*np\\.array\\([^)]*dtype=object[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Avoid dtype=object in np.array unless absolutely needed.",
    "detail": "Using dtype=object disables most NumPy optimizations and vectorized operations, leading to slow code and unexpected bugs. Only use for truly heterogeneous data.",
    "tags": [
      "numpy",
      "performance",
      "dtype",
      "footgun"
    ]
  },
  {
    "id": "datascience-007",
    "pattern": "^python\\s+.*import\\s+numpy.*np\\.save\\([^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "np.save overwrites files without warning. Check your filenames.",
    "detail": "NumPy's np.save will silently overwrite existing files. Always double-check the output filename or use file existence checks to prevent accidental data loss.",
    "tags": [
      "numpy",
      "io",
      "data loss",
      "save"
    ]
  },
  {
    "id": "datascience-008",
    "pattern": "^python\\s+.*import\\s+numpy.*np\\.load\\([^)]*allow_pickle=True[^)]*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "np.load(allow_pickle=True) can execute arbitrary code. Avoid it.",
    "detail": "Enabling allow_pickle=True in np.load allows loading of pickled objects, which can execute arbitrary code if the file is malicious. Only use with trusted sources.",
    "tags": [
      "numpy",
      "security",
      "pickle",
      "danger"
    ]
  },
  {
    "id": "datascience-009",
    "pattern": "^python\\s+.*import\\s+scipy.*scipy\\.io\\.loadmat\\([^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "scipy.io.loadmat loads all variables; filter with variable_names.",
    "detail": "By default, loadmat loads all variables in the .mat file, which can be slow or memory-intensive for large files. Use the variable_names argument to load only what's needed.",
    "tags": [
      "scipy",
      "matlab",
      "io",
      "memory"
    ]
  },
  {
    "id": "datascience-010",
    "pattern": "^python\\s+.*import\\s+polars.*pl\\.scan_csv\\([^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use scan_csv for lazy evaluation in Polars for large CSVs.",
    "detail": "pl.scan_csv returns a lazy DataFrame, enabling query optimization and deferred execution. This is especially efficient for large datasets and complex pipelines.",
    "tags": [
      "polars",
      "csv",
      "lazy",
      "performance"
    ]
  },
  {
    "id": "datascience-011",
    "pattern": "^python\\s+.*import\\s+polars.*pl\\.read_csv\\([^)]*n_rows=\\d+[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use n_rows in pl.read_csv to sample large files quickly.",
    "detail": "The n_rows parameter allows you to read only the first N rows, which is useful for schema inference or quick inspection of massive datasets.",
    "tags": [
      "polars",
      "csv",
      "sampling",
      "performance"
    ]
  },
  {
    "id": "datascience-012",
    "pattern": "^python\\s+.*import\\s+dask.*dask\\.dataframe\\.read_csv\\([^)]*blocksize=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "blocksize=None in dask.read_csv disables parallelism.",
    "detail": "Setting blocksize=None causes Dask to read the entire file as a single partition, negating parallelism and scalability. Use the default or set an explicit blocksize for distributed processing.",
    "tags": [
      "dask",
      "csv",
      "parallel",
      "blocksize"
    ]
  },
  {
    "id": "datascience-013",
    "pattern": "^python\\s+.*import\\s+dask.*dask\\.dataframe\\.to_csv\\([^)]*single_file=True[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "single_file=True in dask.to_csv can bottleneck on large datasets.",
    "detail": "Writing to a single file disables parallel writes and can cause memory or I/O bottlenecks. Prefer the default partitioned output for large data unless a single file is strictly required.",
    "tags": [
      "dask",
      "csv",
      "io",
      "performance"
    ]
  },
  {
    "id": "datascience-014",
    "pattern": "^python\\s+.*import\\s+vaex.*vaex\\.open\\([^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "vaex.open uses memory mapping for fast, low-memory access.",
    "detail": "Vaex uses memory-mapped files, enabling fast access to large datasets without loading them fully into RAM. This is ideal for out-of-core analytics.",
    "tags": [
      "vaex",
      "memory",
      "performance",
      "io"
    ]
  },
  {
    "id": "datascience-015",
    "pattern": "^python\\s+.*import\\s+pyarrow.*pyarrow\\.csv\\.read_csv\\([^)]*convert_options=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "convert_options=None disables type inference in pyarrow.csv.read_csv.",
    "detail": "Without convert_options, pyarrow.csv.read_csv may not infer types as expected, leading to all columns being read as strings. Specify convert_options for correct dtypes.",
    "tags": [
      "pyarrow",
      "csv",
      "dtype",
      "parsing"
    ]
  },
  {
    "id": "datascience-016",
    "pattern": "^python\\s+.*import\\s+pyarrow.*pyarrow\\.parquet\\.write_table\\([^)]*compression=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable compression in pyarrow.parquet.write_table for smaller files.",
    "detail": "By default, no compression is applied. Use compression='snappy' or 'zstd' for significant file size reduction and often faster I/O, as compressed files are quicker to read from disk.",
    "tags": [
      "pyarrow",
      "parquet",
      "compression",
      "performance"
    ]
  },
  {
    "id": "datascience-017",
    "pattern": "^python\\s+.*import\\s+fastparquet.*fastparquet\\.write\\([^)]*compression=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable compression in fastparquet.write for efficient storage.",
    "detail": "fastparquet.write defaults to no compression, resulting in larger files. Use compression='SNAPPY' or 'GZIP' to save disk space and improve read performance.",
    "tags": [
      "fastparquet",
      "parquet",
      "compression",
      "performance"
    ]
  },
  {
    "id": "datascience-018",
    "pattern": "^python\\s+.*import\\s+h5py.*h5py\\.File\\([^)]*mode=['\"]w['\"][^)]*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "h5py.File('w') overwrites existing HDF5 files without warning.",
    "detail": "Opening an HDF5 file in write mode ('w') will silently overwrite any existing file. Use 'a' (append) or check file existence to avoid accidental data loss.",
    "tags": [
      "h5py",
      "hdf5",
      "data loss",
      "io"
    ]
  },
  {
    "id": "datascience-019",
    "pattern": "^python\\s+.*import\\s+h5py.*h5py\\.File\\([^)]*mode=['\"]r['\"][^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "h5py.File('r') fails if file does not exist. Handle exceptions.",
    "detail": "Opening in read mode ('r') will raise an OSError if the file is missing. Wrap in try/except to handle missing files gracefully.",
    "tags": [
      "h5py",
      "hdf5",
      "io",
      "exceptions"
    ]
  },
  {
    "id": "datascience-020",
    "pattern": "^python\\s+.*import\\s+zarr.*zarr\\.open\\([^)]*mode=['\"]w['\"][^)]*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "zarr.open('w') destroys existing data. Use 'a' to append.",
    "detail": "Opening a Zarr store in 'w' mode deletes all existing data. Use 'a' (append) to preserve and extend existing datasets.",
    "tags": [
      "zarr",
      "data loss",
      "io",
      "mode"
    ]
  },
  {
    "id": "datascience-021",
    "pattern": "^python\\s+.*import\\s+feather.*feather\\.write_dataframe\\([^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "feather.write_dataframe overwrites files without warning.",
    "detail": "Writing with feather will overwrite any existing file. Always check the output path to avoid unintentional data loss.",
    "tags": [
      "feather",
      "io",
      "data loss",
      "output"
    ]
  },
  {
    "id": "datascience-022",
    "pattern": "^csvkit\\s+csvlook\\s+.*",
    "cmd": "csvkit",
    "severity": "tip",
    "hint": "Use csvlook -I to disable index column in pretty-printed tables.",
    "detail": "By default, csvlook adds a row index to the output. Use -I to suppress this, making the output cleaner for downstream tools or reports.",
    "tags": [
      "csvkit",
      "csvlook",
      "output",
      "index"
    ]
  },
  {
    "id": "datascience-023",
    "pattern": "^csvkit\\s+csvstat\\s+.*",
    "cmd": "csvkit",
    "severity": "tip",
    "hint": "Use csvstat -c to analyze specific columns for faster stats.",
    "detail": "csvstat can be slow on wide files. Use -c to restrict analysis to relevant columns, improving speed and reducing noise in the output.",
    "tags": [
      "csvkit",
      "csvstat",
      "performance",
      "columns"
    ]
  },
  {
    "id": "datascience-024",
    "pattern": "^csvkit\\s+csvcut\\s+.*-c\\s+\\d+.*",
    "cmd": "csvkit",
    "severity": "warn",
    "hint": "csvcut -c with numeric index is 1-based, not 0-based.",
    "detail": "csvcut uses 1-based column indexing, which differs from Python's 0-based convention. This can lead to off-by-one errors when scripting.",
    "tags": [
      "csvkit",
      "csvcut",
      "columns",
      "footgun"
    ]
  },
  {
    "id": "datascience-025",
    "pattern": "^csvkit\\s+csvgrep\\s+.*-r\\s+.*",
    "cmd": "csvkit",
    "severity": "warn",
    "hint": "csvgrep -r expects a regex; unescaped input may fail silently.",
    "detail": "The -r flag enables regex matching. If your pattern contains special characters, they must be escaped, or matches may not occur as expected.",
    "tags": [
      "csvkit",
      "csvgrep",
      "regex",
      "parsing"
    ]
  },
  {
    "id": "datascience-026",
    "pattern": "^visidata\\s+.*",
    "cmd": "visidata",
    "severity": "tip",
    "hint": "Press Shift+G in visidata to jump to the last row instantly.",
    "detail": "visidata supports Vim-like navigation. Shift+G is especially useful for large files, letting you quickly inspect file tails without scrolling.",
    "tags": [
      "visidata",
      "navigation",
      "performance",
      "ui"
    ]
  },
  {
    "id": "datascience-027",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*memory_map=True[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "memory_map=True in read_csv speeds up repeated reads of large files.",
    "detail": "When memory_map=True, pandas uses mmap to access the file, reducing I/O overhead for repeated reads. This is beneficial for large files accessed multiple times.",
    "tags": [
      "pandas",
      "csv",
      "memory_map",
      "performance"
    ]
  },
  {
    "id": "datascience-028",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*low_memory=True[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "low_memory=True in read_csv may cause mixed dtypes in columns.",
    "detail": "With low_memory=True (the default), pandas may infer mixed types in columns, resulting in object dtype and warnings. Set low_memory=False for consistent type inference at the cost of higher memory usage.",
    "tags": [
      "pandas",
      "csv",
      "dtype",
      "memory"
    ]
  },
  {
    "id": "datascience-029",
    "pattern": "^python\\s+.*import\\s+pandas.*read_parquet\\([^)]*engine=['\"]pyarrow['\"][^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "pyarrow engine in read_parquet is faster and supports more features.",
    "detail": "The pyarrow engine is generally faster and supports advanced Parquet features (e.g., nested types) compared to fastparquet. Use it for best compatibility and speed.",
    "tags": [
      "pandas",
      "parquet",
      "pyarrow",
      "performance"
    ]
  },
  {
    "id": "datascience-030",
    "pattern": "^python\\s+.*import\\s+pandas.*to_parquet\\([^)]*compression=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable compression in to_parquet for smaller, faster files.",
    "detail": "Compression reduces file size and can speed up I/O. Use compression='snappy' or 'gzip' for efficient storage and faster reads.",
    "tags": [
      "pandas",
      "parquet",
      "compression",
      "performance"
    ]
  },
  {
    "id": "datascience-031",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*parse_dates=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "parse_dates=None disables automatic date parsing in read_csv.",
    "detail": "Without parse_dates, date columns are read as strings, which can break downstream time series operations. Specify parse_dates for correct dtype inference.",
    "tags": [
      "pandas",
      "csv",
      "dates",
      "dtype"
    ]
  },
  {
    "id": "datascience-032",
    "pattern": "^python\\s+.*import\\s+dask.*dask\\.dataframe\\.read_parquet\\([^)]*engine=['\"]fastparquet['\"][^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "pyarrow engine in dask.read_parquet is more robust than fastparquet.",
    "detail": "pyarrow supports a wider range of Parquet features and is generally more stable. Use engine='pyarrow' for best compatibility, especially with complex schemas.",
    "tags": [
      "dask",
      "parquet",
      "pyarrow",
      "performance"
    ]
  },
  {
    "id": "datascience-033",
    "pattern": "^python\\s+.*import\\s+numpy.*np\\.loadtxt\\([^)]*delimiter=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "delimiter=None in np.loadtxt may misparse non-whitespace-delimited fi...",
    "detail": "The default delimiter is whitespace. For CSVs or other delimiters, set delimiter explicitly to avoid subtle parsing errors.",
    "tags": [
      "numpy",
      "loadtxt",
      "parsing",
      "delimiter"
    ]
  },
  {
    "id": "datascience-034",
    "pattern": "^python\\s+.*import\\s+numpy.*np\\.genfromtxt\\([^)]*missing_values=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "missing_values=None in np.genfromtxt disables NA handling.",
    "detail": "Without missing_values, np.genfromtxt may misinterpret missing data, leading to incorrect parsing or NaN placement. Specify missing_values for robust NA handling.",
    "tags": [
      "numpy",
      "genfromtxt",
      "missing",
      "parsing"
    ]
  },
  {
    "id": "datascience-035",
    "pattern": "^python\\s+.*import\\s+scipy.*scipy\\.sparse\\.save_npz\\([^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "scipy.sparse.save_npz overwrites files without warning.",
    "detail": "save_npz will overwrite any existing file. Always verify the output path to avoid accidental data loss.",
    "tags": [
      "scipy",
      "sparse",
      "io",
      "data loss"
    ]
  },
  {
    "id": "datascience-036",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*na_filter=False[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "na_filter=False disables NA detection in read_csv.",
    "detail": "With na_filter=False, pandas will not recognize NA values, which can lead to silent data quality issues. Only disable if you are certain there are no missing values.",
    "tags": [
      "pandas",
      "csv",
      "missing",
      "parsing"
    ]
  },
  {
    "id": "datascience-037",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*error_bad_lines=False[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "error_bad_lines=False silently skips malformed rows in read_csv.",
    "detail": "Rows with too many fields are dropped without warning, potentially leading to silent data loss. Use with caution and review the skipped lines.",
    "tags": [
      "pandas",
      "csv",
      "parsing",
      "data loss"
    ]
  },
  {
    "id": "datascience-038",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*quoting=csv\\.QUOTE_NONE[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "QUOTE_NONE disables quote parsing; escapechar must be set.",
    "detail": "When quoting=csv.QUOTE_NONE, you must also specify escapechar, or parsing will fail on quoted fields. This is a common source of subtle CSV bugs.",
    "tags": [
      "pandas",
      "csv",
      "quoting",
      "parsing"
    ]
  },
  {
    "id": "datascience-039",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*usecols=[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "usecols in read_csv speeds up parsing by loading only needed columns.",
    "detail": "Specifying usecols reduces memory usage and speeds up parsing, especially for wide files. This is critical for large datasets with many irrelevant columns.",
    "tags": [
      "pandas",
      "csv",
      "performance",
      "columns"
    ]
  },
  {
    "id": "datascience-040",
    "pattern": "^python\\s+.*import\\s+polars.*pl\\.read_csv\\([^)]*columns=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Specify columns in pl.read_csv to reduce memory and speed up load.",
    "detail": "By default, all columns are loaded. Use columns=[...] to select only those needed, improving performance and reducing memory footprint.",
    "tags": [
      "polars",
      "csv",
      "columns",
      "performance"
    ]
  },
  {
    "id": "datascience-042",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*delimiter=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "delimiter=None defaults to comma; set explicitly for other formats.",
    "detail": "If your file uses tabs or pipes, set delimiter accordingly. Relying on the default can cause subtle parsing errors.",
    "tags": [
      "pandas",
      "csv",
      "delimiter",
      "parsing"
    ]
  },
  {
    "id": "datascience-043",
    "pattern": "^python\\s+.*import\\s+pyarrow.*pyarrow\\.csv\\.read_csv\\([^)]*block_size=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set block_size in pyarrow.csv.read_csv for parallel parsing.",
    "detail": "block_size controls the chunk size for parallel reads. Setting it appropriately can significantly speed up parsing of large files.",
    "tags": [
      "pyarrow",
      "csv",
      "performance",
      "block_size"
    ]
  },
  {
    "id": "datascience-044",
    "pattern": "^python\\s+.*import\\s+polars.*pl\\.read_parquet\\([^)]*use_pyarrow=False[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "use_pyarrow=True in pl.read_parquet supports more Parquet features.",
    "detail": "PyArrow supports advanced Parquet features (e.g., nested columns) that Polars' native reader may not. Enable use_pyarrow=True for best compatibility.",
    "tags": [
      "polars",
      "parquet",
      "pyarrow",
      "compatibility"
    ]
  },
  {
    "id": "datascience-045",
    "pattern": "^python\\s+.*import\\s+dask.*dask\\.dataframe\\.read_csv\\([^)]*assume_missing=False[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "assume_missing=False may cause int columns to become floats in Dask.",
    "detail": "Dask infers columns with missing values as floats if assume_missing=False, leading to silent type promotion. Set assume_missing=True for correct NA handling in integer columns.",
    "tags": [
      "dask",
      "csv",
      "dtype",
      "missing"
    ]
  },
  {
    "id": "datascience-046",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*thousands=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "thousands=None disables thousands separator parsing in read_csv.",
    "detail": "If your data uses thousands separators (e.g., 1,000), set thousands=',' or the appropriate character. Otherwise, numbers may be misparsed as strings.",
    "tags": [
      "pandas",
      "csv",
      "parsing",
      "thousands"
    ]
  },
  {
    "id": "datascience-047",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*encoding=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "encoding=None defaults to UTF-8; set explicitly for non-UTF-8 files.",
    "detail": "Files with non-UTF-8 encodings (e.g., latin1, cp1252) will fail to parse or produce garbled data. Always specify encoding if unsure.",
    "tags": [
      "pandas",
      "csv",
      "encoding",
      "parsing"
    ]
  },
  {
    "id": "datascience-048",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*compression=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set compression in read_csv to read compressed files directly.",
    "detail": "pandas supports reading gzip, bz2, zip, or xz compressed files natively. Set compression='gzip' (or as appropriate) to avoid manual decompression.",
    "tags": [
      "pandas",
      "csv",
      "compression",
      "io"
    ]
  },
  {
    "id": "datascience-049",
    "pattern": "^python\\s+.*import\\s+polars.*pl\\.read_csv\\([^)]*encoding=None[^)]*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "encoding=None in pl.read_csv assumes UTF-8; set for other encodings.",
    "detail": "Non-UTF-8 files will fail or produce incorrect data. Set encoding='utf8-lossy', 'latin1', etc., as needed for your file.",
    "tags": [
      "polars",
      "csv",
      "encoding",
      "parsing"
    ]
  },
  {
    "id": "datascience-050",
    "pattern": "^python\\s+.*import\\s+pandas.*read_csv\\([^)]*float_precision=None[^)]*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set float_precision in read_csv for accurate float parsing.",
    "detail": "float_precision='high' or 'round_trip' can reduce floating point errors when parsing CSVs with many decimals. This is critical for financial or scientific data.",
    "tags": [
      "pandas",
      "csv",
      "float",
      "precision"
    ]
  },
  {
    "id": "mlops-001",
    "pattern": "^mlflow\\s+server(\\s+|$)",
    "cmd": "mlflow",
    "severity": "warn",
    "hint": "Always set --host 0.0.0.0 for remote MLflow server access.",
    "detail": "By default, 'mlflow server' binds to localhost, making it inaccessible remotely. Use '--host 0.0.0.0' to allow connections from other machines. This is critical for collaborative tracking and remote logging.",
    "tags": [
      "mlflow",
      "networking",
      "config"
    ]
  },
  {
    "id": "mlops-002",
    "pattern": "^mlflow\\s+server(?!.*--backend-store-uri)",
    "cmd": "mlflow",
    "severity": "danger",
    "hint": "Set --backend-store-uri to avoid losing experiment metadata.",
    "detail": "Without '--backend-store-uri', MLflow uses a local SQLite file, which can be lost or corrupted. Always specify a persistent backend like MySQL or PostgreSQL for production use to ensure experiment reproducibility.",
    "tags": [
      "mlflow",
      "data-loss",
      "backend"
    ]
  },
  {
    "id": "mlops-003",
    "pattern": "^mlflow\\s+run(?!.*--no-conda)",
    "cmd": "mlflow",
    "severity": "tip",
    "hint": "Use --no-conda if your environment is already set up.",
    "detail": "By default, 'mlflow run' creates a new Conda environment, which can be slow and redundant if dependencies are already installed. The '--no-conda' flag skips this step, speeding up local runs and avoiding environment conflicts.",
    "tags": [
      "mlflow",
      "performance",
      "env"
    ]
  },
  {
    "id": "mlops-004",
    "pattern": "^wandb\\s+login(?!.*--relogin)",
    "cmd": "wandb",
    "severity": "warn",
    "hint": "Use --relogin if switching users or tokens in wandb.",
    "detail": "If you change your WandB account or API token, previous credentials can persist and cause silent authentication failures. The '--relogin' flag forces a fresh login, ensuring correct user context.",
    "tags": [
      "wandb",
      "auth",
      "env"
    ]
  },
  {
    "id": "mlops-005",
    "pattern": "^wandb\\s+sync(?!.*--sync-all)",
    "cmd": "wandb",
    "severity": "tip",
    "hint": "Use --sync-all to upload all offline runs at once.",
    "detail": "By default, 'wandb sync' only uploads new runs. The '--sync-all' flag ensures all offline runs, including those previously synced or failed, are retried. This is useful for bulk uploads after network outages.",
    "tags": [
      "wandb",
      "sync",
      "offline"
    ]
  },
  {
    "id": "mlops-006",
    "pattern": "^dvc\\s+push(?!.*--jobs)",
    "cmd": "dvc",
    "severity": "tip",
    "hint": "Add --jobs N to parallelize DVC push for large datasets.",
    "detail": "The '--jobs' flag allows DVC to upload multiple files concurrently, significantly speeding up data pushes to remote storage. This is especially effective for large datasets or slow networks.",
    "tags": [
      "dvc",
      "performance",
      "parallel"
    ]
  },
  {
    "id": "mlops-007",
    "pattern": "^dvc\\s+pull(?!.*--run-cache)",
    "cmd": "dvc",
    "severity": "tip",
    "hint": "Use --run-cache to fetch cached pipeline results.",
    "detail": "The '--run-cache' flag enables DVC to pull cached command results, not just data files. This can save compute time by reusing previous pipeline outputs, especially in CI/CD workflows.",
    "tags": [
      "dvc",
      "cache",
      "ci"
    ]
  },
  {
    "id": "mlops-008",
    "pattern": "^dvc\\s+init(?!.*--subdir)",
    "cmd": "dvc",
    "severity": "warn",
    "hint": "Use --subdir when initializing DVC in a subdirectory.",
    "detail": "Without '--subdir', 'dvc init' expects to be run at the project root. Running it in a subdirectory without the flag can create misaligned configuration, leading to broken pipelines.",
    "tags": [
      "dvc",
      "init",
      "project-structure"
    ]
  },
  {
    "id": "mlops-009",
    "pattern": "^cml\\s+run(?!.*--cloud)",
    "cmd": "cml",
    "severity": "tip",
    "hint": "Add --cloud to run CML jobs on cloud runners for scalability.",
    "detail": "The '--cloud' flag provisions ephemeral cloud VMs for CML jobs, enabling scalable, isolated runs. This is ideal for heavy ML workloads or when local runners are resource-constrained.",
    "tags": [
      "cml",
      "cloud",
      "scaling"
    ]
  },
  {
    "id": "mlops-010",
    "pattern": "^bentoml\\s+serve(?!.*--production)",
    "cmd": "bentoml",
    "severity": "warn",
    "hint": "Use --production for optimized BentoML serving in prod.",
    "detail": "The '--production' flag enables gunicorn-based serving, which is more robust and performant than the default development server. This is essential for handling real-world traffic and concurrency.",
    "tags": [
      "bentoml",
      "serving",
      "production"
    ]
  },
  {
    "id": "mlops-011",
    "pattern": "^bentoml\\s+serve(?!.*--reload)",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Use --reload for hot-reloading during BentoML development.",
    "detail": "The '--reload' flag watches for code changes and reloads the server automatically. This accelerates the development feedback loop and reduces manual restarts.",
    "tags": [
      "bentoml",
      "dev",
      "reload"
    ]
  },
  {
    "id": "mlops-012",
    "pattern": "^seldon-core-operator(?!.*--namespace)",
    "cmd": "seldon-core-operator",
    "severity": "warn",
    "hint": "Always set --namespace to avoid cluster-wide Seldon deployments.",
    "detail": "Without '--namespace', Seldon Core Operator may install resources cluster-wide, risking conflicts and unintended access. Scoping to a namespace is best practice for multi-tenant clusters.",
    "tags": [
      "seldon",
      "k8s",
      "namespace"
    ]
  },
  {
    "id": "mlops-013",
    "pattern": "^ray\\s+start(?!.*--head)",
    "cmd": "ray",
    "severity": "warn",
    "hint": "Use --head when starting the first Ray node in a cluster.",
    "detail": "The '--head' flag initializes the Ray cluster's head node. Omitting it can cause worker nodes to fail to connect, resulting in a non-functional cluster.",
    "tags": [
      "ray",
      "cluster",
      "init"
    ]
  },
  {
    "id": "mlops-014",
    "pattern": "^ray\\s+start(?!.*--num-cpus)",
    "cmd": "ray",
    "severity": "tip",
    "hint": "Set --num-cpus to control Ray's CPU allocation.",
    "detail": "By default, Ray auto-detects available CPUs, which may overcommit resources on shared systems. Explicitly setting '--num-cpus' prevents resource contention and improves scheduling.",
    "tags": [
      "ray",
      "resource",
      "performance"
    ]
  },
  {
    "id": "mlops-015",
    "pattern": "^prefect\\s+agent\\s+start(?!.*--label)",
    "cmd": "prefect",
    "severity": "tip",
    "hint": "Use --label to target Prefect flows to specific agents.",
    "detail": "Labels allow fine-grained control over which agents execute which flows. This is crucial for routing jobs to specialized hardware or segregated environments.",
    "tags": [
      "prefect",
      "scheduling",
      "labels"
    ]
  },
  {
    "id": "mlops-016",
    "pattern": "^prefect\\s+orion\\s+start(?!.*--host)",
    "cmd": "prefect",
    "severity": "warn",
    "hint": "Set --host 0.0.0.0 for remote Prefect Orion UI access.",
    "detail": "By default, the Orion server binds to localhost, making the UI inaccessible from other machines. Use '--host 0.0.0.0' to enable remote dashboard access.",
    "tags": [
      "prefect",
      "ui",
      "networking"
    ]
  },
  {
    "id": "mlops-017",
    "pattern": "^airflow\\s+webserver(?!.*--daemon)",
    "cmd": "airflow",
    "severity": "tip",
    "hint": "Use --daemon to run Airflow webserver in the background.",
    "detail": "The '--daemon' flag detaches the webserver process, allowing it to run as a background service. This is essential for production deployments and systemd integration.",
    "tags": [
      "airflow",
      "webserver",
      "daemon"
    ]
  },
  {
    "id": "mlops-018",
    "pattern": "^airflow\\s+db\\s+init",
    "cmd": "airflow",
    "severity": "warn",
    "hint": "Always run airflow db upgrade after db init.",
    "detail": "'airflow db init' sets up the initial schema, but migrations may be pending. Running 'airflow db upgrade' ensures all tables and indices are up-to-date, preventing runtime errors.",
    "tags": [
      "airflow",
      "db",
      "migrations"
    ]
  },
  {
    "id": "mlops-019",
    "pattern": "^great_expectations\\s+suite\\s+edit(?!.*--interactive)",
    "cmd": "great_expectations",
    "severity": "tip",
    "hint": "Use --interactive for guided editing of expectation suites.",
    "detail": "The '--interactive' flag launches a Jupyter notebook for suite editing, providing a richer, more user-friendly interface than the CLI alone.",
    "tags": [
      "great_expectations",
      "suite",
      "edit"
    ]
  },
  {
    "id": "mlops-020",
    "pattern": "^great_expectations\\s+checkpoint\\s+run(?!.*--batch-request)",
    "cmd": "great_expectations",
    "severity": "warn",
    "hint": "Use --batch-request to avoid running on stale data.",
    "detail": "Without '--batch-request', checkpoints may use cached or default data batches, leading to misleading validation results. Explicitly specifying the batch ensures data freshness.",
    "tags": [
      "great_expectations",
      "checkpoint",
      "data"
    ]
  },
  {
    "id": "mlops-021",
    "pattern": "^evidently\\s+monitor\\s+start(?!.*--interval)",
    "cmd": "evidently",
    "severity": "tip",
    "hint": "Set --interval to control monitoring frequency in Evidently.",
    "detail": "The '--interval' flag determines how often data drift checks are performed. Tuning this value helps balance resource usage and detection latency.",
    "tags": [
      "evidently",
      "monitoring",
      "performance"
    ]
  },
  {
    "id": "mlops-022",
    "pattern": "^mlflow\\s+ui(?!.*--host)",
    "cmd": "mlflow",
    "severity": "warn",
    "hint": "Set --host 0.0.0.0 to access MLflow UI remotely.",
    "detail": "The MLflow UI binds to localhost by default, which blocks remote access. Use '--host 0.0.0.0' to enable external connections for team collaboration.",
    "tags": [
      "mlflow",
      "ui",
      "networking"
    ]
  },
  {
    "id": "mlops-023",
    "pattern": "^mlflow\\s+artifacts\\s+download(?!.*--artifact-path)",
    "cmd": "mlflow",
    "severity": "warn",
    "hint": "Always specify --artifact-path to avoid ambiguous downloads.",
    "detail": "Omitting '--artifact-path' can result in downloading the wrong artifact or failing silently if multiple artifacts exist. Explicitly set the path for deterministic results.",
    "tags": [
      "mlflow",
      "artifacts",
      "download"
    ]
  },
  {
    "id": "mlops-024",
    "pattern": "^wandb\\s+init(?!.*--entity)",
    "cmd": "wandb",
    "severity": "warn",
    "hint": "Set --entity to ensure runs are logged to the correct project.",
    "detail": "The '--entity' flag specifies the team or user namespace. Omitting it may log runs to a personal account, causing confusion or access issues in shared projects.",
    "tags": [
      "wandb",
      "project",
      "config"
    ]
  },
  {
    "id": "mlops-025",
    "pattern": "^wandb\\s+agent(?!.*--count)",
    "cmd": "wandb",
    "severity": "tip",
    "hint": "Use --count to limit the number of runs in sweeps.",
    "detail": "The '--count' flag restricts the number of runs an agent executes, which is useful for testing or budget control during hyperparameter sweeps.",
    "tags": [
      "wandb",
      "sweeps",
      "budget"
    ]
  },
  {
    "id": "mlops-026",
    "pattern": "^dvc\\s+repro(?!.*--pull)",
    "cmd": "dvc",
    "severity": "warn",
    "hint": "Use --pull to fetch missing data before DVC repro.",
    "detail": "Without '--pull', 'dvc repro' may fail if required data files are missing locally. This flag ensures all dependencies are present before pipeline execution.",
    "tags": [
      "dvc",
      "pipeline",
      "data"
    ]
  },
  {
    "id": "mlops-027",
    "pattern": "^dvc\\s+checkout(?!.*--force)",
    "cmd": "dvc",
    "severity": "warn",
    "hint": "Use --force to overwrite local changes during DVC checkout.",
    "detail": "If files have been modified locally, 'dvc checkout' will refuse to overwrite them unless '--force' is used. This prevents silent data mismatches.",
    "tags": [
      "dvc",
      "checkout",
      "data"
    ]
  },
  {
    "id": "mlops-028",
    "pattern": "^cml\\s+send-comment(?!.*--pr)",
    "cmd": "cml",
    "severity": "warn",
    "hint": "Use --pr to target the correct pull request with CML comments.",
    "detail": "Omitting '--pr' can cause comments to be posted to the wrong location or not at all, especially in multi-PR workflows. Always specify the PR number or URL.",
    "tags": [
      "cml",
      "pr",
      "ci"
    ]
  },
  {
    "id": "mlops-029",
    "pattern": "^bentoml\\s+build(?!.*--optimize)",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Use --optimize to reduce BentoML bundle size and speed up deploys.",
    "detail": "The '--optimize' flag strips unnecessary files and dependencies, producing a leaner bundle. This accelerates deployment and reduces cold start times.",
    "tags": [
      "bentoml",
      "build",
      "performance"
    ]
  },
  {
    "id": "mlops-030",
    "pattern": "^seldon-core-operator(?!.*--webhook)",
    "cmd": "seldon-core-operator",
    "severity": "warn",
    "hint": "Enable --webhook for admission control in Seldon deployments.",
    "detail": "The '--webhook' flag activates Seldon's admission controller, which validates and mutates deployment specs. This prevents misconfigured or insecure model deployments.",
    "tags": [
      "seldon",
      "webhook",
      "security"
    ]
  },
  {
    "id": "mlops-031",
    "pattern": "^ray\\s+submit(?!.*--start)",
    "cmd": "ray",
    "severity": "tip",
    "hint": "Use --start to auto-launch Ray cluster if not running.",
    "detail": "The '--start' flag ensures a Ray cluster is started before submitting jobs, preventing silent failures due to missing clusters.",
    "tags": [
      "ray",
      "submit",
      "cluster"
    ]
  },
  {
    "id": "mlops-032",
    "pattern": "^prefect\\s+deployment\\s+run(?!.*--params)",
    "cmd": "prefect",
    "severity": "warn",
    "hint": "Use --params to override default deployment parameters.",
    "detail": "Omitting '--params' uses hardcoded defaults, which may not match your intended run configuration. Always specify parameters for reproducibility.",
    "tags": [
      "prefect",
      "deployment",
      "params"
    ]
  },
  {
    "id": "mlops-033",
    "pattern": "^airflow\\s+scheduler(?!.*--num-runs)",
    "cmd": "airflow",
    "severity": "tip",
    "hint": "Set --num-runs for finite Airflow scheduler runs in testing.",
    "detail": "The '--num-runs' flag limits the scheduler to a set number of DAG runs, which is useful for CI or debugging without running indefinitely.",
    "tags": [
      "airflow",
      "scheduler",
      "testing"
    ]
  },
  {
    "id": "mlops-034",
    "pattern": "^great_expectations\\s+init(?!.*--no-jupyter)",
    "cmd": "great_expectations",
    "severity": "tip",
    "hint": "Use --no-jupyter to skip notebook launch during init.",
    "detail": "The '--no-jupyter' flag prevents automatic notebook startup, which is useful in headless or CI environments where Jupyter is unavailable.",
    "tags": [
      "great_expectations",
      "init",
      "ci"
    ]
  },
  {
    "id": "mlops-035",
    "pattern": "^evidently\\s+report\\s+generate(?!.*--output)",
    "cmd": "evidently",
    "severity": "warn",
    "hint": "Always set --output to avoid overwriting existing reports.",
    "detail": "Without '--output', reports may overwrite previous files or be written to ambiguous locations. Explicit output paths prevent accidental data loss.",
    "tags": [
      "evidently",
      "report",
      "output"
    ]
  },
  {
    "id": "mlops-036",
    "pattern": "^mlflow\\s+experiments\\s+delete",
    "cmd": "mlflow",
    "severity": "danger",
    "hint": "Deleting experiments is irreversible; backup before running.",
    "detail": "'mlflow experiments delete' permanently removes all runs and metadata for the experiment. There is no undo, and artifacts may become orphaned. Always backup before deletion.",
    "tags": [
      "mlflow",
      "delete",
      "data-loss"
    ]
  },
  {
    "id": "mlops-037",
    "pattern": "^wandb\\s+artifact\\s+delete",
    "cmd": "wandb",
    "severity": "danger",
    "hint": "Deleting artifacts in wandb is permanent; double-check before.",
    "detail": "Artifact deletion cannot be undone and may break downstream runs or reproducibility. Ensure no active jobs depend on the artifact before removing.",
    "tags": [
      "wandb",
      "artifact",
      "delete"
    ]
  },
  {
    "id": "mlops-038",
    "pattern": "^dvc\\s+destroy",
    "cmd": "dvc",
    "severity": "danger",
    "hint": "dvc destroy removes all DVC files and cache. Backup first.",
    "detail": "'dvc destroy' deletes DVC config, cache, and metadata, making it impossible to recover tracked data or pipelines. Use only when decommissioning a project.",
    "tags": [
      "dvc",
      "destroy",
      "data-loss"
    ]
  },
  {
    "id": "mlops-039",
    "pattern": "^cml\\s+pr\\s+create(?!.*--squash)",
    "cmd": "cml",
    "severity": "tip",
    "hint": "Use --squash to keep PR history clean in CML workflows.",
    "detail": "The '--squash' flag merges all commits into one, simplifying review and reducing noise in the repository history.",
    "tags": [
      "cml",
      "pr",
      "git"
    ]
  },
  {
    "id": "mlops-040",
    "pattern": "^bentoml\\s+containerize(?!.*--platform)",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Set --platform for cross-platform BentoML container builds.",
    "detail": "The '--platform' flag allows building images for different architectures (e.g., arm64), which is crucial for deploying to heterogeneous environments.",
    "tags": [
      "bentoml",
      "container",
      "cross-platform"
    ]
  },
  {
    "id": "mlops-041",
    "pattern": "^seldon-core-operator(?!.*--set-controller-id)",
    "cmd": "seldon-core-operator",
    "severity": "warn",
    "hint": "Set --set-controller-id to avoid Seldon controller conflicts.",
    "detail": "In multi-operator clusters, omitting '--set-controller-id' can cause resource contention, as multiple controllers may act on the same CRDs. Always set a unique ID.",
    "tags": [
      "seldon",
      "controller",
      "k8s"
    ]
  },
  {
    "id": "mlops-042",
    "pattern": "^ray\\s+stop",
    "cmd": "ray",
    "severity": "warn",
    "hint": "Check for running jobs before stopping Ray cluster.",
    "detail": "'ray stop' will terminate all processes, potentially killing active jobs and causing data loss. Always ensure the cluster is idle before stopping.",
    "tags": [
      "ray",
      "stop",
      "jobs"
    ]
  },
  {
    "id": "mlops-043",
    "pattern": "^prefect\\s+config\\s+set(?!.*PREFECT_API_URL)",
    "cmd": "prefect",
    "severity": "warn",
    "hint": "Set PREFECT_API_URL to direct flows to the correct backend.",
    "detail": "Without setting 'PREFECT_API_URL', flows may run against a local or default backend, leading to confusion or lost runs in multi-environment setups.",
    "tags": [
      "prefect",
      "config",
      "env"
    ]
  },
  {
    "id": "mlops-044",
    "pattern": "^airflow\\s+connections\\s+add(?!.*--conn-uri)",
    "cmd": "airflow",
    "severity": "warn",
    "hint": "Use --conn-uri to avoid misconfigured Airflow connections.",
    "detail": "The '--conn-uri' flag provides a single, unambiguous connection string, reducing the risk of partial or incorrect connection setups.",
    "tags": [
      "airflow",
      "connections",
      "uri"
    ]
  },
  {
    "id": "mlops-045",
    "pattern": "^great_expectations\\s+docs\\s+build(?!.*--site-name)",
    "cmd": "great_expectations",
    "severity": "tip",
    "hint": "Set --site-name to build docs for a specific data context site.",
    "detail": "The '--site-name' flag allows building documentation for a particular site, which is useful in multi-site or multi-environment projects.",
    "tags": [
      "great_expectations",
      "docs",
      "site"
    ]
  },
  {
    "id": "mlops-046",
    "pattern": "^evidently\\s+test\\s+run(?!.*--reference)",
    "cmd": "evidently",
    "severity": "warn",
    "hint": "Always set --reference for valid data drift comparisons.",
    "detail": "Without a reference dataset, drift tests may produce meaningless or misleading results. The '--reference' flag ensures proper baseline selection.",
    "tags": [
      "evidently",
      "test",
      "drift"
    ]
  },
  {
    "id": "mlops-047",
    "pattern": "^mlflow\\s+models\\s+serve(?!.*--env-manager)",
    "cmd": "mlflow",
    "severity": "tip",
    "hint": "Use --env-manager to control MLflow model serving environments.",
    "detail": "The '--env-manager' flag lets you choose between local, conda, or virtualenv environments, improving reproducibility and isolation.",
    "tags": [
      "mlflow",
      "models",
      "env"
    ]
  },
  {
    "id": "mlops-048",
    "pattern": "^wandb\\s+offline",
    "cmd": "wandb",
    "severity": "warn",
    "hint": "Remember to sync offline runs with wandb sync later.",
    "detail": "'wandb offline' disables live logging. Forgetting to sync can result in lost experiment tracking. Always run 'wandb sync' to upload offline runs.",
    "tags": [
      "wandb",
      "offline",
      "sync"
    ]
  },
  {
    "id": "mlops-049",
    "pattern": "^dvc\\s+import(?!.*--no-exec)",
    "cmd": "dvc",
    "severity": "tip",
    "hint": "Use --no-exec to defer data download during DVC import.",
    "detail": "The '--no-exec' flag creates the import stage without immediately downloading data, which is useful for CI or when only pipeline structure is needed.",
    "tags": [
      "dvc",
      "import",
      "ci"
    ]
  },
  {
    "id": "mlops-050",
    "pattern": "^dvc\\s+add(?!.*--to-remote)",
    "cmd": "dvc",
    "severity": "tip",
    "hint": "Use --to-remote to add large files directly to remote storage.",
    "detail": "The '--to-remote' flag skips local cache, uploading files straight to remote storage. This saves disk space and speeds up workflows for large datasets.",
    "tags": [
      "dvc",
      "add",
      "remote"
    ]
  },
  {
    "id": "ml-001",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.train_test_split\\(.*random_state=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set random_state in train_test_split for reproducible splits.",
    "detail": "Omitting random_state in train_test_split leads to different splits on each run, making results non-reproducible. Always set random_state for consistency, especially in experiments or production pipelines.",
    "tags": [
      "scikit-learn",
      "reproducibility",
      "data-split"
    ]
  },
  {
    "id": "ml-002",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*n_jobs=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use n_jobs=-1 in RandomForest to utilize all CPU cores.",
    "detail": "By default, RandomForestClassifier uses a single core. Setting n_jobs=-1 enables parallel computation across all available processors, significantly speeding up training for large datasets.",
    "tags": [
      "scikit-learn",
      "performance",
      "parallelism"
    ]
  },
  {
    "id": "ml-003",
    "pattern": "^python\\s+.*joblib\\.dump\\(.*compress=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable compression in joblib.dump to save disk space.",
    "detail": "joblib.dump supports a compress argument (e.g., compress=3 or compress='lzma') to reduce model file size. This is critical for large models or when storing artifacts in limited storage environments.",
    "tags": [
      "joblib",
      "model-storage",
      "compression"
    ]
  },
  {
    "id": "ml-004",
    "pattern": "^python\\s+.*sklearn\\.metrics\\.roc_auc_score\\(.*average=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set average in roc_auc_score for multiclass problems.",
    "detail": "roc_auc_score defaults to binary classification. For multiclass, you must specify average='macro', 'weighted', or 'micro' to avoid ValueError or misleading results.",
    "tags": [
      "scikit-learn",
      "metrics",
      "multiclass"
    ]
  },
  {
    "id": "ml-005",
    "pattern": "^python\\s+.*optuna\\.study\\.create_study\\(.*direction=['\"]minimize['\"].*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set direction in create_study to 'maximize' for accuracy metrics.",
    "detail": "Optuna's direction parameter controls optimization. For metrics like accuracy or AUC, use direction='maximize'. Using 'minimize' will yield suboptimal hyperparameters.",
    "tags": [
      "optuna",
      "hyperparameter",
      "optimization"
    ]
  },
  {
    "id": "ml-006",
    "pattern": "^python\\s+.*hyperopt\\.fmin\\(.*max_evals=\\d{1,2}.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set max_evals > 50 in hyperopt.fmin for meaningful search.",
    "detail": "Low max_evals values in hyperopt often result in poor hyperparameter exploration. For non-trivial search spaces, use at least 50-100 evaluations to avoid premature convergence.",
    "tags": [
      "hyperopt",
      "hyperparameter",
      "search"
    ]
  },
  {
    "id": "ml-007",
    "pattern": "^python\\s+.*shap\\.TreeExplainer\\(.*model_output=['\"]probability['\"].*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "TreeExplainer's model_output='probability' can be misleading for mult...",
    "detail": "TreeExplainer with model_output='probability' may not sum to 1 for multiclass models. For multiclass, prefer model_output='raw' and post-process the SHAP values accordingly.",
    "tags": [
      "shap",
      "interpretability",
      "multiclass"
    ]
  },
  {
    "id": "ml-008",
    "pattern": "^python\\s+.*lime\\.lime_tabular\\.LimeTabularExplainer\\(.*discretize_continuous=True.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set discretize_continuous=False for tree-based models in LIME.",
    "detail": "Tree-based models handle continuous features natively. Discretizing them can degrade explanation quality and interpretability. Set discretize_continuous=False for best results.",
    "tags": [
      "lime",
      "interpretability",
      "feature-engineering"
    ]
  },
  {
    "id": "ml-009",
    "pattern": "^python\\s+.*eli5\\.show_weights\\(.*feature_names=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Pass feature_names to eli5.show_weights for readable output.",
    "detail": "Without feature_names, eli5.show_weights displays generic feature indices, making interpretation difficult. Always provide feature_names for clarity, especially with transformed data.",
    "tags": [
      "eli5",
      "interpretability",
      "features"
    ]
  },
  {
    "id": "ml-010",
    "pattern": "^python\\s+.*imblearn\\.over_sampling\\.SMOTE\\(.*random_state=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set random_state in SMOTE for reproducible synthetic samples.",
    "detail": "SMOTE generates new samples based on random neighbors. Without random_state, results vary per run, making experiments irreproducible and debugging difficult.",
    "tags": [
      "imbalanced-learn",
      "sampling",
      "reproducibility"
    ]
  },
  {
    "id": "ml-011",
    "pattern": "^python\\s+.*sklearn\\.pipeline\\.Pipeline\\(.*memory=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set memory in Pipeline to cache transformers for speed.",
    "detail": "Pipelines with memory set to a joblib.Memory instance cache fit/transform steps, avoiding redundant computation in grid search or repeated calls. This can greatly accelerate model selection.",
    "tags": [
      "scikit-learn",
      "pipeline",
      "performance"
    ]
  },
  {
    "id": "ml-012",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.StandardScaler\\(.*with_mean=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "with_mean=False in StandardScaler disables centering; check your data.",
    "detail": "Setting with_mean=False is necessary for sparse matrices, but can lead to unexpected results if your data is dense. Always verify the data type and intended scaling behavior.",
    "tags": [
      "scikit-learn",
      "preprocessing",
      "scaling"
    ]
  },
  {
    "id": "ml-013",
    "pattern": "^python\\s+.*category_encoders\\.OneHotEncoder\\(.*use_cat_names=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set use_cat_names=True in category_encoders for readable columns.",
    "detail": "With use_cat_names=False, encoded columns are generic (e.g., x0_1). Setting use_cat_names=True preserves original category names, aiding interpretability and downstream analysis.",
    "tags": [
      "category_encoders",
      "encoding",
      "features"
    ]
  },
  {
    "id": "ml-014",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.cross_val_score\\(.*n_jobs=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use n_jobs=-1 in cross_val_score for parallel evaluation.",
    "detail": "cross_val_score defaults to single-threaded execution. Setting n_jobs=-1 leverages all CPU cores, drastically reducing evaluation time for large datasets or complex models.",
    "tags": [
      "scikit-learn",
      "cross-validation",
      "performance"
    ]
  },
  {
    "id": "ml-015",
    "pattern": "^python\\s+.*sklearn\\.metrics\\.classification_report\\(.*output_dict=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set output_dict=True for programmatic access to classification_report.",
    "detail": "With output_dict=False, classification_report returns a string. Setting output_dict=True returns a dict, enabling further analysis or logging of metrics.",
    "tags": [
      "scikit-learn",
      "metrics",
      "reporting"
    ]
  },
  {
    "id": "ml-016",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*oob_score=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable oob_score=True for built-in validation in RandomForest.",
    "detail": "oob_score=True computes out-of-bag estimates, providing a quick, unbiased validation score without needing a separate validation set. Useful for model selection and tuning.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "validation"
    ]
  },
  {
    "id": "ml-017",
    "pattern": "^python\\s+.*sklearn\\.linear_model\\.LogisticRegression\\(.*solver=['\"]liblinear['\"].*multi_class=['\"]multinomial['\"].*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "liblinear does not support multinomial; use saga or lbfgs.",
    "detail": "The 'liblinear' solver only supports one-vs-rest for multiclass. For multinomial loss, use 'saga' or 'lbfgs' solvers to avoid ValueError and ensure correct optimization.",
    "tags": [
      "scikit-learn",
      "logisticregression",
      "multiclass"
    ]
  },
  {
    "id": "ml-018",
    "pattern": "^python\\s+.*sklearn\\.decomposition\\.PCA\\(.*svd_solver=['\"]auto['\"].*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set svd_solver='full' in PCA for small datasets for accuracy.",
    "detail": "The 'auto' solver may select randomized SVD for large datasets, which is faster but less accurate. For small datasets, 'full' ensures deterministic and precise results.",
    "tags": [
      "scikit-learn",
      "pca",
      "dimensionality-reduction"
    ]
  },
  {
    "id": "ml-019",
    "pattern": "^python\\s+.*sklearn\\.impute\\.SimpleImputer\\(.*strategy=['\"]most_frequent['\"].*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "most_frequent strategy can leak target info in imputation.",
    "detail": "Using 'most_frequent' on the entire dataset before splitting can cause data leakage. Always fit imputers only on training data to avoid inflating model performance.",
    "tags": [
      "scikit-learn",
      "imputation",
      "data-leakage"
    ]
  },
  {
    "id": "ml-020",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.GradientBoostingClassifier\\(.*warm_start=True.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "warm_start=True in GradientBoosting can cause inconsistent results.",
    "detail": "Enabling warm_start allows incremental fitting, but can lead to unexpected behavior if not managed carefully (e.g., changing hyperparameters between fits). Use with caution and document usage.",
    "tags": [
      "scikit-learn",
      "gradientboosting",
      "training"
    ]
  },
  {
    "id": "ml-021",
    "pattern": "^python\\s+.*sklearn\\.feature_selection\\.SelectKBest\\(.*k='all'.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set k to an integer in SelectKBest to actually select features.",
    "detail": "k='all' retains all features, effectively disabling selection. Specify an integer value for k to reduce dimensionality and improve model generalization.",
    "tags": [
      "scikit-learn",
      "feature-selection",
      "dimensionality"
    ]
  },
  {
    "id": "ml-022",
    "pattern": "^python\\s+.*feature_engine\\.discretisation\\.EqualWidthDiscretiser\\(.*return_object=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set return_object=True for categorical output in EqualWidthDiscretiser.",
    "detail": "With return_object=False, output is numeric. For downstream categorical processing (e.g., encoding), set return_object=True to output object dtype.",
    "tags": [
      "feature-engine",
      "discretisation",
      "categorical"
    ]
  },
  {
    "id": "ml-023",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.GridSearchCV\\(.*refit=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "refit=False disables automatic retraining on best params.",
    "detail": "With refit=False, GridSearchCV does not retrain the estimator on the full dataset with the best parameters. This can lead to confusion when using the .predict method, which will fail.",
    "tags": [
      "scikit-learn",
      "gridsearch",
      "model-selection"
    ]
  },
  {
    "id": "ml-024",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.LabelEncoder\\(.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "LabelEncoder is for target variables, not features.",
    "detail": "LabelEncoder is designed for encoding target labels, not feature columns. Using it on features can introduce unintended ordinal relationships. Use OneHotEncoder or category_encoders for features.",
    "tags": [
      "scikit-learn",
      "encoding",
      "features"
    ]
  },
  {
    "id": "ml-025",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*max_features=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "max_features=None disables feature subsampling in RandomForest.",
    "detail": "Setting max_features=None uses all features at each split, reducing model diversity and potentially overfitting. Default is 'auto', which is usually optimal.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "overfitting"
    ]
  },
  {
    "id": "ml-026",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.StratifiedKFold\\(.*shuffle=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set shuffle=True in StratifiedKFold for randomized splits.",
    "detail": "Without shuffling, splits may be ordered and not representative, especially with sorted data. Always set shuffle=True and specify random_state for reproducible, randomized folds.",
    "tags": [
      "scikit-learn",
      "cross-validation",
      "sampling"
    ]
  },
  {
    "id": "ml-027",
    "pattern": "^python\\s+.*category_encoders\\.TargetEncoder\\(.*min_samples_leaf=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set min_samples_leaf in TargetEncoder to avoid overfitting.",
    "detail": "TargetEncoder can overfit on rare categories. Setting min_samples_leaf ensures smoothing, reducing target leakage and improving generalization.",
    "tags": [
      "category_encoders",
      "encoding",
      "overfitting"
    ]
  },
  {
    "id": "ml-028",
    "pattern": "^python\\s+.*joblib\\.Parallel\\(.*n_jobs=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set n_jobs=-1 in joblib.Parallel for full CPU utilization.",
    "detail": "joblib.Parallel defaults to single-threaded execution. n_jobs=-1 uses all available cores, greatly accelerating parallelizable tasks like cross-validation or grid search.",
    "tags": [
      "joblib",
      "parallelism",
      "performance"
    ]
  },
  {
    "id": "ml-029",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.OneHotEncoder\\(.*sparse=True.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set sparse=False in OneHotEncoder for dense output arrays.",
    "detail": "By default, OneHotEncoder returns a sparse matrix. For small datasets or when integrating with dense pipelines, set sparse=False to get a numpy array.",
    "tags": [
      "scikit-learn",
      "encoding",
      "features"
    ]
  },
  {
    "id": "ml-030",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*bootstrap=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Disabling bootstrap in RandomForest reduces model variance.",
    "detail": "bootstrap=False disables bagging, making all trees see the same data. This reduces ensemble diversity and can increase overfitting risk. Use with caution.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "ensemble"
    ]
  },
  {
    "id": "ml-031",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.MinMaxScaler\\(.*feature_range=\\(0, 1\\).*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Adjust feature_range in MinMaxScaler for outlier robustness.",
    "detail": "The default (0, 1) range can exaggerate the effect of outliers. Consider using a narrower range or robust scaling for datasets with extreme values.",
    "tags": [
      "scikit-learn",
      "scaling",
      "preprocessing"
    ]
  },
  {
    "id": "ml-032",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.train_test_split\\(.*stratify=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set stratify in train_test_split for imbalanced classes.",
    "detail": "Omitting stratify can lead to train/test splits with skewed class distributions, especially in imbalanced datasets. Always set stratify=y for classification tasks.",
    "tags": [
      "scikit-learn",
      "data-split",
      "imbalance"
    ]
  },
  {
    "id": "ml-033",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.StandardScaler\\(.*copy=False.*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "copy=False in StandardScaler mutates input array in-place.",
    "detail": "Setting copy=False causes StandardScaler to overwrite the original data. This can lead to subtle bugs if the original data is needed later. Use with extreme caution.",
    "tags": [
      "scikit-learn",
      "preprocessing",
      "data-integrity"
    ]
  },
  {
    "id": "ml-034",
    "pattern": "^python\\s+.*sklearn\\.metrics\\.confusion_matrix\\(.*normalize=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set normalize in confusion_matrix for relative class proportions.",
    "detail": "normalize='true', 'pred', or 'all' provides relative counts, aiding interpretation in imbalanced datasets. The default (None) returns absolute counts only.",
    "tags": [
      "scikit-learn",
      "metrics",
      "evaluation"
    ]
  },
  {
    "id": "ml-035",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*max_depth=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "max_depth=None allows trees to grow deep and overfit.",
    "detail": "Unlimited tree depth can lead to overfitting, especially on noisy data. Set max_depth to a reasonable value to improve generalization and reduce model size.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "overfitting"
    ]
  },
  {
    "id": "ml-036",
    "pattern": "^python\\s+.*sklearn\\.feature_selection\\.VarianceThreshold\\(.*threshold=0.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Increase threshold in VarianceThreshold to remove low-variance features.",
    "detail": "The default threshold=0 only removes constant features. Setting a small positive value can help eliminate near-constant features that add noise.",
    "tags": [
      "scikit-learn",
      "feature-selection",
      "preprocessing"
    ]
  },
  {
    "id": "ml-037",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*class_weight=None.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set class_weight='balanced' for imbalanced classification tasks.",
    "detail": "class_weight='balanced' automatically adjusts weights inversely proportional to class frequencies, improving performance on imbalanced datasets without manual resampling.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "imbalance"
    ]
  },
  {
    "id": "ml-038",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.GridSearchCV\\(.*error_score='raise'.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "error_score='raise' in GridSearchCV can halt search on estimator errors.",
    "detail": "If an estimator fails, GridSearchCV will raise an exception and stop. Use error_score=np.nan to continue searching and log failures instead.",
    "tags": [
      "scikit-learn",
      "gridsearch",
      "robustness"
    ]
  },
  {
    "id": "ml-039",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.OneHotEncoder\\(.*handle_unknown=['\"]error['\"].*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set handle_unknown='ignore' in OneHotEncoder for unseen categories.",
    "detail": "The default 'error' will raise an exception if new categories appear at transform time. 'ignore' will output all zeros for unknowns, preventing runtime errors in production.",
    "tags": [
      "scikit-learn",
      "encoding",
      "robustness"
    ]
  },
  {
    "id": "ml-040",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*n_estimators=10.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Increase n_estimators in RandomForest for better stability.",
    "detail": "n_estimators=10 is often too low for stable predictions. Use at least 100 for most datasets to reduce variance and improve model robustness.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "stability"
    ]
  },
  {
    "id": "ml-041",
    "pattern": "^python\\s+.*sklearn\\.model_selection\\.cross_val_score\\(.*cv=3.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use cv=5 or higher in cross_val_score for reliable estimates.",
    "detail": "cv=3 can yield high variance in performance estimates. cv=5 or 10 is standard for more reliable and stable cross-validation results.",
    "tags": [
      "scikit-learn",
      "cross-validation",
      "evaluation"
    ]
  },
  {
    "id": "ml-042",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*random_state=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set random_state in RandomForest for reproducible results.",
    "detail": "Without random_state, RandomForest results vary on each run, making debugging and comparisons difficult. Always set random_state for consistent outputs.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "reproducibility"
    ]
  },
  {
    "id": "ml-043",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.PowerTransformer\\(.*standardize=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "standardize=False in PowerTransformer can cause scale issues.",
    "detail": "Without standardization, transformed features may have arbitrary scales, affecting downstream models. Set standardize=True for zero mean and unit variance.",
    "tags": [
      "scikit-learn",
      "preprocessing",
      "scaling"
    ]
  },
  {
    "id": "ml-044",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*criterion=['\"]gini['\"].*\\)",
    "cmd": "python",
    "severity": "upgrade",
    "hint": "Try criterion='entropy' or 'log_loss' for different splits.",
    "detail": "While 'gini' is the default, 'entropy' and 'log_loss' can yield different splits and sometimes better performance, especially for imbalanced or complex datasets.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "criteria"
    ]
  },
  {
    "id": "ml-045",
    "pattern": "^python\\s+.*sklearn\\.pipeline\\.Pipeline\\(.*verbose=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable verbose=True in Pipeline for stepwise execution logs.",
    "detail": "verbose=True prints progress messages for each pipeline step, aiding debugging and monitoring of complex pipelines, especially during grid search or production runs.",
    "tags": [
      "scikit-learn",
      "pipeline",
      "debugging"
    ]
  },
  {
    "id": "ml-046",
    "pattern": "^python\\s+.*sklearn\\.impute\\.KNNImputer\\(.*n_neighbors=1.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "n_neighbors=1 in KNNImputer risks overfitting to nearest neighbor.",
    "detail": "Using a single neighbor can propagate noise or outliers. Use n_neighbors=3 or higher for more robust imputation, as recommended in the scikit-learn documentation.",
    "tags": [
      "scikit-learn",
      "imputation",
      "robustness"
    ]
  },
  {
    "id": "ml-047",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.PolynomialFeatures\\(.*interaction_only=True.*include_bias=True.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set include_bias=False in PolynomialFeatures to avoid intercept column.",
    "detail": "include_bias=True adds a constant column of ones, which is redundant if your model already fits an intercept. Set include_bias=False to avoid collinearity.",
    "tags": [
      "scikit-learn",
      "feature-engineering",
      "polynomial"
    ]
  },
  {
    "id": "ml-048",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*min_samples_split=2.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Increase min_samples_split in RandomForest to reduce overfitting.",
    "detail": "The default (2) can lead to very deep trees and overfitting. Setting min_samples_split to 5 or 10 often improves generalization, especially on noisy data.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "overfitting"
    ]
  },
  {
    "id": "ml-049",
    "pattern": "^python\\s+.*sklearn\\.ensemble\\.RandomForestClassifier\\(.*n_jobs=1.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set n_jobs=-1 in RandomForest for parallel training.",
    "detail": "n_jobs=1 restricts training to a single core. n_jobs=-1 uses all available CPU cores, greatly speeding up training for large datasets.",
    "tags": [
      "scikit-learn",
      "randomforest",
      "performance"
    ]
  },
  {
    "id": "ml-050",
    "pattern": "^python\\s+.*sklearn\\.preprocessing\\.RobustScaler\\(.*quantile_range=\\(25\\.0, 75\\.0\\).*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Adjust quantile_range in RobustScaler for different outlier sensitivity.",
    "detail": "The default (25.0, 75.0) targets the interquartile range. Adjusting this can make scaling more or less sensitive to outliers, depending on your data distribution.",
    "tags": [
      "scikit-learn",
      "scaling",
      "preprocessing"
    ]
  },
  {
    "id": "pytorch-001",
    "pattern": "^torch\\.save\\s+[^,]+\\s*,\\s*['\"]?[^'\"]*\\.pt['\"]?\\s*$",
    "cmd": "torch.save",
    "severity": "warn",
    "hint": "Always save model.state_dict(), not the full model object.",
    "detail": "Saving the entire model object with torch.save can cause issues loading across PyTorch versions or when code changes. The recommended approach is to save only the model's state_dict, which is more portable and robust.",
    "tags": [
      "serialization",
      "compatibility",
      "checkpointing"
    ]
  },
  {
    "id": "pytorch-002",
    "pattern": "^torch\\.load\\s*\\(",
    "cmd": "torch.load",
    "severity": "warn",
    "hint": "Use map_location for device compatibility when loading models.",
    "detail": "By default, torch.load restores tensors to their original device, which can fail if that device is unavailable. Use map_location to remap storage locations, especially when loading GPU-trained models on CPU-only machines.",
    "tags": [
      "serialization",
      "device",
      "checkpointing"
    ]
  },
  {
    "id": "pytorch-003",
    "pattern": "^torch\\.nn\\.DataParallel\\s*\\(",
    "cmd": "torch.nn.DataParallel",
    "severity": "upgrade",
    "hint": "Switch to torch.nn.parallel.DistributedDataParallel for better perfor...",
    "detail": "DataParallel is deprecated for multi-GPU training due to poor scaling and CPU bottlenecks. DistributedDataParallel (DDP) provides faster, more reliable parallelism and is the recommended approach since PyTorch 1.5.",
    "tags": [
      "parallelism",
      "performance",
      "upgrade"
    ]
  },
  {
    "id": "pytorch-004",
    "pattern": "^torch\\.no_grad\\s*\\(",
    "cmd": "torch.no_grad",
    "severity": "tip",
    "hint": "Combine with autocast for faster inference on supported hardware.",
    "detail": "torch.no_grad disables gradient tracking, reducing memory usage during inference. For further speedup and reduced memory, use torch.autocast in tandem to enable mixed precision on CUDA devices.",
    "tags": [
      "inference",
      "autocast",
      "performance"
    ]
  },
  {
    "id": "pytorch-005",
    "pattern": "^torch\\.autocast\\s*\\(",
    "cmd": "torch.autocast",
    "severity": "warn",
    "hint": "autocast is only effective on CUDA devices with AMP support.",
    "detail": "torch.autocast enables mixed precision, but only on CUDA-enabled devices with appropriate hardware and driver support. On CPU or unsupported GPUs, it silently falls back to full precision.",
    "tags": [
      "autocast",
      "AMP",
      "performance"
    ]
  },
  {
    "id": "pytorch-006",
    "pattern": "^torch\\.compile\\s*\\(",
    "cmd": "torch.compile",
    "severity": "tip",
    "hint": "Use mode='max-autotune' for best performance after warmup.",
    "detail": "torch.compile supports several modes. 'max-autotune' can yield the best runtime performance, but requires a warmup phase. Always benchmark with your workload to confirm gains.",
    "tags": [
      "torch.compile",
      "performance",
      "optimization"
    ]
  },
  {
    "id": "pytorch-007",
    "pattern": "^torch\\.compile\\s*\\(.*mode=['\"]?default['\"]?",
    "cmd": "torch.compile",
    "severity": "tip",
    "hint": "Try mode='reduce-overhead' for faster startup in dev workflows.",
    "detail": "The 'reduce-overhead' mode in torch.compile minimizes compilation time, which is useful for rapid prototyping or debugging. It may not yield the best runtime speed but improves iteration time.",
    "tags": [
      "torch.compile",
      "performance",
      "development"
    ]
  },
  {
    "id": "pytorch-008",
    "pattern": "^torch\\.distributed\\.init_process_group\\s*\\(",
    "cmd": "torch.distributed.init_process_group",
    "severity": "warn",
    "hint": "Set MASTER_ADDR and MASTER_PORT env vars for multi-node training.",
    "detail": "PyTorch DDP requires MASTER_ADDR and MASTER_PORT to be set for process rendezvous. Omitting these can cause silent hangs or connection failures, especially in multi-node setups.",
    "tags": [
      "DDP",
      "distributed",
      "environment"
    ]
  },
  {
    "id": "pytorch-009",
    "pattern": "^torch\\.distributed\\.launch\\s",
    "cmd": "torch.distributed.launch",
    "severity": "upgrade",
    "hint": "Switch to torchrun for launching distributed jobs (since 1.9).",
    "detail": "torch.distributed.launch is deprecated. torchrun is the recommended launcher, supporting elastic training and improved error handling. Update scripts to use torchrun for future compatibility.",
    "tags": [
      "DDP",
      "torchrun",
      "upgrade"
    ]
  },
  {
    "id": "pytorch-010",
    "pattern": "^torch\\.optim\\.Adam\\s*\\(",
    "cmd": "torch.optim.Adam",
    "severity": "tip",
    "hint": "Set eps=1e-8 for numerical stability with mixed precision.",
    "detail": "The default eps value in Adam can lead to instability when using AMP/mixed precision. Setting eps=1e-8 (instead of 1e-10) is recommended for stable convergence.",
    "tags": [
      "optimizer",
      "AMP",
      "numerical"
    ]
  },
  {
    "id": "pytorch-011",
    "pattern": "^torch\\.utils\\.data\\.DataLoader\\s*\\(",
    "cmd": "torch.utils.data.DataLoader",
    "severity": "tip",
    "hint": "Set num_workers > 0 for faster data loading on multicore systems.",
    "detail": "By default, DataLoader uses a single worker, which can bottleneck training. Increasing num_workers allows parallel data loading, significantly improving throughput on multicore CPUs.",
    "tags": [
      "dataloader",
      "performance",
      "data"
    ]
  },
  {
    "id": "pytorch-012",
    "pattern": "^torch\\.utils\\.data\\.DataLoader\\s*\\(.*pin_memory=True",
    "cmd": "torch.utils.data.DataLoader",
    "severity": "tip",
    "hint": "Use pin_memory=True to speed up host-to-GPU transfers.",
    "detail": "pin_memory allocates page-locked memory, enabling faster data transfer to CUDA devices. This is especially beneficial for large batch sizes and high-throughput training.",
    "tags": [
      "dataloader",
      "performance",
      "cuda"
    ]
  },
  {
    "id": "pytorch-013",
    "pattern": "^torch\\.utils\\.checkpoint\\.",
    "cmd": "torch.utils.checkpoint",
    "severity": "tip",
    "hint": "Use gradient checkpointing to save memory on large models.",
    "detail": "torch.utils.checkpoint trades compute for memory by recomputing activations during backward pass. This enables training larger models on limited GPU memory, at the cost of increased compute time.",
    "tags": [
      "checkpointing",
      "memory",
      "large models"
    ]
  },
  {
    "id": "pytorch-014",
    "pattern": "^torch\\.cuda\\.empty_cache\\s*\\(",
    "cmd": "torch.cuda.empty_cache",
    "severity": "warn",
    "hint": "empty_cache does not free GPU memory, only cached allocator blocks.",
    "detail": "torch.cuda.empty_cache releases cached memory blocks to the CUDA allocator, but does not reduce the actual memory usage as seen by nvidia-smi. Use with care; it rarely helps with OOM errors.",
    "tags": [
      "cuda",
      "memory",
      "debugging"
    ]
  },
  {
    "id": "pytorch-015",
    "pattern": "^torch\\.manual_seed\\s*\\(",
    "cmd": "torch.manual_seed",
    "severity": "warn",
    "hint": "Set deterministic flags for full reproducibility, not just manual_seed.",
    "detail": "Setting torch.manual_seed alone does not guarantee deterministic results. For full reproducibility, set torch.backends.cudnn.deterministic=True and torch.backends.cudnn.benchmark=False.",
    "tags": [
      "reproducibility",
      "randomness",
      "cudnn"
    ]
  },
  {
    "id": "pytorch-016",
    "pattern": "^torch\\.backends\\.cudnn\\.benchmark\\s*=\\s*True",
    "cmd": "torch.backends.cudnn.benchmark",
    "severity": "tip",
    "hint": "Enable benchmark=True for constant input sizes to speed up training.",
    "detail": "cudnn.benchmark enables auto-tuner for convolution algorithms, improving speed when input sizes are constant. For variable input sizes, it can cause performance drops and memory fragmentation.",
    "tags": [
      "cudnn",
      "performance",
      "convolution"
    ]
  },
  {
    "id": "pytorch-017",
    "pattern": "^torch\\.backends\\.cudnn\\.deterministic\\s*=\\s*True",
    "cmd": "torch.backends.cudnn.deterministic",
    "severity": "warn",
    "hint": "Setting deterministic=True may slow down training significantly.",
    "detail": "Enabling deterministic forces PyTorch to use deterministic algorithms, which can be slower and may not be available for all operations. Only use when strict reproducibility is required.",
    "tags": [
      "cudnn",
      "determinism",
      "performance"
    ]
  },
  {
    "id": "pytorch-018",
    "pattern": "^torch\\.set_num_threads\\s*\\(",
    "cmd": "torch.set_num_threads",
    "severity": "tip",
    "hint": "Tune num_threads for optimal CPU utilization in data-heavy workloads.",
    "detail": "torch.set_num_threads controls the number of OpenMP threads for CPU ops. Setting this too high or low can bottleneck performance; benchmark for your workload and hardware.",
    "tags": [
      "cpu",
      "performance",
      "threading"
    ]
  },
  {
    "id": "pytorch-019",
    "pattern": "^torch\\.set_num_interop_threads\\s*\\(",
    "cmd": "torch.set_num_interop_threads",
    "severity": "tip",
    "hint": "Adjust interop threads for better performance with data loaders.",
    "detail": "set_num_interop_threads controls the number of threads for inter-op parallelism, affecting data loader and model execution overlap. Tune for best throughput on multicore systems.",
    "tags": [
      "cpu",
      "performance",
      "threading"
    ]
  },
  {
    "id": "pytorch-020",
    "pattern": "^torch\\.jit\\.script\\s*\\(",
    "cmd": "torch.jit.script",
    "severity": "tip",
    "hint": "Use torch.jit.script for models with control flow for better speed.",
    "detail": "torch.jit.script converts models with Python control flow to TorchScript, enabling optimizations and deployment outside Python. It can significantly speed up inference and deployment.",
    "tags": [
      "jit",
      "deployment",
      "performance"
    ]
  },
  {
    "id": "pytorch-021",
    "pattern": "^torch\\.jit\\.trace\\s*\\(",
    "cmd": "torch.jit.trace",
    "severity": "warn",
    "hint": "jit.trace ignores control flow; use jit.script for dynamic models.",
    "detail": "torch.jit.trace records operations from example inputs, missing dynamic control flow. For models with data-dependent branches, use torch.jit.script to avoid silent bugs.",
    "tags": [
      "jit",
      "tracing",
      "control flow"
    ]
  },
  {
    "id": "pytorch-022",
    "pattern": "^torchvision\\.transforms\\.Normalize\\s*\\(",
    "cmd": "torchvision.transforms.Normalize",
    "severity": "warn",
    "hint": "Ensure input tensors are float and scaled to [0,1] before Normalize.",
    "detail": "torchvision.transforms.Normalize expects float tensors in [0,1] or [0,255]. Applying it to integer or unscaled tensors can produce incorrect results without errors.",
    "tags": [
      "torchvision",
      "preprocessing",
      "data"
    ]
  },
  {
    "id": "pytorch-023",
    "pattern": "^torchvision\\.datasets\\.",
    "cmd": "torchvision.datasets",
    "severity": "warn",
    "hint": "Set download=True only if dataset is not already present.",
    "detail": "Setting download=True when the dataset is already present can cause unnecessary downloads or overwrite existing data. Always check if the dataset exists before downloading.",
    "tags": [
      "torchvision",
      "datasets",
      "data"
    ]
  },
  {
    "id": "pytorch-024",
    "pattern": "^torch\\.nn\\.functional\\.cross_entropy\\s*\\(",
    "cmd": "torch.nn.functional.cross_entropy",
    "severity": "warn",
    "hint": "cross_entropy expects raw logits, not softmax probabilities.",
    "detail": "Passing softmax outputs to cross_entropy can cause poor gradients and learning. cross_entropy combines log_softmax and NLLLoss; always pass unnormalized logits.",
    "tags": [
      "loss",
      "training",
      "footgun"
    ]
  },
  {
    "id": "pytorch-025",
    "pattern": "^torch\\.nn\\.functional\\.mse_loss\\s*\\(",
    "cmd": "torch.nn.functional.mse_loss",
    "severity": "tip",
    "hint": "Set reduction='none' for per-element loss, not mean or sum.",
    "detail": "By default, mse_loss reduces output to a scalar mean. For per-sample or per-element loss, set reduction='none' to get the unreduced tensor.",
    "tags": [
      "loss",
      "training",
      "reduction"
    ]
  },
  {
    "id": "pytorch-026",
    "pattern": "^torch\\.nn\\.Module\\.eval\\s*\\(",
    "cmd": "torch.nn.Module.eval",
    "severity": "warn",
    "hint": "Call model.eval() before inference to disable dropout/batchnorm.",
    "detail": "Failing to set eval() leaves dropout and batchnorm in training mode, causing non-deterministic or inaccurate inference results. Always switch to eval() before evaluating.",
    "tags": [
      "inference",
      "evaluation",
      "footgun"
    ]
  },
  {
    "id": "pytorch-027",
    "pattern": "^torch\\.nn\\.Module\\.train\\s*\\(",
    "cmd": "torch.nn.Module.train",
    "severity": "warn",
    "hint": "Call model.train() before resuming training after eval().",
    "detail": "After calling eval(), layers like dropout and batchnorm remain in eval mode. Always call train() to restore correct training behavior before resuming training.",
    "tags": [
      "training",
      "mode",
      "footgun"
    ]
  },
  {
    "id": "pytorch-028",
    "pattern": "^torch\\.save\\s*\\(.*pickle_module=",
    "cmd": "torch.save",
    "severity": "danger",
    "hint": "Custom pickle modules can introduce security vulnerabilities.",
    "detail": "Using non-default pickle modules or loading untrusted pickles can execute arbitrary code. Only load models from trusted sources and avoid custom pickle modules unless necessary.",
    "tags": [
      "serialization",
      "security",
      "pickle"
    ]
  },
  {
    "id": "pytorch-029",
    "pattern": "^torch\\.load\\s*\\(.*map_location=['\"]?cuda['\"]?",
    "cmd": "torch.load",
    "severity": "warn",
    "hint": "map_location='cuda' loads to default GPU, not always device 0.",
    "detail": "Specifying map_location='cuda' loads tensors to the current default CUDA device, which may not be device 0 in multi-GPU setups. Use map_location=f'cuda:{rank}' for DDP.",
    "tags": [
      "serialization",
      "cuda",
      "distributed"
    ]
  },
  {
    "id": "pytorch-030",
    "pattern": "^torch\\.cuda\\.manual_seed_all\\s*\\(",
    "cmd": "torch.cuda.manual_seed_all",
    "severity": "warn",
    "hint": "Set both torch.manual_seed and torch.cuda.manual_seed_all for full co...",
    "detail": "torch.manual_seed only affects CPU and the current GPU. Use torch.cuda.manual_seed_all to seed all GPUs for reproducible results in multi-GPU training.",
    "tags": [
      "randomness",
      "cuda",
      "reproducibility"
    ]
  },
  {
    "id": "pytorch-031",
    "pattern": "^torch\\.nn\\.init\\.",
    "cmd": "torch.nn.init",
    "severity": "tip",
    "hint": "Use torch.nn.init for explicit weight initialization control.",
    "detail": "Explicit initialization with torch.nn.init lets you control weight distributions, which can improve convergence and stability, especially for custom architectures.",
    "tags": [
      "initialization",
      "training",
      "convergence"
    ]
  },
  {
    "id": "pytorch-032",
    "pattern": "^torch\\.tensor\\s*\\(.*requires_grad=True",
    "cmd": "torch.tensor",
    "severity": "warn",
    "hint": "requires_grad=True on integer tensors will silently be ignored.",
    "detail": "Gradients are only computed for floating point and complex tensors. Setting requires_grad=True on integer tensors has no effect and does not raise an error.",
    "tags": [
      "autograd",
      "dtype",
      "footgun"
    ]
  },
  {
    "id": "pytorch-033",
    "pattern": "^torch\\.from_numpy\\s*\\(",
    "cmd": "torch.from_numpy",
    "severity": "warn",
    "hint": "from_numpy shares memory; modifying one affects the other.",
    "detail": "torch.from_numpy returns a tensor that shares memory with the original numpy array. Changes to either object are reflected in the other, which can cause subtle bugs.",
    "tags": [
      "interop",
      "numpy",
      "memory"
    ]
  },
  {
    "id": "pytorch-034",
    "pattern": "^torch\\.to\\s*\\(.*non_blocking=True",
    "cmd": "torch.to",
    "severity": "tip",
    "hint": "Use non_blocking=True for async CPU-to-GPU copies with pinned memory.",
    "detail": "non_blocking=True only has effect if the source tensor is in pinned memory. Otherwise, the copy is always blocking. Use with DataLoader(pin_memory=True) for best results.",
    "tags": [
      "cuda",
      "performance",
      "memory"
    ]
  },
  {
    "id": "pytorch-035",
    "pattern": "^torch\\.nn\\.SyncBatchNorm\\s*\\(",
    "cmd": "torch.nn.SyncBatchNorm",
    "severity": "warn",
    "hint": "SyncBatchNorm requires DDP; does not work with DataParallel.",
    "detail": "torch.nn.SyncBatchNorm synchronizes stats across processes, but only works with DistributedDataParallel. Using it with DataParallel or single-process setups will fail or be ineffective.",
    "tags": [
      "batchnorm",
      "DDP",
      "footgun"
    ]
  },
  {
    "id": "pytorch-036",
    "pattern": "^torch\\.cuda\\.amp\\.GradScaler\\s*\\(",
    "cmd": "torch.cuda.amp.GradScaler",
    "severity": "tip",
    "hint": "Use GradScaler with autocast for stable mixed precision training.",
    "detail": "GradScaler dynamically scales loss to prevent underflow in gradients during mixed precision training. Use together with autocast for optimal AMP performance.",
    "tags": [
      "AMP",
      "autocast",
      "training"
    ]
  },
  {
    "id": "pytorch-037",
    "pattern": "^torch\\.cuda\\.amp\\.autocast\\s*\\(",
    "cmd": "torch.cuda.amp.autocast",
    "severity": "tip",
    "hint": "autocast context speeds up training on modern NVIDIA GPUs.",
    "detail": "autocast enables automatic mixed precision, reducing memory and increasing throughput on supported GPUs (Volta and newer). Wrap forward passes for best results.",
    "tags": [
      "AMP",
      "autocast",
      "performance"
    ]
  },
  {
    "id": "pytorch-038",
    "pattern": "^torch\\.distributed\\.fsdp\\.",
    "cmd": "torch.distributed.fsdp",
    "severity": "upgrade",
    "hint": "Use FSDP for large models; replaces legacy model sharding.",
    "detail": "Fully Sharded Data Parallel (FSDP) provides efficient memory usage and scaling for large models, outperforming legacy sharding and DDP for very large parameter counts.",
    "tags": [
      "FSDP",
      "large models",
      "distributed"
    ]
  },
  {
    "id": "pytorch-039",
    "pattern": "^torch\\.profiler\\.",
    "cmd": "torch.profiler",
    "severity": "tip",
    "hint": "Use torch.profiler for detailed GPU/CPU performance analysis.",
    "detail": "torch.profiler provides timeline traces, operator-level stats, and integration with TensorBoard, enabling deep performance analysis and bottleneck identification.",
    "tags": [
      "profiler",
      "performance",
      "debugging"
    ]
  },
  {
    "id": "pytorch-040",
    "pattern": "^torchserve\\s+start",
    "cmd": "torchserve",
    "severity": "warn",
    "hint": "Always specify --model-store and --models for reproducible serving.",
    "detail": "Not specifying --model-store or --models can lead to serving stale or unintended models. Explicitly set these flags for predictable, reproducible deployments.",
    "tags": [
      "torchserve",
      "deployment",
      "serving"
    ]
  },
  {
    "id": "pytorch-041",
    "pattern": "^torchserve\\s+register-model",
    "cmd": "torchserve",
    "severity": "warn",
    "hint": "Register models with explicit --handler for custom inference logic.",
    "detail": "If --handler is omitted, TorchServe uses default handlers, which may not support custom preprocessing or postprocessing. Always specify a handler for non-standard models.",
    "tags": [
      "torchserve",
      "deployment",
      "handler"
    ]
  },
  {
    "id": "pytorch-042",
    "pattern": "^torch\\.nn\\.functional\\.one_hot\\s*\\(",
    "cmd": "torch.nn.functional.one_hot",
    "severity": "warn",
    "hint": "Input to one_hot must be integer tensor; floats cause silent errors.",
    "detail": "torch.nn.functional.one_hot expects integer class indices. Passing float tensors results in incorrect outputs without raising exceptions.",
    "tags": [
      "encoding",
      "footgun",
      "data"
    ]
  },
  {
    "id": "pytorch-043",
    "pattern": "^torch\\.nn\\.ModuleList\\s*\\(",
    "cmd": "torch.nn.ModuleList",
    "severity": "warn",
    "hint": "Use ModuleList for submodules, not plain Python lists.",
    "detail": "Plain Python lists of nn.Modules are not registered as submodules, so their parameters are not tracked by .parameters() or .to(). Always use ModuleList for dynamic submodules.",
    "tags": [
      "modules",
      "parameters",
      "footgun"
    ]
  },
  {
    "id": "pytorch-044",
    "pattern": "^torch\\.nn\\.ParameterList\\s*\\(",
    "cmd": "torch.nn.ParameterList",
    "severity": "warn",
    "hint": "ParameterList is required for dynamic parameters, not plain lists.",
    "detail": "Parameters in plain lists are not registered and won't be updated by optimizers. Use ParameterList to ensure correct registration and optimization.",
    "tags": [
      "parameters",
      "modules",
      "footgun"
    ]
  },
  {
    "id": "pytorch-045",
    "pattern": "^torch\\.nn\\.Sequential\\s*\\(",
    "cmd": "torch.nn.Sequential",
    "severity": "warn",
    "hint": "Sequential cannot express models with branching or skip connections.",
    "detail": "torch.nn.Sequential is limited to simple feedforward stacks. For models with complex topologies, subclass nn.Module and define forward() manually.",
    "tags": [
      "modules",
      "architecture",
      "footgun"
    ]
  },
  {
    "id": "pytorch-046",
    "pattern": "^torch\\.cat\\s*\\(",
    "cmd": "torch.cat",
    "severity": "warn",
    "hint": "cat requires matching shapes except in the concatenation dimension.",
    "detail": "torch.cat will raise a runtime error if input tensors differ in any dimension except the one being concatenated. Always check shapes before concatenation.",
    "tags": [
      "tensor",
      "shape",
      "footgun"
    ]
  },
  {
    "id": "pytorch-047",
    "pattern": "^torch\\.stack\\s*\\(",
    "cmd": "torch.stack",
    "severity": "warn",
    "hint": "stack requires all input tensors to have the same shape.",
    "detail": "Unlike cat, stack creates a new dimension and requires all tensors to be exactly the same shape. Mismatched shapes will cause a runtime error.",
    "tags": [
      "tensor",
      "shape",
      "footgun"
    ]
  },
  {
    "id": "pytorch-048",
    "pattern": "^torch\\.nn\\.functional\\.pad\\s*\\(",
    "cmd": "torch.nn.functional.pad",
    "severity": "warn",
    "hint": "pad expects padding as (left, right, top, bottom, ...), not (top, lef...",
    "detail": "The padding argument order is different from many other libraries. Always check the documentation to avoid shape mismatches or unexpected results.",
    "tags": [
      "tensor",
      "padding",
      "footgun"
    ]
  },
  {
    "id": "pytorch-049",
    "pattern": "^torch\\.nn\\.functional\\.dropout\\s*\\(",
    "cmd": "torch.nn.functional.dropout",
    "severity": "warn",
    "hint": "dropout only active in training mode; set model.train().",
    "detail": "Dropout is only applied when the model is in training mode. During eval, dropout is disabled, which can cause discrepancies if not handled properly.",
    "tags": [
      "dropout",
      "training",
      "mode"
    ]
  },
  {
    "id": "pytorch-050",
    "pattern": "^torch\\.nn\\.functional\\.relu\\s*\\(",
    "cmd": "torch.nn.functional.relu",
    "severity": "tip",
    "hint": "Use inplace=True for memory savings, but beware of autograd issues.",
    "detail": "inplace=True reduces memory usage, but can interfere with autograd if the input is needed for gradient computation. Use with caution and test for correctness.",
    "tags": [
      "relu",
      "memory",
      "autograd"
    ]
  },
  {
    "id": "pytorch-051",
    "pattern": "^torch\\.nn\\.functional\\.softmax\\s*\\(",
    "cmd": "torch.nn.functional.softmax",
    "severity": "warn",
    "hint": "Always specify dim argument for softmax to avoid silent errors.",
    "detail": "Omitting the dim argument can lead to softmax being applied over the wrong axis, producing incorrect outputs without warning.",
    "tags": [
      "softmax",
      "footgun",
      "tensor"
    ]
  },
  {
    "id": "pytorch-052",
    "pattern": "^torch\\.nn\\.functional\\.log_softmax\\s*\\(",
    "cmd": "torch.nn.functional.log_softmax",
    "severity": "warn",
    "hint": "Specify dim for log_softmax; default may not match model output.",
    "detail": "log_softmax without dim can cause unexpected behavior, especially for multi-dimensional outputs. Always set dim explicitly.",
    "tags": [
      "softmax",
      "footgun",
      "tensor"
    ]
  },
  {
    "id": "pytorch-053",
    "pattern": "^torch\\.nn\\.functional\\.layer_norm\\s*\\(",
    "cmd": "torch.nn.functional.layer_norm",
    "severity": "warn",
    "hint": "normalized_shape must match the last N dimensions of input.",
    "detail": "layer_norm expects normalized_shape to match the shape of the last N dimensions of the input tensor. Mismatches raise runtime errors.",
    "tags": [
      "layernorm",
      "shape",
      "footgun"
    ]
  },
  {
    "id": "pytorch-054",
    "pattern": "^torch\\.nn\\.functional\\.group_norm\\s*\\(",
    "cmd": "torch.nn.functional.group_norm",
    "severity": "warn",
    "hint": "num_groups must divide the number of channels exactly.",
    "detail": "group_norm requires num_channels to be divisible by num_groups. Otherwise, a runtime error is raised.",
    "tags": [
      "groupnorm",
      "shape",
      "footgun"
    ]
  },
  {
    "id": "pytorch-055",
    "pattern": "^torch\\.nn\\.functional\\.conv2d\\s*\\(",
    "cmd": "torch.nn.functional.conv2d",
    "severity": "warn",
    "hint": "Input and weight tensors must have matching channel dimensions.",
    "detail": "conv2d expects input shape (N, C_in, H, W) and weight shape (C_out, C_in, kH, kW). Mismatches cause runtime errors.",
    "tags": [
      "conv2d",
      "shape",
      "footgun"
    ]
  },
  {
    "id": "pytorch-056",
    "pattern": "^torch\\.nn\\.functional\\.interpolate\\s*\\(",
    "cmd": "torch.nn.functional.interpolate",
    "severity": "warn",
    "hint": "Set align_corners for consistent results with bilinear/linear modes.",
    "detail": "align_corners changes the interpolation calculation. For reproducibility and matching legacy behavior, always set align_corners explicitly when using bilinear or linear modes.",
    "tags": [
      "interpolation",
      "footgun",
      "compatibility"
    ]
  },
  {
    "id": "pytorch-057",
    "pattern": "^torch\\.nn\\.functional\\.binary_cross_entropy\\s*\\(",
    "cmd": "torch.nn.functional.binary_cross_entropy",
    "severity": "warn",
    "hint": "Input to BCE must be probabilities, not logits.",
    "detail": "binary_cross_entropy expects inputs in [0,1]. For raw logits, use binary_cross_entropy_with_logits to avoid poor gradients and instability.",
    "tags": [
      "loss",
      "training",
      "footgun"
    ]
  },
  {
    "id": "pytorch-058",
    "pattern": "^torch\\.nn\\.functional\\.binary_cross_entropy_with_logits\\s*\\(",
    "cmd": "torch.nn.functional.binary_cross_entropy_with_logits",
    "severity": "tip",
    "hint": "Use BCEWithLogits for numerical stability with logits.",
    "detail": "binary_cross_entropy_with_logits combines a sigmoid layer and BCE loss in one function, providing better numerical stability and gradient flow than chaining separately.",
    "tags": [
      "loss",
      "training",
      "stability"
    ]
  },
  {
    "id": "pytorch-059",
    "pattern": "^torch\\.save\\s*\\(.*_use_new_zipfile_serialization=False",
    "cmd": "torch.save",
    "severity": "upgrade",
    "hint": "Use new zipfile serialization for smaller, faster model files.",
    "detail": "The legacy serialization format is slower and less space-efficient. The new zipfile format (default since 1.6) is recommended for all new models.",
    "tags": [
      "serialization",
      "upgrade",
      "performance"
    ]
  },
  {
    "id": "pytorch-060",
    "pattern": "^torch\\.set_grad_enabled\\s*\\(",
    "cmd": "torch.set_grad_enabled",
    "severity": "tip",
    "hint": "Use set_grad_enabled context to toggle gradients for eval/training.",
    "detail": "set_grad_enabled(True/False) is a context manager that enables or disables autograd globally, useful for switching between training and evaluation without changing code structure.",
    "tags": [
      "autograd",
      "training",
      "inference"
    ]
  },
  {
    "id": "tensorflow-001",
    "pattern": "^python\\s+.*import\\s+keras",
    "cmd": "python",
    "severity": "upgrade",
    "hint": "Use tf.keras instead of standalone keras for TensorFlow integration.",
    "detail": "The standalone keras package is not fully compatible with TensorFlow's backend and features. tf.keras is maintained by TensorFlow, supports SavedModel, tf.data, and distribution strategies. Mixing keras and tf.keras can cause subtle bugs.",
    "tags": [
      "keras",
      "tf.keras",
      "upgrade"
    ]
  },
  {
    "id": "tensorflow-002",
    "pattern": "^python\\s+.*tf\\.keras\\.models\\.load_model\\(.*h5.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Prefer SavedModel over HDF5 (.h5) for model saving/loading.",
    "detail": "HDF5 format does not preserve custom objects, optimizers, or distribution strategies. SavedModel is TensorFlow's recommended format, supporting signatures, custom layers, and TensorFlow Serving.",
    "tags": [
      "tf.keras",
      "SavedModel",
      "model IO"
    ]
  },
  {
    "id": "tensorflow-003",
    "pattern": "^python\\s+.*tf\\.data\\.Dataset\\.from_generator\\(",
    "cmd": "python",
    "severity": "warn",
    "hint": "from_generator disables static graph optimizations. Use from_tensor_s...",
    "detail": "tf.data.Dataset.from_generator yields Python objects, preventing TensorFlow from tracing and optimizing the pipeline. from_tensor_slices enables vectorized, graph-based execution and better performance.",
    "tags": [
      "tf.data",
      "performance",
      "pipeline"
    ]
  },
  {
    "id": "tensorflow-004",
    "pattern": "^python\\s+.*tf\\.function\\(experimental_relax_shapes=True\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Relaxed shapes can cause excessive retracing. Use with care.",
    "detail": "experimental_relax_shapes allows tf.function to accept variable input shapes, but can trigger retracing for each new shape, degrading performance. Use input_signature to control tracing.",
    "tags": [
      "tf.function",
      "performance",
      "tracing"
    ]
  },
  {
    "id": "tensorflow-005",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*use_multiprocessing=True.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "use_multiprocessing=True may deadlock with TensorFlow datasets.",
    "detail": "When using tf.data datasets, enabling use_multiprocessing in Model.fit can cause deadlocks or hangs, especially on Windows. Prefer TensorFlow-native parallelism via tf.data.",
    "tags": [
      "tf.keras",
      "fit",
      "multiprocessing"
    ]
  },
  {
    "id": "tensorflow-006",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*workers=\\d+.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set workers>1 only with numpy arrays, not tf.data datasets.",
    "detail": "The workers argument in Model.fit is ignored when using tf.data datasets, as TensorFlow handles parallelism internally. Using it with datasets can mislead about performance gains.",
    "tags": [
      "tf.keras",
      "fit",
      "workers"
    ]
  },
  {
    "id": "tensorflow-007",
    "pattern": "^python\\s+.*tf\\.keras\\.callbacks\\.ModelCheckpoint\\(.*save_weights_only=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set save_weights_only=True for faster checkpoints if weights suffice.",
    "detail": "By default, ModelCheckpoint saves the entire model, including optimizer state and architecture. If you only need weights for inference or transfer learning, save_weights_only=True is faster and uses less disk space.",
    "tags": [
      "tf.keras",
      "checkpoint",
      "performance"
    ]
  },
  {
    "id": "tensorflow-008",
    "pattern": "^python\\s+.*tf\\.keras\\.optimizers\\.(SGD|Adam|RMSprop)\\(.*lr=.*\\)",
    "cmd": "python",
    "severity": "upgrade",
    "hint": "Use learning_rate instead of deprecated lr argument.",
    "detail": "The lr argument is deprecated in tf.keras optimizers. Use learning_rate for forward compatibility and to avoid warnings in future TensorFlow releases.",
    "tags": [
      "tf.keras",
      "optimizer",
      "deprecation"
    ]
  },
  {
    "id": "tensorflow-009",
    "pattern": "^python\\s+.*tf\\.keras\\.layers\\.BatchNormalization\\(.*trainable=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Setting trainable=False disables updates to moving statistics.",
    "detail": "When trainable=False, BatchNormalization layers do not update moving mean/variance during training, which can degrade model accuracy. Use layer.trainable = False only for inference or transfer learning.",
    "tags": [
      "tf.keras",
      "BatchNormalization",
      "trainable"
    ]
  },
  {
    "id": "tensorflow-010",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*shuffle=False.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Not shuffling data can lead to poor generalization.",
    "detail": "Disabling shuffling in Model.fit can cause the model to learn spurious patterns from data order, especially in classification tasks. Always shuffle training data unless order is required.",
    "tags": [
      "tf.keras",
      "fit",
      "shuffle"
    ]
  },
  {
    "id": "tensorflow-011",
    "pattern": "^python\\s+.*tf\\.data\\.TFRecordDataset\\(",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable compression_type='GZIP' for compressed TFRecords.",
    "detail": "TFRecordDataset can read compressed files with compression_type='GZIP' or 'ZLIB'. This reduces disk usage and I/O, but must match the file's compression. Unmatched types cause silent errors.",
    "tags": [
      "tf.data",
      "TFRecord",
      "compression"
    ]
  },
  {
    "id": "tensorflow-012",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.save\\(.*save_format='h5'.*\\)",
    "cmd": "python",
    "severity": "upgrade",
    "hint": "Use save_format='tf' for SavedModel compatibility and features.",
    "detail": "SavedModel format supports signatures, custom objects, and TensorFlow Serving. The HDF5 format is legacy and lacks full feature support. Prefer save_format='tf' for new projects.",
    "tags": [
      "tf.keras",
      "SavedModel",
      "model IO"
    ]
  },
  {
    "id": "tensorflow-013",
    "pattern": "^python\\s+.*tf\\.function\\(.*autograph=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "autograph=False disables Python control flow conversion.",
    "detail": "With autograph=False, tf.function will not convert Python for/if statements to TensorFlow ops, which may limit graph optimizations and deployment. Use only for debugging or when control flow is static.",
    "tags": [
      "tf.function",
      "autograph",
      "graph"
    ]
  },
  {
    "id": "tensorflow-014",
    "pattern": "^python\\s+.*tf\\.keras\\.mixed_precision\\.set_global_policy\\('mixed_float16'\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Ensure your GPU supports float16 (compute capability >= 7.0).",
    "detail": "Mixed precision requires Volta or newer NVIDIA GPUs (compute capability 7.0+). Using it on unsupported hardware can cause errors or silent accuracy loss. Check with tf.config.list_physical_devices('GPU').",
    "tags": [
      "mixed precision",
      "hardware",
      "GPU"
    ]
  },
  {
    "id": "tensorflow-015",
    "pattern": "^python\\s+.*tf\\.distribute\\.MirroredStrategy\\(",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set TF_GPU_THREAD_MODE=gpu_private for optimal multi-GPU throughput.",
    "detail": "Setting the TF_GPU_THREAD_MODE environment variable to 'gpu_private' can improve performance for MirroredStrategy by dedicating threads to each GPU. This reduces contention and improves scaling.",
    "tags": [
      "tf.distribute",
      "MirroredStrategy",
      "performance"
    ]
  },
  {
    "id": "tensorflow-016",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*steps_per_epoch=0.*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "steps_per_epoch=0 disables training and can silently pass.",
    "detail": "Setting steps_per_epoch=0 causes Model.fit to skip training, but does not raise an error. Always check that steps_per_epoch is positive and matches your dataset size.",
    "tags": [
      "tf.keras",
      "fit",
      "footgun"
    ]
  },
  {
    "id": "tensorflow-017",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.predict\\(.*batch_size=1.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use larger batch_size for faster inference throughput.",
    "detail": "Batch size of 1 leads to inefficient GPU/CPU utilization. Increasing batch_size in predict can significantly improve inference speed, especially on modern hardware.",
    "tags": [
      "tf.keras",
      "predict",
      "performance"
    ]
  },
  {
    "id": "tensorflow-018",
    "pattern": "^python\\s+.*tf\\.data\\.Dataset\\.prefetch\\(.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set prefetch buffer to tf.data.AUTOTUNE for optimal pipeline speed.",
    "detail": "Using tf.data.AUTOTUNE lets TensorFlow dynamically tune the prefetch buffer size for maximum throughput, adapting to system and model characteristics.",
    "tags": [
      "tf.data",
      "prefetch",
      "performance"
    ]
  },
  {
    "id": "tensorflow-019",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*validation_data=.*shuffle=True.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "Do not shuffle validation data; it breaks reproducibility.",
    "detail": "Shuffling validation data can cause inconsistent evaluation metrics across epochs, making it hard to track model progress. Always use shuffle=False for validation datasets.",
    "tags": [
      "tf.keras",
      "fit",
      "validation"
    ]
  },
  {
    "id": "tensorflow-020",
    "pattern": "^python\\s+.*tf\\.keras\\.layers\\.Dense\\(.*activation='softmax'.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use from_logits=True in loss if Dense uses activation='softmax'.",
    "detail": "When the final layer applies softmax, set from_logits=False in your loss. If you forget, the model may train poorly or not converge due to double softmax application.",
    "tags": [
      "tf.keras",
      "Dense",
      "loss"
    ]
  },
  {
    "id": "tensorflow-021",
    "pattern": "^python\\s+.*tf\\.keras\\.layers\\.Dense\\(.*activation=None.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "If activation=None, set from_logits=True in your loss.",
    "detail": "When the output layer does not apply softmax/sigmoid, the loss function must expect logits (from_logits=True). Otherwise, training will be unstable or inaccurate.",
    "tags": [
      "tf.keras",
      "Dense",
      "loss"
    ]
  },
  {
    "id": "tensorflow-022",
    "pattern": "^python\\s+.*tf\\.keras\\.callbacks\\.EarlyStopping\\(.*restore_best_weights=False.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set restore_best_weights=True to recover best model after early stop.",
    "detail": "By default, EarlyStopping does not restore the best weights. Setting restore_best_weights=True ensures the model weights correspond to the best validation metric, not the last epoch.",
    "tags": [
      "tf.keras",
      "EarlyStopping",
      "callbacks"
    ]
  },
  {
    "id": "tensorflow-023",
    "pattern": "^python\\s+.*tf\\.keras\\.optimizers\\.(SGD|Adam|RMSprop)\\(.*clipnorm=.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use clipnorm or clipvalue to stabilize training with noisy gradients.",
    "detail": "Gradient clipping prevents exploding gradients in deep or recurrent networks. clipnorm clips gradients by norm, while clipvalue clips by absolute value. Choose based on your model's sensitivity.",
    "tags": [
      "tf.keras",
      "optimizer",
      "gradient clipping"
    ]
  },
  {
    "id": "tensorflow-024",
    "pattern": "^python\\s+.*tf\\.data\\.Dataset\\.map\\(.*num_parallel_calls=.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set num_parallel_calls=tf.data.AUTOTUNE for optimal mapping speed.",
    "detail": "AUTOTUNE dynamically adjusts parallelism for map transformations, maximizing throughput without manual tuning. This is especially effective for complex data preprocessing.",
    "tags": [
      "tf.data",
      "map",
      "performance"
    ]
  },
  {
    "id": "tensorflow-025",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*class_weight=.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "class_weight is ignored with tf.data datasets unless using numpy arrays.",
    "detail": "When using tf.data datasets, class_weight is only supported if the dataset yields (x, y) tuples. If the dataset yields dictionaries or custom structures, class_weight is silently ignored.",
    "tags": [
      "tf.keras",
      "fit",
      "class_weight"
    ]
  },
  {
    "id": "tensorflow-026",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*steps_per_epoch=.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "steps_per_epoch is required for infinite datasets.",
    "detail": "If your tf.data pipeline is infinite (no .take()), you must specify steps_per_epoch in Model.fit. Otherwise, training will run forever or until interrupted.",
    "tags": [
      "tf.keras",
      "fit",
      "steps_per_epoch"
    ]
  },
  {
    "id": "tensorflow-027",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.save\\(.*include_optimizer=True.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set include_optimizer=False for inference-only model exports.",
    "detail": "Including the optimizer state increases model size and is unnecessary for inference or transfer learning. Set include_optimizer=False to reduce file size and loading time.",
    "tags": [
      "tf.keras",
      "save",
      "optimizer"
    ]
  },
  {
    "id": "tensorflow-028",
    "pattern": "^python\\s+.*tf\\.lite\\.TFLiteConverter\\.from_saved_model\\(",
    "cmd": "python",
    "severity": "tip",
    "hint": "Enable optimizations with converter.optimizations=[tf.lite.Optimize.D...",
    "detail": "Setting optimizations enables quantization and other graph-level improvements, reducing model size and improving inference speed on edge devices. Omit this and you miss major TFLite benefits.",
    "tags": [
      "TFLite",
      "optimization",
      "quantization"
    ]
  },
  {
    "id": "tensorflow-029",
    "pattern": "^python\\s+.*tf\\.keras\\.layers\\.Dropout\\(.*rate=1.*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "Dropout rate=1 disables all neuron outputs; model won't learn.",
    "detail": "A dropout rate of 1.0 means all outputs are zeroed during training, preventing any learning. Use rates between 0.1 and 0.5 for effective regularization.",
    "tags": [
      "tf.keras",
      "Dropout",
      "footgun"
    ]
  },
  {
    "id": "tensorflow-030",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*max_queue_size=0.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "max_queue_size=0 disables data prefetching, slowing training.",
    "detail": "Setting max_queue_size=0 prevents data from being prefetched, causing the model to wait for data loading and reducing GPU utilization. Use a positive value for efficient training.",
    "tags": [
      "tf.keras",
      "fit",
      "performance"
    ]
  },
  {
    "id": "tensorflow-031",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*verbose=2.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Use verbose=2 for concise epoch-level logs in distributed training.",
    "detail": "verbose=2 prints one log line per epoch, reducing log noise in multi-worker or distributed settings, where step-level logs can overwhelm the console.",
    "tags": [
      "tf.keras",
      "fit",
      "logging"
    ]
  },
  {
    "id": "tensorflow-032",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*initial_epoch=.*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Set initial_epoch when resuming training from checkpoints.",
    "detail": "initial_epoch tells Model.fit to resume from a specific epoch, avoiding overwriting logs and ensuring correct learning rate schedules. Forgetting this can restart training from scratch.",
    "tags": [
      "tf.keras",
      "fit",
      "checkpoint"
    ]
  },
  {
    "id": "tensorflow-033",
    "pattern": "^python\\s+.*tf\\.data\\.Dataset\\.shuffle\\(.*buffer_size=1.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "buffer_size=1 disables effective shuffling; increase for randomness.",
    "detail": "A buffer size of 1 means no shuffling occurs. Use a buffer size at least as large as your dataset for true randomness, or a large enough value for partial shuffling.",
    "tags": [
      "tf.data",
      "shuffle",
      "performance"
    ]
  },
  {
    "id": "tensorflow-034",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*sample_weight=.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "sample_weight shape must match output shape or training will fail.",
    "detail": "sample_weight must be broadcastable to the output shape of your model. Mismatched shapes cause ValueError or silent misweighting of samples, affecting training dynamics.",
    "tags": [
      "tf.keras",
      "fit",
      "sample_weight"
    ]
  },
  {
    "id": "tensorflow-035",
    "pattern": "^python\\s+.*tf\\.distribute\\.MultiWorkerMirroredStrategy\\(",
    "cmd": "python",
    "severity": "warn",
    "hint": "Set TF_CONFIG environment variable for multi-worker training.",
    "detail": "TF_CONFIG is required to configure cluster topology for MultiWorkerMirroredStrategy. Omitting it can cause workers to run independently, not as a distributed cluster.",
    "tags": [
      "tf.distribute",
      "MultiWorkerMirroredStrategy",
      "environment"
    ]
  },
  {
    "id": "tensorflow-036",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*callbacks=\\[\\].*\\)",
    "cmd": "python",
    "severity": "tip",
    "hint": "Add callbacks for checkpoints, learning rate schedules, and logging.",
    "detail": "Callbacks like ModelCheckpoint, EarlyStopping, and TensorBoard provide critical features for robust training. An empty callbacks list means you miss out on these capabilities.",
    "tags": [
      "tf.keras",
      "fit",
      "callbacks"
    ]
  },
  {
    "id": "tensorflow-037",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.predict\\(.*steps=0.*\\)",
    "cmd": "python",
    "severity": "danger",
    "hint": "steps=0 disables prediction; no output will be produced.",
    "detail": "Setting steps=0 in Model.predict causes the method to return immediately without any prediction, but does not raise an error. Always specify a positive steps value for generator inputs.",
    "tags": [
      "tf.keras",
      "predict",
      "footgun"
    ]
  },
  {
    "id": "tensorflow-038",
    "pattern": "^python\\s+.*tf\\.keras\\.Model\\.fit\\(.*validation_split=.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "validation_split only works with numpy arrays, not tf.data datasets.",
    "detail": "validation_split is ignored when using tf.data datasets in Model.fit. Use dataset.take() and dataset.skip() to split validation and training data manually.",
    "tags": [
      "tf.keras",
      "fit",
      "validation_split"
    ]
  },
  {
    "id": "tensorflow-039",
    "pattern": "^python\\s+.*tf\\.keras\\.metrics\\.(Accuracy|AUC|Precision|Recall)\\(.*from_logits=True.*\\)",
    "cmd": "python",
    "severity": "warn",
    "hint": "tf.keras metrics do not support from_logits=True; use probabilities.",
    "detail": "tf.keras metrics expect probabilities, not logits. Passing logits can cause incorrect metric calculations. Apply softmax/sigmoid before metric evaluation.",
    "tags": [
      "tf.keras",
      "metrics",
      "logits"
    ]
  },
  {
    "id": "tensorflow-040",
    "pattern": "^python\\s+.*tensorflow_model_server\\s+--model_base_path=.*",
    "cmd": "tensorflow_model_server",
    "severity": "tip",
    "hint": "Use --rest_api_port for HTTP inference in TensorFlow Serving.",
    "detail": "By default, TensorFlow Serving exposes gRPC on port 8500. To enable REST API, specify --rest_api_port (e.g., 8501). This is required for HTTP-based clients and browser inference.",
    "tags": [
      "TF Serving",
      "REST API",
      "deployment"
    ]
  },
  {
    "id": "jax-001",
    "pattern": "^jax\\.jit\\s*\\(",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Use static_argnames for non-array args in jax.jit.",
    "detail": "By default, jax.jit only traces array arguments. Non-array arguments (like booleans or strings) are treated as static if you specify them in static_argnames. Omitting this can cause recompilation or silent errors if non-array arguments change.",
    "tags": [
      "jit",
      "performance",
      "static_argnames"
    ]
  },
  {
    "id": "jax-002",
    "pattern": "^jax\\.jit\\s*\\(.*donate_argnums\\s*=\\s*None",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Set donate_argnums to avoid unnecessary memory copies in jax.jit.",
    "detail": "The donate_argnums argument allows JAX to reuse input buffers, reducing memory pressure and improving performance. If not set, large arrays may be copied unnecessarily, especially on GPUs/TPUs.",
    "tags": [
      "jit",
      "memory",
      "performance"
    ]
  },
  {
    "id": "jax-003",
    "pattern": "^jax\\.vmap\\s*\\(",
    "cmd": "jax.vmap",
    "severity": "tip",
    "hint": "Use in_axes and out_axes for flexible batching in jax.vmap.",
    "detail": "Specifying in_axes and out_axes allows you to control which function arguments and outputs are batched. This avoids shape mismatches and enables more complex batching patterns.",
    "tags": [
      "vmap",
      "batching",
      "performance"
    ]
  },
  {
    "id": "jax-004",
    "pattern": "^jax\\.pmap\\s*\\(",
    "cmd": "jax.pmap",
    "severity": "warn",
    "hint": "pmap requires all devices to be available; check jax.devices().",
    "detail": "If the number of mapped axes does not match the available devices, jax.pmap can silently fail or drop data. Always verify jax.devices() and match axis_size to device count.",
    "tags": [
      "pmap",
      "devices",
      "parallelism"
    ]
  },
  {
    "id": "jax-005",
    "pattern": "^jax\\.grad\\s*\\(.*has_aux\\s*=\\s*False",
    "cmd": "jax.grad",
    "severity": "warn",
    "hint": "Set has_aux=True if your function returns auxiliary outputs.",
    "detail": "If your function returns (loss, aux), omitting has_aux=True will cause jax.grad to ignore the auxiliary outputs, potentially leading to silent bugs or missing information in training loops.",
    "tags": [
      "grad",
      "autodiff",
      "has_aux"
    ]
  },
  {
    "id": "jax-006",
    "pattern": "^jax\\.jit\\s*\\(.*static_argnames\\s*=\\s*None",
    "cmd": "jax.jit",
    "severity": "warn",
    "hint": "Omitting static_argnames can cause excessive recompilation.",
    "detail": "If non-array arguments change and are not marked as static, jax.jit will recompile the function for every new value, leading to performance degradation and high memory usage.",
    "tags": [
      "jit",
      "compilation",
      "static_argnames"
    ]
  },
  {
    "id": "jax-007",
    "pattern": "^jax\\.random\\.split\\s*\\(",
    "cmd": "jax.random.split",
    "severity": "tip",
    "hint": "Always split PRNG keys in JAX to avoid reuse and nondeterminism.",
    "detail": "JAX PRNG keys are single-use; reusing them leads to correlated random numbers and nondeterministic results. Always split keys before passing to random functions.",
    "tags": [
      "random",
      "prng",
      "determinism"
    ]
  },
  {
    "id": "jax-008",
    "pattern": "^flax\\.linen\\.Module\\(",
    "cmd": "flax.linen.Module",
    "severity": "tip",
    "hint": "Use setup() for side-effect-free initialization in Flax modules.",
    "detail": "Flax's setup() method is called once per module instantiation. Avoid side effects in __init__, as Flax expects modules to be pure and stateless outside setup/param methods.",
    "tags": [
      "flax",
      "module",
      "setup"
    ]
  },
  {
    "id": "jax-009",
    "pattern": "^flax\\.linen\\.Module\\..*apply\\(",
    "cmd": "flax.linen.Module.apply",
    "severity": "warn",
    "hint": "Pass rngs argument for stochastic layers in Flax apply.",
    "detail": "If your model uses dropout or other stochastic layers, omitting the rngs argument in apply will cause deterministic behavior or errors. Always provide rngs={'dropout': key} as needed.",
    "tags": [
      "flax",
      "apply",
      "rngs"
    ]
  },
  {
    "id": "jax-010",
    "pattern": "^jax\\.pmap\\s*\\(.*axis_name\\s*=\\s*None",
    "cmd": "jax.pmap",
    "severity": "tip",
    "hint": "Set axis_name for collective operations in jax.pmap.",
    "detail": "Specifying axis_name enables collectives like jax.lax.pmean or psum. Without it, collectives cannot be used within the pmapped function, limiting parallelism.",
    "tags": [
      "pmap",
      "collective",
      "axis_name"
    ]
  },
  {
    "id": "jax-011",
    "pattern": "^jax\\.jit\\s*\\(.*device\\s*=\\s*None",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Set device argument to pin computation to a specific device.",
    "detail": "By default, jax.jit places computation on the default device. Explicitly setting device ensures predictable placement, especially in multi-device environments.",
    "tags": [
      "jit",
      "device",
      "placement"
    ]
  },
  {
    "id": "jax-012",
    "pattern": "^jax\\.pmap\\s*\\(.*in_axes\\s*=\\s*None",
    "cmd": "jax.pmap",
    "severity": "warn",
    "hint": "Set in_axes to control which arguments are mapped in pmap.",
    "detail": "If in_axes is None, all arguments are broadcasted, not mapped. This can lead to silent performance issues or shape mismatches if you expect vectorized mapping.",
    "tags": [
      "pmap",
      "in_axes",
      "broadcast"
    ]
  },
  {
    "id": "jax-013",
    "pattern": "^jax\\.grad\\s*\\(.*argnums\\s*=\\s*None",
    "cmd": "jax.grad",
    "severity": "tip",
    "hint": "Use argnums to differentiate with respect to multiple arguments.",
    "detail": "The argnums parameter allows you to compute gradients with respect to multiple arguments. This is essential for functions with more than one input parameter.",
    "tags": [
      "grad",
      "argnums",
      "autodiff"
    ]
  },
  {
    "id": "jax-014",
    "pattern": "^jax\\.jit\\s*\\(.*backend\\s*=\\s*['\"]cpu['\"]",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Set backend to 'gpu' or 'tpu' for hardware acceleration.",
    "detail": "Specifying backend='cpu' disables hardware acceleration. For best performance, use backend='gpu' or 'tpu' if available, as JAX will otherwise default to CPU.",
    "tags": [
      "jit",
      "backend",
      "performance"
    ]
  },
  {
    "id": "jax-015",
    "pattern": "^jax\\.vmap\\s*\\(.*out_axes\\s*=\\s*None",
    "cmd": "jax.vmap",
    "severity": "tip",
    "hint": "Set out_axes to control output batching in vmap.",
    "detail": "The out_axes parameter determines which outputs are batched. If not set, outputs may be squeezed or have unexpected shapes, leading to subtle bugs.",
    "tags": [
      "vmap",
      "out_axes",
      "batching"
    ]
  },
  {
    "id": "jax-016",
    "pattern": "^jax\\.jit\\s*\\(.*inline\\s*=\\s*True",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Use inline=True to reduce call overhead for small functions.",
    "detail": "Setting inline=True hints to XLA that the function should be inlined, which can reduce call overhead for small, frequently called functions. This is especially useful in tight loops.",
    "tags": [
      "jit",
      "inline",
      "performance"
    ]
  },
  {
    "id": "jax-017",
    "pattern": "^jax\\.jit\\s*\\(.*static_argnums\\s*=\\s*None",
    "cmd": "jax.jit",
    "severity": "warn",
    "hint": "Use static_argnums for non-array arguments to avoid recompilation.",
    "detail": "If non-array arguments are not marked as static, jax.jit will recompile for every new value, causing performance issues and memory bloat.",
    "tags": [
      "jit",
      "static_argnums",
      "compilation"
    ]
  },
  {
    "id": "jax-018",
    "pattern": "^jax\\.random\\.PRNGKey\\(0\\)",
    "cmd": "jax.random.PRNGKey",
    "severity": "warn",
    "hint": "Avoid using a fixed PRNG seed in production.",
    "detail": "Using a fixed seed like 0 can lead to reproducibility but also to predictable outputs and potential security issues. For production, use a dynamic or secure seed.",
    "tags": [
      "random",
      "prng",
      "security"
    ]
  },
  {
    "id": "jax-019",
    "pattern": "^flax\\.linen\\.Module\\..*init\\(",
    "cmd": "flax.linen.Module.init",
    "severity": "warn",
    "hint": "Always pass rngs argument to Flax init for stochastic layers.",
    "detail": "Failing to provide rngs in init will cause stochastic layers like dropout to behave deterministically, potentially harming model generalization.",
    "tags": [
      "flax",
      "init",
      "rngs"
    ]
  },
  {
    "id": "jax-020",
    "pattern": "^flax\\.optim\\.",
    "cmd": "flax.optim",
    "severity": "upgrade",
    "hint": "Switch to Optax for modern, composable optimizers.",
    "detail": "Flax.optim is deprecated in favor of Optax, which provides a more flexible and composable API for gradient transformations and optimizer state management.",
    "tags": [
      "flax",
      "optax",
      "upgrade"
    ]
  },
  {
    "id": "jax-021",
    "pattern": "^optax\\.adam\\(",
    "cmd": "optax.adam",
    "severity": "tip",
    "hint": "Set eps parameter in optax.adam for numerical stability.",
    "detail": "The eps parameter prevents division by zero in Adam optimizer. Tuning it can improve stability, especially in mixed-precision or small-batch scenarios.",
    "tags": [
      "optax",
      "adam",
      "numerical"
    ]
  },
  {
    "id": "jax-022",
    "pattern": "^jax\\.config\\.update\\(['\"]jax_enable_x64['\"]\\s*,\\s*True\\)",
    "cmd": "jax.config.update",
    "severity": "tip",
    "hint": "Enable jax_enable_x64 only if you need double precision.",
    "detail": "Enabling 64-bit mode increases memory usage and can reduce performance. Only use it if your model requires double precision for numerical reasons.",
    "tags": [
      "config",
      "x64",
      "precision"
    ]
  },
  {
    "id": "jax-023",
    "pattern": "^jax\\.pmap\\s*\\(.*donate_argnums\\s*=\\s*None",
    "cmd": "jax.pmap",
    "severity": "tip",
    "hint": "Use donate_argnums to reduce memory pressure in pmap.",
    "detail": "Setting donate_argnums allows JAX to reuse input buffers across devices, reducing memory usage and improving performance in parallel execution.",
    "tags": [
      "pmap",
      "memory",
      "donate_argnums"
    ]
  },
  {
    "id": "jax-024",
    "pattern": "^jax\\.jit\\s*\\(.*cache\\s*=\\s*False",
    "cmd": "jax.jit",
    "severity": "warn",
    "hint": "Disabling cache in jax.jit can cause repeated recompilation.",
    "detail": "Setting cache=False disables function compilation caching, which can lead to repeated, expensive recompilations and degrade performance.",
    "tags": [
      "jit",
      "cache",
      "compilation"
    ]
  },
  {
    "id": "jax-025",
    "pattern": "^jax\\.pmap\\s*\\(.*static_broadcasted_argnums\\s*=\\s*None",
    "cmd": "jax.pmap",
    "severity": "tip",
    "hint": "Use static_broadcasted_argnums for non-mapped arguments in pmap.",
    "detail": "Arguments specified in static_broadcasted_argnums are broadcasted across all devices and treated as static, reducing unnecessary recompilation.",
    "tags": [
      "pmap",
      "static_broadcasted_argnums",
      "performance"
    ]
  },
  {
    "id": "jax-026",
    "pattern": "^jax\\.lax\\.pmean\\(",
    "cmd": "jax.lax.pmean",
    "severity": "warn",
    "hint": "pmean requires axis_name to match pmap's axis_name.",
    "detail": "If axis_name does not match the one used in pmap, pmean will silently fail or raise errors. Always ensure axis_name consistency for collective ops.",
    "tags": [
      "lax",
      "pmean",
      "collective"
    ]
  },
  {
    "id": "jax-027",
    "pattern": "^jax\\.device_put\\(",
    "cmd": "jax.device_put",
    "severity": "tip",
    "hint": "Use device_put to explicitly transfer data to a specific device.",
    "detail": "Explicitly transferring data with device_put can reduce host-device transfer overhead and ensure data locality, especially in multi-device setups.",
    "tags": [
      "device",
      "transfer",
      "performance"
    ]
  },
  {
    "id": "jax-028",
    "pattern": "^jax\\.local_devices\\(",
    "cmd": "jax.local_devices",
    "severity": "tip",
    "hint": "Use local_devices to inspect available hardware before mapping.",
    "detail": "jax.local_devices() returns a list of devices available to the current process. Use it to verify device count and types before running pmap or device-specific code.",
    "tags": [
      "devices",
      "inspection",
      "mapping"
    ]
  },
  {
    "id": "jax-029",
    "pattern": "^jax\\.tree_util\\.tree_map\\(",
    "cmd": "jax.tree_util.tree_map",
    "severity": "tip",
    "hint": "Use tree_map for parameter transformations in PyTree structures.",
    "detail": "tree_map applies a function to each leaf in a PyTree, enabling efficient parameter updates or transformations across nested structures.",
    "tags": [
      "tree_util",
      "pytree",
      "transformation"
    ]
  },
  {
    "id": "jax-030",
    "pattern": "^haiku\\.",
    "cmd": "haiku",
    "severity": "tip",
    "hint": "Haiku requires explicit state management via transform_with_state.",
    "detail": "Unlike Flax, Haiku separates pure functions and stateful operations. Use hk.transform_with_state for models with batchnorm or other stateful layers.",
    "tags": [
      "haiku",
      "state",
      "transform_with_state"
    ]
  },
  {
    "id": "jax-031",
    "pattern": "^orbax\\.",
    "cmd": "orbax",
    "severity": "tip",
    "hint": "Use Orbax for checkpointing with sharded and streaming support.",
    "detail": "Orbax provides efficient checkpointing for large models, supporting sharded and streaming checkpoints, which is crucial for distributed training and recovery.",
    "tags": [
      "orbax",
      "checkpoint",
      "distributed"
    ]
  },
  {
    "id": "jax-032",
    "pattern": "^jax\\.experimental\\.maps\\.",
    "cmd": "jax.experimental.maps",
    "severity": "upgrade",
    "hint": "Switch to jax.sharding and device mesh APIs for new projects.",
    "detail": "The experimental.maps API is deprecated. Use jax.sharding and device mesh primitives for more robust and flexible parallelism.",
    "tags": [
      "maps",
      "sharding",
      "upgrade"
    ]
  },
  {
    "id": "jax-033",
    "pattern": "^jax\\.sharding\\.",
    "cmd": "jax.sharding",
    "severity": "tip",
    "hint": "Use jax.sharding for explicit data and computation partitioning.",
    "detail": "jax.sharding enables fine-grained control over how data and computation are partitioned across devices, improving scalability and performance in distributed setups.",
    "tags": [
      "sharding",
      "partitioning",
      "performance"
    ]
  },
  {
    "id": "jax-034",
    "pattern": "^jax\\.make_jaxpr\\(",
    "cmd": "jax.make_jaxpr",
    "severity": "tip",
    "hint": "Use make_jaxpr to debug and inspect JAX program traces.",
    "detail": "make_jaxpr outputs the intermediate representation of a JAX function, helping identify unnecessary recompilations, data movement, or unexpected traces.",
    "tags": [
      "debug",
      "make_jaxpr",
      "trace"
    ]
  },
  {
    "id": "jax-035",
    "pattern": "^jax\\.disable_jit\\(",
    "cmd": "jax.disable_jit",
    "severity": "tip",
    "hint": "Temporarily disable JIT for debugging with disable_jit context.",
    "detail": "Disabling JIT allows step-by-step debugging and easier error tracing, but should not be used in production due to severe performance penalties.",
    "tags": [
      "debug",
      "jit",
      "disable"
    ]
  },
  {
    "id": "jax-036",
    "pattern": "^jax\\.grad\\s*\\(.*allow_int\\s*=\\s*True",
    "cmd": "jax.grad",
    "severity": "warn",
    "hint": "Gradients of integer-valued functions are zero; avoid allow_int=True.",
    "detail": "Setting allow_int=True allows gradients with respect to integer inputs, but these gradients are always zero, which can silently mask bugs in your code.",
    "tags": [
      "grad",
      "integer",
      "autodiff"
    ]
  },
  {
    "id": "jax-037",
    "pattern": "^jax\\.jit\\s*\\(.*static_argnums\\s*=\\s*0",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Use static_argnums=0 for functions with static first argument.",
    "detail": "Marking the first argument as static ensures that jax.jit does not recompile when it changes, which is important for functions with configuration or mode flags as the first parameter.",
    "tags": [
      "jit",
      "static_argnums",
      "performance"
    ]
  },
  {
    "id": "jax-038",
    "pattern": "^jax\\.jit\\s*\\(.*donate_argnums\\s*=\\s*0",
    "cmd": "jax.jit",
    "severity": "tip",
    "hint": "Set donate_argnums=0 to donate first argument's memory buffer.",
    "detail": "Donating the first argument's buffer can reduce memory usage and speed up computation, especially for large arrays processed in-place.",
    "tags": [
      "jit",
      "donate_argnums",
      "memory"
    ]
  },
  {
    "id": "jax-039",
    "pattern": "^jax\\.pmap\\s*\\(.*axis_size\\s*=\\s*None",
    "cmd": "jax.pmap",
    "severity": "warn",
    "hint": "Set axis_size to match number of devices for correct mapping.",
    "detail": "If axis_size is not set or mismatched, pmap may silently drop data or fail to map across all devices, leading to incorrect parallelism.",
    "tags": [
      "pmap",
      "axis_size",
      "devices"
    ]
  },
  {
    "id": "jax-040",
    "pattern": "^jax\\.jit\\s*\\(.*backend\\s*=\\s*['\"]tpu['\"]",
    "cmd": "jax.jit",
    "severity": "warn",
    "hint": "Ensure TPU runtime is available before setting backend='tpu'.",
    "detail": "Specifying backend='tpu' without a TPU runtime will cause runtime errors. Always check jax.devices() to confirm TPU availability before setting this flag.",
    "tags": [
      "jit",
      "backend",
      "tpu"
    ]
  },
  {
    "id": "huggingface-001",
    "pattern": "^transformers\\s+cli\\s+convert\\s+.*--to-pytorch",
    "cmd": "transformers",
    "severity": "warn",
    "hint": "Always verify model output after --to-pytorch conversion.",
    "detail": "The --to-pytorch flag can silently fail if the source model is not fully compatible. Output weights or architecture mismatches may not raise errors but can cause inference issues. Always validate the converted model on sample data.",
    "tags": [
      "transformers",
      "conversion",
      "compatibility"
    ]
  },
  {
    "id": "huggingface-002",
    "pattern": "^transformers\\s+cli\\s+convert\\s+.*--fp16",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Use --fp16 for faster inference, but check for accuracy drops.",
    "detail": "The --fp16 flag enables half-precision weights, improving speed and reducing memory. However, some models may lose accuracy or become unstable. Always benchmark both performance and output quality after conversion.",
    "tags": [
      "transformers",
      "performance",
      "precision"
    ]
  },
  {
    "id": "huggingface-003",
    "pattern": "^transformers\\s+cli\\s+env",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Run transformers cli env to debug CUDA and dependency issues.",
    "detail": "The cli env command prints detailed environment diagnostics, including CUDA, PyTorch, and library versions. This is invaluable for troubleshooting runtime errors or version mismatches, especially in multi-GPU or containerized setups.",
    "tags": [
      "transformers",
      "debugging",
      "environment"
    ]
  },
  {
    "id": "huggingface-004",
    "pattern": "^transformers\\s+train\\s+.*--fp16",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Enable --fp16 for faster training on supported GPUs.",
    "detail": "Using --fp16 leverages mixed-precision training, reducing memory usage and increasing throughput on modern NVIDIA GPUs. However, not all models or hardware support it; always check for NaN losses or instability.",
    "tags": [
      "transformers",
      "training",
      "performance"
    ]
  },
  {
    "id": "huggingface-005",
    "pattern": "^transformers\\s+train\\s+.*--gradient-accumulation-steps\\s+1",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Increase --gradient-accumulation-steps to fit larger batches.",
    "detail": "Setting gradient accumulation allows effective larger batch sizes without exceeding GPU memory. This can improve convergence and stability, especially on memory-constrained hardware.",
    "tags": [
      "transformers",
      "training",
      "batching"
    ]
  },
  {
    "id": "huggingface-006",
    "pattern": "^transformers\\s+train\\s+.*--overwrite-output-dir",
    "cmd": "transformers",
    "severity": "danger",
    "hint": "Beware: --overwrite-output-dir deletes previous checkpoints.",
    "detail": "Using --overwrite-output-dir will remove existing model outputs and checkpoints in the specified directory. Always back up important results before rerunning with this flag, as recovery is not possible.",
    "tags": [
      "transformers",
      "training",
      "data-loss"
    ]
  },
  {
    "id": "huggingface-007",
    "pattern": "^datasets\\s+load_dataset\\s+.*--cache-dir\\s+.+",
    "cmd": "datasets",
    "severity": "tip",
    "hint": "Set --cache-dir to share datasets across projects.",
    "detail": "Specifying --cache-dir allows multiple projects or users to reuse downloaded datasets, saving bandwidth and disk space. Ensure the directory has appropriate permissions for all users.",
    "tags": [
      "datasets",
      "caching",
      "performance"
    ]
  },
  {
    "id": "huggingface-008",
    "pattern": "^datasets\\s+load_dataset\\s+.*--keep-in-memory",
    "cmd": "datasets",
    "severity": "tip",
    "hint": "Use --keep-in-memory for small datasets to speed up access.",
    "detail": "The --keep-in-memory flag loads the entire dataset into RAM, reducing disk I/O. This is effective for small datasets but can cause OOM errors if the dataset is too large for available memory.",
    "tags": [
      "datasets",
      "performance",
      "memory"
    ]
  },
  {
    "id": "huggingface-009",
    "pattern": "^datasets\\s+load_dataset\\s+.*--download-mode\\s+force_redownload",
    "cmd": "datasets",
    "severity": "warn",
    "hint": "force_redownload ignores cache and may waste bandwidth.",
    "detail": "The force_redownload option re-downloads all files, ignoring any existing cache. Use it only when necessary, as it can be slow and may trigger API rate limits or incur costs on cloud storage.",
    "tags": [
      "datasets",
      "caching",
      "network"
    ]
  },
  {
    "id": "huggingface-010",
    "pattern": "^datasets\\s+load_dataset\\s+.*--split\\s+train\\s+.*--split\\s+test",
    "cmd": "datasets",
    "severity": "warn",
    "hint": "Multiple --split flags may silently override previous splits.",
    "detail": "Specifying --split multiple times can cause only the last value to be used, leading to unexpected dataset contents. Always check the resulting dataset object for the correct splits.",
    "tags": [
      "datasets",
      "splits",
      "footgun"
    ]
  },
  {
    "id": "huggingface-011",
    "pattern": "^accelerate\\s+launch\\s+.*--multi_gpu",
    "cmd": "accelerate",
    "severity": "tip",
    "hint": "Use --multi_gpu for distributed training; check CUDA_VISIBLE_DEVICES.",
    "detail": "The --multi_gpu flag enables distributed training across GPUs. Ensure CUDA_VISIBLE_DEVICES is set correctly, or Accelerate may use unintended devices or fail to initialize.",
    "tags": [
      "accelerate",
      "distributed",
      "gpu"
    ]
  },
  {
    "id": "huggingface-012",
    "pattern": "^accelerate\\s+launch\\s+.*--num_processes\\s+\\d+",
    "cmd": "accelerate",
    "severity": "tip",
    "hint": "Set --num_processes to match available GPUs for best throughput.",
    "detail": "Matching --num_processes to the number of GPUs maximizes parallelism. Setting it too high can cause resource contention and degraded performance.",
    "tags": [
      "accelerate",
      "performance",
      "gpu"
    ]
  },
  {
    "id": "huggingface-013",
    "pattern": "^accelerate\\s+config",
    "cmd": "accelerate",
    "severity": "tip",
    "hint": "Run accelerate config to set up distributed environment interactively.",
    "detail": "The config command generates a configuration file for distributed and mixed-precision training. This avoids common misconfigurations and ensures optimal settings for your hardware.",
    "tags": [
      "accelerate",
      "configuration",
      "distributed"
    ]
  },
  {
    "id": "huggingface-014",
    "pattern": "^accelerate\\s+launch\\s+.*--mixed_precision\\s+bf16",
    "cmd": "accelerate",
    "severity": "tip",
    "hint": "Use --mixed_precision bf16 on Ampere GPUs for better performance.",
    "detail": "bfloat16 (bf16) is supported natively on NVIDIA Ampere and newer GPUs, offering faster training and reduced memory usage compared to fp32, with minimal accuracy loss. Not all hardware supports bf16.",
    "tags": [
      "accelerate",
      "precision",
      "gpu"
    ]
  },
  {
    "id": "huggingface-015",
    "pattern": "^peft\\s+train\\s+.*--lora-r\\s+\\d+",
    "cmd": "peft",
    "severity": "tip",
    "hint": "Tune --lora-r for LoRA adaptation rank; higher is more expressive.",
    "detail": "The --lora-r flag controls the rank of the LoRA adaptation matrices. Higher values increase model capacity but also memory and compute requirements. Experiment to balance performance and resource usage.",
    "tags": [
      "peft",
      "lora",
      "training"
    ]
  },
  {
    "id": "huggingface-016",
    "pattern": "^peft\\s+train\\s+.*--lora-alpha\\s+\\d+",
    "cmd": "peft",
    "severity": "tip",
    "hint": "Adjust --lora-alpha to control adaptation scaling.",
    "detail": "The --lora-alpha parameter scales the LoRA updates. Too high can destabilize training; too low may limit adaptation. Refer to LoRA paper recommendations for typical values.",
    "tags": [
      "peft",
      "lora",
      "training"
    ]
  },
  {
    "id": "huggingface-017",
    "pattern": "^peft\\s+train\\s+.*--resume_from_checkpoint",
    "cmd": "peft",
    "severity": "warn",
    "hint": "Check checkpoint compatibility before resuming training.",
    "detail": "Resuming from a checkpoint with mismatched model or optimizer states can cause silent failures or degraded performance. Always ensure the checkpoint matches the current training configuration.",
    "tags": [
      "peft",
      "checkpoint",
      "training"
    ]
  },
  {
    "id": "huggingface-018",
    "pattern": "^trl\\s+train\\s+.*--reward-model\\s+.+",
    "cmd": "trl",
    "severity": "warn",
    "hint": "Reward model must match architecture and tokenizer.",
    "detail": "Using a reward model with a different architecture or tokenizer than the main model can cause silent misalignment and poor RLHF results. Always verify compatibility before training.",
    "tags": [
      "trl",
      "rlhf",
      "reward-model"
    ]
  },
  {
    "id": "huggingface-019",
    "pattern": "^trl\\s+train\\s+.*--batch-size\\s+\\d+",
    "cmd": "trl",
    "severity": "tip",
    "hint": "Increase --batch-size for more stable RLHF updates.",
    "detail": "Larger batch sizes help stabilize policy gradients in RLHF. However, memory constraints may require gradient accumulation or smaller models.",
    "tags": [
      "trl",
      "rlhf",
      "training"
    ]
  },
  {
    "id": "huggingface-020",
    "pattern": "^trl\\s+train\\s+.*--save-every\\s+\\d+",
    "cmd": "trl",
    "severity": "tip",
    "hint": "Set --save-every to avoid losing progress in long RLHF runs.",
    "detail": "Frequent checkpointing protects against hardware failures or preemptions. However, too frequent saves may slow training due to I/O overhead.",
    "tags": [
      "trl",
      "checkpoint",
      "training"
    ]
  },
  {
    "id": "huggingface-021",
    "pattern": "^diffusers\\s+train\\s+.*--mixed_precision\\s+fp16",
    "cmd": "diffusers",
    "severity": "tip",
    "hint": "Enable --mixed_precision fp16 for faster diffusion model training.",
    "detail": "Mixed-precision training reduces memory usage and speeds up training on compatible GPUs. Monitor for NaN losses, which may indicate instability.",
    "tags": [
      "diffusers",
      "training",
      "performance"
    ]
  },
  {
    "id": "huggingface-022",
    "pattern": "^diffusers\\s+train\\s+.*--gradient_checkpointing",
    "cmd": "diffusers",
    "severity": "tip",
    "hint": "Use --gradient_checkpointing to train larger models on limited GPUs.",
    "detail": "Gradient checkpointing trades compute for memory, allowing training of larger models at the cost of slower backward passes. Useful for diffusion models with high memory requirements.",
    "tags": [
      "diffusers",
      "training",
      "memory"
    ]
  },
  {
    "id": "huggingface-023",
    "pattern": "^diffusers\\s+train\\s+.*--resume_from_checkpoint",
    "cmd": "diffusers",
    "severity": "warn",
    "hint": "Always match model configs when resuming from checkpoint.",
    "detail": "Mismatched model or optimizer configs can cause subtle bugs or degraded performance when resuming. Always check that the checkpoint matches the current training setup.",
    "tags": [
      "diffusers",
      "checkpoint",
      "training"
    ]
  },
  {
    "id": "huggingface-024",
    "pattern": "^tokenizers\\s+train\\s+.*--vocab-size\\s+\\d+",
    "cmd": "tokenizers",
    "severity": "tip",
    "hint": "Set --vocab-size based on dataset size and language complexity.",
    "detail": "Too small a vocab size increases OOV tokens; too large wastes memory and slows inference. Use corpus statistics to guide selection.",
    "tags": [
      "tokenizers",
      "training",
      "vocab"
    ]
  },
  {
    "id": "huggingface-025",
    "pattern": "^tokenizers\\s+train\\s+.*--min-frequency\\s+\\d+",
    "cmd": "tokenizers",
    "severity": "tip",
    "hint": "Increase --min-frequency to filter rare noisy tokens.",
    "detail": "Setting a higher minimum frequency helps exclude typos and rare artifacts, improving tokenizer quality and reducing vocab size.",
    "tags": [
      "tokenizers",
      "training",
      "vocab"
    ]
  },
  {
    "id": "huggingface-026",
    "pattern": "^tokenizers\\s+train\\s+.*--limit-alphabet\\s+\\d+",
    "cmd": "tokenizers",
    "severity": "tip",
    "hint": "Limit alphabet size for more compact tokenizers.",
    "detail": "Restricting the alphabet can improve generalization and reduce model size, but may hurt coverage for diverse languages or domains.",
    "tags": [
      "tokenizers",
      "training",
      "vocab"
    ]
  },
  {
    "id": "huggingface-027",
    "pattern": "^tokenizers\\s+train\\s+.*--unk-token\\s+.+",
    "cmd": "tokenizers",
    "severity": "warn",
    "hint": "Ensure --unk-token matches model's expected unknown token.",
    "detail": "Using a different unknown token than the model expects can cause silent decoding errors or misalignment between tokenizer and model.",
    "tags": [
      "tokenizers",
      "vocab",
      "compatibility"
    ]
  },
  {
    "id": "huggingface-028",
    "pattern": "^evaluate\\s+load\\s+.*--config-name\\s+.+",
    "cmd": "evaluate",
    "severity": "warn",
    "hint": "Config name must match available metric configs.",
    "detail": "Specifying a non-existent config name will cause evaluate to silently fall back or error. Always check available configs for the metric.",
    "tags": [
      "evaluate",
      "metrics",
      "config"
    ]
  },
  {
    "id": "huggingface-029",
    "pattern": "^evaluate\\s+load\\s+.*--cache-dir\\s+.+",
    "cmd": "evaluate",
    "severity": "tip",
    "hint": "Set --cache-dir to reuse downloaded metrics and speed up evaluation.",
    "detail": "Caching avoids repeated downloads and speeds up metric loading, especially in CI or shared environments.",
    "tags": [
      "evaluate",
      "performance",
      "caching"
    ]
  },
  {
    "id": "huggingface-030",
    "pattern": "^evaluate\\s+load\\s+.*--experiment_id\\s+.+",
    "cmd": "evaluate",
    "severity": "tip",
    "hint": "Use --experiment_id to track and compare evaluation runs.",
    "detail": "Assigning a unique experiment ID helps organize results and enables reproducibility, especially in collaborative projects.",
    "tags": [
      "evaluate",
      "tracking",
      "reproducibility"
    ]
  },
  {
    "id": "huggingface-031",
    "pattern": "^huggingface-cli\\s+login\\s+.*--token\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "warn",
    "hint": "Never share your access token; treat it as a secret.",
    "detail": "Tokens grant full access to your HuggingFace account and private models. Exposing them in logs or scripts is a security risk.",
    "tags": [
      "hub",
      "security",
      "auth"
    ]
  },
  {
    "id": "huggingface-032",
    "pattern": "^huggingface-cli\\s+repo\\s+create\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "tip",
    "hint": "Use --private to restrict repo visibility on the Hub.",
    "detail": "By default, new repos are public. Use the --private flag to keep models or datasets confidential until ready for release.",
    "tags": [
      "hub",
      "privacy",
      "repos"
    ]
  },
  {
    "id": "huggingface-033",
    "pattern": "^huggingface-cli\\s+repo\\s+delete\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "danger",
    "hint": "Deleting a repo is irreversible; backup before proceeding.",
    "detail": "Repo deletion permanently removes all files, models, and history from the Hub. There is no undo. Always confirm you have backups.",
    "tags": [
      "hub",
      "data-loss",
      "repos"
    ]
  },
  {
    "id": "huggingface-034",
    "pattern": "^huggingface-cli\\s+repo\\s+clone\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "tip",
    "hint": "Use --branch to clone a specific branch from the Hub.",
    "detail": "Cloning a specific branch can save bandwidth and disk space, and is useful for working with experimental or staging versions.",
    "tags": [
      "hub",
      "repos",
      "git"
    ]
  },
  {
    "id": "huggingface-035",
    "pattern": "^huggingface-cli\\s+repo\\s+ls\\s+.*--all",
    "cmd": "huggingface-cli",
    "severity": "tip",
    "hint": "List all repos, including private, with --all.",
    "detail": "The --all flag shows both public and private repositories, which is useful for auditing or managing access.",
    "tags": [
      "hub",
      "repos",
      "listing"
    ]
  },
  {
    "id": "huggingface-036",
    "pattern": "^huggingface-cli\\s+upload\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "warn",
    "hint": "Uploading large files may hit Hub size limits or fail silently.",
    "detail": "The Hub enforces file and repo size limits. Large uploads may fail without clear errors. Use git-lfs for files over 10MB, and check Hub documentation for quotas.",
    "tags": [
      "hub",
      "upload",
      "limits"
    ]
  },
  {
    "id": "huggingface-037",
    "pattern": "^huggingface-cli\\s+upload\\s+.+--commit-message\\s+.+",
    "cmd": "huggingface-cli",
    "severity": "tip",
    "hint": "Use descriptive commit messages for better model versioning.",
    "detail": "Clear commit messages help track changes and facilitate collaboration, especially in multi-user or production environments.",
    "tags": [
      "hub",
      "upload",
      "versioning"
    ]
  },
  {
    "id": "huggingface-038",
    "pattern": "^huggingface-cli\\s+upload\\s+.+--repo-type\\s+dataset",
    "cmd": "huggingface-cli",
    "severity": "tip",
    "hint": "Specify --repo-type dataset to upload to the datasets Hub.",
    "detail": "By default, uploads go to the model Hub. Use --repo-type to target datasets or spaces, ensuring correct categorization.",
    "tags": [
      "hub",
      "datasets",
      "upload"
    ]
  },
  {
    "id": "huggingface-039",
    "pattern": "^optimum\\s+export\\s+onnx\\s+.+",
    "cmd": "optimum",
    "severity": "tip",
    "hint": "Export models to ONNX for hardware-accelerated inference.",
    "detail": "ONNX exports enable deployment on a wide range of hardware, including NVIDIA TensorRT, Intel OpenVINO, and mobile devices. Always validate exported models for accuracy.",
    "tags": [
      "optimum",
      "onnx",
      "deployment"
    ]
  },
  {
    "id": "huggingface-040",
    "pattern": "^optimum\\s+export\\s+onnx\\s+.*--opset\\s+\\d+",
    "cmd": "optimum",
    "severity": "tip",
    "hint": "Set --opset to match target runtime compatibility.",
    "detail": "Different ONNX runtimes support different opset versions. Using a mismatched opset may cause runtime errors or unsupported operations.",
    "tags": [
      "optimum",
      "onnx",
      "compatibility"
    ]
  },
  {
    "id": "huggingface-041",
    "pattern": "^optimum\\s+export\\s+onnx\\s+.*--fp16",
    "cmd": "optimum",
    "severity": "tip",
    "hint": "Use --fp16 for reduced model size and faster inference.",
    "detail": "Exporting in fp16 reduces memory and can accelerate inference on compatible hardware. Always test for accuracy regression after conversion.",
    "tags": [
      "optimum",
      "onnx",
      "performance"
    ]
  },
  {
    "id": "huggingface-042",
    "pattern": "^optimum\\s+export\\s+onnx\\s+.*--atol\\s+.+",
    "cmd": "optimum",
    "severity": "tip",
    "hint": "Set --atol to control ONNX export accuracy tolerance.",
    "detail": "The --atol flag sets the acceptable absolute error between PyTorch and ONNX outputs. Lower values ensure higher fidelity but may cause export to fail if numerical differences are large.",
    "tags": [
      "optimum",
      "onnx",
      "accuracy"
    ]
  },
  {
    "id": "huggingface-043",
    "pattern": "^text-generation-inference\\s+.*--max-batch-prefill-tokens\\s+\\d+",
    "cmd": "text-generation-inference",
    "severity": "tip",
    "hint": "Increase --max-batch-prefill-tokens for higher throughput.",
    "detail": "Raising this limit allows larger batches during prefill, improving GPU utilization and serving speed. Ensure your hardware has enough memory to handle the increased load.",
    "tags": [
      "tgi",
      "serving",
      "performance"
    ]
  },
  {
    "id": "huggingface-044",
    "pattern": "^text-generation-inference\\s+.*--max-input-length\\s+\\d+",
    "cmd": "text-generation-inference",
    "severity": "warn",
    "hint": "Setting --max-input-length too high may cause OOM errors.",
    "detail": "Longer input sequences consume more memory and may exceed GPU capacity, leading to crashes or degraded performance. Monitor memory usage and adjust accordingly.",
    "tags": [
      "tgi",
      "serving",
      "memory"
    ]
  },
  {
    "id": "huggingface-045",
    "pattern": "^text-generation-inference\\s+.*--max-total-tokens\\s+\\d+",
    "cmd": "text-generation-inference",
    "severity": "tip",
    "hint": "Tune --max-total-tokens for optimal batching and latency.",
    "detail": "This flag controls the total number of tokens processed per batch. Balancing it can improve throughput without increasing latency for individual requests.",
    "tags": [
      "tgi",
      "serving",
      "performance"
    ]
  },
  {
    "id": "huggingface-046",
    "pattern": "^text-generation-inference\\s+.*--sharded",
    "cmd": "text-generation-inference",
    "severity": "tip",
    "hint": "Enable --sharded to serve large models across multiple GPUs.",
    "detail": "Sharding splits the model across devices, allowing inference on models that exceed a single GPU's memory. Ensure all GPUs are identical and connected for best results.",
    "tags": [
      "tgi",
      "serving",
      "gpu"
    ]
  },
  {
    "id": "huggingface-047",
    "pattern": "^text-generation-inference\\s+.*--trust-remote-code",
    "cmd": "text-generation-inference",
    "severity": "danger",
    "hint": "Only use --trust-remote-code with trusted model sources.",
    "detail": "This flag executes arbitrary code from remote repositories, which can be a security risk. Only enable it for models from verified sources.",
    "tags": [
      "tgi",
      "security",
      "remote-code"
    ]
  },
  {
    "id": "huggingface-048",
    "pattern": "^transformers\\s+train\\s+.*--deepspeed\\s+.+",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Use --deepspeed for large-scale distributed training.",
    "detail": "DeepSpeed integration enables efficient memory usage and scaling to many GPUs. Requires a valid deepspeed config file and compatible hardware.",
    "tags": [
      "transformers",
      "deepspeed",
      "distributed"
    ]
  },
  {
    "id": "huggingface-049",
    "pattern": "^transformers\\s+train\\s+.*--dataloader-num-workers\\s+0",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Increase --dataloader-num-workers for faster data loading.",
    "detail": "Setting this flag above 0 enables parallel data loading, reducing training bottlenecks. Tune based on CPU core count and dataset size.",
    "tags": [
      "transformers",
      "training",
      "performance"
    ]
  },
  {
    "id": "huggingface-050",
    "pattern": "^transformers\\s+train\\s+.*--logging-strategy\\s+steps",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Set --logging-steps to control logging frequency with steps strategy.",
    "detail": "Logging too frequently can slow down training and flood logs. Adjust --logging-steps to balance visibility and performance.",
    "tags": [
      "transformers",
      "training",
      "logging"
    ]
  },
  {
    "id": "huggingface-051",
    "pattern": "^datasets\\s+load_dataset\\s+.*--verification_mode\\s+no_checks",
    "cmd": "datasets",
    "severity": "warn",
    "hint": "Disabling verification may allow corrupted or incomplete downloads.",
    "detail": "Verification ensures data integrity. Skipping it can lead to silent data corruption, especially with large or remote datasets.",
    "tags": [
      "datasets",
      "integrity",
      "downloads"
    ]
  },
  {
    "id": "huggingface-052",
    "pattern": "^datasets\\s+load_dataset\\s+.*--use_auth_token\\s+.+",
    "cmd": "datasets",
    "severity": "warn",
    "hint": "Never expose your auth token in shared scripts or logs.",
    "detail": "Auth tokens provide access to private datasets and models. Treat them as secrets and avoid hardcoding in public repositories.",
    "tags": [
      "datasets",
      "security",
      "auth"
    ]
  },
  {
    "id": "huggingface-053",
    "pattern": "^datasets\\s+load_dataset\\s+.*--revision\\s+.+",
    "cmd": "datasets",
    "severity": "tip",
    "hint": "Use --revision to load specific dataset versions or branches.",
    "detail": "Specifying a revision (commit hash, tag, or branch) ensures reproducibility and avoids breaking changes from upstream updates.",
    "tags": [
      "datasets",
      "versioning",
      "reproducibility"
    ]
  },
  {
    "id": "huggingface-054",
    "pattern": "^transformers\\s+train\\s+.*--report_to\\s+none",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Disable reporting to external services with --report_to none.",
    "detail": "This prevents accidental logging to services like WandB or TensorBoard, which may be required in secure or offline environments.",
    "tags": [
      "transformers",
      "privacy",
      "logging"
    ]
  },
  {
    "id": "huggingface-055",
    "pattern": "^transformers\\s+train\\s+.*--save_total_limit\\s+\\d+",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Set --save_total_limit to control checkpoint disk usage.",
    "detail": "Limiting the number of saved checkpoints prevents disk exhaustion during long runs. Oldest checkpoints are deleted automatically.",
    "tags": [
      "transformers",
      "training",
      "checkpoint"
    ]
  },
  {
    "id": "huggingface-056",
    "pattern": "^transformers\\s+train\\s+.*--load_best_model_at_end",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Enable --load_best_model_at_end for automatic model selection.",
    "detail": "This flag loads the checkpoint with the best evaluation metric at the end of training, ensuring optimal model selection for deployment.",
    "tags": [
      "transformers",
      "training",
      "checkpoint"
    ]
  },
  {
    "id": "huggingface-057",
    "pattern": "^transformers\\s+train\\s+.*--per_device_train_batch_size\\s+\\d+",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Tune --per_device_train_batch_size for your GPU memory.",
    "detail": "Batch size impacts memory usage and convergence. Too large causes OOM; too small slows training. Use nvidia-smi to monitor GPU usage.",
    "tags": [
      "transformers",
      "training",
      "batching"
    ]
  },
  {
    "id": "huggingface-058",
    "pattern": "^transformers\\s+train\\s+.*--no_cuda",
    "cmd": "transformers",
    "severity": "warn",
    "hint": "Using --no_cuda disables GPU acceleration.",
    "detail": "This flag forces CPU-only training, which is much slower. Ensure this is intentional, especially on GPU-equipped machines.",
    "tags": [
      "transformers",
      "training",
      "gpu"
    ]
  },
  {
    "id": "huggingface-059",
    "pattern": "^transformers\\s+train\\s+.*--seed\\s+\\d+",
    "cmd": "transformers",
    "severity": "tip",
    "hint": "Set --seed for reproducible training runs.",
    "detail": "Seeding random number generators ensures consistent results across runs, which is critical for debugging and scientific reporting.",
    "tags": [
      "transformers",
      "training",
      "reproducibility"
    ]
  },
  {
    "id": "huggingface-060",
    "pattern": "^transformers\\s+train\\s+.*--fp16\\s+.*--bf16",
    "cmd": "transformers",
    "severity": "warn",
    "hint": "Do not use --fp16 and --bf16 together; pick one precision mode.",
    "detail": "Specifying both flags can cause undefined behavior or runtime errors. Choose the precision mode best suited for your hardware and task.",
    "tags": [
      "transformers",
      "training",
      "precision"
    ]
  },
  {
    "id": "gpu-001",
    "pattern": "^nvidia-smi\\s+-pm\\s+0",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "Disabling persistence mode can cause GPU resets. Use with caution.",
    "detail": "Setting persistence mode off with 'nvidia-smi -pm 0' may cause the GPU to power down between jobs, leading to longer initialization times and potential device resets. This can interrupt running workloads or cause silent failures in multi-user environments.",
    "tags": [
      "nvidia-smi",
      "gpu-management",
      "danger"
    ]
  },
  {
    "id": "gpu-002",
    "pattern": "^nvidia-smi\\s+-rac",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Resetting all compute jobs will kill running GPU processes.",
    "detail": "The '-rac' flag resets all compute jobs on the GPU, forcibly terminating any running processes. This can cause data loss or leave applications in inconsistent states. Use only when you are certain no critical jobs are running.",
    "tags": [
      "nvidia-smi",
      "reset",
      "warn"
    ]
  },
  {
    "id": "gpu-003",
    "pattern": "^CUDA_VISIBLE_DEVICES=\\s*-1",
    "cmd": "CUDA_VISIBLE_DEVICES",
    "severity": "warn",
    "hint": "Setting CUDA_VISIBLE_DEVICES=-1 disables all GPU access.",
    "detail": "Assigning '-1' to CUDA_VISIBLE_DEVICES makes CUDA think no GPUs are present, causing all GPU code to silently fall back to CPU or fail. This is useful for debugging but can lead to confusion if set unintentionally.",
    "tags": [
      "env",
      "cuda",
      "warn"
    ]
  },
  {
    "id": "gpu-004",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-pl\\s+\\d+",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Set GPU power limit with -pl for thermal and energy control.",
    "detail": "The '-pl' flag allows you to set a GPU's power limit in watts, which can help manage thermal output and system stability. Ensure the value is within the allowable range for your GPU, as exceeding limits will result in errors.",
    "tags": [
      "nvidia-smi",
      "power",
      "tip"
    ]
  },
  {
    "id": "gpu-005",
    "pattern": "^nvprof(\\s+|$)",
    "cmd": "nvprof",
    "severity": "upgrade",
    "hint": "nvprof is deprecated. Use Nsight Systems or Nsight Compute.",
    "detail": "NVIDIA has deprecated nvprof in favor of the Nsight suite (nsys, ncu) for profiling. These tools provide more detailed analysis, better visualization, and ongoing support for new CUDA versions.",
    "tags": [
      "nvprof",
      "profiling",
      "upgrade"
    ]
  },
  {
    "id": "gpu-006",
    "pattern": "^cuda-memcheck(\\s+|$)",
    "cmd": "cuda-memcheck",
    "severity": "tip",
    "hint": "Use cuda-memcheck to catch out-of-bounds and memory leaks.",
    "detail": "cuda-memcheck provides runtime memory error detection for CUDA applications, catching out-of-bounds accesses, misaligned memory, and leaks. It can significantly slow execution, so use it for debugging rather than production runs.",
    "tags": [
      "cuda-memcheck",
      "debug",
      "tip"
    ]
  },
  {
    "id": "gpu-007",
    "pattern": "^nvidia-smi\\s+-q",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -q for detailed GPU diagnostics and state reporting.",
    "detail": "The '-q' (query) flag outputs comprehensive information about the GPU, including ECC errors, temperature, memory usage, and driver versions. Useful for troubleshooting hardware or driver issues.",
    "tags": [
      "nvidia-smi",
      "diagnostics",
      "tip"
    ]
  },
  {
    "id": "gpu-008",
    "pattern": "^CUDA_VISIBLE_DEVICES=\\s*([0-9,]+)\\s+python",
    "cmd": "CUDA_VISIBLE_DEVICES",
    "severity": "tip",
    "hint": "Mask GPUs with CUDA_VISIBLE_DEVICES to isolate workloads.",
    "detail": "Setting CUDA_VISIBLE_DEVICES to a comma-separated list masks all other GPUs from the process. This is essential for multi-user systems or when running multiple jobs to avoid contention or accidental resource sharing.",
    "tags": [
      "env",
      "cuda",
      "tip"
    ]
  },
  {
    "id": "gpu-009",
    "pattern": "^nvtop(\\s+|$)",
    "cmd": "nvtop",
    "severity": "tip",
    "hint": "Use nvtop for real-time GPU process and memory monitoring.",
    "detail": "nvtop provides a top-like interface for NVIDIA GPUs, showing per-process GPU utilization, memory, and temperature. It's invaluable for identifying bottlenecks and rogue processes.",
    "tags": [
      "nvtop",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "gpu-010",
    "pattern": "^nvidia-smi\\s+-e\\s+0",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Disabling ECC can cause silent data corruption on supported GPUs.",
    "detail": "ECC (Error Correcting Code) protects against memory bit errors. Disabling it may improve performance slightly but risks undetected data corruption, especially in scientific or financial workloads.",
    "tags": [
      "nvidia-smi",
      "ecc",
      "warn"
    ]
  },
  {
    "id": "gpu-011",
    "pattern": "^nvidia-smi\\s+-L",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -L to list all GPUs and their UUIDs for scripting.",
    "detail": "The '-L' flag lists all detected GPUs with their device numbers and UUIDs. Using UUIDs in scripts is safer than device indices, which can change after reboots or hardware changes.",
    "tags": [
      "nvidia-smi",
      "scripting",
      "tip"
    ]
  },
  {
    "id": "gpu-012",
    "pattern": "^export\\s+CUDA_LAUNCH_BLOCKING=1",
    "cmd": "export",
    "severity": "tip",
    "hint": "Set CUDA_LAUNCH_BLOCKING=1 to debug kernel launch errors.",
    "detail": "Enabling CUDA_LAUNCH_BLOCKING forces synchronous kernel launches, making stack traces more accurate and debugging easier. It will slow down execution, so use only during debugging.",
    "tags": [
      "env",
      "cuda",
      "debug",
      "tip"
    ]
  },
  {
    "id": "gpu-013",
    "pattern": "^nvidia-smi\\s+-f\\s+\\S+",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -f <file> to log GPU stats for later analysis.",
    "detail": "The '-f' flag writes nvidia-smi output to a file, which is useful for long-running jobs or post-mortem analysis. Combine with '-l' for periodic logging.",
    "tags": [
      "nvidia-smi",
      "logging",
      "tip"
    ]
  },
  {
    "id": "gpu-014",
    "pattern": "^nvidia-smi\\s+-l(\\s+\\d+)?",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -l <sec> to monitor GPU stats at intervals.",
    "detail": "The '-l' flag causes nvidia-smi to loop, updating stats every N seconds. This is useful for monitoring GPU usage during training or batch jobs.",
    "tags": [
      "nvidia-smi",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "gpu-015",
    "pattern": "^nvidia-smi\\s+-d\\s+PIDS",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -d PIDS to see which processes are using the GPU.",
    "detail": "The '-d PIDS' option lists all processes currently using GPU resources, including compute and graphics. This helps identify resource contention or rogue jobs.",
    "tags": [
      "nvidia-smi",
      "process",
      "tip"
    ]
  },
  {
    "id": "gpu-016",
    "pattern": "^nvidia-smi\\s+-c\\s+EXCLUSIVE_PROCESS",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "EXCLUSIVE_PROCESS mode restricts GPU to one process at a time.",
    "detail": "Setting compute mode to EXCLUSIVE_PROCESS prevents multiple processes from accessing the GPU simultaneously. This can prevent accidental resource sharing but may block legitimate multi-process workloads.",
    "tags": [
      "nvidia-smi",
      "compute-mode",
      "warn"
    ]
  },
  {
    "id": "gpu-017",
    "pattern": "^nvidia-smi\\s+-gtt\\s+\\d+",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Setting GPU target temperature may cause throttling or shutdown.",
    "detail": "The '-gtt' flag sets the target temperature for the GPU. If set too low, the GPU may throttle performance or shut down to maintain the target, impacting workloads.",
    "tags": [
      "nvidia-smi",
      "temperature",
      "warn"
    ]
  },
  {
    "id": "gpu-018",
    "pattern": "^CUDA_VISIBLE_DEVICES=\\s*\\S*\\s+nvidia-smi",
    "cmd": "CUDA_VISIBLE_DEVICES",
    "severity": "warn",
    "hint": "nvidia-smi ignores CUDA_VISIBLE_DEVICES; use device indices instead.",
    "detail": "nvidia-smi queries all GPUs regardless of CUDA_VISIBLE_DEVICES. Masking GPUs with this variable only affects CUDA applications, not system-level tools.",
    "tags": [
      "env",
      "nvidia-smi",
      "warn"
    ]
  },
  {
    "id": "gpu-019",
    "pattern": "^nvidia-smi\\s+-r",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "nvidia-smi -r resets the GPU, killing all running jobs.",
    "detail": "The '-r' flag performs a device reset, terminating all processes and clearing GPU state. This is irreversible and can cause data loss if jobs are running.",
    "tags": [
      "nvidia-smi",
      "reset",
      "danger"
    ]
  },
  {
    "id": "gpu-020",
    "pattern": "^nvidia-smi\\s+--persistence-mode=0",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "Disabling persistence mode may cause GPU to power down unexpectedly.",
    "detail": "Turning off persistence mode can result in the GPU powering down between jobs, causing delays and potential job failures when the device is re-initialized.",
    "tags": [
      "nvidia-smi",
      "power",
      "danger"
    ]
  },
  {
    "id": "gpu-021",
    "pattern": "^nvidia-smi\\s+-ac\\s+\\d+,\\d+",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Setting application clocks outside supported range can brick GPU.",
    "detail": "The '-ac' flag sets memory and graphics clocks. Using unsupported values may cause the GPU to become unstable or unresponsive, requiring a reboot or RMA.",
    "tags": [
      "nvidia-smi",
      "clocks",
      "warn"
    ]
  },
  {
    "id": "gpu-022",
    "pattern": "^nvidia-smi\\s+-mig\\s+1",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Enable MIG mode for partitioning A100/A30 GPUs.",
    "detail": "Multi-Instance GPU (MIG) allows partitioning supported GPUs into isolated instances. This is essential for maximizing resource utilization in shared environments.",
    "tags": [
      "nvidia-smi",
      "mig",
      "tip"
    ]
  },
  {
    "id": "gpu-023",
    "pattern": "^nsys\\s+profile",
    "cmd": "nsys",
    "severity": "tip",
    "hint": "Use nsys profile for detailed GPU and CPU timeline analysis.",
    "detail": "Nsight Systems (nsys) provides system-wide profiling, capturing both CPU and GPU activity, kernel launches, and memory transfers. It's the recommended tool for performance bottleneck analysis.",
    "tags": [
      "nsight",
      "profiling",
      "tip"
    ]
  },
  {
    "id": "gpu-024",
    "pattern": "^ncu\\s+cli",
    "cmd": "ncu",
    "severity": "tip",
    "hint": "Use ncu CLI for kernel-level GPU performance metrics.",
    "detail": "Nsight Compute CLI (ncu) provides low-level kernel profiling, including occupancy, memory throughput, and instruction statistics. Use it to optimize CUDA kernels.",
    "tags": [
      "nsight",
      "profiling",
      "tip"
    ]
  },
  {
    "id": "gpu-025",
    "pattern": "^export\\s+CUDNN_BENCHMARK=1",
    "cmd": "export",
    "severity": "tip",
    "hint": "Enable CUDNN_BENCHMARK=1 for optimal convolution algorithm selection.",
    "detail": "Setting CUDNN_BENCHMARK=1 allows cuDNN to find the fastest convolution algorithm for your hardware and input sizes, improving deep learning training speed. May cause variable startup time.",
    "tags": [
      "cudnn",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gpu-026",
    "pattern": "^export\\s+CUDNN_DETERMINISTIC=1",
    "cmd": "export",
    "severity": "warn",
    "hint": "CUDNN_DETERMINISTIC=1 disables fastest algorithms for reproducibility.",
    "detail": "Enabling deterministic mode ensures repeatable results but may force slower algorithms, impacting training speed. Use only when strict reproducibility is required.",
    "tags": [
      "cudnn",
      "determinism",
      "warn"
    ]
  },
  {
    "id": "gpu-027",
    "pattern": "^export\\s+NCCL_DEBUG=INFO",
    "cmd": "export",
    "severity": "tip",
    "hint": "Set NCCL_DEBUG=INFO to troubleshoot multi-GPU communication.",
    "detail": "NCCL_DEBUG=INFO provides verbose logging for NCCL operations, helping diagnose hangs or performance issues in distributed training. Logs can be large; use selectively.",
    "tags": [
      "nccl",
      "debug",
      "tip"
    ]
  },
  {
    "id": "gpu-028",
    "pattern": "^export\\s+NCCL_IB_DISABLE=1",
    "cmd": "export",
    "severity": "tip",
    "hint": "Disable InfiniBand with NCCL_IB_DISABLE=1 for Ethernet-only clusters.",
    "detail": "Setting NCCL_IB_DISABLE=1 forces NCCL to use TCP/IP instead of InfiniBand, which is necessary on clusters without IB hardware or when troubleshooting IB issues.",
    "tags": [
      "nccl",
      "network",
      "tip"
    ]
  },
  {
    "id": "gpu-029",
    "pattern": "^python\\s+.*apex.*",
    "cmd": "python",
    "severity": "upgrade",
    "hint": "Apex is deprecated. Use torch.cuda.amp for mixed precision.",
    "detail": "NVIDIA's Apex library is no longer actively maintained. PyTorch's built-in torch.cuda.amp provides native mixed precision training with better support and integration.",
    "tags": [
      "apex",
      "pytorch",
      "upgrade"
    ]
  },
  {
    "id": "gpu-030",
    "pattern": "^export\\s+CUDA_CACHE_DISABLE=1",
    "cmd": "export",
    "severity": "warn",
    "hint": "Disabling CUDA cache slows kernel launches and recompilation.",
    "detail": "CUDA_CACHE_DISABLE=1 prevents caching of compiled kernels, forcing recompilation on every run. This is useful for debugging but significantly increases startup time.",
    "tags": [
      "cuda",
      "cache",
      "warn"
    ]
  },
  {
    "id": "gpu-031",
    "pattern": "^nvidia-smi\\s+-d\\s+MEMORY",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -d MEMORY to monitor GPU memory errors and usage.",
    "detail": "The '-d MEMORY' option displays detailed memory usage and error statistics, helping diagnose leaks or hardware faults.",
    "tags": [
      "nvidia-smi",
      "memory",
      "tip"
    ]
  },
  {
    "id": "gpu-032",
    "pattern": "^nvidia-smi\\s+-d\\s+UTILIZATION",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -d UTILIZATION for fine-grained GPU usage stats.",
    "detail": "The '-d UTILIZATION' flag gives detailed breakdowns of GPU, memory, and encoder/decoder utilization, helping pinpoint bottlenecks in workloads.",
    "tags": [
      "nvidia-smi",
      "utilization",
      "tip"
    ]
  },
  {
    "id": "gpu-033",
    "pattern": "^nvidia-smi\\s+-d\\s+TEMPERATURE",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Monitor GPU temperature with -d TEMPERATURE to prevent throttling.",
    "detail": "Tracking temperature helps prevent thermal throttling or shutdowns, especially in dense server environments. Use this to tune cooling or power settings.",
    "tags": [
      "nvidia-smi",
      "temperature",
      "tip"
    ]
  },
  {
    "id": "gpu-034",
    "pattern": "^export\\s+CUDA_DEVICE_ORDER=PCI_BUS_ID",
    "cmd": "export",
    "severity": "tip",
    "hint": "Set CUDA_DEVICE_ORDER=PCI_BUS_ID for stable device indexing.",
    "detail": "By default, CUDA device indices can change between boots. Setting CUDA_DEVICE_ORDER=PCI_BUS_ID ensures consistent mapping based on hardware topology, which is critical for multi-GPU scripting.",
    "tags": [
      "cuda",
      "env",
      "tip"
    ]
  },
  {
    "id": "gpu-035",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-persistence-mode=1",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Enable persistence mode to reduce GPU initialization latency.",
    "detail": "Persistence mode keeps the GPU driver loaded even when no processes are using the GPU, minimizing startup delays for subsequent jobs.",
    "tags": [
      "nvidia-smi",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gpu-036",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-reset-gpu",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "Resetting a GPU will terminate all running processes on it.",
    "detail": "The '-reset-gpu' flag forcibly resets the specified GPU, killing all processes and clearing device state. Use only when the device is unresponsive and no critical jobs are running.",
    "tags": [
      "nvidia-smi",
      "reset",
      "danger"
    ]
  },
  {
    "id": "gpu-037",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-gpu-reset",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "gpu-reset kills all jobs on the specified GPU. Confirm before use.",
    "detail": "The '-gpu-reset' flag is similar to '-reset-gpu', terminating all processes and resetting the device. Use with extreme caution on shared systems.",
    "tags": [
      "nvidia-smi",
      "reset",
      "danger"
    ]
  },
  {
    "id": "gpu-038",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-mig\\s+0",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Disabling MIG destroys all GPU instances and their data.",
    "detail": "Turning off MIG mode deletes all GPU instances, potentially interrupting running jobs and causing data loss. Always check for active workloads before disabling.",
    "tags": [
      "nvidia-smi",
      "mig",
      "warn"
    ]
  },
  {
    "id": "gpu-039",
    "pattern": "^rocm-smi(\\s+|$)",
    "cmd": "rocm-smi",
    "severity": "tip",
    "hint": "Use rocm-smi for AMD GPU monitoring and management.",
    "detail": "rocm-smi provides functionality similar to nvidia-smi for AMD GPUs, including temperature, fan, and power management. Useful for heterogeneous clusters.",
    "tags": [
      "rocm",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "gpu-040",
    "pattern": "^export\\s+CUDA_MANAGED_FORCE_DEVICE_ALLOC=1",
    "cmd": "export",
    "severity": "tip",
    "hint": "Force device allocation for managed memory to avoid host overcommit.",
    "detail": "CUDA_MANAGED_FORCE_DEVICE_ALLOC=1 ensures managed memory allocations are placed on the device, preventing host memory overcommit and improving performance for large models.",
    "tags": [
      "cuda",
      "memory",
      "tip"
    ]
  },
  {
    "id": "gpu-041",
    "pattern": "^cuda-memcheck\\s+--tool\\s+racecheck",
    "cmd": "cuda-memcheck",
    "severity": "tip",
    "hint": "Use racecheck to detect data races in CUDA kernels.",
    "detail": "The racecheck tool in cuda-memcheck identifies shared memory data races, which can cause intermittent and hard-to-debug errors in parallel code.",
    "tags": [
      "cuda-memcheck",
      "debug",
      "tip"
    ]
  },
  {
    "id": "gpu-042",
    "pattern": "^cuda-memcheck\\s+--leak-check\\s+full",
    "cmd": "cuda-memcheck",
    "severity": "tip",
    "hint": "Enable full leak-check to catch all device memory leaks.",
    "detail": "The '--leak-check full' flag provides comprehensive reporting of device memory leaks, helping prevent memory exhaustion in long-running applications.",
    "tags": [
      "cuda-memcheck",
      "memory",
      "tip"
    ]
  },
  {
    "id": "gpu-043",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-fan\\s+\\d+",
    "cmd": "nvidia-smi",
    "severity": "warn",
    "hint": "Setting fan speed manually may override automatic thermal controls.",
    "detail": "Manually setting fan speed can lead to overheating if not monitored, as it disables automatic thermal management. Use only for testing or in controlled environments.",
    "tags": [
      "nvidia-smi",
      "fan",
      "warn"
    ]
  },
  {
    "id": "gpu-044",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-dmon",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -dmon for real-time GPU utilization and power monitoring.",
    "detail": "The '-dmon' flag provides continuous, tabular monitoring of power, temperature, utilization, and memory, useful for performance tuning and thermal analysis.",
    "tags": [
      "nvidia-smi",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "gpu-045",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-pmon",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Use -pmon for per-process GPU usage monitoring.",
    "detail": "The '-pmon' flag shows real-time GPU usage by process, including memory and compute utilization, helping identify resource hogs or leaks.",
    "tags": [
      "nvidia-smi",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "gpu-046",
    "pattern": "^export\\s+NCCL_P2P_DISABLE=1",
    "cmd": "export",
    "severity": "tip",
    "hint": "Disable NCCL peer-to-peer for debugging or non-P2P topologies.",
    "detail": "NCCL_P2P_DISABLE=1 forces NCCL to use only host memory transfers, useful for debugging or when GPUs lack P2P connectivity. Expect reduced performance.",
    "tags": [
      "nccl",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gpu-047",
    "pattern": "^export\\s+NCCL_SOCKET_IFNAME=\\S+",
    "cmd": "export",
    "severity": "tip",
    "hint": "Set NCCL_SOCKET_IFNAME to specify network interface for NCCL.",
    "detail": "NCCL_SOCKET_IFNAME restricts NCCL to a specific network interface, which is essential for multi-homed nodes or when isolating traffic for performance.",
    "tags": [
      "nccl",
      "network",
      "tip"
    ]
  },
  {
    "id": "gpu-048",
    "pattern": "^export\\s+CUDA_VISIBLE_DEVICES=\\s*$",
    "cmd": "export",
    "severity": "warn",
    "hint": "Empty CUDA_VISIBLE_DEVICES disables all GPU access for child processes.",
    "detail": "Setting CUDA_VISIBLE_DEVICES to an empty string masks all GPUs, causing CUDA applications to see no devices. This can lead to silent CPU fallback or errors.",
    "tags": [
      "cuda",
      "env",
      "warn"
    ]
  },
  {
    "id": "gpu-049",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-e\\s+1",
    "cmd": "nvidia-smi",
    "severity": "tip",
    "hint": "Enable ECC for error protection on supported GPUs.",
    "detail": "Enabling ECC protects against memory bit errors, which is critical for scientific and financial workloads. Some GPUs require a reboot for changes to take effect.",
    "tags": [
      "nvidia-smi",
      "ecc",
      "tip"
    ]
  },
  {
    "id": "gpu-050",
    "pattern": "^nvidia-smi\\s+-i\\s+\\d+\\s+-reset-admin",
    "cmd": "nvidia-smi",
    "severity": "danger",
    "hint": "Admin reset will forcibly reset the GPU and clear all state.",
    "detail": "The '-reset-admin' flag performs an administrative reset, clearing all device state and terminating all jobs. Use only for recovery from unrecoverable errors.",
    "tags": [
      "nvidia-smi",
      "reset",
      "danger"
    ]
  },
  {
    "id": "serving-001",
    "pattern": "^torchserve\\s+--start(\\s+|$)",
    "cmd": "torchserve",
    "severity": "warn",
    "hint": "Always specify --model-store to avoid loading default models.",
    "detail": "If --model-store is not set, TorchServe may use a default directory, potentially loading unwanted or outdated models. Explicitly set --model-store to control which models are available at startup.",
    "tags": [
      "torchserve",
      "startup",
      "models",
      "config"
    ]
  },
  {
    "id": "serving-002",
    "pattern": "^tritonserver\\s+.*--model-control-mode=explicit",
    "cmd": "tritonserver",
    "severity": "tip",
    "hint": "Use --load-model to pre-load models in explicit mode.",
    "detail": "With --model-control-mode=explicit, models are not loaded automatically. Use --load-model=<model_name> to ensure required models are available immediately after server start, reducing first-inference latency.",
    "tags": [
      "triton",
      "models",
      "performance"
    ]
  },
  {
    "id": "serving-003",
    "pattern": "^onnxruntime_server\\s+.*--enable-telemetry",
    "cmd": "onnxruntime_server",
    "severity": "warn",
    "hint": "Disable telemetry in production with --disable-telemetry.",
    "detail": "Telemetry may send usage data externally, which can be a privacy or compliance risk. Always use --disable-telemetry in production environments to prevent unintentional data sharing.",
    "tags": [
      "onnxruntime",
      "telemetry",
      "privacy",
      "production"
    ]
  },
  {
    "id": "serving-004",
    "pattern": "^vllm\\s+serve(\\s+|$)",
    "cmd": "vllm",
    "severity": "tip",
    "hint": "Set --max-num-batched-tokens for optimal GPU utilization.",
    "detail": "The --max-num-batched-tokens flag controls the batching size for inference. Tuning this value can significantly improve throughput and reduce latency, especially on large GPU instances.",
    "tags": [
      "vllm",
      "performance",
      "gpu"
    ]
  },
  {
    "id": "serving-005",
    "pattern": "^text-generation-launcher\\s+.*--max-concurrent-requests=\\d+",
    "cmd": "text-generation-launcher",
    "severity": "tip",
    "hint": "Tune --max-concurrent-requests for your hardware limits.",
    "detail": "Setting --max-concurrent-requests too high can exhaust system resources, leading to degraded performance or crashes. Benchmark and adjust this value based on your CPU/GPU and memory capacity.",
    "tags": [
      "text-generation-inference",
      "performance",
      "concurrency"
    ]
  },
  {
    "id": "serving-006",
    "pattern": "^ollama\\s+run(\\s+|$)",
    "cmd": "ollama",
    "severity": "warn",
    "hint": "Pin model versions to avoid silent upgrades.",
    "detail": "Running ollama without specifying a model version may result in automatic upgrades to newer model versions, which can change outputs or introduce incompatibilities. Always use a specific version tag.",
    "tags": [
      "ollama",
      "models",
      "versioning"
    ]
  },
  {
    "id": "serving-007",
    "pattern": "^llama\\.cpp\\s+.*--n-gpu-layers=0",
    "cmd": "llama.cpp",
    "severity": "tip",
    "hint": "Set --n-gpu-layers to leverage GPU acceleration.",
    "detail": "By default, --n-gpu-layers=0 disables GPU offloading, running inference on CPU only. Increase this value to offload layers to the GPU for significant speedup, especially with large models.",
    "tags": [
      "llama.cpp",
      "gpu",
      "performance"
    ]
  },
  {
    "id": "serving-008",
    "pattern": "^bentoml\\s+serve(\\s+|$)",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Use --production for gunicorn-based multi-worker serving.",
    "detail": "The --production flag enables a production-grade WSGI server (gunicorn) with multiple workers, improving throughput and reliability compared to the default single-worker development server.",
    "tags": [
      "bentoml",
      "production",
      "performance"
    ]
  },
  {
    "id": "serving-009",
    "pattern": "^torchserve\\s+.*--foreground",
    "cmd": "torchserve",
    "severity": "warn",
    "hint": "Avoid --foreground in production; use systemd or supervisord.",
    "detail": "Running TorchServe in the foreground is suitable for debugging but not for production. Use a process manager like systemd or supervisord to ensure automatic restarts and proper logging.",
    "tags": [
      "torchserve",
      "production",
      "process-management"
    ]
  },
  {
    "id": "serving-010",
    "pattern": "^tritonserver\\s+.*--strict-model-config=false",
    "cmd": "tritonserver",
    "severity": "warn",
    "hint": "Set --strict-model-config=true to catch model config errors.",
    "detail": "Disabling strict model config can allow models with misconfigured or missing config.pbtxt files to load, leading to unpredictable inference behavior. Enable strict checking in production for safety.",
    "tags": [
      "triton",
      "models",
      "config"
    ]
  },
  {
    "id": "serving-011",
    "pattern": "^onnxruntime_server\\s+.*--http-port=80",
    "cmd": "onnxruntime_server",
    "severity": "danger",
    "hint": "Avoid running on port 80 without a reverse proxy.",
    "detail": "Binding directly to port 80 can expose the inference server to the public internet, increasing attack surface. Use a reverse proxy (e.g., nginx) for TLS termination and access control.",
    "tags": [
      "onnxruntime",
      "security",
      "network"
    ]
  },
  {
    "id": "serving-012",
    "pattern": "^vllm\\s+serve\\s+.*--disable-log-requests",
    "cmd": "vllm",
    "severity": "warn",
    "hint": "Disabling request logs can hinder debugging and auditing.",
    "detail": "While --disable-log-requests reduces disk I/O, it also removes valuable traceability for troubleshooting and compliance. Use with caution, especially in regulated environments.",
    "tags": [
      "vllm",
      "logging",
      "debugging"
    ]
  },
  {
    "id": "serving-013",
    "pattern": "^text-generation-launcher\\s+.*--trust-remote-code",
    "cmd": "text-generation-launcher",
    "severity": "danger",
    "hint": "Never use --trust-remote-code with unverified models.",
    "detail": "This flag allows execution of arbitrary code from model repositories, which can be exploited for remote code execution. Only use with trusted sources and in isolated environments.",
    "tags": [
      "text-generation-inference",
      "security",
      "models"
    ]
  },
  {
    "id": "serving-014",
    "pattern": "^ollama\\s+pull\\s+[^:]+$",
    "cmd": "ollama",
    "severity": "warn",
    "hint": "Specify a version tag to avoid pulling latest by default.",
    "detail": "Without a version tag, ollama will pull the latest model, which may introduce breaking changes or unexpected behavior. Always specify the exact version needed for reproducibility.",
    "tags": [
      "ollama",
      "models",
      "versioning"
    ]
  },
  {
    "id": "serving-015",
    "pattern": "^llama\\.cpp\\s+.*--threads=\\d+",
    "cmd": "llama.cpp",
    "severity": "tip",
    "hint": "Match --threads to physical CPU cores for best throughput.",
    "detail": "Setting --threads higher than the number of physical cores can lead to context switching overhead, reducing performance. Benchmark with your hardware for optimal settings.",
    "tags": [
      "llama.cpp",
      "performance",
      "cpu"
    ]
  },
  {
    "id": "serving-016",
    "pattern": "^bentoml\\s+serve\\s+.*--reload",
    "cmd": "bentoml",
    "severity": "warn",
    "hint": "Avoid --reload in production; it's for development only.",
    "detail": "The --reload flag enables auto-reloading on code changes, which is resource-intensive and not suitable for production. Use --production for stable deployments.",
    "tags": [
      "bentoml",
      "production",
      "development"
    ]
  },
  {
    "id": "serving-017",
    "pattern": "^torchserve\\s+--stop(\\s+|$)",
    "cmd": "torchserve",
    "severity": "warn",
    "hint": "Check for orphaned processes after stopping TorchServe.",
    "detail": "In some cases, --stop may not terminate all child processes, especially if custom handlers spawn subprocesses. Verify with ps or systemctl to avoid port conflicts or resource leaks.",
    "tags": [
      "torchserve",
      "process",
      "cleanup"
    ]
  },
  {
    "id": "serving-018",
    "pattern": "^tritonserver\\s+.*--backend-config=python,shm-default-byte-size=.*",
    "cmd": "tritonserver",
    "severity": "tip",
    "hint": "Increase shm-default-byte-size for large input tensors.",
    "detail": "The default shared memory size may be insufficient for large payloads, causing silent failures or degraded performance. Tune this value based on your model's input size requirements.",
    "tags": [
      "triton",
      "performance",
      "memory"
    ]
  },
  {
    "id": "serving-019",
    "pattern": "^onnxruntime_server\\s+.*--session-thread-pool-size=\\d+",
    "cmd": "onnxruntime_server",
    "severity": "tip",
    "hint": "Tune --session-thread-pool-size for multi-core CPUs.",
    "detail": "Increasing this value can improve throughput on multi-core systems, but setting it too high may cause contention. Benchmark to find the optimal thread pool size for your workload.",
    "tags": [
      "onnxruntime",
      "performance",
      "cpu"
    ]
  },
  {
    "id": "serving-020",
    "pattern": "^vllm\\s+serve\\s+.*--tensor-parallel-size=\\d+",
    "cmd": "vllm",
    "severity": "tip",
    "hint": "Set --tensor-parallel-size to match available GPUs.",
    "detail": "Tensor parallelism splits model computation across GPUs. Setting this flag higher than the number of GPUs will cause errors; set it to the exact GPU count for optimal scaling.",
    "tags": [
      "vllm",
      "gpu",
      "parallelism"
    ]
  },
  {
    "id": "serving-021",
    "pattern": "^text-generation-launcher\\s+.*--quantize=.*",
    "cmd": "text-generation-launcher",
    "severity": "tip",
    "hint": "Use quantization for faster inference on CPU-bound workloads.",
    "detail": "The --quantize flag enables model quantization, reducing memory usage and improving inference speed, especially on CPUs. Test for accuracy impact before deploying to production.",
    "tags": [
      "text-generation-inference",
      "performance",
      "quantization"
    ]
  },
  {
    "id": "serving-022",
    "pattern": "^ollama\\s+run\\s+.*--gpu=false",
    "cmd": "ollama",
    "severity": "tip",
    "hint": "Enable GPU with --gpu=true for large models.",
    "detail": "Running large models on CPU can be extremely slow. Use --gpu=true to leverage hardware acceleration, significantly reducing inference time for supported models.",
    "tags": [
      "ollama",
      "gpu",
      "performance"
    ]
  },
  {
    "id": "serving-023",
    "pattern": "^llama\\.cpp\\s+.*--mlock",
    "cmd": "llama.cpp",
    "severity": "tip",
    "hint": "Use --mlock to prevent model swapping for low-latency serving.",
    "detail": "The --mlock flag locks model weights in RAM, preventing them from being swapped out. This is crucial for latency-sensitive applications but requires sufficient available memory.",
    "tags": [
      "llama.cpp",
      "performance",
      "memory"
    ]
  },
  {
    "id": "serving-024",
    "pattern": "^bentoml\\s+serve\\s+.*--host=0\\.0\\.0\\.0",
    "cmd": "bentoml",
    "severity": "warn",
    "hint": "Bind to 0.0.0.0 only behind a firewall or reverse proxy.",
    "detail": "Binding to all interfaces exposes the server to the network, increasing risk of unauthorized access. Restrict access with a firewall or use a reverse proxy for security.",
    "tags": [
      "bentoml",
      "network",
      "security"
    ]
  },
  {
    "id": "serving-025",
    "pattern": "^torchserve\\s+.*--ts-config=.*",
    "cmd": "torchserve",
    "severity": "tip",
    "hint": "Use --ts-config to load custom server settings.",
    "detail": "The --ts-config flag allows you to specify a custom configuration file, enabling fine-grained control over logging, model limits, and environment variables. This is essential for advanced deployments.",
    "tags": [
      "torchserve",
      "config",
      "customization"
    ]
  },
  {
    "id": "serving-026",
    "pattern": "^tritonserver\\s+.*--exit-on-error=false",
    "cmd": "tritonserver",
    "severity": "warn",
    "hint": "Set --exit-on-error=true to fail fast on critical errors.",
    "detail": "With --exit-on-error=false, the server may continue running after critical failures, potentially serving bad results. Use true in production to ensure reliability and fast recovery.",
    "tags": [
      "triton",
      "error-handling",
      "production"
    ]
  },
  {
    "id": "serving-027",
    "pattern": "^onnxruntime_server\\s+.*--enable-mem-arena=false",
    "cmd": "onnxruntime_server",
    "severity": "tip",
    "hint": "Enable memory arena for better allocation performance.",
    "detail": "Disabling the memory arena can degrade performance due to inefficient memory management. Only disable for debugging memory leaks or fragmentation issues.",
    "tags": [
      "onnxruntime",
      "performance",
      "memory"
    ]
  },
  {
    "id": "serving-028",
    "pattern": "^vllm\\s+serve\\s+.*--disable-cuda-graph",
    "cmd": "vllm",
    "severity": "tip",
    "hint": "Enable CUDA graph for lower inference latency.",
    "detail": "CUDA graph optimizes kernel launches, reducing overhead and improving latency. Only disable if you encounter compatibility issues with specific hardware or drivers.",
    "tags": [
      "vllm",
      "gpu",
      "performance"
    ]
  },
  {
    "id": "serving-029",
    "pattern": "^text-generation-launcher\\s+.*--max-input-length=\\d+",
    "cmd": "text-generation-launcher",
    "severity": "warn",
    "hint": "Set --max-input-length to prevent OOM on large prompts.",
    "detail": "Unbounded input lengths can cause out-of-memory errors or server crashes. Always set a reasonable --max-input-length based on your model and hardware limits.",
    "tags": [
      "text-generation-inference",
      "memory",
      "limits"
    ]
  },
  {
    "id": "serving-030",
    "pattern": "^ollama\\s+run\\s+.*--timeout=\\d+",
    "cmd": "ollama",
    "severity": "tip",
    "hint": "Adjust --timeout for long-running generation tasks.",
    "detail": "The default timeout may be too short for complex or lengthy generations. Increase --timeout to avoid premature termination of inference requests.",
    "tags": [
      "ollama",
      "performance",
      "timeouts"
    ]
  },
  {
    "id": "serving-031",
    "pattern": "^llama\\.cpp\\s+.*--no-mmap",
    "cmd": "llama.cpp",
    "severity": "tip",
    "hint": "Avoid --no-mmap unless debugging file I/O issues.",
    "detail": "Memory-mapping model files enables faster loading and lower memory usage. Disabling mmap can increase startup time and RAM consumption; use only for troubleshooting.",
    "tags": [
      "llama.cpp",
      "performance",
      "memory"
    ]
  },
  {
    "id": "serving-032",
    "pattern": "^bentoml\\s+serve\\s+.*--timeout=\\d+",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Set --timeout to avoid hanging requests under load.",
    "detail": "Long-running inference without a timeout can tie up workers, reducing throughput and potentially causing denial of service. Tune --timeout based on expected model latency.",
    "tags": [
      "bentoml",
      "performance",
      "timeouts"
    ]
  },
  {
    "id": "serving-033",
    "pattern": "^torchserve\\s+.*--models=.*\\.mar",
    "cmd": "torchserve",
    "severity": "tip",
    "hint": "List multiple models with --models for multi-model serving.",
    "detail": "You can specify multiple .mar files with --models to serve several models concurrently. This enables multi-task inference from a single server instance, improving resource utilization.",
    "tags": [
      "torchserve",
      "models",
      "multi-model"
    ]
  },
  {
    "id": "serving-034",
    "pattern": "^tritonserver\\s+.*--model-repository=.*",
    "cmd": "tritonserver",
    "severity": "warn",
    "hint": "Use separate model repositories for staging and production.",
    "detail": "Mixing staging and production models in a single repository can lead to accidental exposure of untested models. Maintain strict separation to avoid serving experimental models to users.",
    "tags": [
      "triton",
      "models",
      "deployment"
    ]
  },
  {
    "id": "serving-035",
    "pattern": "^onnxruntime_server\\s+.*--enable-gpu",
    "cmd": "onnxruntime_server",
    "severity": "tip",
    "hint": "Install CUDA libraries before enabling GPU support.",
    "detail": "ONNX Runtime requires compatible CUDA and cuDNN libraries for GPU acceleration. If not present, the server will silently fall back to CPU, causing unexpected slowdowns.",
    "tags": [
      "onnxruntime",
      "gpu",
      "dependencies"
    ]
  },
  {
    "id": "serving-036",
    "pattern": "^vllm\\s+serve\\s+.*--max-model-len=\\d+",
    "cmd": "vllm",
    "severity": "tip",
    "hint": "Set --max-model-len to match your model's context window.",
    "detail": "If --max-model-len is set lower than the model's context window, you may get truncated outputs. Set it to the model's full context length for correct results.",
    "tags": [
      "vllm",
      "models",
      "config"
    ]
  },
  {
    "id": "serving-037",
    "pattern": "^text-generation-launcher\\s+.*--port=\\d+",
    "cmd": "text-generation-launcher",
    "severity": "warn",
    "hint": "Avoid well-known ports to prevent conflicts and privilege issues.",
    "detail": "Binding to ports below 1024 requires root privileges and can conflict with system services. Use higher, unprivileged ports for safety and easier deployment.",
    "tags": [
      "text-generation-inference",
      "network",
      "ports"
    ]
  },
  {
    "id": "serving-038",
    "pattern": "^ollama\\s+run\\s+.*--log-level=debug",
    "cmd": "ollama",
    "severity": "warn",
    "hint": "Avoid debug logging in production to protect sensitive data.",
    "detail": "Debug logs may include request payloads, model outputs, or internal errors. Use info or warning level in production to minimize data exposure and log volume.",
    "tags": [
      "ollama",
      "logging",
      "security"
    ]
  },
  {
    "id": "serving-039",
    "pattern": "^llama\\.cpp\\s+.*--lora=.*",
    "cmd": "llama.cpp",
    "severity": "tip",
    "hint": "Use --lora for efficient fine-tuning without full retraining.",
    "detail": "LoRA adapters enable parameter-efficient fine-tuning, reducing compute and memory requirements. This is ideal for customizing large models on limited hardware.",
    "tags": [
      "llama.cpp",
      "fine-tuning",
      "lora"
    ]
  },
  {
    "id": "serving-040",
    "pattern": "^bentoml\\s+serve\\s+.*--workers=\\d+",
    "cmd": "bentoml",
    "severity": "tip",
    "hint": "Increase --workers to handle more concurrent requests.",
    "detail": "More workers allow the server to process multiple requests in parallel, improving throughput. However, setting workers too high can exhaust system resources; tune based on CPU and memory.",
    "tags": [
      "bentoml",
      "performance",
      "concurrency"
    ]
  },
  {
    "id": "docker-001",
    "pattern": "^docker\\s+run\\s+-v\\s+/?:/?\\s*",
    "cmd": "docker",
    "severity": "danger",
    "hint": "Never mount root (/) as a volume. Use a specific path instead.",
    "detail": "Mounting the root directory with -v /:/ exposes the entire host filesystem to the container, risking accidental or malicious modification or deletion of system files. This can lead to total system compromise or data loss.",
    "tags": [
      "run",
      "volume",
      "security",
      "danger"
    ]
  },
  {
    "id": "docker-002",
    "pattern": "^docker\\s+run\\s+--privileged(\\s|$)",
    "cmd": "docker",
    "severity": "danger",
    "hint": "Avoid --privileged unless absolutely necessary. Use fine-grained flags.",
    "detail": "The --privileged flag disables all security mechanisms and grants the container full access to the host, including devices and kernel capabilities. This can lead to severe security breaches. Use --cap-add or device mappings for more controlled access.",
    "tags": [
      "run",
      "security",
      "danger"
    ]
  },
  {
    "id": "docker-003",
    "pattern": "^docker\\s+exec\\s+-u\\s+root(\\s|$)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "Avoid running docker exec as root. Use a non-root user if possible.",
    "detail": "Running commands inside containers as root increases the risk of privilege escalation, especially if the container is compromised. Use the -u flag with a specific user defined in the Dockerfile for better isolation.",
    "tags": [
      "exec",
      "security",
      "warn"
    ]
  },
  {
    "id": "docker-004",
    "pattern": "^docker\\s+run(\\s|$)(?!.*--rm)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --rm to auto-remove containers after exit.",
    "detail": "Without --rm, stopped containers accumulate and consume disk space. The --rm flag ensures containers are automatically removed when they exit, keeping your environment clean.",
    "tags": [
      "run",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "docker-005",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--no-cache)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --no-cache to force a clean build and avoid stale layers.",
    "detail": "Docker caches build layers by default, which can cause outdated dependencies or files to persist. The --no-cache flag disables layer caching, ensuring all steps are rebuilt from scratch.",
    "tags": [
      "build",
      "cache",
      "tip"
    ]
  },
  {
    "id": "docker-006",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--progress)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --progress=plain for detailed build logs in CI environments.",
    "detail": "By default, Docker uses a fancy progress UI which can obscure logs in CI systems. The --progress=plain flag outputs logs in a more readable, line-by-line format, aiding debugging.",
    "tags": [
      "build",
      "logs",
      "tip"
    ]
  },
  {
    "id": "docker-007",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--target)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --target to build up to a specific stage in multi-stage builds.",
    "detail": "Multi-stage builds allow you to define intermediate stages. The --target flag lets you build up to a named stage, which is useful for debugging or extracting build artifacts.",
    "tags": [
      "build",
      "multi-stage",
      "tip"
    ]
  },
  {
    "id": "docker-008",
    "pattern": "^docker\\s+run(\\s|$)(?!.*--network)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Specify --network for custom isolation or performance.",
    "detail": "By default, containers use the bridge network, which may not suit all use cases. The --network flag allows you to connect containers to user-defined networks for better isolation or shared communication.",
    "tags": [
      "run",
      "network",
      "tip"
    ]
  },
  {
    "id": "docker-009",
    "pattern": "^docker\\s+compose\\s+up(\\s|$)(?!.*-d)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add -d to run Compose services in detached mode.",
    "detail": "Without -d, docker compose up blocks the terminal and streams logs. Use -d to run services in the background, allowing you to continue working in the same terminal.",
    "tags": [
      "compose",
      "tip"
    ]
  },
  {
    "id": "docker-010",
    "pattern": "^docker\\s+compose\\s+down(\\s|$)(?!.*--volumes)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "Use --volumes to remove named volumes with compose down.",
    "detail": "docker compose down does not remove named volumes by default, which can lead to stale data persisting between runs. Use --volumes to ensure all associated volumes are deleted.",
    "tags": [
      "compose",
      "volume",
      "warn"
    ]
  },
  {
    "id": "docker-011",
    "pattern": "^docker\\s+logs\\s+[^\\s]+(\\s|$)(?!.*-f)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use -f to follow logs in real-time.",
    "detail": "The -f (follow) flag streams container logs as they are written, which is essential for monitoring long-running processes or debugging startup issues.",
    "tags": [
      "logs",
      "tip"
    ]
  },
  {
    "id": "docker-012",
    "pattern": "^docker\\s+logs\\s+[^\\s]+(\\s|$)(?!.*--tail)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --tail N to limit log output to the last N lines.",
    "detail": "By default, docker logs outputs all available logs, which can be overwhelming. The --tail flag restricts output to the most recent lines, improving readability and performance.",
    "tags": [
      "logs",
      "tip"
    ]
  },
  {
    "id": "docker-013",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--cpus)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --cpus to limit CPU usage for resource control.",
    "detail": "Without CPU limits, containers can consume all available host CPU, impacting other workloads. The --cpus flag restricts the number of CPUs accessible to the container.",
    "tags": [
      "run",
      "performance",
      "tip"
    ]
  },
  {
    "id": "docker-014",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--memory)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Set --memory to cap container RAM usage.",
    "detail": "Containers without memory limits can exhaust host resources, causing system instability. The --memory flag enforces a hard limit, preventing runaway processes.",
    "tags": [
      "run",
      "performance",
      "tip"
    ]
  },
  {
    "id": "docker-015",
    "pattern": "^docker\\s+buildx\\s+build(\\s|$)(?!.*--push)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --push to upload images to a remote registry after build.",
    "detail": "docker buildx build does not push images by default. Use --push to automatically upload the built image to the specified registry, streamlining CI/CD pipelines.",
    "tags": [
      "buildx",
      "registry",
      "tip"
    ]
  },
  {
    "id": "docker-016",
    "pattern": "^docker\\s+buildx\\s+build(\\s|$)(?!.*--platform)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --platform to build multi-architecture images.",
    "detail": "The --platform flag allows building images for different CPU architectures (e.g., linux/amd64, linux/arm64) in a single command, enabling true multi-arch support.",
    "tags": [
      "buildx",
      "multi-arch",
      "tip"
    ]
  },
  {
    "id": "docker-017",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--build-arg)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --build-arg to pass variables at build time.",
    "detail": "Build arguments allow you to inject values (like versions or secrets) into the build process without hardcoding them in the Dockerfile. Use ARG in the Dockerfile to consume them.",
    "tags": [
      "build",
      "build-arg",
      "tip"
    ]
  },
  {
    "id": "docker-018",
    "pattern": "^docker\\s+volume\\s+prune(\\s|$)",
    "cmd": "docker",
    "severity": "danger",
    "hint": "docker volume prune deletes ALL unused volumes. Double-check before r...",
    "detail": "This command irreversibly deletes all unused Docker volumes, potentially resulting in data loss for stopped containers or orphaned volumes. Always verify with docker volume ls before pruning.",
    "tags": [
      "volume",
      "danger",
      "cleanup"
    ]
  },
  {
    "id": "docker-019",
    "pattern": "^docker\\s+system\\s+prune(\\s|$)",
    "cmd": "docker",
    "severity": "danger",
    "hint": "docker system prune removes images, containers, and networks. Use wit...",
    "detail": "This command deletes all stopped containers, unused networks, dangling images, and optionally volumes. Data loss is irreversible. Use --volumes only if you intend to delete all unused volumes as well.",
    "tags": [
      "system",
      "danger",
      "cleanup"
    ]
  },
  {
    "id": "docker-020",
    "pattern": "^docker\\s+rm\\s+-f\\s+[^\\s]+(\\s|$)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "docker rm -f forcefully kills running containers. Prefer graceful stop.",
    "detail": "The -f flag sends SIGKILL to running containers, which can cause data corruption or loss of in-flight transactions. Use docker stop to allow processes to exit cleanly.",
    "tags": [
      "rm",
      "warn",
      "cleanup"
    ]
  },
  {
    "id": "docker-021",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--read-only)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --read-only for immutable root filesystem containers.",
    "detail": "The --read-only flag mounts the container's root filesystem as read-only, reducing the attack surface and preventing accidental writes. Use writable volumes for necessary state.",
    "tags": [
      "run",
      "security",
      "tip"
    ]
  },
  {
    "id": "docker-022",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--user)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "Use --user to avoid running as root inside containers.",
    "detail": "Running as root inside containers is a common security risk. The --user flag allows you to specify a non-root UID/GID, improving isolation and reducing privilege escalation risk.",
    "tags": [
      "run",
      "security",
      "warn"
    ]
  },
  {
    "id": "docker-023",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--env-file)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --env-file to load environment variables from a file.",
    "detail": "Managing many environment variables via multiple -e flags is error-prone. The --env-file flag loads variables from a file, simplifying configuration and reducing mistakes.",
    "tags": [
      "run",
      "env",
      "tip"
    ]
  },
  {
    "id": "docker-024",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--detach)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --detach (-d) to run containers in the background.",
    "detail": "Running containers in the foreground blocks your terminal. The --detach or -d flag runs the container in the background, freeing your shell for other tasks.",
    "tags": [
      "run",
      "tip"
    ]
  },
  {
    "id": "docker-025",
    "pattern": "^docker\\s+ps(\\s|$)(?!.*-a)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add -a to docker ps to list all containers, not just running ones.",
    "detail": "By default, docker ps only shows running containers. The -a flag lists all containers, including stopped ones, which is useful for troubleshooting and cleanup.",
    "tags": [
      "ps",
      "tip"
    ]
  },
  {
    "id": "docker-026",
    "pattern": "^docker\\s+images(\\s|$)(?!.*--digests)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --digests to display image content digests for verification.",
    "detail": "The --digests flag shows the content hash of images, which is crucial for verifying image integrity and ensuring you're running the expected version.",
    "tags": [
      "images",
      "tip"
    ]
  },
  {
    "id": "docker-027",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--squash)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --squash to combine layers and reduce image size.",
    "detail": "The --squash flag merges all build layers into a single layer, minimizing image size and hiding intermediate steps. This can improve security and reduce bandwidth usage.",
    "tags": [
      "build",
      "tip",
      "image-size"
    ]
  },
  {
    "id": "docker-028",
    "pattern": "^docker\\s+pull\\s+[^\\s]+(\\s|$)(?!.*--platform)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --platform to pull images for a specific architecture.",
    "detail": "The --platform flag ensures you pull the correct image variant for your target architecture, which is essential for multi-arch environments or cross-building.",
    "tags": [
      "pull",
      "multi-arch",
      "tip"
    ]
  },
  {
    "id": "docker-029",
    "pattern": "^docker\\s+compose\\s+build(\\s|$)(?!.*--parallel)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --parallel to speed up multi-service builds.",
    "detail": "The --parallel flag builds multiple services concurrently, significantly reducing build times for large Compose projects with independent services.",
    "tags": [
      "compose",
      "build",
      "performance",
      "tip"
    ]
  },
  {
    "id": "docker-030",
    "pattern": "^docker\\s+compose\\s+up(\\s|$)(?!.*--build)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --build to force image rebuilds before starting services.",
    "detail": "docker compose up does not rebuild images by default if they exist. The --build flag ensures all images are rebuilt, picking up changes in Dockerfiles or dependencies.",
    "tags": [
      "compose",
      "build",
      "tip"
    ]
  },
  {
    "id": "docker-031",
    "pattern": "^docker\\s+network\\s+prune(\\s|$)",
    "cmd": "docker",
    "severity": "danger",
    "hint": "docker network prune removes ALL unused networks. Confirm before runn...",
    "detail": "This command deletes all unused networks, which can disrupt service communication if misused. Always check with docker network ls to avoid accidental outages.",
    "tags": [
      "network",
      "danger",
      "cleanup"
    ]
  },
  {
    "id": "docker-032",
    "pattern": "^docker\\s+inspect\\s+[^\\s]+(\\s|$)(?!.*--format)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --format to extract specific fields from inspect output.",
    "detail": "The --format flag allows you to use Go templates to extract only the information you need, making scripts and automation more robust and readable.",
    "tags": [
      "inspect",
      "tip"
    ]
  },
  {
    "id": "docker-033",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--pull)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --pull to always fetch the latest base images.",
    "detail": "By default, Docker uses locally cached base images. The --pull flag forces Docker to check for newer versions, ensuring you build from the most up-to-date base.",
    "tags": [
      "build",
      "tip"
    ]
  },
  {
    "id": "docker-034",
    "pattern": "^docker\\s+login(\\s|$)(?!.*--username)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --username to specify the registry user explicitly.",
    "detail": "Specifying --username avoids ambiguity, especially when working with multiple registries or CI/CD systems. It ensures credentials are applied to the correct account.",
    "tags": [
      "login",
      "registry",
      "tip"
    ]
  },
  {
    "id": "docker-035",
    "pattern": "^docker\\s+tag\\s+[^\\s]+\\s+[^\\s]+(\\s|$)(?!.*:)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "Always tag images with a version, not just 'latest'.",
    "detail": "Relying on the 'latest' tag can cause confusion and accidental rollbacks or upgrades. Tag images with explicit versions to ensure reproducibility and traceability.",
    "tags": [
      "tag",
      "warn",
      "image"
    ]
  },
  {
    "id": "docker-036",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--health-cmd)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Define a --health-cmd to enable container health checks.",
    "detail": "Health checks allow Docker to monitor container status and restart unhealthy containers automatically. Use --health-cmd to specify a command for health evaluation.",
    "tags": [
      "run",
      "health",
      "tip"
    ]
  },
  {
    "id": "docker-037",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--restart)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --restart to control container auto-restart policies.",
    "detail": "The --restart flag configures how Docker handles container restarts on failure or daemon restart. Options include no, on-failure, always, and unless-stopped.",
    "tags": [
      "run",
      "restart",
      "tip"
    ]
  },
  {
    "id": "docker-038",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--secret)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --secret to securely pass secrets during build (buildkit).",
    "detail": "The --secret flag (with BuildKit) injects secrets at build time without baking them into images. This prevents accidental exposure of credentials in image layers.",
    "tags": [
      "build",
      "security",
      "tip"
    ]
  },
  {
    "id": "docker-039",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--cap-drop)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --cap-drop to remove unneeded Linux capabilities.",
    "detail": "Containers run with a default set of Linux capabilities. Use --cap-drop to remove those not required, reducing the attack surface and improving security.",
    "tags": [
      "run",
      "security",
      "tip"
    ]
  },
  {
    "id": "docker-040",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--tmpfs)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --tmpfs to mount temporary filesystems for ephemeral data.",
    "detail": "The --tmpfs flag mounts a temporary filesystem in memory, ideal for sensitive or ephemeral data that should not persist between container runs.",
    "tags": [
      "run",
      "tmpfs",
      "tip"
    ]
  },
  {
    "id": "docker-041",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--compress)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --compress to reduce build context upload size.",
    "detail": "The --compress flag compresses the build context sent to the Docker daemon, which can speed up builds over slow networks and reduce bandwidth usage.",
    "tags": [
      "build",
      "performance",
      "tip"
    ]
  },
  {
    "id": "docker-042",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--shm-size)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --shm-size to increase shared memory for memory-intensive apps.",
    "detail": "The default /dev/shm size is 64MB, which may be insufficient for some applications (e.g., databases, browsers). Use --shm-size to allocate more shared memory.",
    "tags": [
      "run",
      "performance",
      "tip"
    ]
  },
  {
    "id": "docker-043",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--label)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --label to add metadata to images for traceability.",
    "detail": "Labels allow you to store metadata (e.g., version, maintainer, build date) in images, aiding in automation, auditing, and management.",
    "tags": [
      "build",
      "metadata",
      "tip"
    ]
  },
  {
    "id": "docker-044",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--log-driver)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Set --log-driver for advanced logging backends.",
    "detail": "Docker supports multiple logging drivers (e.g., json-file, syslog, journald). Use --log-driver to integrate with centralized logging solutions or optimize log performance.",
    "tags": [
      "run",
      "logs",
      "tip"
    ]
  },
  {
    "id": "docker-045",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--security-opt)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --security-opt for advanced security profiles (e.g., seccomp).",
    "detail": "The --security-opt flag allows you to apply custom security profiles, such as seccomp or AppArmor, for fine-grained control over container permissions.",
    "tags": [
      "run",
      "security",
      "tip"
    ]
  },
  {
    "id": "docker-046",
    "pattern": "^docker\\s+stats(\\s|$)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use docker stats to monitor real-time container resource usage.",
    "detail": "docker stats provides live metrics for CPU, memory, network, and disk I/O per container. It's essential for diagnosing performance bottlenecks and capacity planning.",
    "tags": [
      "stats",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "docker-047",
    "pattern": "^docker\\s+scan\\s+[^\\s]+(\\s|$)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use docker scan to check images for known vulnerabilities.",
    "detail": "docker scan integrates with Snyk to analyze images for CVEs and security issues. Regular scanning helps maintain a secure container supply chain.",
    "tags": [
      "scan",
      "security",
      "tip"
    ]
  },
  {
    "id": "docker-048",
    "pattern": "^docker\\s+compose\\s+up(\\s|$)(?!.*--remove-orphans)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --remove-orphans to clean up containers not in your compose file.",
    "detail": "When services are removed from docker-compose.yml, orphaned containers may persist. The --remove-orphans flag ensures only defined services are running.",
    "tags": [
      "compose",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "docker-049",
    "pattern": "^docker\\s+compose\\s+down(\\s|$)(?!.*--rmi)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --rmi all to remove images built by Compose.",
    "detail": "The --rmi all flag deletes all images used by services, freeing disk space and ensuring a clean environment for future builds.",
    "tags": [
      "compose",
      "cleanup",
      "tip"
    ]
  },
  {
    "id": "docker-050",
    "pattern": "^docker\\s+buildx\\s+build(\\s|$)(?!.*--cache-to)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --cache-to/--cache-from for remote build cache sharing.",
    "detail": "These flags allow sharing build cache between CI jobs or developers, significantly speeding up builds and reducing redundant work.",
    "tags": [
      "buildx",
      "cache",
      "tip"
    ]
  },
  {
    "id": "docker-051",
    "pattern": "^docker\\s+compose\\s+up(\\s|$)(?!.*--scale)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --scale to run multiple instances of a service.",
    "detail": "The --scale flag allows you to specify the number of container instances for a service, enabling easy horizontal scaling for testing or load balancing.",
    "tags": [
      "compose",
      "scaling",
      "tip"
    ]
  },
  {
    "id": "docker-052",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--device)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --device to give containers access to host devices.",
    "detail": "The --device flag allows you to pass host devices (e.g., /dev/snd for audio, /dev/nvidia0 for GPUs) into containers, enabling hardware acceleration or special device access.",
    "tags": [
      "run",
      "device",
      "tip"
    ]
  },
  {
    "id": "docker-053",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--file)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --file to specify a non-default Dockerfile location.",
    "detail": "The --file flag lets you build from Dockerfiles not named 'Dockerfile' or located outside the build context root, supporting more complex project layouts.",
    "tags": [
      "build",
      "tip"
    ]
  },
  {
    "id": "docker-054",
    "pattern": "^docker\\s+compose(\\s|$)",
    "cmd": "docker",
    "severity": "upgrade",
    "hint": "Switch to 'docker compose' (space), not 'docker-compose' (hyphen).",
    "detail": "The new Compose V2 is integrated into the Docker CLI as 'docker compose', offering better performance, new features, and improved compatibility. The legacy 'docker-compose' is deprecated.",
    "tags": [
      "compose",
      "upgrade"
    ]
  },
  {
    "id": "docker-055",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--init)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Add --init to handle zombie processes in containers.",
    "detail": "The --init flag runs tini as PID 1, reaping orphaned child processes and preventing resource leaks in long-running containers.",
    "tags": [
      "run",
      "init",
      "tip"
    ]
  },
  {
    "id": "docker-056",
    "pattern": "^docker\\s+run\\s+[^\\s]+(\\s|$)(?!.*--ulimit)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --ulimit to set resource limits for processes in containers.",
    "detail": "The --ulimit flag sets user-level resource limits (e.g., open files, processes), preventing runaway resource usage and improving container stability.",
    "tags": [
      "run",
      "ulimit",
      "tip"
    ]
  },
  {
    "id": "docker-057",
    "pattern": "^docker\\s+build(\\s|$)(?!.*--network)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use --network to control network mode during build.",
    "detail": "The --network flag sets the networking mode for RUN instructions, enabling access to build-time dependencies or proxies. Useful for builds behind firewalls or with custom DNS.",
    "tags": [
      "build",
      "network",
      "tip"
    ]
  },
  {
    "id": "docker-058",
    "pattern": "^docker\\s+save\\s+[^\\s]+(\\s|$)(?!.*\\.tar)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Save images to a .tar file for portable backups or transfers.",
    "detail": "docker save exports images as tarballs, which can be imported elsewhere with docker load. This is essential for air-gapped or offline environments.",
    "tags": [
      "save",
      "backup",
      "tip"
    ]
  },
  {
    "id": "docker-059",
    "pattern": "^docker\\s+compose\\s+config(\\s|$)",
    "cmd": "docker",
    "severity": "tip",
    "hint": "Use docker compose config to validate and view merged configs.",
    "detail": "This command merges multiple Compose files and interpolates environment variables, allowing you to verify the final configuration before deployment.",
    "tags": [
      "compose",
      "config",
      "tip"
    ]
  },
  {
    "id": "docker-060",
    "pattern": "^docker\\s+context\\s+use\\s+[^\\s]+(\\s|$)",
    "cmd": "docker",
    "severity": "warn",
    "hint": "Check your Docker context to avoid deploying to the wrong environment.",
    "detail": "docker context use switches between local and remote Docker environments. Accidentally targeting production or a shared environment can result in unintended deployments or data loss.",
    "tags": [
      "context",
      "warn",
      "environment"
    ]
  },
  {
    "id": "kubernetes-001",
    "pattern": "^kubectl\\s+delete\\s+.*--force\\s+--grace-period=0",
    "cmd": "kubectl",
    "severity": "danger",
    "hint": "Avoid --force --grace-period=0 unless you must orphan resources.",
    "detail": "Using --force with --grace-period=0 forcibly deletes resources without waiting for finalizers, which can orphan dependent resources or corrupt cluster state. Only use for stuck resources after careful diagnosis.",
    "tags": [
      "kubectl",
      "delete",
      "danger",
      "force"
    ]
  },
  {
    "id": "kubernetes-002",
    "pattern": "^kubectl\\s+apply\\s+-f\\s+.*\\.yaml\\s*$",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --prune with apply to remove obsolete resources.",
    "detail": "kubectl apply by default only creates or updates resources, never deleting obsolete ones. The --prune flag, combined with --selector, ensures removed resources in your manifests are deleted from the cluster, keeping state in sync.",
    "tags": [
      "kubectl",
      "apply",
      "prune",
      "tip"
    ]
  },
  {
    "id": "kubernetes-003",
    "pattern": "^kubectl\\s+get\\s+pods(\\s+|$)",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Add -o wide to see node, IP, and container info.",
    "detail": "kubectl get pods -o wide displays additional columns such as node assignment, pod IP, and container images, which are invaluable for debugging scheduling and networking issues.",
    "tags": [
      "kubectl",
      "get",
      "pods",
      "tip"
    ]
  },
  {
    "id": "kubernetes-004",
    "pattern": "^kubectl\\s+exec\\s+-it\\s+.*sh",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Use --namespace to avoid exec'ing into the wrong pod.",
    "detail": "Without specifying --namespace, kubectl exec defaults to the 'default' namespace, which can lead to confusion or accidental commands in the wrong environment, especially in multi-tenant clusters.",
    "tags": [
      "kubectl",
      "exec",
      "namespace",
      "warn"
    ]
  },
  {
    "id": "kubernetes-005",
    "pattern": "^kubectl\\s+delete\\s+namespace\\s+.*",
    "cmd": "kubectl",
    "severity": "danger",
    "hint": "Deleting a namespace removes all its resources irreversibly.",
    "detail": "kubectl delete namespace triggers deletion of all resources within that namespace, including pods, services, secrets, and configmaps. Recovery is not possible unless you have backups.",
    "tags": [
      "kubectl",
      "namespace",
      "delete",
      "danger"
    ]
  },
  {
    "id": "kubernetes-006",
    "pattern": "^kubectl\\s+apply\\s+-f\\s+.*\\.yaml\\s+--validate=false",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Avoid --validate=false unless you know schema is correct.",
    "detail": "Disabling validation skips client-side schema checks, which can allow malformed manifests to reach the API server, potentially causing runtime errors or rejected resources.",
    "tags": [
      "kubectl",
      "apply",
      "validate",
      "warn"
    ]
  },
  {
    "id": "kubernetes-007",
    "pattern": "^kubectl\\s+get\\s+.*\\s+-A",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Be cautious with -A; it lists resources cluster-wide.",
    "detail": "The -A or --all-namespaces flag aggregates resources from all namespaces, which can overwhelm output or expose sensitive info. Use with care, especially in production.",
    "tags": [
      "kubectl",
      "get",
      "all-namespaces",
      "warn"
    ]
  },
  {
    "id": "kubernetes-008",
    "pattern": "^kubectl\\s+port-forward\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --address to restrict port-forward to localhost.",
    "detail": "By default, kubectl port-forward binds only to localhost, but specifying --address can expose the port on all interfaces, which may be a security risk. Always restrict to 127.0.0.1 unless necessary.",
    "tags": [
      "kubectl",
      "port-forward",
      "tip",
      "security"
    ]
  },
  {
    "id": "kubernetes-009",
    "pattern": "^kubectl\\s+logs\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --tail or --since for efficient log retrieval.",
    "detail": "kubectl logs retrieves the entire log by default, which can be slow for large logs. Use --tail=N or --since=1h to limit output and speed up troubleshooting.",
    "tags": [
      "kubectl",
      "logs",
      "tip",
      "performance"
    ]
  },
  {
    "id": "kubernetes-010",
    "pattern": "^kubectl\\s+rollout\\s+undo\\s+deployment/.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Check rollout history before undoing deployments.",
    "detail": "kubectl rollout undo reverts to the previous revision, but if no previous revision exists or the history is pruned, this can fail or have unexpected effects. Always check rollout history first.",
    "tags": [
      "kubectl",
      "rollout",
      "undo",
      "warn"
    ]
  },
  {
    "id": "kubernetes-011",
    "pattern": "^kubectl\\s+cp\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl cp can silently fail with large files or symlinks.",
    "detail": "kubectl cp uses tar under the hood and may fail with large files, symlinks, or special files, sometimes without clear error messages. Always verify file integrity after copy.",
    "tags": [
      "kubectl",
      "cp",
      "warn",
      "files"
    ]
  },
  {
    "id": "kubernetes-012",
    "pattern": "^kubectl\\s+get\\s+events",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Sort events by timestamp with --sort-by='.metadata.creationTimestamp'.",
    "detail": "By default, kubectl get events returns unsorted output. Use --sort-by to order events chronologically, making it easier to trace issues.",
    "tags": [
      "kubectl",
      "events",
      "tip",
      "debugging"
    ]
  },
  {
    "id": "kubernetes-013",
    "pattern": "^kubectl\\s+describe\\s+pod\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Include --namespace to avoid ambiguity in multi-tenant clusters.",
    "detail": "Without --namespace, kubectl describe pod defaults to the current namespace, which may not be where the pod resides. Always specify --namespace for clarity.",
    "tags": [
      "kubectl",
      "describe",
      "namespace",
      "tip"
    ]
  },
  {
    "id": "kubernetes-014",
    "pattern": "^kubectl\\s+apply\\s+-k\\s+.*",
    "cmd": "kubectl",
    "severity": "upgrade",
    "hint": "Use kustomize CLI for advanced overlays and validation.",
    "detail": "kubectl apply -k supports basic kustomize features, but the standalone kustomize CLI offers more advanced patching, validation, and plugins, improving workflow for complex deployments.",
    "tags": [
      "kubectl",
      "kustomize",
      "upgrade"
    ]
  },
  {
    "id": "kubernetes-015",
    "pattern": "^helm\\s+install\\s+.*--set\\s+.*",
    "cmd": "helm",
    "severity": "warn",
    "hint": "Prefer --values over --set for complex or multiline values.",
    "detail": "The --set flag is limited for complex data types and multiline values, often leading to parsing errors. Use --values (or -f) with a YAML file for clarity and maintainability.",
    "tags": [
      "helm",
      "install",
      "set",
      "warn"
    ]
  },
  {
    "id": "kubernetes-016",
    "pattern": "^helm\\s+upgrade\\s+.*--force",
    "cmd": "helm",
    "severity": "danger",
    "hint": "Using --force deletes and recreates resources; data may be lost.",
    "detail": "The --force flag deletes and recreates resources, not just updating them. This can cause downtime or loss of persistent data if not handled carefully.",
    "tags": [
      "helm",
      "upgrade",
      "force",
      "danger"
    ]
  },
  {
    "id": "kubernetes-017",
    "pattern": "^kubectl\\s+scale\\s+deployment/.*\\s+--replicas=0",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Scaling to zero stops all pods; ensure this is intentional.",
    "detail": "Setting replicas to zero stops all workload pods, which may disrupt services or cause readiness/liveness probes to fail. Confirm this is the desired action before proceeding.",
    "tags": [
      "kubectl",
      "scale",
      "replicas",
      "warn"
    ]
  },
  {
    "id": "kubernetes-018",
    "pattern": "^kubectl\\s+edit\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl edit does not validate changes until save; syntax errors poss...",
    "detail": "kubectl edit opens the resource in your editor, but only validates on save. Invalid YAML or schema errors can cause the update to fail silently or partially apply.",
    "tags": [
      "kubectl",
      "edit",
      "warn"
    ]
  },
  {
    "id": "kubernetes-019",
    "pattern": "^kubectl\\s+get\\s+svc",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use -o yaml/json to inspect service endpoints and selectors.",
    "detail": "kubectl get svc -o yaml or -o json reveals full service definitions, including selectors, ports, and annotations, which are essential for debugging connectivity issues.",
    "tags": [
      "kubectl",
      "service",
      "tip"
    ]
  },
  {
    "id": "kubernetes-020",
    "pattern": "^kubectl\\s+run\\s+.*",
    "cmd": "kubectl",
    "severity": "upgrade",
    "hint": "kubectl run is deprecated for deployments; use kubectl create.",
    "detail": "kubectl run now only creates pods, not deployments or replicasets. For deployments, use kubectl create deployment or apply a manifest for full control.",
    "tags": [
      "kubectl",
      "run",
      "upgrade"
    ]
  },
  {
    "id": "kubernetes-021",
    "pattern": "^kubectl\\s+get\\s+nodes",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Add -o wide to see node internal/external IPs and OS info.",
    "detail": "kubectl get nodes -o wide displays additional node details, such as IP addresses, OS, and kernel version, aiding in troubleshooting node-level issues.",
    "tags": [
      "kubectl",
      "nodes",
      "tip"
    ]
  },
  {
    "id": "kubernetes-022",
    "pattern": "^kubectl\\s+describe\\s+deployment\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Check Events section for rollout and scheduling issues.",
    "detail": "kubectl describe deployment includes an Events section that logs rollout progress, failures, and scheduling problems, which are not visible in kubectl get output.",
    "tags": [
      "kubectl",
      "describe",
      "deployment",
      "tip"
    ]
  },
  {
    "id": "kubernetes-023",
    "pattern": "^kubectl\\s+get\\s+configmap\\s+.*-o\\s+jsonpath=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use jsonpath for precise configmap value extraction.",
    "detail": "The -o jsonpath flag allows extracting specific fields from configmaps, which is more efficient than parsing full YAML or JSON output for scripting and automation.",
    "tags": [
      "kubectl",
      "configmap",
      "jsonpath",
      "tip"
    ]
  },
  {
    "id": "kubernetes-024",
    "pattern": "^kubectl\\s+replace\\s+-f\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl replace deletes and recreates resources; data may be lost.",
    "detail": "kubectl replace removes and recreates resources, which can delete associated data (e.g., PVCs) if not handled with care. Use apply for in-place updates when possible.",
    "tags": [
      "kubectl",
      "replace",
      "warn"
    ]
  },
  {
    "id": "kubernetes-025",
    "pattern": "^kubectl\\s+get\\s+secret\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Secrets are base64-encoded, not encrypted; handle with care.",
    "detail": "kubectl get secret outputs data in base64, which is easily decoded. Avoid exposing secrets in logs or scripts, and use RBAC to restrict access.",
    "tags": [
      "kubectl",
      "secret",
      "warn",
      "security"
    ]
  },
  {
    "id": "kubernetes-026",
    "pattern": "^kubectl\\s+proxy\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl proxy opens the API server on localhost; restrict access.",
    "detail": "kubectl proxy creates a local HTTP proxy to the Kubernetes API server, potentially exposing sensitive endpoints if not properly secured. Limit access and monitor usage.",
    "tags": [
      "kubectl",
      "proxy",
      "warn",
      "security"
    ]
  },
  {
    "id": "kubernetes-027",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--watch",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --watch-only to avoid initial resource dump.",
    "detail": "The --watch flag streams resource changes but also prints the current state first. Use --watch-only to see only updates, which is useful for monitoring real-time changes.",
    "tags": [
      "kubectl",
      "watch",
      "tip"
    ]
  },
  {
    "id": "kubernetes-028",
    "pattern": "^kubectl\\s+top\\s+pod\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl top requires metrics-server to be installed.",
    "detail": "kubectl top relies on metrics-server for resource usage data. If metrics-server is missing or misconfigured, top will return errors or incomplete data.",
    "tags": [
      "kubectl",
      "top",
      "warn",
      "metrics"
    ]
  },
  {
    "id": "kubernetes-029",
    "pattern": "^kubectl\\s+create\\s+service\\s+clusterip\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Specify --tcp or --udp for explicit port protocol.",
    "detail": "kubectl create service clusterip defaults to TCP ports. Use --tcp or --udp to explicitly set the protocol, avoiding ambiguity for multi-protocol services.",
    "tags": [
      "kubectl",
      "service",
      "tip"
    ]
  },
  {
    "id": "kubernetes-030",
    "pattern": "^kubectl\\s+get\\s+ingress\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use -o yaml to inspect ingress annotations and backend details.",
    "detail": "kubectl get ingress -o yaml exposes full ingress configuration, including annotations, backend service mappings, and TLS settings, which are critical for troubleshooting routing issues.",
    "tags": [
      "kubectl",
      "ingress",
      "tip"
    ]
  },
  {
    "id": "kubernetes-031",
    "pattern": "^kubectl\\s+get\\s+all",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl get all omits some resource types (e.g., CRDs).",
    "detail": "kubectl get all only lists core resource types (pods, services, deployments, etc.), omitting custom resources and some system objects. Use explicit resource types for completeness.",
    "tags": [
      "kubectl",
      "get",
      "warn"
    ]
  },
  {
    "id": "kubernetes-032",
    "pattern": "^kubectl\\s+config\\s+use-context\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Always verify current context with kubectl config current-context.",
    "detail": "Switching contexts can lead to accidental actions in the wrong cluster or namespace. Always confirm the active context before running sensitive commands.",
    "tags": [
      "kubectl",
      "config",
      "context",
      "warn"
    ]
  },
  {
    "id": "kubernetes-033",
    "pattern": "^kubectl\\s+apply\\s+-f\\s+.*\\s+--dry-run(=client|=server)?",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --dry-run=server for full API validation.",
    "detail": "--dry-run=client only validates locally, missing server-side admission checks. --dry-run=server submits to the API server for full validation, catching more errors before apply.",
    "tags": [
      "kubectl",
      "apply",
      "dry-run",
      "tip"
    ]
  },
  {
    "id": "kubernetes-034",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--field-selector=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --field-selector for efficient server-side filtering.",
    "detail": "The --field-selector flag filters resources on the server, reducing data transfer and client-side parsing, which is especially useful in large clusters.",
    "tags": [
      "kubectl",
      "get",
      "field-selector",
      "tip"
    ]
  },
  {
    "id": "kubernetes-035",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--output=name",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --output=name for scripting and resource piping.",
    "detail": "--output=name returns only resource names, making it ideal for piping into xargs or other kubectl commands for batch operations.",
    "tags": [
      "kubectl",
      "get",
      "output",
      "tip"
    ]
  },
  {
    "id": "kubernetes-036",
    "pattern": "^kubectl\\s+auth\\s+can-i\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Check RBAC permissions with --as or --as-group.",
    "detail": "kubectl auth can-i supports --as and --as-group to test permissions as another user or group, which is invaluable for RBAC troubleshooting and policy validation.",
    "tags": [
      "kubectl",
      "auth",
      "rbac",
      "tip"
    ]
  },
  {
    "id": "kubernetes-037",
    "pattern": "^kubectl\\s+delete\\s+pod\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Deleting a pod does not remove its PVCs by default.",
    "detail": "kubectl delete pod only deletes the pod object; persistent volume claims (PVCs) remain unless explicitly deleted. This can leave orphaned storage.",
    "tags": [
      "kubectl",
      "delete",
      "pod",
      "warn"
    ]
  },
  {
    "id": "kubernetes-038",
    "pattern": "^kubectl\\s+get\\s+statefulset\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "StatefulSets retain PVCs even after deletion; clean up manually.",
    "detail": "Deleting a StatefulSet does not delete its associated PVCs. Manual cleanup is required to avoid unused persistent volumes consuming storage.",
    "tags": [
      "kubectl",
      "statefulset",
      "tip"
    ]
  },
  {
    "id": "kubernetes-039",
    "pattern": "^kubectl\\s+get\\s+job\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --show-labels to debug job selectors and completions.",
    "detail": "--show-labels displays resource labels, helping to debug job selectors, completions, and parallelism settings for batch workloads.",
    "tags": [
      "kubectl",
      "job",
      "tip"
    ]
  },
  {
    "id": "kubernetes-040",
    "pattern": "^kubectl\\s+create\\s+rolebinding\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "RoleBindings are namespace-scoped; use ClusterRoleBinding for cluster...",
    "detail": "RoleBindings only grant permissions within a single namespace. For cluster-wide access, use ClusterRoleBinding, or you may encounter unexpected authorization failures.",
    "tags": [
      "kubectl",
      "rbac",
      "rolebinding",
      "warn"
    ]
  },
  {
    "id": "kubernetes-041",
    "pattern": "^kubectl\\s+apply\\s+-f\\s+.*\\s+--record",
    "cmd": "kubectl",
    "severity": "upgrade",
    "hint": "--record is deprecated; use annotations for change tracking.",
    "detail": "The --record flag is deprecated in recent kubectl versions. Use kubectl annotate or CI/CD tooling to track change history in resource annotations.",
    "tags": [
      "kubectl",
      "apply",
      "upgrade"
    ]
  },
  {
    "id": "kubernetes-042",
    "pattern": "^kubectl\\s+get\\s+deployment\\s+.*\\s+--show-managed-fields",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Show managed fields to debug server-side apply ownership.",
    "detail": "--show-managed-fields displays which manager (kubectl, controller, etc.) owns each field, helping resolve field conflicts and server-side apply issues.",
    "tags": [
      "kubectl",
      "deployment",
      "tip"
    ]
  },
  {
    "id": "kubernetes-043",
    "pattern": "^kubectl\\s+delete\\s+.*\\s+--cascade=orphan",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "--cascade=orphan leaves child resources unmanaged.",
    "detail": "Using --cascade=orphan deletes the parent resource but leaves child resources (e.g., pods, replicasets) orphaned, which can cause resource leaks and confusion.",
    "tags": [
      "kubectl",
      "delete",
      "cascade",
      "warn"
    ]
  },
  {
    "id": "kubernetes-044",
    "pattern": "^kubectl\\s+get\\s+pod\\s+.*\\s+-o\\s+json",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use jq to filter pod JSON output for specific fields.",
    "detail": "kubectl get pod -o json outputs full resource data, which can be piped to jq for extracting container statuses, resource requests, or events, streamlining debugging.",
    "tags": [
      "kubectl",
      "pod",
      "json",
      "tip"
    ]
  },
  {
    "id": "kubernetes-045",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--label-columns=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Display custom label columns for quick resource grouping.",
    "detail": "--label-columns adds specified labels as columns in output, aiding in grouping and identifying resources by environment, team, or version.",
    "tags": [
      "kubectl",
      "labels",
      "tip"
    ]
  },
  {
    "id": "kubernetes-046",
    "pattern": "^kubectl\\s+get\\s+pod\\s+.*\\s+--all-namespaces",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "Output may be overwhelming; filter with --selector or --field-selector.",
    "detail": "Listing all pods across namespaces can produce massive output in large clusters. Use --selector or --field-selector to narrow results and avoid missing critical info.",
    "tags": [
      "kubectl",
      "pod",
      "all-namespaces",
      "warn"
    ]
  },
  {
    "id": "kubernetes-047",
    "pattern": "^kubectl\\s+cordon\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Cordon marks node unschedulable but does not evict pods.",
    "detail": "kubectl cordon prevents new pods from being scheduled but does not affect existing pods. Use drain to safely evict pods before maintenance.",
    "tags": [
      "kubectl",
      "cordon",
      "tip"
    ]
  },
  {
    "id": "kubernetes-048",
    "pattern": "^kubectl\\s+drain\\s+.*",
    "cmd": "kubectl",
    "severity": "warn",
    "hint": "kubectl drain may hang on pods without controllers or PDBs.",
    "detail": "kubectl drain waits for pods to terminate, but pods without controllers or those protected by PodDisruptionBudgets (PDBs) can block the operation. Use --force and --delete-emptydir-data with caution.",
    "tags": [
      "kubectl",
      "drain",
      "warn"
    ]
  },
  {
    "id": "kubernetes-049",
    "pattern": "^kubectl\\s+get\\s+daemonset\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Check desired vs. current pod count for rollout status.",
    "detail": "kubectl get daemonset shows desired and current pod counts. Discrepancies indicate scheduling or rollout issues, often due to taints or node selectors.",
    "tags": [
      "kubectl",
      "daemonset",
      "tip"
    ]
  },
  {
    "id": "kubernetes-050",
    "pattern": "^kubectl\\s+debug\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "kubectl debug can attach ephemeral containers for live troubleshooting.",
    "detail": "kubectl debug (1.18+) injects ephemeral containers into running pods for debugging without restarting them, preserving state and minimizing disruption.",
    "tags": [
      "kubectl",
      "debug",
      "tip"
    ]
  },
  {
    "id": "kubernetes-051",
    "pattern": "^kubectl\\s+get\\s+crd\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use -o yaml to inspect CRD schema and validation rules.",
    "detail": "kubectl get crd -o yaml reveals custom resource definitions, including openAPI schema, subresources, and validation, which are critical for debugging CRD-related issues.",
    "tags": [
      "kubectl",
      "crd",
      "tip"
    ]
  },
  {
    "id": "kubernetes-052",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--chunk-size=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Set --chunk-size to avoid client timeouts on large resource lists.",
    "detail": "--chunk-size splits large resource lists into manageable chunks, reducing memory usage and avoiding timeouts when querying thousands of objects.",
    "tags": [
      "kubectl",
      "get",
      "performance",
      "tip"
    ]
  },
  {
    "id": "kubernetes-053",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--server-side",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --server-side for declarative apply and conflict resolution.",
    "detail": "--server-side enables server-side apply, which tracks field ownership and resolves conflicts more robustly than client-side apply, especially in GitOps workflows.",
    "tags": [
      "kubectl",
      "apply",
      "server-side",
      "tip"
    ]
  },
  {
    "id": "kubernetes-054",
    "pattern": "^kubectl\\s+create\\s+namespace\\s+.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Label namespaces for environment or team ownership.",
    "detail": "Adding labels to namespaces (e.g., env=prod, team=devops) improves resource organization and enables RBAC, network policies, and cost tracking by label selectors.",
    "tags": [
      "kubectl",
      "namespace",
      "tip"
    ]
  },
  {
    "id": "kubernetes-055",
    "pattern": "^kubectl\\s+get\\s+pod\\s+.*\\s+--output=custom-columns=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Define custom columns to display specific pod fields.",
    "detail": "--output=custom-columns lets you tailor output to show fields like restarts, node, or image, streamlining monitoring and troubleshooting.",
    "tags": [
      "kubectl",
      "pod",
      "custom-columns",
      "tip"
    ]
  },
  {
    "id": "kubernetes-056",
    "pattern": "^kustomize\\s+build\\s+.*",
    "cmd": "kustomize",
    "severity": "tip",
    "hint": "Use --enable-alpha-plugins for advanced patching.",
    "detail": "--enable-alpha-plugins unlocks custom generators and transformers, allowing sophisticated resource customization beyond standard overlays.",
    "tags": [
      "kustomize",
      "build",
      "tip"
    ]
  },
  {
    "id": "kubernetes-057",
    "pattern": "^kubectl\\s+create\\s+secret\\s+generic\\s+.*\\s+--from-file=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --from-env-file for bulk secret creation from env files.",
    "detail": "--from-env-file parses key-value pairs from a file, simplifying creation of multi-key secrets and reducing manual errors compared to multiple --from-literal or --from-file flags.",
    "tags": [
      "kubectl",
      "secret",
      "tip"
    ]
  },
  {
    "id": "kubernetes-058",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--template=.*",
    "cmd": "kubectl",
    "severity": "upgrade",
    "hint": "--template is deprecated; use -o go-template instead.",
    "detail": "--template is deprecated in favor of -o go-template, which offers improved templating syntax and compatibility for custom output formatting.",
    "tags": [
      "kubectl",
      "template",
      "upgrade"
    ]
  },
  {
    "id": "kubernetes-059",
    "pattern": "^kubectl\\s+get\\s+.*\\s+--sort-by=.*",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Sort resources by any field for easier analysis.",
    "detail": "--sort-by sorts resources by arbitrary fields (e.g., .metadata.creationTimestamp), making it easier to identify oldest/newest resources or troubleshoot rollout order.",
    "tags": [
      "kubectl",
      "get",
      "sort-by",
      "tip"
    ]
  },
  {
    "id": "kubernetes-060",
    "pattern": "^kubectl\\s+apply\\s+-f\\s+.*\\s+--wait",
    "cmd": "kubectl",
    "severity": "tip",
    "hint": "Use --wait to block until resources are ready after apply.",
    "detail": "--wait blocks until all applied resources reach a ready state or timeout, which is crucial for CI/CD pipelines to ensure deployments are successful before proceeding.",
    "tags": [
      "kubectl",
      "apply",
      "wait",
      "tip"
    ]
  },
  {
    "id": "aws-001",
    "pattern": "^aws\\s+s3\\s+rm\\s+s3://[^\\s]+\\s+--recursive",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Double-check bucket and prefix before --recursive delete.",
    "detail": "Using 'aws s3 rm s3://bucket --recursive' will delete all objects under the specified prefix or bucket irreversibly. There is no trash or undo, and accidental deletions can be catastrophic. Always validate the bucket and prefix, and consider using --dryrun first.",
    "tags": [
      "s3",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "aws-002",
    "pattern": "^aws\\s+s3\\s+cp\\s+.*--recursive",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Add --exclude/--include to filter files when using --recursive.",
    "detail": "The --recursive flag copies all files under the specified path. Use --exclude and --include to fine-tune which files are transferred, reducing unnecessary data transfer and cost. Patterns are evaluated in order, so specificity matters.",
    "tags": [
      "s3",
      "performance",
      "filtering"
    ]
  },
  {
    "id": "aws-003",
    "pattern": "^aws\\s+ec2\\s+terminate-instances\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Check instance IDs and region before terminating EC2 instances.",
    "detail": "Terminating EC2 instances is irreversible and deletes all ephemeral data. If the wrong region or instance ID is specified, you may destroy production resources. Always verify with 'aws ec2 describe-instances' and use --region explicitly.",
    "tags": [
      "ec2",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "aws-004",
    "pattern": "^aws\\s+configure\\s+set\\s+aws_access_key_id\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Never set credentials directly; use profiles or environment variables.",
    "detail": "Storing credentials in the default profile can lead to accidental use in the wrong context. Use named profiles for separation, and prefer environment variables or IAM roles for automation to avoid credential leakage.",
    "tags": [
      "iam",
      "credentials",
      "security"
    ]
  },
  {
    "id": "aws-005",
    "pattern": "^aws\\s+s3\\s+sync\\s+.*--delete",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Review source and destination before using --delete with s3 sync.",
    "detail": "The --delete flag removes files in the destination that do not exist in the source. A misordered source/destination or incorrect path can result in mass deletions. Always run with --dryrun to preview changes.",
    "tags": [
      "s3",
      "sync",
      "data-loss"
    ]
  },
  {
    "id": "aws-006",
    "pattern": "^aws\\s+s3\\s+ls\\s+s3://",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --human-readable and --summarize for better output.",
    "detail": "Adding --human-readable displays file sizes in readable units, and --summarize gives a total count and size. These flags help quickly assess bucket usage, especially for large datasets.",
    "tags": [
      "s3",
      "usability",
      "listing"
    ]
  },
  {
    "id": "aws-007",
    "pattern": "^aws\\s+iam\\s+delete-user\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Backup user policies and keys before deleting IAM users.",
    "detail": "Deleting an IAM user removes all associated access keys, policies, and MFA devices. Recovery is not possible. Export user details and credentials before deletion for audit or migration purposes.",
    "tags": [
      "iam",
      "danger",
      "user-management"
    ]
  },
  {
    "id": "aws-008",
    "pattern": "^aws\\s+ec2\\s+run-instances\\s+.*--associate-public-ip-address",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Avoid public IPs for sensitive workloads; use private subnets.",
    "detail": "Associating a public IP exposes the instance to the internet. For production or sensitive data, launch instances in private subnets and use NAT or VPN for outbound access. This reduces attack surface.",
    "tags": [
      "ec2",
      "networking",
      "security"
    ]
  },
  {
    "id": "aws-009",
    "pattern": "^aws\\s+lambda\\s+update-function-code\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Use --publish to create a new version for safe rollbacks.",
    "detail": "Without --publish, the update only affects the $LATEST version. Using --publish creates a new, immutable version, enabling safe rollbacks and traffic shifting via aliases. This is critical for production deployments.",
    "tags": [
      "lambda",
      "deployment",
      "versioning"
    ]
  },
  {
    "id": "aws-010",
    "pattern": "^aws\\s+cloudformation\\s+delete-stack\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Deleting stacks removes all managed resources. Confirm dependencies.",
    "detail": "Deleting a CloudFormation stack deletes all resources it created, including databases, VPCs, and EC2 instances. Orphaned resources may incur costs or break dependencies. Review the stack's resources and outputs before deletion.",
    "tags": [
      "cloudformation",
      "danger",
      "infrastructure"
    ]
  },
  {
    "id": "aws-011",
    "pattern": "^aws\\s+eks\\s+update-kubeconfig\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --alias to manage multiple EKS clusters in kubeconfig.",
    "detail": "The --alias flag adds a context with a custom name, making it easier to switch between clusters using kubectl. This prevents accidental operations on the wrong cluster and improves workflow efficiency.",
    "tags": [
      "eks",
      "kubeconfig",
      "multi-cluster"
    ]
  },
  {
    "id": "aws-012",
    "pattern": "^aws\\s+ssm\\s+send-command\\s+.*--document-name\\s+AWS-RunShellScript",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Validate script content and instance IDs to avoid broad execution.",
    "detail": "Running shell scripts via SSM can affect multiple instances if targets are misconfigured. Always specify instance IDs or tags precisely, and review script content for safety and idempotency.",
    "tags": [
      "ssm",
      "automation",
      "remote-exec"
    ]
  },
  {
    "id": "aws-013",
    "pattern": "^aws\\s+secretsmanager\\s+delete-secret\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Set --recovery-window to allow secret recovery after deletion.",
    "detail": "By default, secrets are scheduled for deletion after 30 days. You can set --recovery-window-in-days to adjust this period. Immediate deletion (--force-delete-without-recovery) is irreversible and should be used with caution.",
    "tags": [
      "secretsmanager",
      "danger",
      "recovery"
    ]
  },
  {
    "id": "aws-014",
    "pattern": "^aws\\s+ec2\\s+create-image\\s+.*--no-reboot",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Using --no-reboot may result in inconsistent AMIs.",
    "detail": "The --no-reboot flag skips instance shutdown, which can cause file system or application state inconsistencies in the resulting AMI. Only use this flag if you are certain the instance is quiescent.",
    "tags": [
      "ec2",
      "ami",
      "consistency"
    ]
  },
  {
    "id": "aws-015",
    "pattern": "^aws\\s+s3\\s+cp\\s+.*--storage-class\\s+GLACIER",
    "cmd": "aws",
    "severity": "warn",
    "hint": "GLACIER storage class makes files inaccessible for hours after upload.",
    "detail": "Objects uploaded with GLACIER class are not immediately retrievable. Retrieval requests can take several hours and incur additional costs. Use for archival only, not for active data.",
    "tags": [
      "s3",
      "storage",
      "performance"
    ]
  },
  {
    "id": "aws-016",
    "pattern": "^aws\\s+iam\\s+create-access-key\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Rotate access keys regularly and avoid creating unnecessary keys.",
    "detail": "Long-lived access keys increase the risk of compromise. Use IAM roles for EC2 or Lambda where possible, and delete unused keys promptly. Monitor key usage with CloudTrail.",
    "tags": [
      "iam",
      "security",
      "access-keys"
    ]
  },
  {
    "id": "aws-017",
    "pattern": "^aws\\s+ec2\\s+describe-instances\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --query to filter output and --output table for readability.",
    "detail": "The --query flag allows JMESPath filtering, reducing noise and improving scriptability. --output table or --output text provides more human-friendly formatting for quick reviews.",
    "tags": [
      "ec2",
      "cli",
      "usability"
    ]
  },
  {
    "id": "aws-018",
    "pattern": "^aws\\s+s3\\s+sync\\s+.*--size-only",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Relying on --size-only may skip updated files with same size.",
    "detail": "The --size-only flag ignores timestamps and only compares file sizes. Files with changed content but identical size will not be synced, leading to silent data inconsistency.",
    "tags": [
      "s3",
      "sync",
      "footgun"
    ]
  },
  {
    "id": "aws-019",
    "pattern": "^aws\\s+cloudwatch\\s+get-metric-statistics\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --start-time and --end-time in ISO8601 for precise queries.",
    "detail": "CloudWatch metric queries default to UTC and require ISO8601 timestamps. Using local time or incorrect formats can result in empty or misleading data. Always specify time range explicitly.",
    "tags": [
      "cloudwatch",
      "metrics",
      "time"
    ]
  },
  {
    "id": "aws-020",
    "pattern": "^aws\\s+configure\\s+list",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --profile to check non-default AWS CLI profiles.",
    "detail": "By default, 'aws configure list' shows only the default profile. Use --profile <name> to verify credentials and region for other profiles, preventing accidental use of wrong credentials.",
    "tags": [
      "cli",
      "profiles",
      "config"
    ]
  },
  {
    "id": "aws-021",
    "pattern": "^aws\\s+ecs\\s+update-service\\s+.*--force-new-deployment",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --force-new-deployment to roll out new task definitions.",
    "detail": "This flag forces ECS to replace all running tasks, even if the task definition hasn't changed. It's useful for picking up new environment variables or secrets without updating the image.",
    "tags": [
      "ecs",
      "deployment",
      "tasks"
    ]
  },
  {
    "id": "aws-022",
    "pattern": "^aws\\s+iam\\s+attach-user-policy\\s+.*--policy-arn\\s+arn:aws:iam::aws:policy/AdministratorAccess",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Avoid granting AdministratorAccess to users; use least privilege.",
    "detail": "AdministratorAccess grants full control over all AWS resources. Assigning it to users increases risk of accidental or malicious actions. Prefer fine-grained, task-specific policies.",
    "tags": [
      "iam",
      "security",
      "privilege"
    ]
  },
  {
    "id": "aws-023",
    "pattern": "^aws\\s+ssm\\s+get-parameters\\s+.*--with-decryption",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --with-decryption to retrieve SecureString parameters.",
    "detail": "Without --with-decryption, SecureString parameters are returned encrypted. This flag is required to obtain plaintext values for use in scripts or applications.",
    "tags": [
      "ssm",
      "parameters",
      "security"
    ]
  },
  {
    "id": "aws-024",
    "pattern": "^aws\\s+s3\\s+ls\\s+s3://[^\\s]+$",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Add trailing slash to list bucket prefixes, not objects.",
    "detail": "A trailing slash after the bucket name lists only the top-level prefixes (folders), while omitting it lists all objects. This distinction helps navigate large buckets efficiently.",
    "tags": [
      "s3",
      "listing",
      "usability"
    ]
  },
  {
    "id": "aws-025",
    "pattern": "^aws\\s+ec2\\s+delete-volume\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Ensure volume is detached and backed up before deletion.",
    "detail": "Deleting an EBS volume is irreversible and destroys all data. Volumes must be detached from instances before deletion. Always snapshot important volumes first.",
    "tags": [
      "ec2",
      "ebs",
      "data-loss"
    ]
  },
  {
    "id": "aws-026",
    "pattern": "^aws\\s+cloudformation\\s+update-stack\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Use --capabilities CAPABILITY_IAM for stacks creating IAM resources.",
    "detail": "CloudFormation requires explicit acknowledgment to create or modify IAM resources. Failing to specify --capabilities CAPABILITY_IAM or CAPABILITY_NAMED_IAM causes silent stack update failures.",
    "tags": [
      "cloudformation",
      "iam",
      "footgun"
    ]
  },
  {
    "id": "aws-027",
    "pattern": "^aws\\s+ec2\\s+create-snapshot\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Tag snapshots with --tag-specifications for tracking and cleanup.",
    "detail": "Snapshots accumulate quickly and incur costs. Use --tag-specifications to label snapshots with project, environment, or expiration, enabling automation for lifecycle management.",
    "tags": [
      "ec2",
      "ebs",
      "tagging"
    ]
  },
  {
    "id": "aws-028",
    "pattern": "^aws\\s+rds\\s+delete-db-instance\\s+.*--skip-final-snapshot",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Never use --skip-final-snapshot unless data loss is acceptable.",
    "detail": "Skipping the final snapshot deletes the database irreversibly, with no backup. Only use this flag for test databases or when data is intentionally disposable.",
    "tags": [
      "rds",
      "data-loss",
      "danger"
    ]
  },
  {
    "id": "aws-029",
    "pattern": "^aws\\s+sts\\s+assume-role\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Export AWS_SESSION_TOKEN, AWS_ACCESS_KEY_ID, and AWS_SECRET_ACCESS_KEY.",
    "detail": "Assume-role returns temporary credentials that must be exported to the environment for use by the AWS CLI or SDKs. Forgetting this step leads to authentication failures.",
    "tags": [
      "sts",
      "iam",
      "roles"
    ]
  },
  {
    "id": "aws-030",
    "pattern": "^aws\\s+cost-explorer\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Enable Cost Explorer in the AWS Console before using CLI.",
    "detail": "Cost Explorer API access is disabled by default. You must enable it in the AWS Console, or CLI commands will fail with an error. Data may take up to 24 hours to appear after activation.",
    "tags": [
      "cost-explorer",
      "billing",
      "setup"
    ]
  },
  {
    "id": "aws-031",
    "pattern": "^aws\\s+configure\\s+set\\s+region\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Set region per profile to avoid accidental cross-region operations.",
    "detail": "Setting region globally can cause commands to run in the wrong region, leading to resource creation or deletion in unintended accounts. Use --profile to scope region settings.",
    "tags": [
      "cli",
      "region",
      "profiles"
    ]
  },
  {
    "id": "aws-032",
    "pattern": "^aws\\s+ecr\\s+get-login",
    "cmd": "aws",
    "severity": "upgrade",
    "hint": "Use 'get-login-password' for ECR authentication (v2 CLI).",
    "detail": "'aws ecr get-login' is deprecated and insecure, as it outputs a full docker login command with credentials. Use 'aws ecr get-login-password' piped to 'docker login' for improved security and compatibility.",
    "tags": [
      "ecr",
      "upgrade",
      "security"
    ]
  },
  {
    "id": "aws-033",
    "pattern": "^aws\\s+lambda\\s+invoke\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --log-type Tail to get base64-encoded logs in the response.",
    "detail": "The --log-type Tail flag returns the last 4 KB of logs with the response. Decode the base64 output to quickly debug Lambda executions without checking CloudWatch.",
    "tags": [
      "lambda",
      "debugging",
      "logs"
    ]
  },
  {
    "id": "aws-034",
    "pattern": "^aws\\s+s3\\s+sync\\s+.*--delete.*--dryrun",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Always use --dryrun with --delete to preview deletions.",
    "detail": "Combining --delete and --dryrun shows which files would be deleted without making changes. This is essential for verifying sync direction and preventing accidental data loss.",
    "tags": [
      "s3",
      "sync",
      "safety"
    ]
  },
  {
    "id": "aws-035",
    "pattern": "^aws\\s+ec2\\s+describe-instances\\s+.*--filters",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use multiple --filters to narrow down instance queries.",
    "detail": "You can specify multiple --filters to match tags, instance states, or other properties, reducing output size and API rate limit consumption. Filters are ANDed together for precise selection.",
    "tags": [
      "ec2",
      "filtering",
      "performance"
    ]
  },
  {
    "id": "aws-036",
    "pattern": "^aws\\s+cloudformation\\s+deploy\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --no-fail-on-empty-changeset to avoid errors on no-op deploys.",
    "detail": "By default, 'aws cloudformation deploy' fails if there are no changes. The --no-fail-on-empty-changeset flag allows scripts to proceed gracefully when no updates are needed.",
    "tags": [
      "cloudformation",
      "deployment",
      "automation"
    ]
  },
  {
    "id": "aws-037",
    "pattern": "^aws\\s+iam\\s+delete-access-key\\s+.*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Ensure the key is unused before deletion to avoid outages.",
    "detail": "Deleting an active access key in use by applications or automation will cause authentication failures. Audit key usage with CloudTrail and rotate keys before removal.",
    "tags": [
      "iam",
      "access-keys",
      "security"
    ]
  },
  {
    "id": "aws-038",
    "pattern": "^aws\\s+ecs\\s+register-task-definition\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --cli-input-json for complex task definitions.",
    "detail": "Passing task definitions as JSON files via --cli-input-json is less error-prone than long inline arguments. It also enables version control and easier updates.",
    "tags": [
      "ecs",
      "task-definition",
      "usability"
    ]
  },
  {
    "id": "aws-039",
    "pattern": "^aws\\s+s3\\s+mb\\s+s3://[^\\s]+",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Bucket names are globally unique; check for conflicts.",
    "detail": "S3 bucket names must be unique across all AWS accounts and regions. Attempting to create a bucket with an existing name will fail silently if not checked. Use descriptive, unique names.",
    "tags": [
      "s3",
      "bucket",
      "naming"
    ]
  },
  {
    "id": "aws-040",
    "pattern": "^aws\\s+eks\\s+delete-cluster\\s+.*",
    "cmd": "aws",
    "severity": "danger",
    "hint": "Deleting EKS clusters removes all managed resources. Confirm backups.",
    "detail": "EKS cluster deletion destroys all control plane resources and may orphan worker nodes or persistent volumes. Ensure all workloads and data are backed up and decommissioned.",
    "tags": [
      "eks",
      "danger",
      "cluster"
    ]
  },
  {
    "id": "aws-041",
    "pattern": "^aws\\s+secretsmanager\\s+put-secret-value\\s+.*--secret-binary",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --secret-binary for non-UTF8 data; --secret-string for text.",
    "detail": "The --secret-binary flag allows storing arbitrary binary data, while --secret-string is for UTF-8 encoded text. Mixing them can cause retrieval or decoding errors.",
    "tags": [
      "secretsmanager",
      "data",
      "encoding"
    ]
  },
  {
    "id": "aws-042",
    "pattern": "^aws\\s+ec2\\s+modify-instance-attribute\\s+.*--instance-type",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Stop the instance before changing its type.",
    "detail": "Most instance types require the instance to be stopped before changing type. Attempting modification while running may fail silently or cause unexpected downtime.",
    "tags": [
      "ec2",
      "instance-type",
      "modification"
    ]
  },
  {
    "id": "aws-043",
    "pattern": "^aws\\s+s3\\s+cp\\s+.*--acl\\s+public-read",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Granting public-read exposes objects to the internet.",
    "detail": "Setting --acl public-read makes the object accessible to anyone with the URL. This can lead to data leaks if used unintentionally. Review object permissions and bucket policies regularly.",
    "tags": [
      "s3",
      "acl",
      "security"
    ]
  },
  {
    "id": "aws-044",
    "pattern": "^aws\\s+cloudwatch\\s+put-metric-data\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --timestamp to backfill or correct metric data.",
    "detail": "By default, put-metric-data uses the current time. The --timestamp flag allows you to specify historical or corrected data points, which is essential for accurate monitoring and reporting.",
    "tags": [
      "cloudwatch",
      "metrics",
      "timestamp"
    ]
  },
  {
    "id": "aws-045",
    "pattern": "^aws\\s+iam\\s+create-user\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Add tags at creation with --tags for better user tracking.",
    "detail": "Using --tags during user creation helps track ownership, purpose, or environment. Tags can be used for automation, billing, and compliance audits.",
    "tags": [
      "iam",
      "user",
      "tagging"
    ]
  },
  {
    "id": "aws-046",
    "pattern": "^aws\\s+ssm\\s+start-session\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --profile and --region to avoid connecting to wrong accounts.",
    "detail": "SSM sessions default to the current profile and region. Explicitly set these to prevent accidental access to production or test environments, especially in multi-account setups.",
    "tags": [
      "ssm",
      "session",
      "profiles"
    ]
  },
  {
    "id": "aws-047",
    "pattern": "^aws\\s+cloudformation\\s+validate-template\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Validate templates before deployment to catch syntax errors.",
    "detail": "The validate-template command checks for structural and syntax issues but does not verify resource existence or permissions. Use it as a first step before stack creation.",
    "tags": [
      "cloudformation",
      "template",
      "validation"
    ]
  },
  {
    "id": "aws-048",
    "pattern": "^aws\\s+ec2\\s+describe-volumes\\s+.*",
    "cmd": "aws",
    "severity": "tip",
    "hint": "Use --filters to find unattached EBS volumes for cleanup.",
    "detail": "Unattached EBS volumes incur charges. Filter by 'status=available' to list unused volumes, enabling cost-saving cleanup.",
    "tags": [
      "ec2",
      "ebs",
      "cleanup"
    ]
  },
  {
    "id": "aws-049",
    "pattern": "^aws\\s+s3\\s+sync\\s+.*--exclude\\s+\\*",
    "cmd": "aws",
    "severity": "warn",
    "hint": "Using --exclude '*' with no --include will sync nothing.",
    "detail": "The --exclude '*' pattern matches all files, so unless paired with --include for specific files, no data will be transferred. This can lead to silent sync failures.",
    "tags": [
      "s3",
      "sync",
      "footgun"
    ]
  },
  {
    "id": "aws-050",
    "pattern": "^aws\\s+configure\\s+import",
    "cmd": "aws",
    "severity": "upgrade",
    "hint": "Use 'aws configure import' to bulk load credentials from CSV.",
    "detail": "The 'import' subcommand allows importing multiple profiles from a CSV file, streamlining onboarding and credential management. This is more efficient than manual entry.",
    "tags": [
      "cli",
      "profiles",
      "upgrade"
    ]
  },
  {
    "id": "gcp-azure-001",
    "pattern": "^gcloud\\s+compute\\s+instances\\s+delete\\s+.*--quiet",
    "cmd": "gcloud",
    "severity": "danger",
    "hint": "Avoid --quiet with destructive commands; review resources first.",
    "detail": "Using --quiet with gcloud compute instances delete skips confirmation, risking accidental deletion of critical VMs. Always double-check instance names and consider omitting --quiet unless running in CI/CD with strict resource scoping.",
    "tags": [
      "gcloud",
      "danger",
      "compute",
      "deletion"
    ]
  },
  {
    "id": "gcp-azure-002",
    "pattern": "^gsutil\\s+rm\\s+-r\\s+gs://.*",
    "cmd": "gsutil",
    "severity": "danger",
    "hint": "gsutil rm -r deletes entire buckets irreversibly. Use with caution.",
    "detail": "gsutil rm -r recursively deletes all objects in a bucket, and the operation cannot be undone. There is no trash or recovery for GCS buckets; ensure you are targeting the correct bucket and consider using versioning for critical data.",
    "tags": [
      "gsutil",
      "danger",
      "gcs",
      "deletion"
    ]
  },
  {
    "id": "gcp-azure-003",
    "pattern": "^gcloud\\s+auth\\s+activate-service-account\\s+.*--key-file=.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "Never commit service account key files to source control.",
    "detail": "Service account keys grant full access to resources and are a common vector for credential leaks. Use Workload Identity or environment-based authentication when possible, and always add key files to .gitignore.",
    "tags": [
      "gcloud",
      "security",
      "service-account",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-004",
    "pattern": "^gcloud\\s+projects\\s+delete\\s+.*",
    "cmd": "gcloud",
    "severity": "danger",
    "hint": "Deleting a project removes all resources and billing. Triple-check ta...",
    "detail": "gcloud projects delete schedules all resources for deletion, including storage, compute, and IAM bindings. Recovery is only possible within a short window. Confirm project ID and consider using IAM policies to restrict this action.",
    "tags": [
      "gcloud",
      "danger",
      "project",
      "deletion"
    ]
  },
  {
    "id": "gcp-azure-005",
    "pattern": "^bq\\s+rm\\s+-r\\s+.*",
    "cmd": "bq",
    "severity": "danger",
    "hint": "bq rm -r deletes datasets and tables permanently. Confirm before runn...",
    "detail": "The -r flag recursively deletes datasets and their tables in BigQuery. There is no trash or undo. Always verify dataset names and consider exporting data before deletion.",
    "tags": [
      "bq",
      "danger",
      "bigquery",
      "deletion"
    ]
  },
  {
    "id": "gcp-azure-006",
    "pattern": "^az\\s+group\\s+delete\\s+.*--yes.*",
    "cmd": "az",
    "severity": "danger",
    "hint": "az group delete --yes destroys all resources in the group. Double-check.",
    "detail": "Deleting a resource group in Azure removes all contained resources, including VMs, storage, and networking. This is irreversible. Always validate the group contents and use tagging to prevent accidental deletion.",
    "tags": [
      "az",
      "danger",
      "azure",
      "resource-group"
    ]
  },
  {
    "id": "gcp-azure-007",
    "pattern": "^gcloud\\s+container\\s+clusters\\s+delete\\s+.*",
    "cmd": "gcloud",
    "severity": "danger",
    "hint": "Deleting GKE clusters removes all workloads and configs. Confirm first.",
    "detail": "gcloud container clusters delete will permanently remove the cluster, including all workloads, persistent disks, and node pools. There is no recovery. Backup critical data and review cluster contents before deletion.",
    "tags": [
      "gcloud",
      "danger",
      "gke",
      "kubernetes"
    ]
  },
  {
    "id": "gcp-azure-008",
    "pattern": "^az\\s+aks\\s+delete\\s+.*--yes.*",
    "cmd": "az",
    "severity": "danger",
    "hint": "az aks delete --yes removes the AKS cluster and all workloads.",
    "detail": "Deleting an AKS cluster destroys all associated resources, including node pools and persistent storage. Ensure you have exported any required data and reviewed the cluster's resource group before proceeding.",
    "tags": [
      "az",
      "danger",
      "aks",
      "kubernetes"
    ]
  },
  {
    "id": "gcp-azure-009",
    "pattern": "^gcloud\\s+run\\s+deploy\\s+.*--allow-unauthenticated",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "Avoid --allow-unauthenticated unless public access is intended.",
    "detail": "The --allow-unauthenticated flag exposes your Cloud Run service to the public internet. Only use this for endpoints meant to be public, and prefer IAM-based access for internal APIs.",
    "tags": [
      "gcloud",
      "cloud-run",
      "security",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-010",
    "pattern": "^az\\s+storage\\s+blob\\s+delete\\s+.*--account-key=.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "Avoid using --account-key on the CLI; prefer managed identities.",
    "detail": "Passing storage account keys via CLI exposes them in shell history and process lists. Use Azure AD authentication or managed identities for improved security and auditability.",
    "tags": [
      "az",
      "security",
      "storage",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-011",
    "pattern": "^gcloud\\s+auth\\s+login\\s+.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "gcloud auth login sets user credentials; may override service accounts.",
    "detail": "Running gcloud auth login sets user credentials as active, which can override service account authentication in CI/CD environments. Use gcloud auth activate-service-account for automation.",
    "tags": [
      "gcloud",
      "auth",
      "warn",
      "service-account"
    ]
  },
  {
    "id": "gcp-azure-012",
    "pattern": "^az\\s+login\\s+--use-device-code",
    "cmd": "az",
    "severity": "tip",
    "hint": "Use --use-device-code for headless or remote environments.",
    "detail": "The --use-device-code flag allows authentication in environments without a browser, such as SSH sessions or CI/CD runners. This method is more secure than storing credentials in scripts.",
    "tags": [
      "az",
      "auth",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-013",
    "pattern": "^gsutil\\s+cp\\s+.*gs://.*\\s+gs://.*",
    "cmd": "gsutil",
    "severity": "tip",
    "hint": "Use -m with gsutil cp for parallel transfers between buckets.",
    "detail": "The -m flag enables parallel (multi-threaded/multi-processing) transfers, significantly speeding up large copy operations between GCS buckets. This is especially useful for datasets with many small files.",
    "tags": [
      "gsutil",
      "performance",
      "tip",
      "gcs"
    ]
  },
  {
    "id": "gcp-azure-014",
    "pattern": "^bq\\s+query\\s+.*",
    "cmd": "bq",
    "severity": "tip",
    "hint": "Add --use_legacy_sql=false to ensure Standard SQL is used.",
    "detail": "By default, bq query may use legacy SQL, which lacks modern features and compatibility. Explicitly setting --use_legacy_sql=false ensures Standard SQL, which is recommended for new queries and better feature support.",
    "tags": [
      "bq",
      "bigquery",
      "sql",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-015",
    "pattern": "^az\\s+copy\\s+.*",
    "cmd": "az",
    "severity": "upgrade",
    "hint": "Use azcopy for high-performance Azure blob transfers.",
    "detail": "azcopy is a dedicated, multi-threaded tool optimized for large-scale Azure Blob Storage transfers. It outperforms the basic az copy command and supports advanced features like sync and resume.",
    "tags": [
      "az",
      "azcopy",
      "upgrade",
      "storage"
    ]
  },
  {
    "id": "gcp-azure-016",
    "pattern": "^gcloud\\s+compute\\s+scp\\s+.*",
    "cmd": "gcloud",
    "severity": "tip",
    "hint": "Use --compress with gcloud compute scp for faster transfers.",
    "detail": "The --compress flag enables SSH compression, which can significantly speed up file transfers over slow or high-latency links, especially for text-heavy files.",
    "tags": [
      "gcloud",
      "compute",
      "scp",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-017",
    "pattern": "^az\\s+ml\\s+run\\s+submit\\s+.*",
    "cmd": "az",
    "severity": "tip",
    "hint": "Use --no-wait to submit Azure ML runs asynchronously.",
    "detail": "The --no-wait flag allows your CLI session to return immediately after submitting a run, enabling parallel job submissions or scripting without blocking for job completion.",
    "tags": [
      "az",
      "azure-ml",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-018",
    "pattern": "^gcloud\\s+container\\s+clusters\\s+get-credentials\\s+.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "get-credentials overwrites kubeconfig; use --kubeconfig to avoid.",
    "detail": "By default, get-credentials writes to ~/.kube/config, potentially overwriting existing contexts. Use --kubeconfig to specify a different file and avoid disrupting other clusters' access.",
    "tags": [
      "gcloud",
      "gke",
      "kubeconfig",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-019",
    "pattern": "^az\\s+aks\\s+get-credentials\\s+.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "az aks get-credentials merges with kubeconfig; backup first.",
    "detail": "Merging credentials can introduce conflicts or overwrite existing contexts. Always backup your ~/.kube/config before running this command, especially in multi-cluster environments.",
    "tags": [
      "az",
      "aks",
      "kubeconfig",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-020",
    "pattern": "^gsutil\\s+rsync\\s+.*",
    "cmd": "gsutil",
    "severity": "tip",
    "hint": "Use -m with gsutil rsync for faster, parallel synchronization.",
    "detail": "The -m flag enables multi-threaded/multi-processing operations, greatly improving performance for large directory synchronizations between local and GCS or between buckets.",
    "tags": [
      "gsutil",
      "performance",
      "rsync",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-021",
    "pattern": "^az\\s+devops\\s+login\\s+--token\\s+.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "Never paste PAT tokens directly; use environment variables.",
    "detail": "Personal Access Tokens (PATs) can be captured in shell history or process lists. Store tokens in secure environment variables or use Azure Key Vault for automation.",
    "tags": [
      "az",
      "devops",
      "security",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-022",
    "pattern": "^gcloud\\s+config\\s+set\\s+project\\s+.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "Setting project globally affects all future gcloud commands.",
    "detail": "gcloud config set project changes the default project for all subsequent commands, which can lead to accidental resource creation or deletion in the wrong project. Use the --project flag for one-off commands.",
    "tags": [
      "gcloud",
      "config",
      "project",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-023",
    "pattern": "^az\\s+account\\s+set\\s+--subscription\\s+.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "Setting subscription globally may affect unrelated scripts.",
    "detail": "az account set changes the default subscription for all az commands in the current environment. Use --subscription per command to avoid cross-subscription mistakes.",
    "tags": [
      "az",
      "subscription",
      "config",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-024",
    "pattern": "^gcloud\\s+iam\\s+service-accounts\\s+keys\\s+create\\s+.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "Rotate service account keys regularly and audit usage.",
    "detail": "Service account keys are long-lived credentials. GCP recommends rotating keys frequently and monitoring their usage in Cloud Audit Logs. Prefer Workload Identity Federation for short-lived credentials.",
    "tags": [
      "gcloud",
      "iam",
      "service-account",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-025",
    "pattern": "^az\\s+ad\\s+sp\\s+create-for-rbac\\s+.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "Store appId and password securely; never hardcode in scripts.",
    "detail": "Service principal credentials grant broad access and should be treated as secrets. Use Azure Key Vault or environment variables to manage them securely.",
    "tags": [
      "az",
      "ad",
      "service-principal",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-026",
    "pattern": "^gcloud\\s+compute\\s+instances\\s+create\\s+.*--preemptible",
    "cmd": "gcloud",
    "severity": "tip",
    "hint": "Preemptible VMs are cost-effective but can be terminated anytime.",
    "detail": "Preemptible VMs offer significant cost savings but may be terminated after 24 hours or sooner if resources are needed. Use for stateless workloads and ensure your application can handle interruptions.",
    "tags": [
      "gcloud",
      "compute",
      "preemptible",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-027",
    "pattern": "^az\\s+vm\\s+create\\s+.*--priority\\s+Spot",
    "cmd": "az",
    "severity": "tip",
    "hint": "Spot VMs are cheaper but can be evicted at any time.",
    "detail": "Spot VMs provide cost savings but may be evicted with little notice. Use for fault-tolerant workloads and ensure your deployment can handle interruptions gracefully.",
    "tags": [
      "az",
      "vm",
      "spot",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-028",
    "pattern": "^gcloud\\s+beta\\s+.*",
    "cmd": "gcloud",
    "severity": "warn",
    "hint": "Beta commands may change or break; use in production with caution.",
    "detail": "gcloud beta exposes features that are not yet GA and may have breaking changes or lack support. Always test thoroughly before using in production workflows.",
    "tags": [
      "gcloud",
      "beta",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-029",
    "pattern": "^az\\s+extension\\s+add\\s+--name\\s+.*",
    "cmd": "az",
    "severity": "warn",
    "hint": "Azure CLI extensions may not be stable; review before installing.",
    "detail": "Extensions can introduce breaking changes or security issues. Only install trusted extensions and monitor for updates or deprecations.",
    "tags": [
      "az",
      "extension",
      "warn"
    ]
  },
  {
    "id": "gcp-azure-030",
    "pattern": "^gsutil\\s+cp\\s+.*--recursive",
    "cmd": "gsutil",
    "severity": "tip",
    "hint": "Combine -m and --recursive for efficient multi-file transfers.",
    "detail": "Using -m with --recursive enables parallel, recursive copying, which is much faster for large directories or buckets with many files.",
    "tags": [
      "gsutil",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-031",
    "pattern": "^az\\s+storage\\s+blob\\s+upload\\s+.*",
    "cmd": "az",
    "severity": "tip",
    "hint": "Use --max-connections for faster blob uploads.",
    "detail": "The --max-connections flag increases parallelism, speeding up large file uploads to Azure Blob Storage. Tune this value based on your network and CPU resources.",
    "tags": [
      "az",
      "storage",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-032",
    "pattern": "^gcloud\\s+functions\\s+deploy\\s+.*--runtime=python2.*",
    "cmd": "gcloud",
    "severity": "upgrade",
    "hint": "Python 2 is deprecated; use --runtime=python3.11 or higher.",
    "detail": "Python 2 is no longer supported in GCP Cloud Functions. Migrate to Python 3.11+ for security and compatibility. Update your code and dependencies accordingly.",
    "tags": [
      "gcloud",
      "functions",
      "upgrade",
      "python"
    ]
  },
  {
    "id": "gcp-azure-033",
    "pattern": "^az\\s+webapp\\s+up\\s+.*",
    "cmd": "az",
    "severity": "tip",
    "hint": "Use --sku for production-grade Azure Web Apps.",
    "detail": "The default SKU for az webapp up is often the free tier, which has resource and scaling limits. Specify --sku for higher performance and production workloads.",
    "tags": [
      "az",
      "webapp",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-034",
    "pattern": "^gcloud\\s+storage\\s+buckets\\s+create\\s+.*",
    "cmd": "gcloud",
    "severity": "tip",
    "hint": "Set --location and --storage-class for optimal performance.",
    "detail": "Choosing the right --location and --storage-class can reduce latency and cost. Regional buckets offer better performance for local workloads, while Nearline/Coldline classes are cost-effective for infrequent access.",
    "tags": [
      "gcloud",
      "storage",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-035",
    "pattern": "^az\\s+storage\\s+container\\s+create\\s+.*",
    "cmd": "az",
    "severity": "tip",
    "hint": "Set --public-access off unless you need anonymous blob access.",
    "detail": "By default, containers may allow public access. Use --public-access off to restrict access and prevent accidental data exposure.",
    "tags": [
      "az",
      "storage",
      "security",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-036",
    "pattern": "^gcloud\\s+run\\s+deploy\\s+.*--cpu-throttling",
    "cmd": "gcloud",
    "severity": "tip",
    "hint": "Tune --cpu-throttling for cost and performance in Cloud Run.",
    "detail": "Enabling CPU throttling reduces costs for idle containers but may impact cold start latency. Adjust this setting based on workload characteristics and performance requirements.",
    "tags": [
      "gcloud",
      "cloud-run",
      "performance",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-037",
    "pattern": "^az\\s+aks\\s+nodepool\\s+add\\s+.*",
    "cmd": "az",
    "severity": "tip",
    "hint": "Use --enable-cluster-autoscaler for dynamic scaling.",
    "detail": "Enabling cluster autoscaler allows AKS to automatically adjust node count based on workload demand, optimizing cost and resource utilization.",
    "tags": [
      "az",
      "aks",
      "autoscaler",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-038",
    "pattern": "^gcloud\\s+container\\s+clusters\\s+create\\s+.*--enable-autoscaling",
    "cmd": "gcloud",
    "severity": "tip",
    "hint": "Set --enable-autoscaling for efficient GKE resource usage.",
    "detail": "Autoscaling automatically adjusts node pool size based on pod demand, reducing manual intervention and optimizing costs. Tune min and max node counts for your workload.",
    "tags": [
      "gcloud",
      "gke",
      "autoscaler",
      "tip"
    ]
  },
  {
    "id": "gcp-azure-039",
    "pattern": "^az\\s+ml\\s+workspace\\s+delete\\s+.*--yes.*",
    "cmd": "az",
    "severity": "danger",
    "hint": "Deleting an ML workspace removes all experiments and assets.",
    "detail": "This action is irreversible and deletes all associated runs, models, and datasets. Backup critical artifacts before deleting an Azure ML workspace.",
    "tags": [
      "az",
      "ml",
      "danger",
      "deletion"
    ]
  },
  {
    "id": "gcp-azure-040",
    "pattern": "^gcloud\\s+iam\\s+roles\\s+delete\\s+.*",
    "cmd": "gcloud",
    "severity": "danger",
    "hint": "Deleting custom IAM roles may break dependent services.",
    "detail": "Removing a custom IAM role immediately revokes permissions for all users and service accounts assigned to it. Audit role usage before deletion to avoid service outages.",
    "tags": [
      "gcloud",
      "iam",
      "danger",
      "roles"
    ]
  },
  {
    "id": "terraform-001",
    "pattern": "^terraform\\s+destroy(\\s+|$)",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "Use -target to limit destroy scope and avoid full infra deletion.",
    "detail": "Running 'terraform destroy' without -target will destroy all managed resources in the current state, which can lead to irreversible data loss. Use '-target=resource.type.name' to limit destruction to specific resources. Always double-check the plan output before confirming.",
    "tags": [
      "destroy",
      "data-loss",
      "scope",
      "state"
    ]
  },
  {
    "id": "terraform-002",
    "pattern": "^terraform\\s+apply(\\s+|$)",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Always run 'terraform plan' before 'apply' to preview changes.",
    "detail": "Applying changes without first running 'terraform plan' can lead to unexpected infrastructure modifications, especially in collaborative environments. 'terraform plan' helps you review and verify the proposed changes, reducing the risk of accidental resource alteration or deletion.",
    "tags": [
      "apply",
      "plan",
      "preview",
      "best-practice"
    ]
  },
  {
    "id": "terraform-003",
    "pattern": "^terraform\\s+state\\s+rm\\s+",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "State rm removes tracking\u2014resource is unmanaged, not destroyed.",
    "detail": "'terraform state rm' detaches a resource from Terraform state but does not destroy the actual resource in the provider. This can lead to orphaned infrastructure that is no longer managed or tracked, potentially causing drift or security issues.",
    "tags": [
      "state",
      "rm",
      "orphan",
      "drift"
    ]
  },
  {
    "id": "terraform-004",
    "pattern": "^terraform\\s+import\\s+",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Import does not update config\u2014edit .tf files to match resource.",
    "detail": "'terraform import' only adds the resource to state; it does not create or update Terraform configuration files. If the resource configuration in .tf files does not match the actual resource, subsequent plans may attempt to modify or destroy it.",
    "tags": [
      "import",
      "state",
      "config",
      "drift"
    ]
  },
  {
    "id": "terraform-005",
    "pattern": "^terraform\\s+plan(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -detailed-exitcode for CI drift detection and automation.",
    "detail": "The '-detailed-exitcode' flag causes 'terraform plan' to return exit code 2 if there are changes, 0 if no changes, and 1 on error. This is essential for CI/CD pipelines to programmatically detect drift or pending changes.",
    "tags": [
      "plan",
      "ci",
      "drift",
      "automation"
    ]
  },
  {
    "id": "terraform-006",
    "pattern": "^terraform\\s+apply\\s+-auto-approve",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "Avoid -auto-approve in production\u2014review plans before applying.",
    "detail": "Using '-auto-approve' skips the interactive approval step, applying all changes without review. This can result in unintended or destructive modifications, especially in production environments. Always review the plan output before applying.",
    "tags": [
      "apply",
      "auto-approve",
      "production",
      "review"
    ]
  },
  {
    "id": "terraform-007",
    "pattern": "^terraform\\s+workspace\\s+select\\s+default",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Default workspace shares state\u2014use named workspaces for isolation.",
    "detail": "The 'default' workspace is shared and can lead to accidental resource overlap or state corruption. Named workspaces provide isolation for environments like dev, staging, and prod, preventing cross-environment interference.",
    "tags": [
      "workspace",
      "state",
      "isolation",
      "environments"
    ]
  },
  {
    "id": "terraform-008",
    "pattern": "^terraform\\s+init(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -upgrade to update provider and module versions automatically.",
    "detail": "The '-upgrade' flag forces Terraform to download the latest versions of providers and modules permitted by the configuration constraints. This ensures you are not using outdated dependencies, which may include bug fixes or security updates.",
    "tags": [
      "init",
      "upgrade",
      "providers",
      "modules"
    ]
  },
  {
    "id": "terraform-009",
    "pattern": "^terraform\\s+state\\s+push\\s+",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "State push can overwrite remote state\u2014risking loss of updates.",
    "detail": "'terraform state push' forcefully uploads a local state file to the remote backend, potentially overwriting concurrent changes made by others. This can cause loss of recent resource changes or state corruption in collaborative workflows.",
    "tags": [
      "state",
      "push",
      "remote",
      "collaboration"
    ]
  },
  {
    "id": "terraform-010",
    "pattern": "^terraform\\s+apply\\s+-refresh=false",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Skipping refresh may cause drift\u2014ensure state matches real infra.",
    "detail": "Using '-refresh=false' prevents Terraform from syncing state with the actual infrastructure before applying changes. This can result in plans based on stale or incorrect state, leading to drift or failed applies.",
    "tags": [
      "apply",
      "refresh",
      "drift",
      "state"
    ]
  },
  {
    "id": "terraform-011",
    "pattern": "^terraform\\s+plan\\s+-out(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Save plan output with -out for reproducible, auditable applies.",
    "detail": "The '-out' flag saves the plan to a binary file, which can then be used with 'terraform apply' to ensure that only the reviewed changes are applied. This is critical for audit trails and preventing drift between plan and apply steps.",
    "tags": [
      "plan",
      "out",
      "audit",
      "reproducibility"
    ]
  },
  {
    "id": "terraform-012",
    "pattern": "^terraform\\s+state\\s+mv\\s+",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "State mv only moves tracking\u2014update configs to match new address.",
    "detail": "'terraform state mv' changes the resource address in state but does not update configuration files. Failing to update .tf files can cause future plans to recreate or destroy resources unexpectedly.",
    "tags": [
      "state",
      "mv",
      "config",
      "drift"
    ]
  },
  {
    "id": "terraform-013",
    "pattern": "^terraform\\s+output(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -json for machine-readable outputs in scripts and CI.",
    "detail": "The '-json' flag outputs Terraform outputs in JSON format, making it easier to parse and consume in automation scripts or CI/CD pipelines. This avoids brittle text parsing and supports robust integrations.",
    "tags": [
      "output",
      "json",
      "automation",
      "ci"
    ]
  },
  {
    "id": "terraform-014",
    "pattern": "^terraform\\s+apply\\s+-parallelism\\s+\\d+",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Tune -parallelism for faster applies; default is 10 concurrent ops.",
    "detail": "The '-parallelism' flag controls the number of concurrent resource operations. Increasing this value can speed up applies for large infrastructures, but may overwhelm API rate limits or hit provider quotas.",
    "tags": [
      "apply",
      "parallelism",
      "performance",
      "scaling"
    ]
  },
  {
    "id": "terraform-015",
    "pattern": "^terraform\\s+plan\\s+-var-file=.+",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Ensure var-file is environment-specific to avoid config leaks.",
    "detail": "Using '-var-file' loads variable values from a file, which can inadvertently expose secrets or mix environment settings if not managed carefully. Always use dedicated var-files per environment and restrict sensitive data.",
    "tags": [
      "plan",
      "var-file",
      "secrets",
      "environments"
    ]
  },
  {
    "id": "terraform-016",
    "pattern": "^terraform\\s+destroy\\s+-target=.+",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Targeted destroy may leave dependencies orphaned\u2014review plan.",
    "detail": "Using '-target' with 'destroy' can delete a resource without cleaning up its dependencies, potentially leaving orphaned resources or breaking infrastructure relationships. Always review the plan output for unintended side effects.",
    "tags": [
      "destroy",
      "target",
      "dependencies",
      "orphan"
    ]
  },
  {
    "id": "terraform-017",
    "pattern": "^terraform\\s+init\\s+-backend-config=.+",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -backend-config for non-hardcoded backend secrets or URLs.",
    "detail": "The '-backend-config' flag allows you to supply backend settings (like credentials or endpoints) at runtime, keeping sensitive data out of version control and supporting environment-specific backends.",
    "tags": [
      "init",
      "backend",
      "secrets",
      "config"
    ]
  },
  {
    "id": "terraform-018",
    "pattern": "^terraform\\s+taint\\s+",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Taint marks resource for recreation\u2014use with caution in prod.",
    "detail": "'terraform taint' marks a resource as tainted, forcing its destruction and recreation on the next apply. This can cause downtime or data loss if used carelessly, especially on stateful or production resources.",
    "tags": [
      "taint",
      "recreation",
      "downtime",
      "production"
    ]
  },
  {
    "id": "terraform-019",
    "pattern": "^terraform\\s+refresh(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Refresh updates state from real infra\u2014use before plan for accuracy.",
    "detail": "'terraform refresh' syncs the state file with the actual infrastructure, ensuring that subsequent plans and applies are based on the latest resource status. This is especially useful after manual changes outside Terraform.",
    "tags": [
      "refresh",
      "state",
      "accuracy",
      "drift"
    ]
  },
  {
    "id": "terraform-020",
    "pattern": "^terraform\\s+force-unlock\\s+",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "Force-unlock can cause state corruption\u2014ensure no active operations.",
    "detail": "'terraform force-unlock' removes a state lock, potentially while another operation is still running. This can corrupt the state file or cause conflicting resource changes. Only use after verifying no other Terraform processes are active.",
    "tags": [
      "force-unlock",
      "state",
      "corruption",
      "concurrency"
    ]
  },
  {
    "id": "terraform-021",
    "pattern": "^terraform\\s+providers(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use providers lock file to pin versions and avoid drift.",
    "detail": "Terraform generates a '.terraform.lock.hcl' file to lock provider versions, ensuring reproducible builds and avoiding unexpected upgrades. Always commit this file to version control for team consistency.",
    "tags": [
      "providers",
      "lock",
      "versions",
      "reproducibility"
    ]
  },
  {
    "id": "terraform-022",
    "pattern": "^terraform\\s+state\\s+pull(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use state pull to debug or backup remote state safely.",
    "detail": "'terraform state pull' downloads the current state from the backend, allowing you to inspect or backup the state file without risking accidental overwrites. This is safer than manipulating state files directly.",
    "tags": [
      "state",
      "pull",
      "debug",
      "backup"
    ]
  },
  {
    "id": "terraform-023",
    "pattern": "^terraform\\s+plan\\s+-lock=false",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Disabling state lock risks concurrent changes\u2014avoid in teams.",
    "detail": "The '-lock=false' flag disables state locking, allowing multiple operations to run concurrently. This can cause state corruption or conflicting changes in collaborative environments. Use only for debugging or in isolated workflows.",
    "tags": [
      "plan",
      "lock",
      "concurrency",
      "state"
    ]
  },
  {
    "id": "terraform-024",
    "pattern": "^terraform\\s+apply\\s+-lock=false",
    "cmd": "terraform",
    "severity": "danger",
    "hint": "Never disable state lock on apply\u2014risk of state corruption.",
    "detail": "Applying changes without a state lock can result in simultaneous modifications to the state file, leading to corruption or resource drift. Always allow Terraform to manage state locks during applies.",
    "tags": [
      "apply",
      "lock",
      "danger",
      "corruption"
    ]
  },
  {
    "id": "terraform-025",
    "pattern": "^terraform\\s+plan\\s+-input=false",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Set all variables or plan will fail with -input=false.",
    "detail": "The '-input=false' flag disables interactive prompts for variables. If any required variables are unset, the plan will fail. Ensure all variables are set via files or environment variables.",
    "tags": [
      "plan",
      "input",
      "variables",
      "automation"
    ]
  },
  {
    "id": "terraform-026",
    "pattern": "^terraform\\s+apply\\s+-input=false",
    "cmd": "terraform",
    "severity": "warn",
    "hint": "Apply will fail if required variables are missing with -input=false.",
    "detail": "Disabling input prompts during apply is essential for automation, but all required variables must be set beforehand. Missing variables will cause the operation to fail without prompting.",
    "tags": [
      "apply",
      "input",
      "variables",
      "automation"
    ]
  },
  {
    "id": "terraform-027",
    "pattern": "^terraform\\s+plan\\s+-refresh-only",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -refresh-only to update state without proposing changes.",
    "detail": "'terraform plan -refresh-only' updates the state file to match real infrastructure, but does not propose any resource changes. This is useful for drift detection and state synchronization without risk of modification.",
    "tags": [
      "plan",
      "refresh-only",
      "drift",
      "state"
    ]
  },
  {
    "id": "terraform-028",
    "pattern": "^terraform\\s+state\\s+list(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use state list to audit managed resources and detect drift.",
    "detail": "'terraform state list' outputs all resources tracked in the current state file, helping you audit managed infrastructure and spot missing or orphaned resources.",
    "tags": [
      "state",
      "list",
      "audit",
      "drift"
    ]
  },
  {
    "id": "terraform-029",
    "pattern": "^terraform\\s+plan\\s+-compact-warnings",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Compact warnings for cleaner CI logs with -compact-warnings.",
    "detail": "The '-compact-warnings' flag reduces the verbosity of warning messages in plan output, making CI logs easier to read and less cluttered, especially in large projects.",
    "tags": [
      "plan",
      "warnings",
      "ci",
      "logs"
    ]
  },
  {
    "id": "terraform-030",
    "pattern": "^terraform\\s+apply\\s+-replace=.+",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -replace to force recreation of specific resources safely.",
    "detail": "The '-replace' flag marks a resource for recreation during apply, without tainting or modifying state manually. This is safer and more explicit than using 'taint', especially for stateless resources.",
    "tags": [
      "apply",
      "replace",
      "recreation",
      "safety"
    ]
  },
  {
    "id": "terraform-031",
    "pattern": "^terraform\\s+providers\\s+lock",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Run 'providers lock' to update the provider lock file explicitly.",
    "detail": "'terraform providers lock' updates the '.terraform.lock.hcl' file, ensuring provider versions are pinned and reproducible. This is especially useful after adding or upgrading providers.",
    "tags": [
      "providers",
      "lock",
      "versions",
      "reproducibility"
    ]
  },
  {
    "id": "terraform-032",
    "pattern": "^terraform\\s+validate(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Validate checks syntax and provider constraints before plan/apply.",
    "detail": "'terraform validate' ensures your configuration is syntactically valid and that provider requirements are met. This helps catch errors early, before running plan or apply, and is ideal for CI/CD pipelines.",
    "tags": [
      "validate",
      "syntax",
      "ci",
      "best-practice"
    ]
  },
  {
    "id": "terraform-033",
    "pattern": "^terraform\\s+console(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use console to interactively test expressions and outputs.",
    "detail": "'terraform console' provides a REPL for evaluating Terraform expressions, variables, and outputs, making it easier to debug and experiment with configuration logic.",
    "tags": [
      "console",
      "debug",
      "expressions",
      "outputs"
    ]
  },
  {
    "id": "terraform-034",
    "pattern": "^terraform\\s+graph(\\s+|$)",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Graph visualizes resource dependencies\u2014use with Graphviz for diagrams.",
    "detail": "'terraform graph' outputs a DOT format dependency graph of resources, which can be rendered with Graphviz to visualize infrastructure relationships and detect circular dependencies.",
    "tags": [
      "graph",
      "dependencies",
      "visualization",
      "debug"
    ]
  },
  {
    "id": "terraform-036",
    "pattern": "^terraform\\s+plan\\s+-no-color",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Use -no-color for machine-readable logs in CI pipelines.",
    "detail": "The '-no-color' flag disables ANSI color codes in output, making logs easier to parse in CI/CD systems and preventing issues with colorized output in log aggregators.",
    "tags": [
      "plan",
      "no-color",
      "ci",
      "logs"
    ]
  },
  {
    "id": "terraform-037",
    "pattern": "^terraform\\s+state\\s+replace-provider\\s+",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Replace-provider updates provider references in state after migration.",
    "detail": "'terraform state replace-provider' rewrites provider references in the state file, which is essential when migrating between provider sources or namespaces. This avoids state drift and provider mismatches.",
    "tags": [
      "state",
      "provider",
      "migration",
      "replace"
    ]
  },
  {
    "id": "terraform-038",
    "pattern": "^terraform\\s+plan\\s+-parallelism\\s+\\d+",
    "cmd": "terraform",
    "severity": "tip",
    "hint": "Increase -parallelism for faster planning on large infrastructures.",
    "detail": "The '-parallelism' flag also affects 'terraform plan', allowing more concurrent resource checks. This can significantly reduce planning time for large projects, but may increase API throttling risk.",
    "tags": [
      "plan",
      "parallelism",
      "performance",
      "scaling"
    ]
  },
  {
    "id": "terraform-039",
    "pattern": "^terragrunt\\s+run-all\\s+apply(\\s+|$)",
    "cmd": "terragrunt",
    "severity": "tip",
    "hint": "Use run-all for orchestrated multi-module applies with Terragrunt.",
    "detail": "'terragrunt run-all apply' applies changes across multiple modules in dependency order, streamlining complex infrastructure deployments. This avoids manual sequencing and reduces human error.",
    "tags": [
      "terragrunt",
      "run-all",
      "modules",
      "orchestration"
    ]
  },
  {
    "id": "terraform-040",
    "pattern": "^terraform\\s+module\\s+",
    "cmd": "terraform",
    "severity": "upgrade",
    "hint": "Use the 'terraform-bundle' or 'terraform-provider' for module packaging.",
    "detail": "For advanced module packaging and dependency management, consider using 'terraform-bundle' or custom provider plugins. These tools offer more control over module distribution and versioning than basic module sources.",
    "tags": [
      "module",
      "bundle",
      "provider",
      "upgrade"
    ]
  },
  {
    "id": "db-sql-001",
    "pattern": "^psql\\s+-c\\s+['\"]?DROP\\s+DATABASE['\"]?",
    "cmd": "psql",
    "severity": "danger",
    "hint": "Double-check before running DROP DATABASE; irreversible data loss.",
    "detail": "The DROP DATABASE command permanently deletes the database and all contained data. There is no undo, and active connections can block the drop. Always ensure you are connected to the correct server and database before executing.",
    "tags": [
      "data-loss",
      "psql",
      "danger"
    ]
  },
  {
    "id": "db-sql-002",
    "pattern": "^mysql\\s+-u\\s+\\w+\\s+-p\\s+.*--execute=['\"]?DROP\\s+DATABASE",
    "cmd": "mysql",
    "severity": "danger",
    "hint": "DROP DATABASE in MySQL is irreversible. Confirm target DB first.",
    "detail": "Executing DROP DATABASE in MySQL deletes all tables and data instantly. Ensure you are not connected to a production or critical environment. Consider using --safe-updates to prevent accidental mass changes.",
    "tags": [
      "mysql",
      "data-loss",
      "danger"
    ]
  },
  {
    "id": "db-sql-003",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?DROP\\s+TABLE",
    "cmd": "sqlite3",
    "severity": "danger",
    "hint": "DROP TABLE in SQLite is permanent. Backup before proceeding.",
    "detail": "SQLite does not support transactional DDL for DROP TABLE. Once dropped, the table and its data are unrecoverable unless you have a backup. Always verify the table name and database file.",
    "tags": [
      "sqlite3",
      "data-loss",
      "danger"
    ]
  },
  {
    "id": "db-sql-004",
    "pattern": "^psql\\s+.*--single-transaction.*-f\\s+",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Use --single-transaction with -f for atomic script execution.",
    "detail": "The --single-transaction flag wraps the entire script in a transaction, ensuring all statements succeed or none are applied. This is especially useful for schema migrations. Note: Some commands (e.g., CREATE DATABASE) cannot run inside a transaction block.",
    "tags": [
      "psql",
      "transactions",
      "tip"
    ]
  },
  {
    "id": "db-sql-005",
    "pattern": "^pg_dump\\s+.*-Fc",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use -Fc for custom-format dumps; enables parallel restore.",
    "detail": "The -Fc flag creates a custom-format archive, which is more flexible than plain SQL. It supports parallel restores with pg_restore -j, selective table restoration, and compression. Avoid plain text for large or critical backups.",
    "tags": [
      "pg_dump",
      "backup",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-006",
    "pattern": "^pg_restore\\s+.*-j\\s+\\d+",
    "cmd": "pg_restore",
    "severity": "tip",
    "hint": "Use -j for parallel restore; speeds up large database imports.",
    "detail": "The -j flag enables parallel jobs during restore, significantly reducing import time for large databases. Only works with custom-format (-Fc) dumps. Ensure the target server has sufficient resources to handle parallelism.",
    "tags": [
      "pg_restore",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-007",
    "pattern": "^psql\\s+.*-f\\s+\\S+",
    "cmd": "psql",
    "severity": "warn",
    "hint": "psql -f does not stop on errors unless ON_ERROR_STOP=1 is set.",
    "detail": "By default, psql -f continues executing subsequent commands even if one fails. Set the ON_ERROR_STOP variable or use --set=ON_ERROR_STOP=on to abort on the first error, preventing partial or inconsistent changes.",
    "tags": [
      "psql",
      "error-handling",
      "warn"
    ]
  },
  {
    "id": "db-sql-008",
    "pattern": "^mysql\\s+.*--skip-column-names",
    "cmd": "mysql",
    "severity": "tip",
    "hint": "Use --skip-column-names for scripting; output is easier to parse.",
    "detail": "The --skip-column-names flag omits header rows from query output, making it more suitable for shell scripting or CSV processing. Combine with -B for tab-separated output.",
    "tags": [
      "mysql",
      "scripting",
      "tip"
    ]
  },
  {
    "id": "db-sql-009",
    "pattern": "^psql\\s+.*-c\\s+['\"]?VACUUM",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Use VACUUM FULL for space reclamation; plain VACUUM only cleans.",
    "detail": "VACUUM reclaims dead tuples but does not shrink the physical file size. Use VACUUM FULL to compact the table and release disk space, but note it requires an exclusive lock and is slower.",
    "tags": [
      "psql",
      "maintenance",
      "tip"
    ]
  },
  {
    "id": "db-sql-010",
    "pattern": "^psql\\s+.*-c\\s+['\"]?ANALYZE",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Run ANALYZE after bulk loads to update query planner stats.",
    "detail": "ANALYZE collects statistics about table contents, helping the query planner choose optimal execution strategies. After large data imports or major updates, running ANALYZE ensures efficient query performance.",
    "tags": [
      "psql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-011",
    "pattern": "^psql\\s+.*-c\\s+['\"]?EXPLAIN\\s+ANALYZE",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Use EXPLAIN ANALYZE to get actual query execution times.",
    "detail": "EXPLAIN ANALYZE runs the query and provides real execution metrics, including timing and row counts. This is essential for diagnosing slow queries and understanding planner decisions. Beware: it actually executes the query.",
    "tags": [
      "psql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-012",
    "pattern": "^mysql\\s+.*--safe-updates",
    "cmd": "mysql",
    "severity": "tip",
    "hint": "Enable --safe-updates to prevent accidental mass data changes.",
    "detail": "The --safe-updates flag (also --i-am-a-dummy) restricts UPDATE and DELETE statements without a WHERE clause or LIMIT, reducing the risk of accidental data loss.",
    "tags": [
      "mysql",
      "safety",
      "tip"
    ]
  },
  {
    "id": "db-sql-013",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?PRAGMA\\s+foreign_keys=OFF",
    "cmd": "sqlite3",
    "severity": "warn",
    "hint": "Disabling foreign_keys in SQLite can silently break constraints.",
    "detail": "PRAGMA foreign_keys=OFF disables enforcement of foreign key constraints, which can lead to orphaned rows and data inconsistencies. Always re-enable after maintenance and verify data integrity.",
    "tags": [
      "sqlite3",
      "integrity",
      "warn"
    ]
  },
  {
    "id": "db-sql-014",
    "pattern": "^psql\\s+.*-c\\s+['\"]?BEGIN",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Wrap DML in BEGIN/COMMIT for atomic multi-step changes.",
    "detail": "Using BEGIN and COMMIT ensures that a series of data modifications are applied atomically. If an error occurs, you can ROLLBACK to revert all changes, preventing partial updates.",
    "tags": [
      "psql",
      "transactions",
      "tip"
    ]
  },
  {
    "id": "db-sql-015",
    "pattern": "^pg_dump\\s+.*--no-owner",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --no-owner when restoring to a different user or server.",
    "detail": "The --no-owner flag omits ownership commands from the dump, avoiding permission errors when restoring to a database where the original roles do not exist.",
    "tags": [
      "pg_dump",
      "migration",
      "tip"
    ]
  },
  {
    "id": "db-sql-016",
    "pattern": "^pg_dump\\s+.*--data-only",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --data-only to export just table data, not schema.",
    "detail": "The --data-only flag exports only the table contents, omitting schema definitions. Useful for refreshing data in an existing schema or partial restores.",
    "tags": [
      "pg_dump",
      "backup",
      "tip"
    ]
  },
  {
    "id": "db-sql-017",
    "pattern": "^pg_restore\\s+.*--list",
    "cmd": "pg_restore",
    "severity": "tip",
    "hint": "Use --list to see dump contents before restoring.",
    "detail": "The --list flag displays all objects in a custom-format dump file, allowing you to plan selective restores or verify backup completeness before proceeding.",
    "tags": [
      "pg_restore",
      "backup",
      "tip"
    ]
  },
  {
    "id": "db-sql-018",
    "pattern": "^mysql\\s+.*--defaults-file=\\S+",
    "cmd": "mysql",
    "severity": "warn",
    "hint": "Check --defaults-file path; wrong file can cause silent misconfig.",
    "detail": "The --defaults-file flag loads options from a specific config file. If the path is incorrect or missing required settings, connections or queries may fail silently or use unexpected credentials.",
    "tags": [
      "mysql",
      "config",
      "warn"
    ]
  },
  {
    "id": "db-sql-019",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+search_path=",
    "cmd": "psql",
    "severity": "warn",
    "hint": "Changing search_path affects table resolution; double-check schema.",
    "detail": "The search_path determines which schemas are searched for unqualified table names. Setting it incorrectly can cause queries to operate on the wrong tables, leading to subtle bugs.",
    "tags": [
      "psql",
      "schema",
      "warn"
    ]
  },
  {
    "id": "db-sql-020",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?PRAGMA\\s+journal_mode=OFF",
    "cmd": "sqlite3",
    "severity": "danger",
    "hint": "Disabling journaling risks corruption; avoid PRAGMA journal_mode=OFF.",
    "detail": "Turning off journaling in SQLite disables crash recovery, making the database highly susceptible to corruption on power loss or crashes. Use WAL or DELETE modes for safer operation.",
    "tags": [
      "sqlite3",
      "corruption",
      "danger"
    ]
  },
  {
    "id": "db-sql-021",
    "pattern": "^psql\\s+.*--no-password",
    "cmd": "psql",
    "severity": "warn",
    "hint": "Using --no-password can cause silent auth failures if password needed.",
    "detail": "The --no-password flag disables password prompts. If the server requires a password and none is provided via environment or .pgpass, the connection will fail without prompting, which can be hard to debug.",
    "tags": [
      "psql",
      "auth",
      "warn"
    ]
  },
  {
    "id": "db-sql-022",
    "pattern": "^mysql\\s+-u\\s+root\\s+-p",
    "cmd": "mysql",
    "severity": "warn",
    "hint": "Avoid using root for routine queries; use least-privilege accounts.",
    "detail": "Running queries as root increases risk of accidental schema or data changes. Always use dedicated users with minimal privileges for application or reporting access.",
    "tags": [
      "mysql",
      "security",
      "warn"
    ]
  },
  {
    "id": "db-sql-023",
    "pattern": "^psql\\s+.*-c\\s+['\"]?CREATE\\s+INDEX",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Use CONCURRENTLY for CREATE INDEX on large tables to avoid locks.",
    "detail": "CREATE INDEX CONCURRENTLY allows index creation without locking writes to the table, minimizing downtime. Note: Cannot run inside a transaction block and is slower than regular CREATE INDEX.",
    "tags": [
      "psql",
      "indexes",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-024",
    "pattern": "^psql\\s+.*-c\\s+['\"]?REINDEX",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Use REINDEX to fix bloat or corruption in indexes.",
    "detail": "REINDEX rebuilds indexes, which can resolve corruption or excessive bloat. It requires an exclusive lock on the table or index, so plan maintenance windows accordingly.",
    "tags": [
      "psql",
      "indexes",
      "maintenance",
      "tip"
    ]
  },
  {
    "id": "db-sql-025",
    "pattern": "^psql\\s+.*-c\\s+['\"]?CLUSTER",
    "cmd": "psql",
    "severity": "tip",
    "hint": "CLUSTER rewrites tables for better index locality; exclusive lock nee...",
    "detail": "The CLUSTER command physically reorders table data to match an index, improving locality for certain queries. It requires an exclusive lock and can be slow on large tables.",
    "tags": [
      "psql",
      "performance",
      "maintenance",
      "tip"
    ]
  },
  {
    "id": "db-sql-026",
    "pattern": "^pg_dump\\s+.*--exclude-table-data=\\S+",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --exclude-table-data to omit large or sensitive tables.",
    "detail": "The --exclude-table-data flag skips data for specified tables, useful for excluding logs or PII from backups while retaining schema definitions.",
    "tags": [
      "pg_dump",
      "backup",
      "privacy",
      "tip"
    ]
  },
  {
    "id": "db-sql-027",
    "pattern": "^mysql\\s+.*--ssl-mode=DISABLED",
    "cmd": "mysql",
    "severity": "danger",
    "hint": "Disabling SSL exposes credentials and data in transit.",
    "detail": "Setting --ssl-mode=DISABLED causes all traffic, including passwords, to be sent in plaintext. Only use on trusted, isolated networks. Prefer --ssl-mode=REQUIRED or higher for production.",
    "tags": [
      "mysql",
      "security",
      "danger"
    ]
  },
  {
    "id": "db-sql-028",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+statement_timeout=",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Set statement_timeout to prevent runaway queries.",
    "detail": "statement_timeout aborts queries that run longer than the specified duration, protecting against accidental long-running operations. Set per-session or per-query as needed.",
    "tags": [
      "psql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-029",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?PRAGMA\\s+synchronous=OFF",
    "cmd": "sqlite3",
    "severity": "danger",
    "hint": "PRAGMA synchronous=OFF risks data loss on power failure.",
    "detail": "Setting synchronous=OFF disables most disk syncs, improving speed but risking unrecoverable data loss if the system crashes or loses power. Use only for temporary or disposable databases.",
    "tags": [
      "sqlite3",
      "performance",
      "danger"
    ]
  },
  {
    "id": "db-sql-030",
    "pattern": "^psql\\s+.*-c\\s+['\"]?LOCK\\s+TABLE",
    "cmd": "psql",
    "severity": "warn",
    "hint": "LOCK TABLE blocks concurrent access; use sparingly.",
    "detail": "Explicitly locking tables can cause contention and block other sessions, leading to deadlocks or timeouts. Prefer row-level locks or advisory locks when possible.",
    "tags": [
      "psql",
      "concurrency",
      "warn"
    ]
  },
  {
    "id": "db-sql-031",
    "pattern": "^pg_dump\\s+.*--no-privileges",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --no-privileges to skip GRANT/REVOKE statements in dumps.",
    "detail": "The --no-privileges flag omits privilege commands, useful when restoring to environments with different user management or when sharing schema-only dumps.",
    "tags": [
      "pg_dump",
      "backup",
      "tip"
    ]
  },
  {
    "id": "db-sql-032",
    "pattern": "^mysql\\s+.*--max_allowed_packet=\\d+",
    "cmd": "mysql",
    "severity": "tip",
    "hint": "Increase --max_allowed_packet for large BLOB or import operations.",
    "detail": "The max_allowed_packet variable controls the largest packet size the server will accept. Too low a value can cause import failures or truncated BLOBs. Adjust as needed for your workload.",
    "tags": [
      "mysql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-033",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+work_mem=",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Increase work_mem for complex queries; revert after use.",
    "detail": "work_mem controls memory used for sorts and hashes before spilling to disk. Raising it can speed up large queries but risks exhausting server memory if set too high globally.",
    "tags": [
      "psql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-034",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+maintenance_work_mem=",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Raise maintenance_work_mem for faster index creation or vacuum.",
    "detail": "maintenance_work_mem is used for maintenance tasks like VACUUM, CREATE INDEX, and ALTER TABLE. Increasing it can significantly speed up these operations, but only set high for maintenance sessions.",
    "tags": [
      "psql",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-035",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+log_statement=",
    "cmd": "psql",
    "severity": "warn",
    "hint": "Enabling log_statement=all can fill logs rapidly; use with care.",
    "detail": "Setting log_statement to 'all' logs every statement, which is useful for debugging but can quickly fill disk space and impact performance. Use temporarily and monitor log volume.",
    "tags": [
      "psql",
      "logging",
      "warn"
    ]
  },
  {
    "id": "db-sql-036",
    "pattern": "^pg_dump\\s+.*--compress=\\d+",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --compress for smaller dumps; tradeoff: higher CPU usage.",
    "detail": "The --compress flag (with custom format) reduces dump file size, which is helpful for backups and transfers. Higher values increase CPU usage but yield better compression.",
    "tags": [
      "pg_dump",
      "backup",
      "performance",
      "tip"
    ]
  },
  {
    "id": "db-sql-037",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+autocommit=off",
    "cmd": "psql",
    "severity": "warn",
    "hint": "Postgres does not support SET autocommit; use BEGIN/COMMIT.",
    "detail": "Unlike MySQL, PostgreSQL does not have an autocommit setting. All statements are autocommitted unless wrapped in BEGIN/COMMIT. Using SET autocommit=off has no effect and may cause confusion.",
    "tags": [
      "psql",
      "transactions",
      "warn"
    ]
  },
  {
    "id": "db-sql-038",
    "pattern": "^mysql\\s+.*--init-command=",
    "cmd": "mysql",
    "severity": "tip",
    "hint": "Use --init-command to set session variables at connect time.",
    "detail": "The --init-command flag allows you to run SQL on connect, such as SET NAMES or custom session variables. Useful for scripting or enforcing session-level settings.",
    "tags": [
      "mysql",
      "config",
      "tip"
    ]
  },
  {
    "id": "db-sql-039",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+lock_timeout=",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Set lock_timeout to avoid waiting indefinitely for locks.",
    "detail": "lock_timeout aborts any statement that waits longer than the specified time for a lock, preventing sessions from hanging due to blocked resources.",
    "tags": [
      "psql",
      "concurrency",
      "tip"
    ]
  },
  {
    "id": "db-sql-040",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?PRAGMA\\s+auto_vacuum=FULL",
    "cmd": "sqlite3",
    "severity": "tip",
    "hint": "Enable auto_vacuum=FULL to reclaim space automatically.",
    "detail": "auto_vacuum=FULL causes SQLite to move data and shrink the database file as rows are deleted. It may impact write performance but prevents database bloat over time.",
    "tags": [
      "sqlite3",
      "maintenance",
      "tip"
    ]
  },
  {
    "id": "db-sql-041",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SELECT\\s+\\*\\s+FROM\\s+pg_stat_activity",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Monitor pg_stat_activity for blocking queries and connection leaks.",
    "detail": "pg_stat_activity shows all active sessions, queries, and wait states. Regularly checking it helps identify long-running or idle connections, which can exhaust resources or cause locks.",
    "tags": [
      "psql",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "db-sql-042",
    "pattern": "^pgbouncer\\s+.*--auth_type=plain",
    "cmd": "pgbouncer",
    "severity": "danger",
    "hint": "Avoid --auth_type=plain; use scram-sha-256 or md5 for security.",
    "detail": "plain authentication sends passwords in cleartext between client and pgbouncer. Use scram-sha-256 or md5 to prevent credential interception, especially on untrusted networks.",
    "tags": [
      "pgbouncer",
      "security",
      "danger"
    ]
  },
  {
    "id": "db-sql-043",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SET\\s+client_encoding=",
    "cmd": "psql",
    "severity": "warn",
    "hint": "Mismatched client_encoding can corrupt non-ASCII data.",
    "detail": "Setting client_encoding incorrectly can cause data corruption or unreadable characters in non-ASCII text. Always match client_encoding to your application's expected encoding.",
    "tags": [
      "psql",
      "encoding",
      "warn"
    ]
  },
  {
    "id": "db-sql-044",
    "pattern": "^mysql\\s+.*--local-infile=1",
    "cmd": "mysql",
    "severity": "danger",
    "hint": "Enabling --local-infile exposes server to file injection attacks.",
    "detail": "The --local-infile option allows clients to load local files into tables, which can be exploited if untrusted users have access. Disable unless absolutely necessary and restrict file paths.",
    "tags": [
      "mysql",
      "security",
      "danger"
    ]
  },
  {
    "id": "db-sql-045",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SELECT\\s+\\*\\s+FROM\\s+pg_indexes",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Query pg_indexes to audit and optimize index usage.",
    "detail": "pg_indexes provides metadata about all indexes in the database. Regularly reviewing it helps identify redundant or missing indexes, improving query performance.",
    "tags": [
      "psql",
      "indexes",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "db-sql-046",
    "pattern": "^pg_dump\\s+.*--section=pre-data",
    "cmd": "pg_dump",
    "severity": "tip",
    "hint": "Use --section to dump only schema (pre-data) or data sections.",
    "detail": "The --section flag allows selective dumping of schema (pre-data), data, or post-data (indexes, constraints). Useful for partial restores or schema-only migrations.",
    "tags": [
      "pg_dump",
      "backup",
      "tip"
    ]
  },
  {
    "id": "db-sql-047",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SELECT\\s+pg_is_in_recovery",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Check pg_is_in_recovery to distinguish standby from primary.",
    "detail": "pg_is_in_recovery() returns true on standby servers and false on primaries. Useful for scripts that need to detect replication roles or avoid writes on replicas.",
    "tags": [
      "psql",
      "replication",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "db-sql-048",
    "pattern": "^psql\\s+.*-c\\s+['\"]?SELECT\\s+pg_last_xact_replay_timestamp",
    "cmd": "psql",
    "severity": "tip",
    "hint": "Monitor replication lag with pg_last_xact_replay_timestamp.",
    "detail": "This function returns the timestamp of the last replayed transaction on a standby, allowing you to measure replication lag and monitor streaming replication health.",
    "tags": [
      "psql",
      "replication",
      "monitoring",
      "tip"
    ]
  },
  {
    "id": "db-sql-050",
    "pattern": "^sqlite3\\s+\\S+\\s+['\"]?VACUUM",
    "cmd": "sqlite3",
    "severity": "tip",
    "hint": "Run VACUUM to shrink SQLite files after large deletes.",
    "detail": "VACUUM rebuilds the database file, reclaiming unused space and defragmenting data. It can be slow and requires enough free disk space for a copy of the database.",
    "tags": [
      "sqlite3",
      "maintenance",
      "tip"
    ]
  },
  {
    "id": "db-nosql-001",
    "pattern": "^redis-cli\\s+FLUSHALL(\\s+--async)?\\s*$",
    "cmd": "redis-cli",
    "severity": "danger",
    "hint": "FLUSHALL deletes all keys in all databases. Use --async to avoid bloc...",
    "detail": "The FLUSHALL command irreversibly removes every key from every Redis database. Omitting --async blocks the server during deletion, which can cause downtime on large datasets. Always double-check the environment before running.",
    "tags": [
      "redis",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-002",
    "pattern": "^redis-cli\\s+CONFIG\\s+SET\\s+appendonly\\s+no\\s*$",
    "cmd": "redis-cli",
    "severity": "warn",
    "hint": "Disabling appendonly risks data loss after a crash. Use with caution.",
    "detail": "Turning off appendonly disables Redis's AOF persistence. If the server crashes, all data since the last RDB snapshot will be lost. Only disable for ephemeral caches or when absolutely necessary.",
    "tags": [
      "redis",
      "persistence",
      "data-loss"
    ]
  },
  {
    "id": "db-nosql-003",
    "pattern": "^mongosh\\s+--eval\\s+.*db\\.dropDatabase\\(\\).*",
    "cmd": "mongosh",
    "severity": "danger",
    "hint": "dropDatabase() deletes all collections in the database. Confirm targe...",
    "detail": "The dropDatabase() command removes the entire database, including all collections and data. There is no undo. Always verify the current database context with db before executing.",
    "tags": [
      "mongodb",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-004",
    "pattern": "^mongosh\\s+--host\\s+localhost\\s+--ssl\\s*$",
    "cmd": "mongosh",
    "severity": "warn",
    "hint": "Using --ssl without --tlsCAFile may silently skip validation.",
    "detail": "Specifying --ssl enables TLS, but without --tlsCAFile, mongosh may not verify the server certificate, risking MITM attacks. Always provide --tlsCAFile for secure connections.",
    "tags": [
      "mongodb",
      "security",
      "ssl"
    ]
  },
  {
    "id": "db-nosql-005",
    "pattern": "^cqlsh\\s+.*--ssl\\s*$",
    "cmd": "cqlsh",
    "severity": "warn",
    "hint": "--ssl alone does not verify certificates. Use --cqlshrc for CA config.",
    "detail": "The --ssl flag in cqlsh enables encryption but does not enforce certificate validation unless configured in ~/.cqlshrc. Without CA settings, connections are vulnerable to MITM.",
    "tags": [
      "cassandra",
      "security",
      "ssl"
    ]
  },
  {
    "id": "db-nosql-006",
    "pattern": "^cqlsh\\s+.*--request-timeout=\\d+\\s*$",
    "cmd": "cqlsh",
    "severity": "tip",
    "hint": "Increase --request-timeout for large queries to avoid timeouts.",
    "detail": "The default request timeout in cqlsh is 10 seconds. Complex or large queries may require a higher value to complete successfully, especially on busy clusters.",
    "tags": [
      "cassandra",
      "performance",
      "timeouts"
    ]
  },
  {
    "id": "db-nosql-007",
    "pattern": "^elasticsearch\\s+delete\\s+.*--index\\s+.*",
    "cmd": "elasticsearch",
    "severity": "danger",
    "hint": "Deleting an index is irreversible. Back up data first.",
    "detail": "The delete API in Elasticsearch permanently removes the specified index and all its documents. There is no built-in undo. Always snapshot important data before deletion.",
    "tags": [
      "elasticsearch",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-008",
    "pattern": "^elasticsearch\\s+bulk\\s+.*--refresh\\s+wait_for\\s*$",
    "cmd": "elasticsearch",
    "severity": "tip",
    "hint": "Use --refresh wait_for to ensure bulk data is immediately searchable.",
    "detail": "The --refresh wait_for option blocks until the bulk-inserted data is visible for search. This is useful for tests or scripts that need immediate consistency, but may impact performance.",
    "tags": [
      "elasticsearch",
      "consistency",
      "performance"
    ]
  },
  {
    "id": "db-nosql-009",
    "pattern": "^opensearch\\s+delete\\s+.*--index\\s+.*",
    "cmd": "opensearch",
    "severity": "danger",
    "hint": "Deleting an index in OpenSearch is permanent. Confirm index name.",
    "detail": "The delete API in OpenSearch irreversibly removes the index and all its data. Double-check the index name and consider taking a snapshot before proceeding.",
    "tags": [
      "opensearch",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-010",
    "pattern": "^clickhouse-client\\s+--query=\\\"DROP\\s+DATABASE.*\\\"",
    "cmd": "clickhouse-client",
    "severity": "danger",
    "hint": "DROP DATABASE deletes all tables and data. Use --if-exists to avoid e...",
    "detail": "DROP DATABASE removes the entire database and all contained tables. The --if-exists flag prevents errors if the database is missing, but does not prevent data loss. Always confirm the target.",
    "tags": [
      "clickhouse",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-011",
    "pattern": "^clickhouse-client\\s+--query=\\\"SELECT.*\\\"\\s*$",
    "cmd": "clickhouse-client",
    "severity": "tip",
    "hint": "Use --format=CSV or --format=JSON for easier data export.",
    "detail": "By default, clickhouse-client outputs in a human-readable table format. For scripting or data export, specify --format=CSV or --format=JSON for machine-friendly output.",
    "tags": [
      "clickhouse",
      "export",
      "format"
    ]
  },
  {
    "id": "db-nosql-012",
    "pattern": "^influx\\s+delete\\s+--org\\s+.*--bucket\\s+.*--start\\s+.*--stop\\s+.*",
    "cmd": "influx",
    "severity": "danger",
    "hint": "influx delete removes all points in the time range. Double-check bounds.",
    "detail": "The influx delete command irreversibly deletes all data points in the specified time range for the given bucket and org. Always verify the --start and --stop values before running.",
    "tags": [
      "influxdb",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-013",
    "pattern": "^influx\\s+write\\s+--file\\s+.*",
    "cmd": "influx",
    "severity": "tip",
    "hint": "Use --precision flag to match timestamp granularity in your data.",
    "detail": "The --precision flag (ns, us, ms, s) ensures timestamps in your input file are interpreted correctly. Mismatched precision can cause data to appear at the wrong time or be rejected.",
    "tags": [
      "influxdb",
      "import",
      "precision"
    ]
  },
  {
    "id": "db-nosql-014",
    "pattern": "^mongosh\\s+--eval\\s+.*db\\.dropCollection\\(.*\\).*",
    "cmd": "mongosh",
    "severity": "danger",
    "hint": "dropCollection() deletes all documents in the collection. Confirm name.",
    "detail": "dropCollection() removes the entire collection and all its documents. There is no undo. Ensure you are operating on the intended collection.",
    "tags": [
      "mongodb",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-015",
    "pattern": "^redis-cli\\s+MONITOR\\s*$",
    "cmd": "redis-cli",
    "severity": "warn",
    "hint": "MONITOR streams all commands and can impact performance on busy servers.",
    "detail": "MONITOR outputs every command processed by the Redis server in real time. On production or busy servers, this can cause significant performance degradation and expose sensitive data.",
    "tags": [
      "redis",
      "performance",
      "security"
    ]
  },
  {
    "id": "db-nosql-016",
    "pattern": "^redis-cli\\s+--scan\\s*$",
    "cmd": "redis-cli",
    "severity": "tip",
    "hint": "Use --pattern to limit scan results and avoid large keyspace traversal.",
    "detail": "The --scan option iterates over all keys, which can be slow on large databases. Use --pattern to filter keys and reduce load on the server.",
    "tags": [
      "redis",
      "performance",
      "scan"
    ]
  },
  {
    "id": "db-nosql-017",
    "pattern": "^mongosh\\s+--quiet\\s+.*",
    "cmd": "mongosh",
    "severity": "tip",
    "hint": "--quiet suppresses output, useful for scripts. Check for silent errors.",
    "detail": "The --quiet flag reduces output, making it suitable for automation. However, errors may not be visible unless explicitly handled. Always check exit codes or error logs.",
    "tags": [
      "mongodb",
      "scripting",
      "output"
    ]
  },
  {
    "id": "db-nosql-018",
    "pattern": "^cqlsh\\s+.*--execute\\s+.*DROP\\s+TABLE.*",
    "cmd": "cqlsh",
    "severity": "danger",
    "hint": "DROP TABLE deletes all data in the table. Use --if-exists to avoid er...",
    "detail": "DROP TABLE removes the table and its data permanently. The --if-exists clause prevents errors if the table is missing, but does not prevent data loss.",
    "tags": [
      "cassandra",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-019",
    "pattern": "^cqlsh\\s+.*--execute\\s+.*TRUNCATE.*",
    "cmd": "cqlsh",
    "severity": "danger",
    "hint": "TRUNCATE removes all rows from a table. No undo is possible.",
    "detail": "The TRUNCATE command deletes all data in the specified table, but retains the schema. This operation is irreversible and does not fire triggers.",
    "tags": [
      "cassandra",
      "data-loss",
      "dangerous"
    ]
  },
  {
    "id": "db-nosql-020",
    "pattern": "^elasticsearch\\s+.*--max-concurrent-searches=\\d+\\s*$",
    "cmd": "elasticsearch",
    "severity": "tip",
    "hint": "Tune --max-concurrent-searches for optimal parallel query performance.",
    "detail": "The --max-concurrent-searches flag controls the number of parallel searches. Setting it too high may overload nodes; too low underutilizes resources. Adjust based on cluster capacity.",
    "tags": [
      "elasticsearch",
      "performance",
      "tuning"
    ]
  },
  {
    "id": "db-nosql-021",
    "pattern": "^opensearch\\s+bulk\\s+.*--pipeline\\s+.*",
    "cmd": "opensearch",
    "severity": "tip",
    "hint": "Use --pipeline to preprocess documents during bulk ingest.",
    "detail": "The --pipeline flag enables ingest pipelines for transformation or enrichment of documents during bulk indexing. This can improve data quality and reduce post-processing.",
    "tags": [
      "opensearch",
      "ingest",
      "pipelines"
    ]
  },
  {
    "id": "db-nosql-022",
    "pattern": "^clickhouse-client\\s+--query=\\\"INSERT\\s+INTO.*\\\"\\s*$",
    "cmd": "clickhouse-client",
    "severity": "tip",
    "hint": "Use --max_insert_threads for parallel inserts to boost throughput.",
    "detail": "The --max_insert_threads flag allows parallel processing of insert statements, significantly improving ingestion speed on multi-core systems.",
    "tags": [
      "clickhouse",
      "performance",
      "insert"
    ]
  },
  {
    "id": "db-nosql-023",
    "pattern": "^influx\\s+query\\s+.*--type=flux\\s*$",
    "cmd": "influx",
    "severity": "upgrade",
    "hint": "Flux is the modern query language; migrate from InfluxQL for new feat...",
    "detail": "Flux offers advanced data transformation and analytics capabilities compared to InfluxQL. For new projects or advanced queries, prefer --type=flux.",
    "tags": [
      "influxdb",
      "upgrade",
      "flux"
    ]
  },
  {
    "id": "db-nosql-024",
    "pattern": "^mongosh\\s+.*--username\\s+.*--password\\s+.*",
    "cmd": "mongosh",
    "severity": "warn",
    "hint": "Passing passwords on the command line can leak secrets. Use env vars.",
    "detail": "Supplying --password exposes credentials in process listings and shell history. Use environment variables or prompt for passwords to avoid accidental leaks.",
    "tags": [
      "mongodb",
      "security",
      "credentials"
    ]
  },
  {
    "id": "db-nosql-025",
    "pattern": "^redis-cli\\s+--rdb\\s+.*",
    "cmd": "redis-cli",
    "severity": "tip",
    "hint": "Use --rdb to create a portable RDB snapshot for backup or migration.",
    "detail": "The --rdb flag generates a binary dump of the database, which can be restored on another server. This is useful for backups or migrating data between Redis instances.",
    "tags": [
      "redis",
      "backup",
      "migration"
    ]
  },
  {
    "id": "db-nosql-026",
    "pattern": "^cqlsh\\s+.*--color\\s+never\\s*$",
    "cmd": "cqlsh",
    "severity": "tip",
    "hint": "Disable color output with --color never for script-friendly output.",
    "detail": "The --color never flag disables ANSI color codes, making output easier to parse in scripts or logs. Useful for automation and CI pipelines.",
    "tags": [
      "cassandra",
      "output",
      "scripting"
    ]
  },
  {
    "id": "db-nosql-027",
    "pattern": "^elasticsearch\\s+.*--sniff\\s*$",
    "cmd": "elasticsearch",
    "severity": "warn",
    "hint": "--sniff can break if nodes are behind NAT or load balancers.",
    "detail": "The --sniff option discovers cluster nodes, but can fail if nodes report private or unreachable addresses. Disable sniffing in cloud or NATed environments.",
    "tags": [
      "elasticsearch",
      "networking",
      "sniff"
    ]
  },
  {
    "id": "db-nosql-028",
    "pattern": "^opensearch\\s+.*--no-verify-ssl\\s*$",
    "cmd": "opensearch",
    "severity": "warn",
    "hint": "--no-verify-ssl disables certificate validation. Avoid in production.",
    "detail": "Disabling SSL verification exposes clients to MITM attacks. Only use --no-verify-ssl for debugging or trusted test environments.",
    "tags": [
      "opensearch",
      "security",
      "ssl"
    ]
  },
  {
    "id": "db-nosql-029",
    "pattern": "^clickhouse-client\\s+.*--secure\\s*$",
    "cmd": "clickhouse-client",
    "severity": "warn",
    "hint": "--secure enables TLS, but verify server certificates for safety.",
    "detail": "The --secure flag encrypts traffic, but does not validate server certificates unless configured. Set --host and --ca-file to enforce validation.",
    "tags": [
      "clickhouse",
      "security",
      "ssl"
    ]
  },
  {
    "id": "db-nosql-030",
    "pattern": "^influx\\s+backup\\s+.*--full\\s*$",
    "cmd": "influx",
    "severity": "tip",
    "hint": "Use --full for a complete backup, including metadata and data.",
    "detail": "The --full flag ensures all data, metadata, and schema are included in the backup. Without it, only incremental or partial data may be saved.",
    "tags": [
      "influxdb",
      "backup",
      "full"
    ]
  },
  {
    "id": "db-nosql-031",
    "pattern": "^mongosh\\s+.*--host\\s+.*--tlsAllowInvalidCertificates\\s*$",
    "cmd": "mongosh",
    "severity": "warn",
    "hint": "--tlsAllowInvalidCertificates skips certificate validation. Risky!",
    "detail": "This flag allows connections to servers with invalid or self-signed certificates, exposing clients to MITM. Use only in trusted test environments.",
    "tags": [
      "mongodb",
      "security",
      "ssl"
    ]
  },
  {
    "id": "db-nosql-032",
    "pattern": "^redis-cli\\s+--pipe\\s*$",
    "cmd": "redis-cli",
    "severity": "tip",
    "hint": "Use --pipe for high-throughput bulk imports. Format input carefully.",
    "detail": "The --pipe mode enables efficient mass insertion using the Redis protocol. Input must be in raw protocol format; errors are not always reported per command.",
    "tags": [
      "redis",
      "performance",
      "import"
    ]
  },
  {
    "id": "db-nosql-033",
    "pattern": "^cqlsh\\s+.*--debug\\s*$",
    "cmd": "cqlsh",
    "severity": "tip",
    "hint": "Enable --debug for verbose output to troubleshoot connection issues.",
    "detail": "The --debug flag prints detailed logs, including protocol exchanges and errors. Useful for diagnosing authentication or network problems.",
    "tags": [
      "cassandra",
      "debug",
      "troubleshooting"
    ]
  },
  {
    "id": "db-nosql-034",
    "pattern": "^elasticsearch\\s+.*--output\\s+table\\s*$",
    "cmd": "elasticsearch",
    "severity": "tip",
    "hint": "Use --output json for machine-readable results in scripts.",
    "detail": "The default table output is for human readability. For automation or parsing, --output json is preferable.",
    "tags": [
      "elasticsearch",
      "output",
      "scripting"
    ]
  },
  {
    "id": "db-nosql-035",
    "pattern": "^opensearch\\s+.*--profile\\s+.*",
    "cmd": "opensearch",
    "severity": "tip",
    "hint": "Use --profile to analyze query performance bottlenecks.",
    "detail": "The --profile flag provides detailed timing and resource usage for queries, helping identify slow stages or inefficient operations.",
    "tags": [
      "opensearch",
      "performance",
      "profiling"
    ]
  },
  {
    "id": "db-nosql-036",
    "pattern": "^clickhouse-client\\s+--query=\\\"OPTIMIZE\\s+TABLE.*\\\"\\s*$",
    "cmd": "clickhouse-client",
    "severity": "tip",
    "hint": "OPTIMIZE TABLE merges parts for faster queries. Schedule during off-p...",
    "detail": "OPTIMIZE TABLE merges data parts, improving read performance but consuming significant resources. Run during low-traffic periods to avoid impacting users.",
    "tags": [
      "clickhouse",
      "performance",
      "maintenance"
    ]
  },
  {
    "id": "db-nosql-037",
    "pattern": "^influx\\s+restore\\s+.*--full\\s*$",
    "cmd": "influx",
    "severity": "tip",
    "hint": "Use --full to restore all metadata and data from a backup.",
    "detail": "The --full flag ensures that both data and metadata are restored, preserving database structure and retention policies. Without it, only partial data may be recovered.",
    "tags": [
      "influxdb",
      "restore",
      "full"
    ]
  },
  {
    "id": "db-nosql-038",
    "pattern": "^mongosh\\s+.*--host\\s+.*--authenticationDatabase\\s+admin\\s*$",
    "cmd": "mongosh",
    "severity": "tip",
    "hint": "Use --authenticationDatabase when authenticating as admin user.",
    "detail": "Specifying --authenticationDatabase is required when the user exists in a different database than the one being accessed. This is common for admin users.",
    "tags": [
      "mongodb",
      "authentication",
      "admin"
    ]
  },
  {
    "id": "db-nosql-039",
    "pattern": "^redis-cli\\s+--cluster\\s+reshard\\s+.*",
    "cmd": "redis-cli",
    "severity": "danger",
    "hint": "Resharding moves slots and can cause data loss if interrupted.",
    "detail": "The --cluster reshard command redistributes hash slots among nodes. If interrupted, data may be lost or cluster state may become inconsistent. Always back up before resharding.",
    "tags": [
      "redis",
      "cluster",
      "reshard"
    ]
  },
  {
    "id": "db-nosql-040",
    "pattern": "^cqlsh\\s+.*--no-color\\s*$",
    "cmd": "cqlsh",
    "severity": "tip",
    "hint": "Use --no-color for plain output in logs or scripts.",
    "detail": "The --no-color flag disables colored output, making logs and script parsing more reliable. Useful for CI/CD pipelines and automated tooling.",
    "tags": [
      "cassandra",
      "output",
      "scripting"
    ]
  },
  {
    "id": "node-001",
    "pattern": "^npm\\s+install\\s+-g\\s+",
    "cmd": "npm",
    "severity": "warn",
    "hint": "Prefer npx or local installs over global npm -g installs.",
    "detail": "Global npm installs can cause version conflicts and require sudo, leading to permission issues. Use npx for one-off executions or add dependencies locally to avoid polluting the global namespace.",
    "tags": [
      "npm",
      "global",
      "best-practices"
    ]
  },
  {
    "id": "node-002",
    "pattern": "^npm\\s+install(\\s+|$)",
    "cmd": "npm",
    "severity": "tip",
    "hint": "Use --frozen-lockfile or ci for reproducible installs.",
    "detail": "npm install may update your package-lock.json, causing drift from CI. Use npm ci or --frozen-lockfile to ensure exact dependency versions, matching your lockfile and avoiding surprises.",
    "tags": [
      "npm",
      "install",
      "ci"
    ]
  },
  {
    "id": "node-003",
    "pattern": "^npm\\s+run\\s+",
    "cmd": "npm",
    "severity": "tip",
    "hint": "Add --if-present to skip missing scripts without error.",
    "detail": "By default, npm run fails if the script is missing. The --if-present flag allows scripts to be optional, which is useful in monorepos or multi-environment setups.",
    "tags": [
      "npm",
      "scripts",
      "flags"
    ]
  },
  {
    "id": "node-004",
    "pattern": "^npm\\s+publish(\\s|$)",
    "cmd": "npm",
    "severity": "danger",
    "hint": "Double-check registry and .npmrc before publishing.",
    "detail": "npm publish will push your package to the configured registry, which may be public by default. Always verify your .npmrc and registry settings to avoid leaking private code.",
    "tags": [
      "npm",
      "publish",
      "security"
    ]
  },
  {
    "id": "node-005",
    "pattern": "^npm\\s+install\\s+.*--save",
    "cmd": "npm",
    "severity": "upgrade",
    "hint": "Omit --save; it's the default since npm 5.0.0.",
    "detail": "The --save flag is redundant in modern npm versions, as dependencies are saved by default. Removing it cleans up your command usage and avoids confusion.",
    "tags": [
      "npm",
      "flags",
      "upgrade"
    ]
  },
  {
    "id": "node-006",
    "pattern": "^npm\\s+update(\\s|$)",
    "cmd": "npm",
    "severity": "warn",
    "hint": "npm update ignores devDependencies by default.",
    "detail": "npm update only updates dependencies, not devDependencies unless explicitly named. To update devDependencies, specify them or use npm-check-updates for broader coverage.",
    "tags": [
      "npm",
      "update",
      "dependencies"
    ]
  },
  {
    "id": "node-007",
    "pattern": "^npm\\s+install\\s+.*--legacy-peer-deps",
    "cmd": "npm",
    "severity": "warn",
    "hint": "Avoid --legacy-peer-deps unless absolutely necessary.",
    "detail": "This flag bypasses peer dependency conflicts, potentially causing runtime errors. Prefer resolving peer dependencies properly to ensure compatibility.",
    "tags": [
      "npm",
      "peer-deps",
      "install"
    ]
  },
  {
    "id": "node-008",
    "pattern": "^npm\\s+cache\\s+clean(\\s|$)",
    "cmd": "npm",
    "severity": "tip",
    "hint": "Use --force with npm cache clean for full cache removal.",
    "detail": "npm cache clean requires the --force flag to actually remove the cache. Without it, the command is a no-op for safety reasons.",
    "tags": [
      "npm",
      "cache",
      "flags"
    ]
  },
  {
    "id": "node-009",
    "pattern": "^npx\\s+",
    "cmd": "npx",
    "severity": "tip",
    "hint": "Use --no-install to avoid auto-installing missing packages.",
    "detail": "npx will install missing packages by default, which can be slow and unexpected. Use --no-install to restrict to locally available binaries and prevent network calls.",
    "tags": [
      "npx",
      "flags",
      "performance"
    ]
  },
  {
    "id": "node-010",
    "pattern": "^npx\\s+.*-p\\s+",
    "cmd": "npx",
    "severity": "warn",
    "hint": "npx -p installs packages globally for the session.",
    "detail": "Using -p with npx installs packages temporarily, but they persist for the session. This can pollute your environment and cause version mismatches if not managed carefully.",
    "tags": [
      "npx",
      "install",
      "environment"
    ]
  },
  {
    "id": "node-011",
    "pattern": "^yarn\\s+install(\\s|$)",
    "cmd": "yarn",
    "severity": "tip",
    "hint": "Use --frozen-lockfile for deterministic installs in CI.",
    "detail": "yarn install can update yarn.lock unless --frozen-lockfile is set. This flag ensures the install matches the lockfile exactly, preventing accidental drift.",
    "tags": [
      "yarn",
      "install",
      "ci"
    ]
  },
  {
    "id": "node-012",
    "pattern": "^yarn\\s+global\\s+add\\s+",
    "cmd": "yarn",
    "severity": "warn",
    "hint": "Global yarn installs can conflict with local dependencies.",
    "detail": "yarn global add installs binaries globally, which can mask or conflict with project-local versions. Prefer npx or local installs for project consistency.",
    "tags": [
      "yarn",
      "global",
      "dependencies"
    ]
  },
  {
    "id": "node-013",
    "pattern": "^yarn\\s+add\\s+.*--dev.*--peer",
    "cmd": "yarn",
    "severity": "warn",
    "hint": "Don't mix --dev and --peer; peerDeps must be regular deps.",
    "detail": "A dependency cannot be both dev and peer. Peer dependencies should be regular dependencies, while devDependencies are for build/test tools.",
    "tags": [
      "yarn",
      "dependencies",
      "peer"
    ]
  },
  {
    "id": "node-014",
    "pattern": "^yarn\\s+upgrade\\s+",
    "cmd": "yarn",
    "severity": "tip",
    "hint": "Use --latest to upgrade to the newest versions.",
    "detail": "yarn upgrade upgrades dependencies within the version ranges in package.json. Use --latest to ignore version ranges and get the newest versions available.",
    "tags": [
      "yarn",
      "upgrade",
      "dependencies"
    ]
  },
  {
    "id": "node-015",
    "pattern": "^pnpm\\s+install(\\s|$)",
    "cmd": "pnpm",
    "severity": "tip",
    "hint": "Use --frozen-lockfile for reproducible installs in CI.",
    "detail": "pnpm install can update pnpm-lock.yaml unless --frozen-lockfile is used. This ensures the install matches the lockfile exactly, preventing accidental changes.",
    "tags": [
      "pnpm",
      "install",
      "ci"
    ]
  },
  {
    "id": "node-016",
    "pattern": "^pnpm\\s+add\\s+.*--global",
    "cmd": "pnpm",
    "severity": "warn",
    "hint": "Global pnpm installs can mask local dependencies.",
    "detail": "pnpm add --global installs binaries globally, which can conflict with project-local versions and lead to unexpected behavior. Prefer local installs when possible.",
    "tags": [
      "pnpm",
      "global",
      "dependencies"
    ]
  },
  {
    "id": "node-017",
    "pattern": "^pnpm\\s+install\\s+.*--shamefully-hoist",
    "cmd": "pnpm",
    "severity": "warn",
    "hint": "Use --shamefully-hoist only for legacy compatibility.",
    "detail": "This flag flattens node_modules, breaking pnpm's isolation model. Use it only if you have dependencies that require a flat node_modules structure.",
    "tags": [
      "pnpm",
      "install",
      "compatibility"
    ]
  },
  {
    "id": "node-018",
    "pattern": "^pnpm\\s+update(\\s|$)",
    "cmd": "pnpm",
    "severity": "tip",
    "hint": "Use --latest to upgrade all dependencies to newest versions.",
    "detail": "pnpm update without --latest only updates within semver ranges. Use --latest to upgrade to the newest versions, potentially updating your lockfile and package.json.",
    "tags": [
      "pnpm",
      "update",
      "dependencies"
    ]
  },
  {
    "id": "node-019",
    "pattern": "^node\\s+.*\\.ts(\\s|$)",
    "cmd": "node",
    "severity": "warn",
    "hint": "node can't run TypeScript files directly; use ts-node.",
    "detail": "node does not understand TypeScript syntax. Use ts-node or compile your .ts files to .js before running with node.",
    "tags": [
      "node",
      "typescript",
      "ts-node"
    ]
  },
  {
    "id": "node-020",
    "pattern": "^node\\s+.*--inspect-brk",
    "cmd": "node",
    "severity": "tip",
    "hint": "Use --inspect-brk for debugging from the first line.",
    "detail": "The --inspect-brk flag pauses execution on the first line, allowing you to attach a debugger before any code runs. Useful for debugging initialization code.",
    "tags": [
      "node",
      "debug",
      "inspect"
    ]
  },
  {
    "id": "node-021",
    "pattern": "^node\\s+.*--max-old-space-size=\\d+",
    "cmd": "node",
    "severity": "tip",
    "hint": "Tune --max-old-space-size for memory-intensive workloads.",
    "detail": "This flag sets the V8 heap size in MB. Increasing it can prevent out-of-memory errors for large builds or data processing, but may impact GC performance.",
    "tags": [
      "node",
      "memory",
      "performance"
    ]
  },
  {
    "id": "node-022",
    "pattern": "^nvm\\s+install\\s+node",
    "cmd": "nvm",
    "severity": "tip",
    "hint": "nvm install node always installs the latest version.",
    "detail": "The alias 'node' refers to the latest available Node.js version. For reproducibility, specify an explicit version number.",
    "tags": [
      "nvm",
      "node",
      "versions"
    ]
  },
  {
    "id": "node-023",
    "pattern": "^nvm\\s+use\\s+system",
    "cmd": "nvm",
    "severity": "warn",
    "hint": "nvm use system may not work if system node is not in PATH.",
    "detail": "If your system node is installed outside standard locations, nvm may fail to find it. Ensure your PATH includes the system node binary.",
    "tags": [
      "nvm",
      "node",
      "environment"
    ]
  },
  {
    "id": "node-024",
    "pattern": "^ts-node\\s+.*--transpile-only",
    "cmd": "ts-node",
    "severity": "tip",
    "hint": "Use --transpile-only for faster TypeScript execution.",
    "detail": "This flag skips type checking, greatly speeding up execution. Use it for scripts where type safety is not critical or already checked in CI.",
    "tags": [
      "ts-node",
      "typescript",
      "performance"
    ]
  },
  {
    "id": "node-025",
    "pattern": "^ts-node\\s+.*--files",
    "cmd": "ts-node",
    "severity": "warn",
    "hint": "Use --files if your tsconfig excludes files by default.",
    "detail": "By default, ts-node only includes files referenced in the entry point. --files loads all files specified in tsconfig, which is necessary for some setups.",
    "tags": [
      "ts-node",
      "typescript",
      "config"
    ]
  },
  {
    "id": "node-026",
    "pattern": "^eslint\\s+.*--fix",
    "cmd": "eslint",
    "severity": "tip",
    "hint": "Use --fix to auto-correct fixable lint errors.",
    "detail": "The --fix flag automatically corrects many common linting issues. Review changes before committing, as some fixes may be stylistic or incomplete.",
    "tags": [
      "eslint",
      "lint",
      "fix"
    ]
  },
  {
    "id": "node-027",
    "pattern": "^eslint\\s+.*--max-warnings=0",
    "cmd": "eslint",
    "severity": "tip",
    "hint": "Set --max-warnings=0 to fail CI on any lint warnings.",
    "detail": "This flag causes eslint to exit with code 1 if any warnings are found, enforcing strict linting in CI pipelines.",
    "tags": [
      "eslint",
      "ci",
      "lint"
    ]
  },
  {
    "id": "node-028",
    "pattern": "^prettier\\s+.*--write",
    "cmd": "prettier",
    "severity": "tip",
    "hint": "Use --check to verify formatting without writing files.",
    "detail": "The --check flag lets you verify code formatting in CI without modifying files, making it suitable for pre-commit or CI checks.",
    "tags": [
      "prettier",
      "format",
      "ci"
    ]
  },
  {
    "id": "node-029",
    "pattern": "^vitest\\s+run(\\s|$)",
    "cmd": "vitest",
    "severity": "tip",
    "hint": "Use --threads for parallel test execution.",
    "detail": "The --threads flag enables parallel test running, significantly speeding up large test suites. Adjust thread count based on CPU cores for optimal performance.",
    "tags": [
      "vitest",
      "test",
      "performance"
    ]
  },
  {
    "id": "node-030",
    "pattern": "^vitest\\s+watch(\\s|$)",
    "cmd": "vitest",
    "severity": "tip",
    "hint": "Use --changed to only watch and run changed tests.",
    "detail": "The --changed flag restricts watch mode to only run tests affected by recent changes, reducing feedback time during development.",
    "tags": [
      "vitest",
      "test",
      "watch"
    ]
  },
  {
    "id": "node-031",
    "pattern": "^jest\\s+.*--runInBand",
    "cmd": "jest",
    "severity": "tip",
    "hint": "Use --runInBand for debugging or CI environments.",
    "detail": "This flag runs tests serially in a single process, which can help with debugging or resource-constrained CI runners. It may slow down large test suites.",
    "tags": [
      "jest",
      "test",
      "ci"
    ]
  },
  {
    "id": "node-032",
    "pattern": "^jest\\s+.*--maxWorkers=\\d+",
    "cmd": "jest",
    "severity": "tip",
    "hint": "Tune --maxWorkers for optimal parallel test performance.",
    "detail": "Setting --maxWorkers controls the number of parallel test workers. Adjust based on your CPU and memory to avoid resource contention or underutilization.",
    "tags": [
      "jest",
      "test",
      "performance"
    ]
  },
  {
    "id": "node-033",
    "pattern": "^jest\\s+.*--detectOpenHandles",
    "cmd": "jest",
    "severity": "tip",
    "hint": "Use --detectOpenHandles to debug hanging tests.",
    "detail": "This flag helps identify asynchronous resources that prevent Jest from exiting, such as unclosed database connections or timers.",
    "tags": [
      "jest",
      "test",
      "debug"
    ]
  },
  {
    "id": "node-034",
    "pattern": "^webpack\\s+.*--mode\\s+development",
    "cmd": "webpack",
    "severity": "tip",
    "hint": "Use --mode production for optimized builds.",
    "detail": "The production mode enables minification and other optimizations. Always use --mode production for deployment builds to reduce bundle size and improve performance.",
    "tags": [
      "webpack",
      "build",
      "performance"
    ]
  },
  {
    "id": "node-035",
    "pattern": "^webpack\\s+.*--watch",
    "cmd": "webpack",
    "severity": "tip",
    "hint": "Use --watch-poll for reliable file watching on network drives.",
    "detail": "Native file watching may not work on all filesystems. --watch-poll uses polling, which is slower but more reliable on network or Docker-mounted volumes.",
    "tags": [
      "webpack",
      "watch",
      "filesystem"
    ]
  },
  {
    "id": "node-036",
    "pattern": "^vite\\s+build(\\s|$)",
    "cmd": "vite",
    "severity": "tip",
    "hint": "Use --mode to specify environment variables for builds.",
    "detail": "The --mode flag loads environment variables from .env.<mode> files, allowing for environment-specific builds (e.g., staging, production).",
    "tags": [
      "vite",
      "build",
      "environment"
    ]
  },
  {
    "id": "node-037",
    "pattern": "^vite\\s+preview(\\s|$)",
    "cmd": "vite",
    "severity": "tip",
    "hint": "Use --host to expose preview server on your network.",
    "detail": "By default, vite preview binds to localhost. Use --host to allow access from other devices, useful for mobile or cross-device testing.",
    "tags": [
      "vite",
      "preview",
      "network"
    ]
  },
  {
    "id": "node-038",
    "pattern": "^esbuild\\s+.*--watch",
    "cmd": "esbuild",
    "severity": "tip",
    "hint": "Use --incremental for faster rebuilds in watch mode.",
    "detail": "The --incremental flag enables caching, making subsequent rebuilds much faster. It's especially beneficial for large codebases during development.",
    "tags": [
      "esbuild",
      "build",
      "performance"
    ]
  },
  {
    "id": "node-039",
    "pattern": "^esbuild\\s+.*--minify",
    "cmd": "esbuild",
    "severity": "tip",
    "hint": "Combine --minify with --sourcemap for production debugging.",
    "detail": "Minification reduces bundle size, but makes debugging harder. Adding --sourcemap preserves source mapping, aiding post-deployment debugging.",
    "tags": [
      "esbuild",
      "build",
      "debug"
    ]
  },
  {
    "id": "node-040",
    "pattern": "^rollup\\s+.*--watch",
    "cmd": "rollup",
    "severity": "tip",
    "hint": "Use --silent to suppress verbose logs in watch mode.",
    "detail": "The --silent flag reduces console noise, making it easier to spot important messages during continuous development.",
    "tags": [
      "rollup",
      "watch",
      "logs"
    ]
  },
  {
    "id": "node-041",
    "pattern": "^rollup\\s+.*--environment\\s+",
    "cmd": "rollup",
    "severity": "tip",
    "hint": "Use --environment to inject env vars into your build.",
    "detail": "This flag sets environment variables for your Rollup build, which can be accessed in plugins or code, enabling environment-specific builds.",
    "tags": [
      "rollup",
      "build",
      "environment"
    ]
  },
  {
    "id": "node-042",
    "pattern": "^turbo\\s+run\\s+",
    "cmd": "turbo",
    "severity": "tip",
    "hint": "Use --parallel to run tasks concurrently.",
    "detail": "The --parallel flag allows turbo to execute independent tasks simultaneously, significantly reducing build and test times in monorepos.",
    "tags": [
      "turbo",
      "build",
      "performance"
    ]
  },
  {
    "id": "node-043",
    "pattern": "^turbo\\s+run\\s+.*--filter",
    "cmd": "turbo",
    "severity": "tip",
    "hint": "Use --filter to target specific packages in monorepos.",
    "detail": "The --filter flag restricts turbo run to specific packages, speeding up workflows and reducing unnecessary builds in large monorepos.",
    "tags": [
      "turbo",
      "monorepo",
      "performance"
    ]
  },
  {
    "id": "node-044",
    "pattern": "^npm\\s+audit\\s+fix\\s+--force",
    "cmd": "npm",
    "severity": "danger",
    "hint": "Avoid --force; it may break dependencies or introduce bugs.",
    "detail": "Using --force with npm audit fix can install breaking changes or incompatible versions, potentially destabilizing your project.",
    "tags": [
      "npm",
      "audit",
      "security"
    ]
  },
  {
    "id": "node-045",
    "pattern": "^npm\\s+ci\\s+",
    "cmd": "npm",
    "severity": "tip",
    "hint": "Use npm ci for clean, reproducible installs in CI/CD.",
    "detail": "npm ci removes node_modules and installs exactly what's in package-lock.json, ensuring consistent environments across machines and builds.",
    "tags": [
      "npm",
      "ci",
      "install"
    ]
  },
  {
    "id": "node-046",
    "pattern": "^npm\\s+run\\s+.*--silent",
    "cmd": "npm",
    "severity": "tip",
    "hint": "Use --silent to suppress npm output for cleaner logs.",
    "detail": "The --silent flag reduces log noise, making it easier to spot errors or important messages in CI/CD pipelines.",
    "tags": [
      "npm",
      "scripts",
      "logs"
    ]
  },
  {
    "id": "node-047",
    "pattern": "^yarn\\s+dlx\\s+",
    "cmd": "yarn",
    "severity": "upgrade",
    "hint": "Use yarn dlx instead of npx for Yarn v2+ projects.",
    "detail": "npx is not compatible with Yarn v2+ (berry). Use yarn dlx to execute binaries from npm packages without installing them globally.",
    "tags": [
      "yarn",
      "dlx",
      "upgrade"
    ]
  },
  {
    "id": "node-048",
    "pattern": "^pnpm\\s+exec\\s+",
    "cmd": "pnpm",
    "severity": "upgrade",
    "hint": "Use pnpm exec instead of npx for pnpm-managed projects.",
    "detail": "pnpm exec runs binaries from local or workspace dependencies, avoiding global installs and ensuring version consistency.",
    "tags": [
      "pnpm",
      "exec",
      "upgrade"
    ]
  },
  {
    "id": "node-049",
    "pattern": "^npm\\s+start(\\s|$)",
    "cmd": "npm",
    "severity": "warn",
    "hint": "npm start fails if no start script is defined.",
    "detail": "If your package.json lacks a start script, npm start will error. Always define a start script for clarity and compatibility with deployment tools.",
    "tags": [
      "npm",
      "scripts",
      "start"
    ]
  },
  {
    "id": "node-050",
    "pattern": "^node\\s+.*--require\\s+esm",
    "cmd": "node",
    "severity": "upgrade",
    "hint": "Use native ES modules; --require esm is legacy.",
    "detail": "Node.js natively supports ES modules with .mjs or \"type\": \"module\" in package.json. The esm package is deprecated and may cause compatibility issues.",
    "tags": [
      "node",
      "esm",
      "upgrade"
    ]
  },
  {
    "id": "perf-001",
    "pattern": "^perf\\s+record\\s+-a\\s+-g\\s+",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --call-graph dwarf for more accurate stack traces.",
    "detail": "The default call graph method may miss inlined or optimized-out frames. Adding --call-graph dwarf enables DWARF-based unwinding, improving stack accuracy at the cost of higher overhead. Check perf record --help for more details.",
    "tags": [
      "perf",
      "stacktraces",
      "profiling"
    ]
  },
  {
    "id": "perf-002",
    "pattern": "^perf\\s+record\\s+-F\\s+\\d+\\s+",
    "cmd": "perf",
    "severity": "warn",
    "hint": "High -F values can cause system overhead and data loss.",
    "detail": "Setting a high sampling frequency (-F) increases overhead and buffer overflows, leading to lost samples. Monitor /proc/sys/kernel/perf_event_max_sample_rate and adjust accordingly. Use lower frequencies for production systems.",
    "tags": [
      "perf",
      "sampling",
      "overhead"
    ]
  },
  {
    "id": "perf-003",
    "pattern": "^perf\\s+record\\s+.*--call-graph\\s+fp",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Frame pointer unwinding fails on binaries without frame pointers.",
    "detail": "Modern compilers often omit frame pointers for optimization. Using --call-graph fp on such binaries results in incomplete or broken call stacks. Prefer --call-graph dwarf if possible.",
    "tags": [
      "perf",
      "stacktraces",
      "unwinding"
    ]
  },
  {
    "id": "perf-004",
    "pattern": "^perf\\s+record\\s+.*--call-graph\\s+dwarf",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Increase mmap pages with -m for deep DWARF stacks.",
    "detail": "DWARF unwinding generates larger stack traces, requiring more buffer space. Use -m to increase mmap pages and avoid lost events. See perf-record(1) for buffer sizing guidance.",
    "tags": [
      "perf",
      "buffers",
      "dwarf"
    ]
  },
  {
    "id": "perf-005",
    "pattern": "^perf\\s+record\\s+.*-o\\s+/tmp/.*",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Storing perf.data on tmpfs risks data loss if system reboots.",
    "detail": "Writing perf.data to /tmp or other tmpfs locations means the data will be lost on reboot or crash. Use persistent storage for long-running or critical profiling sessions.",
    "tags": [
      "perf",
      "storage",
      "data-loss"
    ]
  },
  {
    "id": "perf-006",
    "pattern": "^perf\\s+stat\\s+-e\\s+cycles,.*",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Add -r for statistical reliability in perf stat runs.",
    "detail": "perf stat can show significant run-to-run variance. Using -r N repeats the measurement N times and reports mean/stddev, improving confidence in results. See perf-stat(1) for details.",
    "tags": [
      "perf",
      "statistics",
      "reliability"
    ]
  },
  {
    "id": "perf-007",
    "pattern": "^perf\\s+record\\s+.*--freq\\s+\\d+",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Check perf_event_max_sample_rate to avoid silent throttling.",
    "detail": "The kernel may silently throttle your requested sampling frequency if it exceeds /proc/sys/kernel/perf_event_max_sample_rate. Always verify the actual sampling rate in perf report output.",
    "tags": [
      "perf",
      "sampling",
      "kernel"
    ]
  },
  {
    "id": "perf-008",
    "pattern": "^perf\\s+top\\s+",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use -G for call graph view in perf top.",
    "detail": "The -G flag enables a hierarchical call graph display, making it easier to spot hot code paths. This is particularly useful for interactive performance exploration.",
    "tags": [
      "perf",
      "top",
      "callgraph"
    ]
  },
  {
    "id": "perf-009",
    "pattern": "^perf\\s+record\\s+.*--user",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Using --user misses kernel time; profile full stack if needed.",
    "detail": "The --user flag restricts sampling to user-space, omitting kernel time. For workloads with significant kernel activity (e.g., I/O), omit --user to capture the full picture.",
    "tags": [
      "perf",
      "kernel",
      "profiling"
    ]
  },
  {
    "id": "perf-010",
    "pattern": "^perf\\s+report\\s+.*--stdio",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --sort dso,symbol for better aggregation in perf report.",
    "detail": "Sorting by dso (shared object) and symbol groups similar functions, making it easier to identify hotspots across libraries. Combine with --stdio for scripting or exporting.",
    "tags": [
      "perf",
      "report",
      "aggregation"
    ]
  },
  {
    "id": "perf-011",
    "pattern": "^flamegraph\\s+.*",
    "cmd": "flamegraph",
    "severity": "tip",
    "hint": "Use --title to label flamegraphs for easier comparison.",
    "detail": "The --title flag sets a custom title in the SVG output, making it easier to distinguish between multiple flamegraphs when analyzing performance regressions.",
    "tags": [
      "flamegraph",
      "visualization",
      "labeling"
    ]
  },
  {
    "id": "perf-012",
    "pattern": "^perf\\s+inject\\s+.*--jit",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --jit to decode JITed code symbols in perf.data.",
    "detail": "The --jit flag processes JIT dump files, resolving symbols for JITed code (e.g., Java, .NET). Without this, stack traces may show as [unknown].",
    "tags": [
      "perf",
      "jit",
      "symbols"
    ]
  },
  {
    "id": "perf-014",
    "pattern": "^strace\\s+.*-o\\s+/tmp/.*",
    "cmd": "strace",
    "severity": "warn",
    "hint": "Writing strace logs to /tmp risks data loss on reboot.",
    "detail": "Like perf, strace logs in /tmp (tmpfs) are lost on reboot or crash. For long traces or debugging critical issues, use persistent storage.",
    "tags": [
      "strace",
      "storage",
      "data-loss"
    ]
  },
  {
    "id": "perf-015",
    "pattern": "^strace\\s+.*-ttt",
    "cmd": "strace",
    "severity": "tip",
    "hint": "Use -T to include syscall duration in strace output.",
    "detail": "The -T flag appends the time spent in each syscall, helping identify slow system calls. Combine with -ttt for high-resolution timestamps.",
    "tags": [
      "strace",
      "timing",
      "syscalls"
    ]
  },
  {
    "id": "perf-016",
    "pattern": "^dtrace\\s+.*-s\\s+",
    "cmd": "dtrace",
    "severity": "warn",
    "hint": "Running dtrace -s as non-root may silently fail.",
    "detail": "DTrace scripts often require elevated privileges. Running as non-root may result in no output or partial tracing, without clear errors. Always check permissions.",
    "tags": [
      "dtrace",
      "permissions",
      "footgun"
    ]
  },
  {
    "id": "perf-017",
    "pattern": "^bpftrace\\s+.*-e\\s+",
    "cmd": "bpftrace",
    "severity": "warn",
    "hint": "bpftrace -e scripts may fail if kernel lacks BPF features.",
    "detail": "Some bpftrace scripts require recent kernel features (e.g., kfunc, typed maps). Check kernel version and /sys/kernel/debug/tracing/available_filter_functions for compatibility.",
    "tags": [
      "bpftrace",
      "kernel",
      "compatibility"
    ]
  },
  {
    "id": "perf-018",
    "pattern": "^bpftrace\\s+.*-v",
    "cmd": "bpftrace",
    "severity": "tip",
    "hint": "Use -v for verbose output to debug BPF program loading.",
    "detail": "The -v flag prints detailed information about BPF program compilation and loading, which is invaluable for troubleshooting verifier errors or missing probes.",
    "tags": [
      "bpftrace",
      "debugging",
      "verbose"
    ]
  },
  {
    "id": "perf-019",
    "pattern": "^valgrind\\s+--tool=memcheck\\s+",
    "cmd": "valgrind",
    "severity": "tip",
    "hint": "Use --leak-check=full for detailed memory leak reports.",
    "detail": "The default leak check is summary-only. --leak-check=full provides stack traces for each leak, making it easier to pinpoint sources. Combine with --show-leak-kinds=all for full coverage.",
    "tags": [
      "valgrind",
      "memcheck",
      "leaks"
    ]
  },
  {
    "id": "perf-020",
    "pattern": "^valgrind\\s+--tool=callgrind\\s+",
    "cmd": "valgrind",
    "severity": "tip",
    "hint": "Use callgrind_annotate to interpret callgrind.out files.",
    "detail": "Raw callgrind.out files are hard to read. callgrind_annotate parses and summarizes them, showing inclusive/exclusive costs per function. Use KCachegrind for GUI visualization.",
    "tags": [
      "valgrind",
      "callgrind",
      "profiling"
    ]
  },
  {
    "id": "perf-021",
    "pattern": "^heaptrack\\s+",
    "cmd": "heaptrack",
    "severity": "tip",
    "hint": "Run heaptrack_gui for interactive leak and allocation analysis.",
    "detail": "heaptrack_gui provides a powerful interface for exploring memory usage, allocation hotspots, and leak sources. It supports filtering, backtrace navigation, and time-based analysis.",
    "tags": [
      "heaptrack",
      "gui",
      "memory"
    ]
  },
  {
    "id": "perf-022",
    "pattern": "^gprof\\s+.*",
    "cmd": "gprof",
    "severity": "upgrade",
    "hint": "Use perf or async-profiler for modern, low-overhead profiling.",
    "detail": "gprof relies on instrumentation and is not thread-safe, often missing modern performance bottlenecks. perf and async-profiler offer sampling-based, multi-threaded profiling with better accuracy.",
    "tags": [
      "gprof",
      "profiling",
      "modern"
    ]
  },
  {
    "id": "perf-023",
    "pattern": "^py-spy\\s+record\\s+",
    "cmd": "py-spy",
    "severity": "tip",
    "hint": "Use --native to include C extension frames in py-spy.",
    "detail": "The --native flag enables capturing C extension stack frames, providing a more complete picture for Python programs that use native libraries (e.g., NumPy, TensorFlow).",
    "tags": [
      "py-spy",
      "python",
      "native"
    ]
  },
  {
    "id": "perf-024",
    "pattern": "^py-spy\\s+top\\s+",
    "cmd": "py-spy",
    "severity": "tip",
    "hint": "Use --idle to include idle threads in py-spy top output.",
    "detail": "By default, py-spy omits idle threads. The --idle flag shows all threads, which is useful for debugging deadlocks or thread starvation.",
    "tags": [
      "py-spy",
      "threads",
      "debugging"
    ]
  },
  {
    "id": "perf-025",
    "pattern": "^async-profiler\\s+.*--event\\s+alloc",
    "cmd": "async-profiler",
    "severity": "tip",
    "hint": "Use --alloc for allocation profiling in async-profiler.",
    "detail": "The --event alloc option tracks object allocations, not just CPU usage. This helps identify memory churn and GC pressure in JVM applications.",
    "tags": [
      "async-profiler",
      "allocation",
      "jvm"
    ]
  },
  {
    "id": "perf-026",
    "pattern": "^async-profiler\\s+.*--output\\s+flamegraph",
    "cmd": "async-profiler",
    "severity": "tip",
    "hint": "Use --output svg for interactive flamegraph navigation.",
    "detail": "SVG output supports zooming and searching in modern browsers, making it easier to analyze large call stacks. Use --output svg for best results.",
    "tags": [
      "async-profiler",
      "flamegraph",
      "output"
    ]
  },
  {
    "id": "perf-027",
    "pattern": "^jstack\\s+\\d+",
    "cmd": "jstack",
    "severity": "warn",
    "hint": "jstack on production JVMs may pause the process briefly.",
    "detail": "jstack can cause JVM safepoints, briefly pausing all threads. For latency-sensitive systems, use async-profiler or perf for non-intrusive stack sampling.",
    "tags": [
      "jstack",
      "jvm",
      "latency"
    ]
  },
  {
    "id": "perf-028",
    "pattern": "^perf\\s+record\\s+.*-p\\s+\\d+",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Attaching to PID without root may miss kernel events.",
    "detail": "Non-root users can only profile their own processes and may lack access to kernel events. For full-system profiling, run as root or adjust perf_event_paranoid.",
    "tags": [
      "perf",
      "permissions",
      "kernel"
    ]
  },
  {
    "id": "perf-029",
    "pattern": "^perf\\s+record\\s+.*-e\\s+cycles",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use -e cycles:u to restrict sampling to user-space cycles.",
    "detail": "The :u modifier limits event collection to user-space, reducing noise from kernel activity. Use :k for kernel-only, or omit for both.",
    "tags": [
      "perf",
      "events",
      "sampling"
    ]
  },
  {
    "id": "perf-030",
    "pattern": "^perf\\s+record\\s+.*-e\\s+instructions",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Combine -e instructions with cycles to measure IPC.",
    "detail": "Collecting both instructions and cycles allows calculation of Instructions Per Cycle (IPC), a key metric for CPU-bound workloads. Use perf stat for direct IPC reporting.",
    "tags": [
      "perf",
      "ipc",
      "cpu"
    ]
  },
  {
    "id": "perf-031",
    "pattern": "^perf\\s+stat\\s+.*-e\\s+cache-misses",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Add -e cache-references to contextualize cache-misses.",
    "detail": "cache-misses alone lacks context. Pairing with cache-references lets you compute miss rates, a more actionable metric for tuning code or hardware.",
    "tags": [
      "perf",
      "cache",
      "metrics"
    ]
  },
  {
    "id": "perf-032",
    "pattern": "^perf\\s+record\\s+.*--per-thread",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --per-thread for fine-grained profiling in multi-threaded apps.",
    "detail": "This flag records events per thread, not per process, enabling detailed analysis of thread-level hotspots. Useful for profiling highly parallel workloads.",
    "tags": [
      "perf",
      "threads",
      "profiling"
    ]
  },
  {
    "id": "perf-033",
    "pattern": "^perf\\s+record\\s+.*--no-inherit",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Using --no-inherit misses child process events.",
    "detail": "By default, perf records events from child processes. --no-inherit disables this, which can lead to incomplete profiles for applications that fork or exec.",
    "tags": [
      "perf",
      "fork",
      "profiling"
    ]
  },
  {
    "id": "perf-034",
    "pattern": "^perf\\s+record\\s+.*--filter",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --filter to focus on specific functions or libraries.",
    "detail": "The --filter option allows you to restrict profiling to functions or DSOs matching a pattern, reducing noise and overhead. See perf-record(1) for syntax.",
    "tags": [
      "perf",
      "filtering",
      "profiling"
    ]
  },
  {
    "id": "perf-035",
    "pattern": "^perf\\s+record\\s+.*--branch-filter",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --branch-filter to analyze branch mispredictions.",
    "detail": "Branch filter events help diagnose pipeline stalls due to mispredicted branches. Requires hardware support (check perf list).",
    "tags": [
      "perf",
      "branch",
      "cpu"
    ]
  },
  {
    "id": "perf-036",
    "pattern": "^perf\\s+record\\s+.*--overwrite",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Using --overwrite risks losing early profiling data.",
    "detail": "The --overwrite mode uses a ring buffer, discarding oldest data when full. This is useful for capturing the end of a workload, but early events are lost if the buffer is too small.",
    "tags": [
      "perf",
      "buffer",
      "data-loss"
    ]
  },
  {
    "id": "perf-037",
    "pattern": "^perf\\s+record\\s+.*--sched-stat",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --sched-stat to profile scheduler latency.",
    "detail": "This option collects scheduling statistics, revealing time spent waiting on the scheduler. Useful for diagnosing latency in multi-threaded or I/O-bound workloads.",
    "tags": [
      "perf",
      "scheduler",
      "latency"
    ]
  },
  {
    "id": "perf-038",
    "pattern": "^perf\\s+record\\s+.*--cpu\\s+\\d+",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --cpu to restrict profiling to specific CPUs.",
    "detail": "Profiling a single CPU reduces overhead and focuses on workloads pinned to that core. Useful for NUMA or core-specific performance analysis.",
    "tags": [
      "perf",
      "cpu",
      "profiling"
    ]
  },
  {
    "id": "perf-039",
    "pattern": "^perf\\s+record\\s+.*--timestamp",
    "cmd": "perf",
    "severity": "tip",
    "hint": "Use --timestamp to correlate perf events with logs.",
    "detail": "Timestamps in perf.data enable precise correlation with application logs or external events, aiding root cause analysis of performance anomalies.",
    "tags": [
      "perf",
      "timestamp",
      "correlation"
    ]
  },
  {
    "id": "perf-040",
    "pattern": "^perf\\s+record\\s+.*--all-cpus",
    "cmd": "perf",
    "severity": "warn",
    "hint": "Profiling all CPUs increases overhead; use selectively.",
    "detail": "The --all-cpus flag collects events from every CPU, which can impact system performance and generate large data files. Limit duration or scope for production systems.",
    "tags": [
      "perf",
      "cpu",
      "overhead"
    ]
  },
  {
    "id": "monitoring-001",
    "pattern": "^prometheus\\s+--storage.tsdb.retention.time=\\d+[smhdwy]$",
    "cmd": "prometheus",
    "severity": "danger",
    "hint": "Check retention time\u2014too low can cause unexpected data loss.",
    "detail": "Setting --storage.tsdb.retention.time too low (e.g., hours or days) can cause Prometheus to aggressively delete historical metrics. This is irreversible and may break dashboards or alerting. Always confirm retention aligns with your compliance and troubleshooting needs.",
    "tags": [
      "prometheus",
      "data-loss",
      "retention"
    ]
  },
  {
    "id": "monitoring-002",
    "pattern": "^prometheus\\s+--web.enable-admin-api$",
    "cmd": "prometheus",
    "severity": "danger",
    "hint": "Restrict admin API\u2014exposes delete and snapshot endpoints.",
    "detail": "The --web.enable-admin-api flag enables endpoints for deleting series and taking snapshots. If exposed without authentication or on public interfaces, this can be abused for data deletion or exfiltration. Always secure or avoid enabling in production.",
    "tags": [
      "prometheus",
      "security",
      "api"
    ]
  },
  {
    "id": "monitoring-003",
    "pattern": "^prometheus\\s+--config.file=.+$",
    "cmd": "prometheus",
    "severity": "warn",
    "hint": "Validate config with 'promtool check config' before reload.",
    "detail": "Prometheus does not validate the config file on startup unless explicitly checked. Syntax or logical errors can cause silent startup failures or missing targets. Use 'promtool check config <file>' to catch issues early.",
    "tags": [
      "prometheus",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-004",
    "pattern": "^alertmanager\\s+--config.file=.+$",
    "cmd": "alertmanager",
    "severity": "warn",
    "hint": "Test Alertmanager config with 'amtool check-config' first.",
    "detail": "Alertmanager can silently ignore misconfigured receivers or routes, causing missed alerts. Use 'amtool check-config <file>' to validate before applying changes, especially in production.",
    "tags": [
      "alertmanager",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-005",
    "pattern": "^grafana\\s+server.*--homepath=.+$",
    "cmd": "grafana",
    "severity": "warn",
    "hint": "Ensure plugins and provisioning paths match custom homepath.",
    "detail": "Setting --homepath changes the base directory for Grafana, but plugins, provisioning, and data paths may not update automatically. This can cause missing dashboards or plugins. Double-check all related paths in config.",
    "tags": [
      "grafana",
      "config",
      "paths"
    ]
  },
  {
    "id": "monitoring-006",
    "pattern": "^grafana\\s+cli\\s+plugins\\s+install\\s+.+$",
    "cmd": "grafana",
    "severity": "tip",
    "hint": "Restart Grafana after plugin install for changes to take effect.",
    "detail": "Grafana plugins installed via CLI are not loaded until the server restarts. Forgetting this step leads to confusion when plugins don't appear in the UI. Always restart the Grafana service after plugin changes.",
    "tags": [
      "grafana",
      "plugins",
      "restart"
    ]
  },
  {
    "id": "monitoring-007",
    "pattern": "^loki\\s+--config.file=.+$",
    "cmd": "loki",
    "severity": "warn",
    "hint": "Validate Loki config with 'loki -print-config-stderr' before reload.",
    "detail": "Loki may start with an invalid config but fail to ingest or query logs properly. Use 'loki -print-config-stderr -config.file=<file>' to catch errors before applying changes.",
    "tags": [
      "loki",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-008",
    "pattern": "^loki\\s+.*--target=all$",
    "cmd": "loki",
    "severity": "tip",
    "hint": "Use specific --target for lower resource usage in microservices.",
    "detail": "Running Loki with --target=all starts all components in one process, which is resource-intensive. For distributed or microservice setups, specify only the required targets (e.g., ingester, querier) to optimize performance.",
    "tags": [
      "loki",
      "performance",
      "microservices"
    ]
  },
  {
    "id": "monitoring-009",
    "pattern": "^tempo\\s+--config.file=.+$",
    "cmd": "tempo",
    "severity": "warn",
    "hint": "Check for storage config errors\u2014Tempo may silently drop traces.",
    "detail": "Tempo will silently drop incoming traces if storage configuration is invalid or unreachable. Always validate storage endpoints and permissions before deploying new configs.",
    "tags": [
      "tempo",
      "config",
      "storage"
    ]
  },
  {
    "id": "monitoring-010",
    "pattern": "^opentelemetry-collector\\s+--config=.+$",
    "cmd": "opentelemetry-collector",
    "severity": "warn",
    "hint": "Validate config with 'otelcol --config <file> --dry-run'.",
    "detail": "The OpenTelemetry Collector can fail to start or drop data if the config is invalid. Use the --dry-run flag to validate configuration syntax and component wiring before applying.",
    "tags": [
      "opentelemetry",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-011",
    "pattern": "^jaeger\\s+all-in-one.*$",
    "cmd": "jaeger",
    "severity": "tip",
    "hint": "Use production deployment modes for scalability, not all-in-one.",
    "detail": "The 'all-in-one' Jaeger mode is for development and testing only. For production, use dedicated collector, agent, and query components for better scalability and reliability.",
    "tags": [
      "jaeger",
      "deployment",
      "scalability"
    ]
  },
  {
    "id": "monitoring-012",
    "pattern": "^datadog-agent\\s+start.*$",
    "cmd": "datadog-agent",
    "severity": "warn",
    "hint": "Check for missing integrations\u2014agent may start without errors.",
    "detail": "Datadog Agent will start even if integration configs are missing or invalid, but metrics will not be collected. Always verify integration status with 'datadog-agent status' after startup.",
    "tags": [
      "datadog",
      "integration",
      "status"
    ]
  },
  {
    "id": "monitoring-013",
    "pattern": "^datadog-agent\\s+config\\s+check.*$",
    "cmd": "datadog-agent",
    "severity": "tip",
    "hint": "Use 'datadog-agent config check' to validate YAML syntax.",
    "detail": "Datadog Agent configs are YAML and sensitive to indentation errors. The 'config check' command can catch subtle mistakes that might otherwise cause silent failures in metric collection.",
    "tags": [
      "datadog",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-014",
    "pattern": "^telegraf\\s+-config\\s+.+$",
    "cmd": "telegraf",
    "severity": "warn",
    "hint": "Test Telegraf config with 'telegraf --test' before reload.",
    "detail": "Telegraf can start with a broken config, but plugins may silently fail. Use 'telegraf --test --config <file>' to ensure all inputs and outputs are working as expected.",
    "tags": [
      "telegraf",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-015",
    "pattern": "^telegraf\\s+-config\\s+.+\\s+--input-filter=.+$",
    "cmd": "telegraf",
    "severity": "tip",
    "hint": "Use --input-filter to limit plugins and speed up testing.",
    "detail": "The --input-filter flag lets you test only specific plugins, reducing startup time and noise when debugging or developing new input plugins. This is especially useful in large configs.",
    "tags": [
      "telegraf",
      "performance",
      "testing"
    ]
  },
  {
    "id": "monitoring-016",
    "pattern": "^netdata\\s+start.*$",
    "cmd": "netdata",
    "severity": "warn",
    "hint": "Secure Netdata web UI\u2014default is open to all interfaces.",
    "detail": "Netdata's web UI binds to all interfaces by default, exposing metrics and dashboards to anyone on the network. Restrict access with the 'bind to' config or firewall rules to avoid information leaks.",
    "tags": [
      "netdata",
      "security",
      "network"
    ]
  },
  {
    "id": "monitoring-017",
    "pattern": "^netdata\\s+update.*$",
    "cmd": "netdata",
    "severity": "tip",
    "hint": "Restart Netdata after update to apply new plugins and fixes.",
    "detail": "Netdata updates may include new collectors or bug fixes that require a service restart to take effect. Failing to restart can leave the agent running outdated code or missing features.",
    "tags": [
      "netdata",
      "update",
      "restart"
    ]
  },
  {
    "id": "monitoring-018",
    "pattern": "^glances\\s+--export-csv.*$",
    "cmd": "glances",
    "severity": "tip",
    "hint": "Use --export-csv for logging, but rotate files to avoid disk fill.",
    "detail": "Glances can export metrics to CSV, but files grow quickly. Implement log rotation or periodic truncation to prevent disk exhaustion, especially on long-running systems.",
    "tags": [
      "glances",
      "logging",
      "disk"
    ]
  },
  {
    "id": "monitoring-019",
    "pattern": "^glances\\s+--webserver.*$",
    "cmd": "glances",
    "severity": "warn",
    "hint": "Protect Glances webserver with authentication or firewall.",
    "detail": "The Glances webserver exposes real-time system metrics and is unauthenticated by default. Always secure access with --username/--password or restrict via firewall to trusted networks.",
    "tags": [
      "glances",
      "security",
      "web"
    ]
  },
  {
    "id": "monitoring-020",
    "pattern": "^prometheus\\s+--web.listen-address=0.0.0.0:9090$",
    "cmd": "prometheus",
    "severity": "danger",
    "hint": "Do not expose Prometheus UI to the public internet.",
    "detail": "Binding Prometheus to 0.0.0.0 exposes the UI and API to all networks, risking data leaks or remote manipulation. Always restrict access to trusted networks or use a reverse proxy with authentication.",
    "tags": [
      "prometheus",
      "security",
      "network"
    ]
  },
  {
    "id": "monitoring-021",
    "pattern": "^prometheus\\s+--storage.tsdb.retention.size=\\d+[MG]B$",
    "cmd": "prometheus",
    "severity": "warn",
    "hint": "Set retention size carefully\u2014can cause silent data truncation.",
    "detail": "If --storage.tsdb.retention.size is set too low, Prometheus will silently delete old data to stay within the limit. This can break historical queries and alerting. Monitor disk usage and retention closely.",
    "tags": [
      "prometheus",
      "retention",
      "storage"
    ]
  },
  {
    "id": "monitoring-022",
    "pattern": "^prometheus\\s+--query.max-concurrency=\\d+$",
    "cmd": "prometheus",
    "severity": "tip",
    "hint": "Tune --query.max-concurrency for heavy dashboard usage.",
    "detail": "The default max concurrency for queries may be too low for busy Grafana dashboards. Increasing this value can improve responsiveness but may increase CPU/memory usage. Monitor resource impact after tuning.",
    "tags": [
      "prometheus",
      "performance",
      "queries"
    ]
  },
  {
    "id": "monitoring-023",
    "pattern": "^grafana\\s+server.*--config=.+$",
    "cmd": "grafana",
    "severity": "warn",
    "hint": "Validate Grafana config with 'grafana-server --config <file> --test'.",
    "detail": "Grafana may start with invalid configs but fail to load datasources or dashboards. Use the --test flag to validate configuration before applying changes in production.",
    "tags": [
      "grafana",
      "config",
      "validation"
    ]
  },
  {
    "id": "monitoring-024",
    "pattern": "^loki\\s+.*--log.level=debug$",
    "cmd": "loki",
    "severity": "tip",
    "hint": "Avoid debug log level in production\u2014can flood disk and logs.",
    "detail": "Running Loki with --log.level=debug generates verbose logs, quickly filling disk and making troubleshooting harder. Use info or warn in production, enabling debug only for short-term troubleshooting.",
    "tags": [
      "loki",
      "logging",
      "performance"
    ]
  },
  {
    "id": "monitoring-025",
    "pattern": "^opentelemetry-collector\\s+.*--mem-ballast-size-mib=\\d+$",
    "cmd": "opentelemetry-collector",
    "severity": "tip",
    "hint": "Set --mem-ballast-size-mib to 1/3-1/2 of available memory.",
    "detail": "The memory ballast flag reduces GC pressure, but setting it too high can cause OOM errors. Follow best practices: allocate 1/3 to 1/2 of total memory for ballast, adjusting as needed for your workload.",
    "tags": [
      "opentelemetry",
      "performance",
      "memory"
    ]
  },
  {
    "id": "monitoring-026",
    "pattern": "^telegraf\\s+--debug$",
    "cmd": "telegraf",
    "severity": "tip",
    "hint": "Use --debug only for troubleshooting\u2014can expose sensitive data.",
    "detail": "Telegraf's debug mode logs raw metric data, including credentials or secrets in some plugin outputs. Avoid running in debug mode in production for extended periods.",
    "tags": [
      "telegraf",
      "debug",
      "security"
    ]
  },
  {
    "id": "monitoring-027",
    "pattern": "^netdata\\s+.*--disable-telemetry$",
    "cmd": "netdata",
    "severity": "tip",
    "hint": "Use --disable-telemetry to prevent sending usage stats upstream.",
    "detail": "Netdata collects and sends anonymous usage data by default. The --disable-telemetry flag disables this, which may be required for privacy or compliance in regulated environments.",
    "tags": [
      "netdata",
      "privacy",
      "telemetry"
    ]
  },
  {
    "id": "monitoring-028",
    "pattern": "^find\\s+.*-name\\s+.*\\.log$",
    "cmd": "find",
    "severity": "upgrade",
    "hint": "Use 'fd' for faster, user-friendly log file searches.",
    "detail": "The 'fd' tool is a modern replacement for 'find', offering parallelism and a simpler syntax. For example, 'fd .log' is faster and more intuitive for searching log files in monitoring environments.",
    "tags": [
      "find",
      "upgrade",
      "fd"
    ]
  },
  {
    "id": "monitoring-029",
    "pattern": "^jaeger\\s+.*--sampling.strategies-file=.+$",
    "cmd": "jaeger",
    "severity": "warn",
    "hint": "Reload Jaeger after changing sampling strategies file.",
    "detail": "Jaeger does not automatically reload the sampling strategies file. Changes require a process restart or SIGHUP to take effect, or traces may be sampled incorrectly.",
    "tags": [
      "jaeger",
      "sampling",
      "reload"
    ]
  },
  {
    "id": "monitoring-030",
    "pattern": "^datadog-agent\\s+status.*$",
    "cmd": "datadog-agent",
    "severity": "tip",
    "hint": "Run 'datadog-agent status' after config changes to verify health.",
    "detail": "The 'status' command provides a detailed snapshot of agent health, integrations, and errors. Use it after any config or integration change to catch issues before they impact monitoring.",
    "tags": [
      "datadog",
      "status",
      "health"
    ]
  },
  {
    "id": "vim-001",
    "pattern": "^vim\\s+-y\\s+",
    "cmd": "vim",
    "severity": "danger",
    "hint": "Avoid -y (easy mode); disables many safety prompts.",
    "detail": "The -y flag starts Vim in 'easy mode', which disables many normal safety checks and keybindings. This can lead to accidental data loss or overwriting files without warning. Only use -y for very specific, controlled scenarios.",
    "tags": [
      "danger",
      "flags",
      "safety"
    ]
  },
  {
    "id": "vim-002",
    "pattern": "^vim\\s+.*\\s+--clean",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use --clean to start without plugins or config for debugging.",
    "detail": "The --clean flag launches Vim or Neovim without loading user or system vimrc/init.vim files, plugins, or customizations. This is invaluable for isolating issues caused by configuration or plugins, as it ensures a pristine environment.",
    "tags": [
      "debug",
      "flags",
      "config"
    ]
  },
  {
    "id": "vim-003",
    "pattern": "^nvim\\s+.*\\s+--headless",
    "cmd": "nvim",
    "severity": "tip",
    "hint": "Use --headless for scripting or CI to avoid UI overhead.",
    "detail": "The --headless flag runs Neovim without a UI, ideal for scripting, automation, or CI environments. It allows you to run Ex commands and exit, reducing resource usage and avoiding graphical issues.",
    "tags": [
      "automation",
      "ci",
      "flags"
    ]
  },
  {
    "id": "vim-004",
    "pattern": "^vim\\s+.*\\s+\\+qall!?$",
    "cmd": "vim",
    "severity": "danger",
    "hint": "qall! closes all files, discarding unsaved changes.",
    "detail": "The :qall! Ex command (or +qall! on the CLI) forces Vim to quit all windows, discarding any unsaved changes. Use with caution, as this cannot be undone and will result in data loss for any modified buffers.",
    "tags": [
      "danger",
      "quit",
      "data-loss"
    ]
  },
  {
    "id": "vim-005",
    "pattern": "^vim\\s+.*\\s+\\+wq!?$",
    "cmd": "vim",
    "severity": "warn",
    "hint": "wq! writes and quits, overwriting read-only files.",
    "detail": "The :wq! command (or +wq! on the CLI) writes changes and quits, forcibly overwriting files even if they are read-only. This can lead to accidental overwrites or permission issues if not intended.",
    "tags": [
      "warn",
      "write",
      "quit"
    ]
  },
  {
    "id": "vim-006",
    "pattern": "^vim\\s+.*\\s+\\+set\\s+.*nocompatible",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Always use 'set nocompatible' to enable Vim features.",
    "detail": "The 'nocompatible' setting disables Vi compatibility mode, enabling Vim's full feature set. Many plugins and modern settings require this; forgetting it can cause subtle breakage.",
    "tags": [
      "config",
      "compatibility",
      "tip"
    ]
  },
  {
    "id": "vim-007",
    "pattern": "^vim\\s+.*\\s+\\+set\\s+.*compatible",
    "cmd": "vim",
    "severity": "warn",
    "hint": "Avoid 'set compatible'; it disables many Vim features.",
    "detail": "The 'compatible' setting reverts Vim to Vi-compatible mode, disabling many enhancements and breaking plugin functionality. Only use this for strict legacy compatibility.",
    "tags": [
      "warn",
      "compatibility",
      "config"
    ]
  },
  {
    "id": "vim-008",
    "pattern": "^vim\\s+.*\\s+\\+source\\s+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +source to load custom scripts at startup.",
    "detail": "The +source flag allows you to execute a Vim script immediately after startup, enabling custom initialization or automation. This is useful for project-specific settings or bulk edits.",
    "tags": [
      "automation",
      "config",
      "tip"
    ]
  },
  {
    "id": "vim-009",
    "pattern": "^vim\\s+.*\\s+\\+\\d+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +N to open at line N, speeding up navigation.",
    "detail": "The +N flag (e.g., +42) opens the file at line N, which is faster than manually jumping after opening. This is especially useful in scripts or when reviewing logs.",
    "tags": [
      "navigation",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-010",
    "pattern": "^vim\\s+.*\\s+\\+G",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +G to jump to the end of the file on open.",
    "detail": "The +G flag opens the file at the last line, which is handy for logs or files where new content is appended. This saves time over manual navigation.",
    "tags": [
      "navigation",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-011",
    "pattern": "^vim\\s+.*\\s+\\+\\s*%s/",
    "cmd": "vim",
    "severity": "warn",
    "hint": "Use \\V in :%s/ to avoid regex surprises in search/replace.",
    "detail": "By default, :%s/ uses Vim's regex engine, which can interpret special characters unintentionally. Prefixing the pattern with \\V switches to 'very nomagic' mode, treating most characters literally and reducing accidental matches.",
    "tags": [
      "search",
      "replace",
      "regex"
    ]
  },
  {
    "id": "vim-012",
    "pattern": "^vim\\s+.*\\s+\\+g/",
    "cmd": "vim",
    "severity": "warn",
    "hint": "Be cautious: :g/ executes on all matches, not just one.",
    "detail": "The :global (:g/) command runs the given Ex command on every line matching the pattern. This can have wide-reaching effects, especially with destructive commands like :d (delete). Always review your pattern.",
    "tags": [
      "global",
      "warn",
      "pattern"
    ]
  },
  {
    "id": "vim-013",
    "pattern": "^vim\\s+.*\\s+\\+normal\\s+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +normal for batch editing with normal mode commands.",
    "detail": "The +normal flag executes normal mode commands on startup, enabling scripted edits. This is powerful for automation but requires precise syntax to avoid unintended changes.",
    "tags": [
      "automation",
      "normal",
      "tip"
    ]
  },
  {
    "id": "vim-014",
    "pattern": "^vim\\s+.*\\s+\\+call\\s+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +call to invoke Vimscript functions at startup.",
    "detail": "The +call flag allows you to call Vimscript functions immediately after startup, enabling complex automation or setup routines. Useful for project-specific workflows.",
    "tags": [
      "automation",
      "vimscript",
      "tip"
    ]
  },
  {
    "id": "vim-015",
    "pattern": "^vim\\s+-u\\s+NONE",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use -u NONE to skip all config for troubleshooting.",
    "detail": "The -u NONE option starts Vim without loading any vimrc file, providing a clean slate for debugging issues related to configuration or plugins. This is more thorough than --clean in some cases.",
    "tags": [
      "debug",
      "config",
      "tip"
    ]
  },
  {
    "id": "vim-016",
    "pattern": "^vim\\s+-u\\s+\\S+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use -u <file> to specify a custom vimrc for this session.",
    "detail": "The -u flag lets you provide a specific vimrc file, enabling per-project or temporary configurations without affecting your main setup. Useful for testing or isolated workflows.",
    "tags": [
      "config",
      "tip",
      "custom"
    ]
  },
  {
    "id": "vim-017",
    "pattern": "^vim\\s+-r\\s+",
    "cmd": "vim",
    "severity": "warn",
    "hint": "vim -r recovers swap files; check for unsaved changes first.",
    "detail": "The -r flag attempts to recover files from Vim's swap files after a crash. Always review the recovered content before saving, as it may contain partial or conflicting changes.",
    "tags": [
      "recovery",
      "warn",
      "swap"
    ]
  },
  {
    "id": "vim-018",
    "pattern": "^vim\\s+-b\\s+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use -b for binary files to avoid data corruption.",
    "detail": "The -b flag opens files in binary mode, disabling certain text processing features that can corrupt non-text files. Essential for editing binaries or files with non-ASCII data.",
    "tags": [
      "binary",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-019",
    "pattern": "^vim\\s+-R\\s+",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use -R for readonly mode to prevent accidental edits.",
    "detail": "The -R flag opens files in readonly mode, which prevents accidental modifications. Useful for reviewing logs or config files where edits are not intended.",
    "tags": [
      "readonly",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-020",
    "pattern": "^vim\\s+.*\\s+\\+copen",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +copen to open the quickfix window on startup.",
    "detail": "The +copen flag opens the quickfix window immediately, streamlining workflows that rely on compiler or grep output. This saves time over manually opening it after Vim starts.",
    "tags": [
      "quickfix",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-021",
    "pattern": "^vim\\s+.*\\s+\\+lopen",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use +lopen to open the location list window on startup.",
    "detail": "The +lopen flag opens the location list window, which is similar to quickfix but scoped to the current window. Useful for LSP diagnostics or project navigation.",
    "tags": [
      "location-list",
      "tip",
      "flags"
    ]
  },
  {
    "id": "vim-022",
    "pattern": "^vim\\s+.*\\s+\\+registers",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :registers to view all yank/delete registers.",
    "detail": "The :registers command shows the contents of all Vim registers, helping you track yanked, deleted, or macro content. This aids in avoiding accidental overwrites and improves macro usage.",
    "tags": [
      "registers",
      "tip",
      "yank"
    ]
  },
  {
    "id": "vim-023",
    "pattern": "^vim\\s+.*\\s+\\+marks",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :marks to list all marks for quick navigation.",
    "detail": "The :marks command displays all current marks, allowing you to quickly jump to saved positions. This is especially useful in large files or multi-file editing sessions.",
    "tags": [
      "marks",
      "tip",
      "navigation"
    ]
  },
  {
    "id": "vim-024",
    "pattern": "^vim\\s+.*\\s+\\+ls",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :ls to list all open buffers for fast switching.",
    "detail": "The :ls command lists all open buffers, showing their status and numbers. Combine with :bN to quickly switch between files without leaving Vim.",
    "tags": [
      "buffers",
      "tip",
      "navigation"
    ]
  },
  {
    "id": "vim-025",
    "pattern": "^vim\\s+.*\\s+\\+LspInfo",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :LspInfo to debug LSP client/server status.",
    "detail": "The :LspInfo command (in Neovim with LSP enabled) shows the status of connected language servers, their capabilities, and any errors. Essential for troubleshooting LSP integration issues.",
    "tags": [
      "lsp",
      "tip",
      "debug"
    ]
  },
  {
    "id": "vim-026",
    "pattern": "^vim\\s+.*\\s+\\+LspRestart",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :LspRestart to recover from LSP crashes.",
    "detail": "The :LspRestart command (Neovim) restarts the language server client, which is useful when the server crashes or becomes unresponsive. This avoids needing to restart the entire editor.",
    "tags": [
      "lsp",
      "tip",
      "recovery"
    ]
  },
  {
    "id": "vim-027",
    "pattern": "^vim\\s+.*\\s+\\+LspLog",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :LspLog to view LSP debug logs for troubleshooting.",
    "detail": "The :LspLog command (Neovim) opens the log file for LSP communications, which is invaluable for debugging protocol issues, server startup failures, or misconfigurations.",
    "tags": [
      "lsp",
      "tip",
      "debug"
    ]
  },
  {
    "id": "vim-028",
    "pattern": "^vim\\s+.*\\s+\\+qf",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Use :cdo/:cfdo to run commands across quickfix/location lists.",
    "detail": ":cdo and :cfdo allow you to execute Ex commands on each file or line in the quickfix or location list, enabling powerful batch editing or refactoring workflows.",
    "tags": [
      "quickfix",
      "tip",
      "batch"
    ]
  },
  {
    "id": "vim-029",
    "pattern": "^vim\\s+.*\\s+\\+set\\s+.*lazyredraw",
    "cmd": "vim",
    "severity": "tip",
    "hint": "Enable 'set lazyredraw' for faster macros and scripts.",
    "detail": "The 'lazyredraw' option tells Vim not to redraw the screen during macros or scripts, greatly improving performance for bulk edits or complex macros. Remember to disable it for interactive editing.",
    "tags": [
      "performance",
      "macros",
      "tip"
    ]
  },
  {
    "id": "vim-030",
    "pattern": "^vim\\s+.*\\s+\\+set\\s+.*inccommand=split",
    "cmd": "vim",
    "severity": "upgrade",
    "hint": "Use 'inccommand=split' for live preview of :substitute.",
    "detail": "The 'inccommand=split' option (Neovim) provides a live preview of substitutions in a split window, making complex search/replace operations safer and more intuitive. This is a modern alternative to traditional :%s/ workflows.",
    "tags": [
      "upgrade",
      "substitute",
      "preview"
    ]
  },
  {
    "id": "tmux-001",
    "pattern": "^tmux\\s+kill-server",
    "cmd": "tmux",
    "severity": "danger",
    "hint": "Use 'tmux kill-server' with caution\u2014kills all sessions instantly.",
    "detail": "The 'tmux kill-server' command terminates the tmux server, closing all sessions and destroying all unsaved work in every pane. There is no confirmation prompt or undo. Always check for active sessions with 'tmux ls' before running.",
    "tags": [
      "sessions",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "tmux-002",
    "pattern": "^tmux\\s+kill-session(\\s+|$)",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Specify '-t <session>' to avoid killing the wrong session.",
    "detail": "Without the '-t' flag, 'tmux kill-session' may default to the current session, which can lead to accidental closure. Always use '-t' to target the intended session explicitly.",
    "tags": [
      "sessions",
      "warn",
      "footgun"
    ]
  },
  {
    "id": "tmux-003",
    "pattern": "^tmux\\s+new-session(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-d' to create detached sessions for background tasks.",
    "detail": "The '-d' flag allows you to start a session without attaching, which is ideal for initializing environments or scripts in the background. This avoids interrupting your current terminal workflow.",
    "tags": [
      "sessions",
      "tip",
      "background"
    ]
  },
  {
    "id": "tmux-004",
    "pattern": "^tmux\\s+attach(-session)?(\\s+|$)",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Use '-t <session>' to avoid attaching to the wrong session.",
    "detail": "If multiple sessions exist, omitting '-t' can attach you to an unintended session. Always specify the session name or number to ensure you connect to the correct environment.",
    "tags": [
      "sessions",
      "warn",
      "footgun"
    ]
  },
  {
    "id": "tmux-005",
    "pattern": "^tmux\\s+send-keys(\\s+.*)?$",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-t <pane>' to target specific panes for automation.",
    "detail": "By default, 'send-keys' operates on the current pane. For scripting or automation, always use '-t' to direct commands to the intended pane, especially in multi-pane layouts.",
    "tags": [
      "automation",
      "tip",
      "panes"
    ]
  },
  {
    "id": "tmux-006",
    "pattern": "^tmux\\s+source-file(\\s+|$)",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Source files with care\u2014invalid configs can break your session.",
    "detail": "Sourcing a malformed tmux config can instantly disrupt key bindings and layouts. Always validate configuration changes before sourcing, and consider using a test session.",
    "tags": [
      "config",
      "warn",
      "footgun"
    ]
  },
  {
    "id": "tmux-007",
    "pattern": "^tmux\\s+rename-session(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use unique session names to avoid confusion in scripts.",
    "detail": "Renaming a session to a name already in use can cause ambiguity and script failures. Always check existing session names with 'tmux ls' before renaming.",
    "tags": [
      "sessions",
      "tip",
      "naming"
    ]
  },
  {
    "id": "tmux-008",
    "pattern": "^tmux\\s+split-window(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-h' for horizontal and '-v' for vertical splits.",
    "detail": "By default, 'split-window' uses the layout defined in your config or defaults to horizontal. Explicitly specify '-h' or '-v' for predictable pane arrangements, especially in scripts.",
    "tags": [
      "panes",
      "tip",
      "layout"
    ]
  },
  {
    "id": "tmux-009",
    "pattern": "^tmux\\s+resize-pane(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-Z' to toggle pane zoom for focused work.",
    "detail": "The '-Z' flag zooms the current pane, maximizing it temporarily. This is invaluable for focusing on a single task without losing your pane layout.",
    "tags": [
      "panes",
      "tip",
      "productivity"
    ]
  },
  {
    "id": "tmux-010",
    "pattern": "^tmux\\s+list-sessions(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'tmux ls' as a shorthand for listing sessions.",
    "detail": "'tmux ls' is an alias for 'tmux list-sessions' and is much faster to type. Both commands provide the same output, listing all active sessions with details.",
    "tags": [
      "sessions",
      "tip",
      "shorthand"
    ]
  },
  {
    "id": "tmux-011",
    "pattern": "^tmux\\s+list-panes(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-a' to list panes across all windows and sessions.",
    "detail": "The '-a' flag with 'list-panes' gives a global view, which is essential for automation and monitoring in complex tmux environments.",
    "tags": [
      "panes",
      "tip",
      "monitoring"
    ]
  },
  {
    "id": "tmux-012",
    "pattern": "^tmux\\s+new-window(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-n <name>' to name windows for easier navigation.",
    "detail": "Naming windows helps with navigation, scripting, and automation. Unnamed windows are assigned numeric titles, which can be confusing in large sessions.",
    "tags": [
      "windows",
      "tip",
      "naming"
    ]
  },
  {
    "id": "tmux-013",
    "pattern": "^tmux\\s+detach(-client)?(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-a' to detach all clients except the current one.",
    "detail": "Detaching all other clients is useful in shared environments or when cleaning up stale connections. This ensures only your client remains attached.",
    "tags": [
      "sessions",
      "tip",
      "clients"
    ]
  },
  {
    "id": "tmux-014",
    "pattern": "^tmux\\s+copy-mode(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-u' to enter copy mode with mouse scrollback enabled.",
    "detail": "The '-u' flag enables mouse-based selection and scrollback in copy mode, making it easier to navigate and copy text, especially in long outputs.",
    "tags": [
      "copy-mode",
      "tip",
      "usability"
    ]
  },
  {
    "id": "tmux-015",
    "pattern": "^tmux\\s+save-buffer(\\s+|$)",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Specify a file to avoid overwriting the default buffer.",
    "detail": "Without a filename, 'save-buffer' writes to the default buffer file, potentially overwriting previous content. Always specify a unique file to preserve important data.",
    "tags": [
      "buffers",
      "warn",
      "data-loss"
    ]
  },
  {
    "id": "tmux-016",
    "pattern": "^tmux\\s+load-buffer(\\s+|$)",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Ensure the file exists before loading a buffer.",
    "detail": "Loading a non-existent file into the buffer will silently fail, leaving the buffer unchanged. Always check file paths before using 'load-buffer'.",
    "tags": [
      "buffers",
      "warn",
      "footgun"
    ]
  },
  {
    "id": "tmux-017",
    "pattern": "^tmux\\s+run-shell(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'run-shell' for hooks and automation in your tmux config.",
    "detail": "'run-shell' executes shell commands from within tmux, enabling dynamic configuration, hooks, and plugin management. This is essential for advanced automation.",
    "tags": [
      "automation",
      "tip",
      "hooks"
    ]
  },
  {
    "id": "tmux-018",
    "pattern": "^tmux\\s+set(-option)?(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-g' to set global options affecting all sessions.",
    "detail": "The '-g' flag applies settings globally, ensuring consistency across all sessions and windows. Without '-g', options only affect the current context.",
    "tags": [
      "config",
      "tip",
      "global"
    ]
  },
  {
    "id": "tmux-019",
    "pattern": "^tmux\\s+show-messages(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'show-messages' to debug recent tmux errors and warnings.",
    "detail": "This command displays the message log, including errors and warnings from recent tmux operations. It's invaluable for troubleshooting configuration or plugin issues.",
    "tags": [
      "debug",
      "tip",
      "logs"
    ]
  },
  {
    "id": "tmux-020",
    "pattern": "^tmux\\s+display-message(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-p' to print formatted output for scripting.",
    "detail": "The '-p' flag outputs messages directly to stdout, making it ideal for scripts that need to capture tmux state or variable values.",
    "tags": [
      "scripting",
      "tip",
      "output"
    ]
  },
  {
    "id": "tmux-021",
    "pattern": "^tmux\\s+-S\\s+",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-S <socket>' to run multiple tmux servers in parallel.",
    "detail": "The '-S' flag specifies a custom socket path, allowing you to run isolated tmux servers. This is useful for testing, automation, or separating workspaces.",
    "tags": [
      "socket",
      "tip",
      "parallel"
    ]
  },
  {
    "id": "tmux-022",
    "pattern": "^tmux\\s+switch-client(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-t <session>' to switch clients between sessions efficiently.",
    "detail": "Switching clients with '-t' is faster than detaching and reattaching, especially when managing multiple sessions from a single terminal.",
    "tags": [
      "clients",
      "tip",
      "sessions"
    ]
  },
  {
    "id": "tmux-023",
    "pattern": "^tmux\\s+resurrect",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Ensure tmux-resurrect plugin is installed before using 'resurrect'.",
    "detail": "'tmux resurrect' commands require the plugin; otherwise, commands will silently fail. Always verify plugin installation and configuration before relying on session restoration.",
    "tags": [
      "plugins",
      "warn",
      "resurrect"
    ]
  },
  {
    "id": "tmux-024",
    "pattern": "^tmux\\s+list-keys(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'list-keys -T <table>' to view custom key bindings.",
    "detail": "Key tables allow for context-specific bindings. Listing keys with '-T' helps debug or document custom workflows, especially when using plugins.",
    "tags": [
      "key-bindings",
      "tip",
      "debug"
    ]
  },
  {
    "id": "tmux-025",
    "pattern": "^tmux\\s+bind-key(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use '-n' to bind keys without a prefix for quick actions.",
    "detail": "The '-n' flag creates bindings that work without the tmux prefix key, enabling rapid access to frequent commands. Use with care to avoid conflicts.",
    "tags": [
      "key-bindings",
      "tip",
      "productivity"
    ]
  },
  {
    "id": "tmux-026",
    "pattern": "^tmux\\s+has-session(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'has-session' in scripts to check if a session exists.",
    "detail": "This command exits with 0 if the session exists, 1 otherwise. It's a robust way to conditionally create or attach to sessions in automation scripts.",
    "tags": [
      "scripting",
      "tip",
      "sessions"
    ]
  },
  {
    "id": "tmux-027",
    "pattern": "^tmux\\s+start-server(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Explicitly start the tmux server for preloading plugins or configs.",
    "detail": "Starting the server without a session allows you to preload plugins, source files, or set options before user interaction. Useful for advanced automation or CI/CD setups.",
    "tags": [
      "server",
      "tip",
      "plugins"
    ]
  },
  {
    "id": "tmux-028",
    "pattern": "^tmux\\s+display-panes(\\s+|$)",
    "cmd": "tmux",
    "severity": "tip",
    "hint": "Use 'display-panes' to quickly identify pane numbers for targeting.",
    "detail": "This overlays pane numbers on the screen, making it easy to target panes with commands like 'select-pane -t'. Essential for complex layouts.",
    "tags": [
      "panes",
      "tip",
      "usability"
    ]
  },
  {
    "id": "tmux-029",
    "pattern": "^tmux\\s+.*nested.*",
    "cmd": "tmux",
    "severity": "warn",
    "hint": "Nested tmux sessions can cause key binding conflicts.",
    "detail": "Running tmux inside another tmux session can lead to confusing prefix/key behavior and display issues. Consider using different prefix keys or alternate terminal multiplexers for nesting.",
    "tags": [
      "nested",
      "warn",
      "key-bindings"
    ]
  },
  {
    "id": "tmux-030",
    "pattern": "^tmux\\s+.*",
    "cmd": "tmux",
    "severity": "upgrade",
    "hint": "Try 'zellij' for a modern, Rust-based tmux alternative.",
    "detail": "Zellij offers a modern terminal multiplexer experience with built-in layouts, plugin support, and improved usability. It addresses many long-standing tmux pain points, especially for new users.",
    "tags": [
      "upgrade",
      "modern",
      "alternatives"
    ]
  },
  {
    "id": "pkgmgr-001",
    "pattern": "^apt\\s+upgrade(\\s+|$)",
    "cmd": "apt",
    "severity": "warn",
    "hint": "Use 'apt full-upgrade' to handle kernel and dependency changes.",
    "detail": "'apt upgrade' will not remove obsolete packages or install new dependencies if it requires removing installed packages. 'apt full-upgrade' (or 'dist-upgrade') is required for major system upgrades, such as kernel or library transitions.",
    "tags": [
      "apt",
      "upgrade",
      "dependency"
    ]
  },
  {
    "id": "pkgmgr-002",
    "pattern": "^apt\\s+install\\s+.*-y(\\s+|$)",
    "cmd": "apt",
    "severity": "warn",
    "hint": "Review packages before using '-y' to auto-confirm installations.",
    "detail": "The '-y' flag auto-confirms all prompts, which can lead to unintended package installations or removals, especially if dependencies change. Always check the list of affected packages before using '-y' in scripts.",
    "tags": [
      "apt",
      "automation",
      "scripting"
    ]
  },
  {
    "id": "pkgmgr-003",
    "pattern": "^apt\\s+remove\\s+.*--purge(\\s+|$)",
    "cmd": "apt",
    "severity": "danger",
    "hint": "Double-check before using '--purge' to avoid data/config loss.",
    "detail": "'apt remove --purge' deletes both the package and its configuration files, which may include user-modified settings. This action is irreversible and can cause loss of critical configuration data.",
    "tags": [
      "apt",
      "remove",
      "danger"
    ]
  },
  {
    "id": "pkgmgr-004",
    "pattern": "^apt\\s+autoremove(\\s+|$)",
    "cmd": "apt",
    "severity": "warn",
    "hint": "Check the list before running 'autoremove' to avoid removing needed d...",
    "detail": "'apt autoremove' removes packages installed as dependencies that are no longer required. However, it may sometimes remove packages still needed by manually installed software if package metadata is incorrect.",
    "tags": [
      "apt",
      "autoremove",
      "dependency"
    ]
  },
  {
    "id": "pkgmgr-005",
    "pattern": "^apt\\s+update(\\s+|$)",
    "cmd": "apt",
    "severity": "tip",
    "hint": "Use 'apt update -o Acquire::Retries=3' for flaky networks.",
    "detail": "The 'Acquire::Retries' option allows apt to retry failed downloads, which is especially useful on unstable connections. This can prevent partial updates and inconsistent package states.",
    "tags": [
      "apt",
      "update",
      "network"
    ]
  },
  {
    "id": "pkgmgr-006",
    "pattern": "^yum\\s+update(\\s+|$)",
    "cmd": "yum",
    "severity": "upgrade",
    "hint": "Switch to 'dnf' for faster, more reliable package management.",
    "detail": "'dnf' is the modern replacement for 'yum' in most RPM-based distributions. It offers improved dependency resolution, better performance, and more robust transaction handling.",
    "tags": [
      "yum",
      "dnf",
      "upgrade"
    ]
  },
  {
    "id": "pkgmgr-007",
    "pattern": "^yum\\s+remove\\s+.*-y(\\s+|$)",
    "cmd": "yum",
    "severity": "danger",
    "hint": "Avoid '-y' with 'yum remove' to prevent accidental mass removals.",
    "detail": "Using '-y' with 'yum remove' can result in the removal of critical packages due to dependency chains. Always review the list of packages to be removed before confirming.",
    "tags": [
      "yum",
      "remove",
      "danger"
    ]
  },
  {
    "id": "pkgmgr-008",
    "pattern": "^dnf\\s+clean\\s+all(\\s+|$)",
    "cmd": "dnf",
    "severity": "warn",
    "hint": "Use 'dnf clean packages' to avoid deleting metadata.",
    "detail": "'dnf clean all' removes all cached packages and repository metadata, which can slow down future operations. Use 'dnf clean packages' to only remove downloaded packages, preserving metadata for faster updates.",
    "tags": [
      "dnf",
      "clean",
      "cache"
    ]
  },
  {
    "id": "pkgmgr-009",
    "pattern": "^dnf\\s+upgrade(\\s+|$)",
    "cmd": "dnf",
    "severity": "tip",
    "hint": "Use '--refresh' to force metadata update before upgrading.",
    "detail": "The '--refresh' flag ensures that dnf fetches the latest repository metadata before upgrading, preventing issues caused by stale cache and ensuring the latest packages are installed.",
    "tags": [
      "dnf",
      "upgrade",
      "metadata"
    ]
  },
  {
    "id": "pkgmgr-010",
    "pattern": "^pacman\\s+-Syu(\\s+|$)",
    "cmd": "pacman",
    "severity": "tip",
    "hint": "Use 'pacman -Syu --noconfirm' only in trusted automation.",
    "detail": "'--noconfirm' skips all prompts, which can lead to unintended package changes or removals. Only use this flag in controlled, automated environments where package lists are vetted.",
    "tags": [
      "pacman",
      "automation",
      "scripting"
    ]
  },
  {
    "id": "pkgmgr-011",
    "pattern": "^pacman\\s+-Rns\\s+",
    "cmd": "pacman",
    "severity": "danger",
    "hint": "Double-check dependencies before using '-Rns' for removals.",
    "detail": "'pacman -Rns' removes a package and its unused dependencies, which can sometimes remove packages required by other software if dependencies are not tracked correctly.",
    "tags": [
      "pacman",
      "remove",
      "danger"
    ]
  },
  {
    "id": "pkgmgr-012",
    "pattern": "^pacman\\s+-Sy(\\s+|$)",
    "cmd": "pacman",
    "severity": "warn",
    "hint": "Avoid 'pacman -Sy' without '-u' to prevent partial upgrades.",
    "detail": "Running 'pacman -Sy' updates the package database without upgrading packages, which can cause a partial upgrade state and break dependencies. Always use 'pacman -Syu' for safe system upgrades.",
    "tags": [
      "pacman",
      "upgrade",
      "partial-upgrade"
    ]
  },
  {
    "id": "pkgmgr-013",
    "pattern": "^brew\\s+install\\s+.*--build-from-source(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use '--build-from-source' only if you need custom builds.",
    "detail": "Building from source is slower and may introduce inconsistencies if dependencies have changed upstream. Prefer pre-built bottles unless you require specific build options or patches.",
    "tags": [
      "brew",
      "install",
      "performance"
    ]
  },
  {
    "id": "pkgmgr-014",
    "pattern": "^brew\\s+upgrade(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use 'brew upgrade --greedy' to update all outdated dependencies.",
    "detail": "By default, 'brew upgrade' only upgrades explicitly installed formulae. The '--greedy' flag also upgrades dependencies of installed formulae, ensuring all packages are up-to-date.",
    "tags": [
      "brew",
      "upgrade",
      "dependency"
    ]
  },
  {
    "id": "pkgmgr-015",
    "pattern": "^brew\\s+cleanup(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Run 'brew cleanup' regularly to free disk space from old versions.",
    "detail": "Homebrew retains old versions of formulae after upgrades. 'brew cleanup' removes these, freeing disk space and reducing clutter in your Cellar.",
    "tags": [
      "brew",
      "cleanup",
      "disk"
    ]
  },
  {
    "id": "pkgmgr-016",
    "pattern": "^brew\\s+doctor(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use 'brew doctor' after major OS upgrades to spot issues.",
    "detail": "'brew doctor' checks for common issues in your Homebrew setup, especially after OS upgrades or manual changes to system paths. It can help diagnose subtle environment or linking problems.",
    "tags": [
      "brew",
      "diagnostics",
      "os-upgrade"
    ]
  },
  {
    "id": "pkgmgr-017",
    "pattern": "^cargo\\s+install\\s+",
    "cmd": "cargo",
    "severity": "tip",
    "hint": "Use '--locked' to ensure reproducible builds with Cargo.lock.",
    "detail": "The '--locked' flag makes 'cargo install' fail if the Cargo.lock file is missing or out of date, ensuring dependencies are resolved exactly as specified. This is critical for reproducible builds.",
    "tags": [
      "cargo",
      "install",
      "reproducibility"
    ]
  },
  {
    "id": "pkgmgr-018",
    "pattern": "^cargo\\s+update(\\s+|$)",
    "cmd": "cargo",
    "severity": "warn",
    "hint": "Avoid 'cargo update' in CI unless you want dependency drift.",
    "detail": "'cargo update' updates all dependencies to the latest allowed versions, which can introduce breaking changes. Pin dependencies in CI to avoid unexpected failures.",
    "tags": [
      "cargo",
      "update",
      "ci"
    ]
  },
  {
    "id": "pkgmgr-019",
    "pattern": "^go\\s+get\\s+",
    "cmd": "go",
    "severity": "upgrade",
    "hint": "Use 'go install' with version suffix for Go 1.17+.",
    "detail": "'go get' is deprecated for installing binaries as of Go 1.17. Use 'go install pkg@version' to install executables, which avoids polluting go.mod and ensures versioned installs.",
    "tags": [
      "go",
      "install",
      "upgrade"
    ]
  },
  {
    "id": "pkgmgr-020",
    "pattern": "^go\\s+install\\s+[^@]+$",
    "cmd": "go",
    "severity": "warn",
    "hint": "Specify version with '@' to avoid non-reproducible installs.",
    "detail": "Installing without a version suffix pulls the latest version, which can change over time. Always use 'go install pkg@vX.Y.Z' for reproducible builds.",
    "tags": [
      "go",
      "install",
      "versioning"
    ]
  },
  {
    "id": "pkgmgr-021",
    "pattern": "^gem\\s+install\\s+.*--user-install(\\s+|$)",
    "cmd": "gem",
    "severity": "tip",
    "hint": "Set GEM_PATH and GEM_HOME for consistent user gem installs.",
    "detail": "Using '--user-install' installs gems to a user directory, but you must ensure GEM_PATH and GEM_HOME are set in your environment for Ruby to find them. Otherwise, installed gems may not be available.",
    "tags": [
      "gem",
      "install",
      "environment"
    ]
  },
  {
    "id": "pkgmgr-022",
    "pattern": "^gem\\s+update(\\s+|$)",
    "cmd": "gem",
    "severity": "warn",
    "hint": "Avoid 'gem update' globally; update only needed gems.",
    "detail": "Running 'gem update' without specifying a gem updates all installed gems, which can break dependencies or introduce incompatibilities. Prefer updating gems individually.",
    "tags": [
      "gem",
      "update",
      "dependency"
    ]
  },
  {
    "id": "pkgmgr-023",
    "pattern": "^mix\\s+deps.get(\\s+|$)",
    "cmd": "mix",
    "severity": "tip",
    "hint": "Use 'MIX_ENV=prod mix deps.get' for production dependencies.",
    "detail": "Mix supports environment-specific dependencies. Setting MIX_ENV ensures only the relevant dependencies are fetched, reducing build size and attack surface for production releases.",
    "tags": [
      "mix",
      "deps",
      "environment"
    ]
  },
  {
    "id": "pkgmgr-024",
    "pattern": "^mix\\s+deps.update\\s+--all(\\s+|$)",
    "cmd": "mix",
    "severity": "warn",
    "hint": "Updating all deps can break your build; update selectively.",
    "detail": "'mix deps.update --all' updates every dependency to the latest version allowed by mix.exs, which can introduce breaking changes. Prefer updating individual dependencies and testing thoroughly.",
    "tags": [
      "mix",
      "update",
      "dependency"
    ]
  },
  {
    "id": "pkgmgr-025",
    "pattern": "^stack\\s+upgrade(\\s+|$)",
    "cmd": "stack",
    "severity": "tip",
    "hint": "Run 'stack upgrade' outside project dirs to avoid config conflicts.",
    "detail": "Upgrading Stack inside a project directory may interfere with local configuration files (stack.yaml), causing unexpected behaviour. Upgrade from your home directory to avoid conflicts.",
    "tags": [
      "stack",
      "upgrade",
      "config"
    ]
  },
  {
    "id": "pkgmgr-026",
    "pattern": "^stack\\s+build(\\s+|$)",
    "cmd": "stack",
    "severity": "tip",
    "hint": "Use '--fast' to skip optimizations for quicker dev builds.",
    "detail": "The '--fast' flag disables optimizations and enables faster builds, which is useful during development. Production builds should omit this flag for optimized binaries.",
    "tags": [
      "stack",
      "build",
      "performance"
    ]
  },
  {
    "id": "pkgmgr-027",
    "pattern": "^cabal\\s+install(\\s+|$)",
    "cmd": "cabal",
    "severity": "tip",
    "hint": "Use '--lib' to install libraries for GHCi and scripts.",
    "detail": "The '--lib' flag installs libraries into the global or user environment, making them available for GHCi and scripts. Without it, cabal may only build executables.",
    "tags": [
      "cabal",
      "install",
      "library"
    ]
  },
  {
    "id": "pkgmgr-028",
    "pattern": "^cabal\\s+update(\\s+|$)",
    "cmd": "cabal",
    "severity": "tip",
    "hint": "Run 'cabal update' before installing to refresh package list.",
    "detail": "Cabal caches the package index locally. Running 'cabal update' ensures you have the latest package information, preventing install failures due to missing or outdated packages.",
    "tags": [
      "cabal",
      "update",
      "cache"
    ]
  },
  {
    "id": "pkgmgr-029",
    "pattern": "^nix\\s+env\\s+-i(\\s+|$)",
    "cmd": "nix",
    "severity": "upgrade",
    "hint": "Use 'nix profile install' instead of deprecated 'nix-env -i'.",
    "detail": "'nix-env -i' is deprecated in favor of 'nix profile install', which provides better reproducibility and profile management. The new command also integrates with flakes and modern Nix workflows.",
    "tags": [
      "nix",
      "upgrade",
      "profile"
    ]
  },
  {
    "id": "pkgmgr-030",
    "pattern": "^nix\\s+shell\\s+",
    "cmd": "nix",
    "severity": "tip",
    "hint": "Use '--pure' to isolate environment from user shell variables.",
    "detail": "The '--pure' flag launches a shell with only the declared dependencies, avoiding contamination from user environment variables. This improves reproducibility and prevents subtle bugs.",
    "tags": [
      "nix",
      "shell",
      "environment"
    ]
  },
  {
    "id": "pkgmgr-031",
    "pattern": "^nix\\s+build\\s+",
    "cmd": "nix",
    "severity": "tip",
    "hint": "Use '--no-link' to build without symlinking to result/.",
    "detail": "The '--no-link' flag prevents 'nix build' from creating a symlink in the current directory, which is useful in CI or scripts where you want to avoid polluting the workspace.",
    "tags": [
      "nix",
      "build",
      "ci"
    ]
  },
  {
    "id": "pkgmgr-032",
    "pattern": "^apt\\s+install\\s+.*--reinstall(\\s+|$)",
    "cmd": "apt",
    "severity": "tip",
    "hint": "Use '--reinstall' to fix corrupted or missing files in packages.",
    "detail": "'apt install --reinstall' forces reinstallation of packages, which is helpful if files are missing or corrupted. This does not affect configuration files unless combined with '--purge'.",
    "tags": [
      "apt",
      "reinstall",
      "repair"
    ]
  },
  {
    "id": "pkgmgr-033",
    "pattern": "^dnf\\s+history\\s+undo\\s+",
    "cmd": "dnf",
    "severity": "tip",
    "hint": "Use 'dnf history undo <ID>' to revert problematic transactions.",
    "detail": "DNF tracks transaction history, allowing you to undo specific changes by referencing their transaction ID. This is useful for rolling back unintended upgrades or removals.",
    "tags": [
      "dnf",
      "history",
      "rollback"
    ]
  },
  {
    "id": "pkgmgr-034",
    "pattern": "^pacman\\s+-Qdtq(\\s+|$)",
    "cmd": "pacman",
    "severity": "tip",
    "hint": "Use 'pacman -Rns $(pacman -Qdtq)' to remove orphaned packages.",
    "detail": "'pacman -Qdtq' lists orphaned packages (no longer required as dependencies). Removing them with '-Rns' helps keep your system clean and reduces attack surface.",
    "tags": [
      "pacman",
      "orphan",
      "cleanup"
    ]
  },
  {
    "id": "pkgmgr-035",
    "pattern": "^brew\\s+pin\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Pin critical formulae to prevent accidental upgrades.",
    "detail": "'brew pin' locks a formula at its current version, preventing upgrades. This is useful for critical dependencies or when newer versions introduce breaking changes.",
    "tags": [
      "brew",
      "pin",
      "versioning"
    ]
  },
  {
    "id": "pkgmgr-036",
    "pattern": "^cargo\\s+install\\s+.*--force(\\s+|$)",
    "cmd": "cargo",
    "severity": "warn",
    "hint": "Avoid '--force' unless you need to overwrite existing binaries.",
    "detail": "'--force' overwrites installed binaries without warning, which can break workflows if the new version is incompatible. Use with caution and test after upgrading.",
    "tags": [
      "cargo",
      "install",
      "overwrite"
    ]
  },
  {
    "id": "pkgmgr-037",
    "pattern": "^gem\\s+uninstall\\s+.*--all(\\s+|$)",
    "cmd": "gem",
    "severity": "danger",
    "hint": "Be careful with '--all'; it removes all versions of a gem.",
    "detail": "'gem uninstall --all' deletes every installed version of the specified gem, which can break applications relying on specific versions. Consider removing only unused versions.",
    "tags": [
      "gem",
      "uninstall",
      "danger"
    ]
  },
  {
    "id": "pkgmgr-038",
    "pattern": "^mix\\s+local.hex(\\s+|$)",
    "cmd": "mix",
    "severity": "tip",
    "hint": "Update Hex regularly to get security and performance fixes.",
    "detail": "Hex is the package manager for Elixir. Keeping it updated ensures you have the latest security patches and features, reducing risk and improving build reliability.",
    "tags": [
      "mix",
      "hex",
      "update"
    ]
  },
  {
    "id": "pkgmgr-039",
    "pattern": "^stack\\s+clean(\\s+|$)",
    "cmd": "stack",
    "severity": "tip",
    "hint": "Run 'stack clean' to reclaim disk space from old builds.",
    "detail": "'stack clean' removes build artifacts, freeing disk space and preventing issues caused by stale object files. It's especially useful before switching branches or dependency versions.",
    "tags": [
      "stack",
      "clean",
      "disk"
    ]
  },
  {
    "id": "pkgmgr-040",
    "pattern": "^nix\\s+collect-garbage(\\s+|$)",
    "cmd": "nix",
    "severity": "tip",
    "hint": "Use 'nix-collect-garbage -d' to delete old generations and free space.",
    "detail": "'nix-collect-garbage -d' removes all unreachable store paths and old generations, freeing significant disk space. This is safe, but you cannot roll back to deleted generations.",
    "tags": [
      "nix",
      "garbage-collection",
      "disk"
    ]
  },
  {
    "id": "build-001",
    "pattern": "^make(\\s+)?$",
    "cmd": "make",
    "severity": "tip",
    "hint": "Use -jN to enable parallel builds for faster compilation.",
    "detail": "By default, make runs jobs serially, which is slow on multicore systems. The -j flag lets you specify the number of jobs to run in parallel, e.g., make -j4. This can drastically reduce build times, but beware of race conditions in poorly written Makefiles.",
    "tags": [
      "performance",
      "make",
      "parallelism"
    ]
  },
  {
    "id": "build-002",
    "pattern": "^make\\s+-j(\\s+)?$",
    "cmd": "make",
    "severity": "warn",
    "hint": "Always specify a number with -j to avoid resource exhaustion.",
    "detail": "Using make -j without a number launches as many jobs as possible, which can overwhelm your system and cause thrashing or OOM kills. It's safer to use -j$(nproc) or a fixed number matching your CPU cores.",
    "tags": [
      "make",
      "parallelism",
      "resources"
    ]
  },
  {
    "id": "build-003",
    "pattern": "^make\\s+clean(\\s+)?$",
    "cmd": "make",
    "severity": "warn",
    "hint": "make clean may not remove all generated files; check your Makefile.",
    "detail": "The clean target is user-defined and may not cover all build artifacts, especially if new files were added or if out-of-tree builds are used. Review your Makefile or use git clean -fdx for a full reset (with caution).",
    "tags": [
      "make",
      "cleanup",
      "artifacts"
    ]
  },
  {
    "id": "build-004",
    "pattern": "^cmake\\s+\\.\\s*$",
    "cmd": "cmake",
    "severity": "warn",
    "hint": "Avoid in-source builds; use a separate build directory.",
    "detail": "Running cmake . writes build files into your source tree, which can pollute it and make cleaning difficult. Best practice is to create a build/ directory and run cmake .. from there to keep artifacts isolated.",
    "tags": [
      "cmake",
      "build-dir",
      "best-practice"
    ]
  },
  {
    "id": "build-005",
    "pattern": "^cmake\\s+.*-G\\s+\"?Unix Makefiles\"?.*$",
    "cmd": "cmake",
    "severity": "tip",
    "hint": "Consider Ninja (-G Ninja) for faster builds than Makefiles.",
    "detail": "Ninja is a modern, fast build system that works seamlessly with CMake. Using -G Ninja often results in significantly faster incremental and parallel builds compared to traditional Unix Makefiles.",
    "tags": [
      "cmake",
      "ninja",
      "performance",
      "upgrade"
    ]
  },
  {
    "id": "build-006",
    "pattern": "^ninja(\\s+)?$",
    "cmd": "ninja",
    "severity": "tip",
    "hint": "Use -jN to control parallelism; default is all CPU cores.",
    "detail": "Ninja automatically uses all available CPU cores, which can sometimes overload systems with limited memory. Use ninja -j4 to restrict the number of concurrent jobs, especially on CI or memory-constrained environments.",
    "tags": [
      "ninja",
      "parallelism",
      "performance"
    ]
  },
  {
    "id": "build-007",
    "pattern": "^bazel\\s+clean(\\s+)?$",
    "cmd": "bazel",
    "severity": "danger",
    "hint": "bazel clean wipes all build outputs; use rarely and with care.",
    "detail": "bazel clean deletes the entire output base, including all build artifacts and caches. This is a heavy operation that can lead to long rebuild times. Prefer bazel clean --expunge_async for less disruption, or avoid unless troubleshooting.",
    "tags": [
      "bazel",
      "cleanup",
      "danger"
    ]
  },
  {
    "id": "build-008",
    "pattern": "^bazel\\s+build(\\s+)?$",
    "cmd": "bazel",
    "severity": "tip",
    "hint": "Use --config=opt for optimized release builds.",
    "detail": "By default, Bazel builds in a non-optimized mode. Adding --config=opt enables compiler optimizations (e.g., -O2), which is essential for production binaries. Custom configs may exist in your workspace for further tuning.",
    "tags": [
      "bazel",
      "optimization",
      "performance"
    ]
  },
  {
    "id": "build-009",
    "pattern": "^buck\\s+build(\\s+)?$",
    "cmd": "buck",
    "severity": "tip",
    "hint": "Use --show-output to display built artifact paths.",
    "detail": "buck build by default only prints the build status. The --show-output flag lists the actual output files, which is useful for scripting or debugging build results.",
    "tags": [
      "buck",
      "output",
      "usability"
    ]
  },
  {
    "id": "build-010",
    "pattern": "^meson\\s+setup(\\s+)?$",
    "cmd": "meson",
    "severity": "warn",
    "hint": "Always use a separate build directory for meson setup.",
    "detail": "Meson enforces out-of-source builds, but running meson setup . can still cause issues if the directory isn't clean. Always create a dedicated build directory and run meson setup builddir to avoid polluting your source tree.",
    "tags": [
      "meson",
      "build-dir",
      "best-practice"
    ]
  },
  {
    "id": "build-011",
    "pattern": "^cargo\\s+build(\\s+)?$",
    "cmd": "cargo",
    "severity": "tip",
    "hint": "Use --release for optimized Rust binaries.",
    "detail": "cargo build compiles in debug mode by default, resulting in slower binaries. Use cargo build --release to enable optimizations (profile.release), which is critical for benchmarking and production deployments.",
    "tags": [
      "cargo",
      "rust",
      "optimization"
    ]
  },
  {
    "id": "build-012",
    "pattern": "^cargo\\s+clean(\\s+)?$",
    "cmd": "cargo",
    "severity": "warn",
    "hint": "cargo clean removes all target/ files; rebuilds will be slow.",
    "detail": "cargo clean deletes the entire target directory, including incremental build caches. This forces a full rebuild next time, which can be time-consuming for large projects. Use only when necessary.",
    "tags": [
      "cargo",
      "cleanup",
      "performance"
    ]
  },
  {
    "id": "build-013",
    "pattern": "^go\\s+build(\\s+)?$",
    "cmd": "go",
    "severity": "tip",
    "hint": "Set GOFLAGS='-trimpath' to remove local paths from binaries.",
    "detail": "The -trimpath flag omits local filesystem paths from the compiled binary, improving reproducibility and security by not leaking developer directory structures. You can export GOFLAGS='-trimpath' to apply it globally.",
    "tags": [
      "go",
      "security",
      "reproducibility"
    ]
  },
  {
    "id": "build-015",
    "pattern": "^tsc(\\s+)?$",
    "cmd": "tsc",
    "severity": "warn",
    "hint": "Without --noEmit, tsc may overwrite existing JS files.",
    "detail": "Running tsc without --noEmit will generate or overwrite .js files according to your tsconfig.json. This can cause confusion if your output directory is not properly set, or if you have mixed JS/TS sources.",
    "tags": [
      "typescript",
      "tsc",
      "output",
      "footgun"
    ]
  },
  {
    "id": "build-016",
    "pattern": "^tsc\\s+--watch(\\s+)?$",
    "cmd": "tsc",
    "severity": "tip",
    "hint": "Use --incremental for faster TypeScript rebuilds in watch mode.",
    "detail": "The --incremental flag enables TypeScript's incremental compilation, which caches build information and significantly speeds up subsequent builds, especially in large projects.",
    "tags": [
      "typescript",
      "tsc",
      "performance"
    ]
  },
  {
    "id": "build-017",
    "pattern": "^gradle\\s+build(\\s+)?$",
    "cmd": "gradle",
    "severity": "tip",
    "hint": "Use --parallel to build independent projects concurrently.",
    "detail": "The --parallel flag allows Gradle to build multiple subprojects at once, leveraging multicore CPUs for faster builds. Not all tasks are parallelizable; check your build scripts for thread safety.",
    "tags": [
      "gradle",
      "performance",
      "parallelism"
    ]
  },
  {
    "id": "build-018",
    "pattern": "^gradle\\s+clean(\\s+)?$",
    "cmd": "gradle",
    "severity": "warn",
    "hint": "gradle clean deletes all build outputs; use with caution.",
    "detail": "gradle clean removes the build/ directory, forcing a full rebuild on the next build command. This can be time-consuming for large projects. Use only when necessary to resolve build issues.",
    "tags": [
      "gradle",
      "cleanup",
      "performance"
    ]
  },
  {
    "id": "build-019",
    "pattern": "^mvn\\s+clean(\\s+)?$",
    "cmd": "mvn",
    "severity": "warn",
    "hint": "mvn clean deletes target/; incremental builds will be lost.",
    "detail": "mvn clean removes the target directory, including compiled classes and cached dependencies. This disables incremental compilation and can slow down subsequent builds. Use only for a fresh start.",
    "tags": [
      "maven",
      "cleanup",
      "performance"
    ]
  },
  {
    "id": "build-020",
    "pattern": "^mvn\\s+install(\\s+)?$",
    "cmd": "mvn",
    "severity": "tip",
    "hint": "Use -T 1C for parallel Maven builds using all CPU cores.",
    "detail": "The -T 1C flag tells Maven to use one thread per core, enabling parallel build of modules. This can drastically reduce build times, but may expose thread-safety issues in poorly configured projects.",
    "tags": [
      "maven",
      "performance",
      "parallelism"
    ]
  },
  {
    "id": "build-021",
    "pattern": "^ant\\s+clean(\\s+)?$",
    "cmd": "ant",
    "severity": "warn",
    "hint": "ant clean may not remove all artifacts; check your build.xml.",
    "detail": "The clean target in Ant is user-defined and may not cover all generated files, especially if custom tasks or directories are used. Review your build.xml to ensure complete cleanup.",
    "tags": [
      "ant",
      "cleanup",
      "artifacts"
    ]
  },
  {
    "id": "build-022",
    "pattern": "^ant\\s+.*-lib\\s+.*$",
    "cmd": "ant",
    "severity": "warn",
    "hint": "Ensure -lib paths are absolute or relative to the invocation dir.",
    "detail": "The -lib flag adds external jars to Ant's classpath, but paths are resolved relative to the current working directory, not the build.xml location. This can cause classpath issues if invoked from different directories.",
    "tags": [
      "ant",
      "classpath",
      "footgun"
    ]
  },
  {
    "id": "build-023",
    "pattern": "^make\\s+-C\\s+/?$",
    "cmd": "make",
    "severity": "danger",
    "hint": "make -C / runs as root and can damage your system.",
    "detail": "Running make -C / executes the Makefile in the root directory, which can lead to unintentional system-wide changes or deletions if the Makefile contains destructive targets. Double-check your directory before using -C.",
    "tags": [
      "make",
      "danger",
      "filesystem"
    ]
  },
  {
    "id": "build-024",
    "pattern": "^cmake\\s+--build\\s+.*$",
    "cmd": "cmake",
    "severity": "tip",
    "hint": "Use --parallel N for faster builds with cmake --build.",
    "detail": "cmake --build supports the --parallel (or -j) flag to control the number of parallel jobs, similar to make or ninja. This can significantly speed up builds on multicore systems.",
    "tags": [
      "cmake",
      "performance",
      "parallelism"
    ]
  },
  {
    "id": "build-025",
    "pattern": "^make\\s+.*-B.*$",
    "cmd": "make",
    "severity": "warn",
    "hint": "make -B forces all targets to rebuild, ignoring timestamps.",
    "detail": "The -B (or --always-make) flag causes make to treat all targets as out-of-date, rebuilding everything regardless of file modification times. Use only when you suspect dependency tracking is broken.",
    "tags": [
      "make",
      "rebuild",
      "performance"
    ]
  },
  {
    "id": "build-026",
    "pattern": "^ninja\\s+-t\\s+clean(\\s+)?$",
    "cmd": "ninja",
    "severity": "warn",
    "hint": "ninja -t clean only removes outputs known to the build graph.",
    "detail": "ninja -t clean deletes files generated by the current build.ninja file, but may leave behind orphaned or manually created files. For a full cleanup, consider deleting the entire build directory.",
    "tags": [
      "ninja",
      "cleanup",
      "artifacts"
    ]
  },
  {
    "id": "build-027",
    "pattern": "^bazel\\s+build\\s+.*--sandbox_debug.*$",
    "cmd": "bazel",
    "severity": "tip",
    "hint": "Use --sandbox_debug to troubleshoot sandboxed build failures.",
    "detail": "The --sandbox_debug flag preserves the sandbox environment after a build failure, allowing you to inspect the filesystem and logs for debugging. This is invaluable for diagnosing non-reproducible errors.",
    "tags": [
      "bazel",
      "debugging",
      "sandbox"
    ]
  },
  {
    "id": "build-028",
    "pattern": "^make\\s+.*--dry-run.*$",
    "cmd": "make",
    "severity": "tip",
    "hint": "Use --dry-run (-n) to preview build steps without executing them.",
    "detail": "The --dry-run or -n flag tells make to print the commands it would execute, but not actually run them. This is useful for verifying build logic or debugging complex Makefiles.",
    "tags": [
      "make",
      "debugging",
      "safety"
    ]
  },
  {
    "id": "build-029",
    "pattern": "^cmake\\s+.*-E\\s+.*$",
    "cmd": "cmake",
    "severity": "tip",
    "hint": "cmake -E runs portable commands; use for scripting in CMake.",
    "detail": "The -E flag exposes a set of platform-independent commands (e.g., copy, remove, tar) that can be used in scripts or custom commands, ensuring portability across different build environments.",
    "tags": [
      "cmake",
      "scripting",
      "portability"
    ]
  },
  {
    "id": "build-030",
    "pattern": "^find\\s+.*-name\\s+Makefile.*$",
    "cmd": "find",
    "severity": "upgrade",
    "hint": "Use fd . -e Makefile for faster, user-friendly searching.",
    "detail": "fd is a modern replacement for find, offering a simpler syntax, colorized output, and better performance. For example, fd . -e Makefile quickly lists all Makefiles in the directory tree.",
    "tags": [
      "find",
      "fd",
      "upgrade",
      "usability"
    ]
  },
  {
    "id": "fpga-001",
    "pattern": "^ghdl\\s+--clean\\s+.*",
    "cmd": "ghdl",
    "severity": "danger",
    "hint": "Use --clean with caution; it deletes all build artifacts.",
    "detail": "The --clean flag in ghdl removes all generated files in the working directory, including object files and elaborated binaries. This is irreversible and can cause loss of simulation results or logs if not backed up. Always verify the directory before running this command.",
    "tags": [
      "ghdl",
      "cleanup",
      "data-loss"
    ]
  },
  {
    "id": "fpga-002",
    "pattern": "^vivado\\s+.*-mode\\s+batch.*",
    "cmd": "vivado",
    "severity": "tip",
    "hint": "Use -source <tcl> with -mode batch for full automation.",
    "detail": "Running Vivado in batch mode without specifying a -source TCL script will start Vivado but not execute any design flow steps. Always pair -mode batch with -source to automate synthesis, implementation, or bitstream generation.",
    "tags": [
      "vivado",
      "automation",
      "batch"
    ]
  },
  {
    "id": "fpga-003",
    "pattern": "^yosys\\s+.*-p\\s+\".*synth_xilinx.*\".*",
    "cmd": "yosys",
    "severity": "tip",
    "hint": "Add -flatten before synth_xilinx for better optimization.",
    "detail": "Flattening the design hierarchy before running synth_xilinx can improve logic optimization and resource utilization. Use the 'flatten' command or -flatten flag to merge modules, especially for deeply nested designs.",
    "tags": [
      "yosys",
      "optimization",
      "xilinx"
    ]
  },
  {
    "id": "fpga-004",
    "pattern": "^quartus_sh\\s+--clean.*",
    "cmd": "quartus_sh",
    "severity": "danger",
    "hint": "quartus_sh --clean deletes all project output files.",
    "detail": "The --clean option removes all generated files, including intermediate compilation results and reports. This action cannot be undone and may require a full recompilation, which is time-consuming for large designs.",
    "tags": [
      "quartus",
      "cleanup",
      "data-loss"
    ]
  },
  {
    "id": "fpga-005",
    "pattern": "^vitis\\s+.*--clean.*",
    "cmd": "vitis",
    "severity": "warn",
    "hint": "Check workspace before using --clean; it removes all build outputs.",
    "detail": "The --clean flag in Vitis deletes all build artifacts in the workspace, including logs and intermediate files. Ensure you have backed up important results or logs before running this command.",
    "tags": [
      "vitis",
      "cleanup",
      "workspace"
    ]
  },
  {
    "id": "fpga-006",
    "pattern": "^verilator\\s+.*--trace-fst.*",
    "cmd": "verilator",
    "severity": "tip",
    "hint": "Use --trace-fst for smaller, faster waveform dumps.",
    "detail": "The --trace-fst flag enables FST waveform output, which is more compact and faster to write than traditional VCD files. This reduces disk usage and speeds up simulation post-processing, especially for large designs.",
    "tags": [
      "verilator",
      "waveform",
      "performance"
    ]
  },
  {
    "id": "fpga-007",
    "pattern": "^ghdl\\s+.*-r\\s+.*--wave=.*\\.vcd.*",
    "cmd": "ghdl",
    "severity": "tip",
    "hint": "Use --wave=*.ghw for richer waveform support in GTKWave.",
    "detail": "The GHW format preserves more signal metadata than VCD and is better supported by GTKWave. Use --wave=*.ghw for improved debugging and signal inspection during simulation.",
    "tags": [
      "ghdl",
      "waveform",
      "debugging"
    ]
  },
  {
    "id": "fpga-008",
    "pattern": "^vivado\\s+.*write_bitstream.*-force.*",
    "cmd": "vivado",
    "severity": "warn",
    "hint": "Avoid -force unless you intend to overwrite existing bitstreams.",
    "detail": "The -force flag overwrites existing bitstream files without prompting. This can lead to accidental loss of previous builds, especially in shared directories or CI environments.",
    "tags": [
      "vivado",
      "bitstream",
      "overwrite"
    ]
  },
  {
    "id": "fpga-009",
    "pattern": "^yosys\\s+.*-p\\s+\".*write_verilog.*\".*",
    "cmd": "yosys",
    "severity": "tip",
    "hint": "Use -noattr with write_verilog to omit synthesis attributes.",
    "detail": "The -noattr flag prevents synthesis attributes from being written to the output Verilog, resulting in cleaner, more portable netlists. This is useful when targeting multiple tools or sharing code.",
    "tags": [
      "yosys",
      "verilog",
      "portability"
    ]
  },
  {
    "id": "fpga-010",
    "pattern": "^nextpnr-.*\\s+--json\\s+.*\\.json\\s+--write\\s+.*\\.json.*",
    "cmd": "nextpnr",
    "severity": "warn",
    "hint": "Don't overwrite input JSON with --write; use a new filename.",
    "detail": "Specifying the same file for --json (input) and --write (output) can corrupt your design netlist. Always use a different output filename to preserve the original synthesis results.",
    "tags": [
      "nextpnr",
      "file-io",
      "corruption"
    ]
  },
  {
    "id": "fpga-011",
    "pattern": "^cocotb\\s+.*",
    "cmd": "cocotb",
    "severity": "tip",
    "hint": "Set MODULE and TOPLEVEL_LANG env vars for multi-language designs.",
    "detail": "Cocotb relies on MODULE and TOPLEVEL_LANG environment variables to correctly identify the testbench and language (VHDL or Verilog). Omitting these can cause silent failures or incorrect simulation behavior.",
    "tags": [
      "cocotb",
      "environment",
      "simulation"
    ]
  },
  {
    "id": "fpga-012",
    "pattern": "^iverilog\\s+.*-g2005.*",
    "cmd": "iverilog",
    "severity": "warn",
    "hint": "Use -g2012 for SystemVerilog features; -g2005 lacks support.",
    "detail": "The -g2005 flag restricts iverilog to Verilog 2005 features. For SystemVerilog constructs, use -g2012 to avoid syntax errors and simulation mismatches.",
    "tags": [
      "iverilog",
      "verilog",
      "compatibility"
    ]
  },
  {
    "id": "fpga-013",
    "pattern": "^modelsim\\s+.*-do\\s+.*",
    "cmd": "modelsim",
    "severity": "tip",
    "hint": "Use -c with -do for headless batch simulation.",
    "detail": "The -c flag runs ModelSim in command-line mode, which is faster and uses less memory than the GUI. This is ideal for CI pipelines or automated regression testing.",
    "tags": [
      "modelsim",
      "batch",
      "automation"
    ]
  },
  {
    "id": "fpga-014",
    "pattern": "^openFPGALoader\\s+.*-e.*",
    "cmd": "openFPGALoader",
    "severity": "danger",
    "hint": "The -e flag erases the entire flash; use with extreme caution.",
    "detail": "Erasing the flash will remove all user data and bootloaders from the FPGA board. Ensure you have backups and understand the board's recovery process before using this option.",
    "tags": [
      "openFPGALoader",
      "flash",
      "data-loss"
    ]
  },
  {
    "id": "fpga-015",
    "pattern": "^vivado\\s+.*-nolog.*",
    "cmd": "vivado",
    "severity": "warn",
    "hint": "Avoid -nolog in CI; logs are essential for debugging failures.",
    "detail": "The -nolog flag disables log file generation, making it difficult to diagnose synthesis or implementation issues after the fact. Always retain logs in automated environments.",
    "tags": [
      "vivado",
      "logging",
      "ci"
    ]
  },
  {
    "id": "fpga-016",
    "pattern": "^yosys\\s+.*-m\\s+gates.*",
    "cmd": "yosys",
    "severity": "upgrade",
    "hint": "Use ABC9 for modern technology mapping instead of gates plugin.",
    "detail": "ABC9 provides improved mapping and optimization for modern FPGAs compared to the legacy gates plugin. Enable ABC9 with 'synth_xilinx -abc9' or 'synth_ecp5 -abc9' for better results.",
    "tags": [
      "yosys",
      "upgrade",
      "abc9"
    ]
  },
  {
    "id": "fpga-017",
    "pattern": "^ghdl\\s+.*-fexplicit.*",
    "cmd": "ghdl",
    "severity": "tip",
    "hint": "Use -fexplicit for better compatibility with synthesis tools.",
    "detail": "The -fexplicit flag ensures all signal assignments are explicit, which helps downstream synthesis tools like Yosys or Quartus parse the design more reliably.",
    "tags": [
      "ghdl",
      "compatibility",
      "synthesis"
    ]
  },
  {
    "id": "fpga-018",
    "pattern": "^quartus_map\\s+.*--family\\s+.*",
    "cmd": "quartus_map",
    "severity": "warn",
    "hint": "Ensure --family matches your target device for correct mapping.",
    "detail": "Using the wrong family can cause Quartus to map primitives incorrectly, leading to failed fits or suboptimal performance. Always double-check the --family argument against your device datasheet.",
    "tags": [
      "quartus",
      "mapping",
      "device"
    ]
  },
  {
    "id": "fpga-019",
    "pattern": "^verilator\\s+.*-j\\s+\\d+.*",
    "cmd": "verilator",
    "severity": "tip",
    "hint": "Use -j <n> to parallelize Verilator's code generation.",
    "detail": "The -j flag enables parallel make jobs during Verilator's code generation, significantly speeding up large simulations on multicore systems. Set -j to the number of available CPU cores for best performance.",
    "tags": [
      "verilator",
      "performance",
      "parallel"
    ]
  },
  {
    "id": "fpga-020",
    "pattern": "^yosys\\s+.*-p\\s+\".*synth_ice40.*\".*",
    "cmd": "yosys",
    "severity": "tip",
    "hint": "Add -top <module> to synth_ice40 for correct top module selection.",
    "detail": "Explicitly specifying the top module with -top avoids accidental synthesis of the wrong module, which can silently produce incorrect bitstreams.",
    "tags": [
      "yosys",
      "ice40",
      "top-module"
    ]
  },
  {
    "id": "fpga-021",
    "pattern": "^nextpnr-ice40\\s+.*--freq\\s+\\d+.*",
    "cmd": "nextpnr-ice40",
    "severity": "tip",
    "hint": "Set --freq to guide timing-driven placement and routing.",
    "detail": "The --freq flag informs nextpnr's timing engine of your target clock frequency, enabling more aggressive optimization and better timing closure.",
    "tags": [
      "nextpnr",
      "timing",
      "optimization"
    ]
  },
  {
    "id": "fpga-022",
    "pattern": "^cocotb\\s+.*pytest.*",
    "cmd": "cocotb",
    "severity": "upgrade",
    "hint": "Use cocotb-test for modern pytest integration.",
    "detail": "The cocotb-test package provides better pytest integration, parallel test execution, and improved reporting compared to legacy cocotb-pytest wrappers.",
    "tags": [
      "cocotb",
      "pytest",
      "upgrade"
    ]
  },
  {
    "id": "fpga-023",
    "pattern": "^vivado\\s+.*-threads\\s+\\d+.*",
    "cmd": "vivado",
    "severity": "tip",
    "hint": "Increase -threads for faster synthesis and implementation.",
    "detail": "The -threads flag allows Vivado to parallelize synthesis and implementation tasks, reducing build times on multicore systems. Set the value to match your CPU's core count for optimal speed.",
    "tags": [
      "vivado",
      "performance",
      "parallel"
    ]
  },
  {
    "id": "fpga-024",
    "pattern": "^quartus_sh\\s+.*--flow.*",
    "cmd": "quartus_sh",
    "severity": "tip",
    "hint": "Use --flow compile for full project build automation.",
    "detail": "The --flow compile option automates analysis, synthesis, fitting, and bitstream generation in one step, reducing manual intervention and scripting complexity.",
    "tags": [
      "quartus",
      "automation",
      "build"
    ]
  },
  {
    "id": "fpga-025",
    "pattern": "^yosys\\s+.*-q.*",
    "cmd": "yosys",
    "severity": "warn",
    "hint": "Avoid -q in CI; errors may be hidden in quiet mode.",
    "detail": "The -q (quiet) flag suppresses most output, making it easy to miss warnings or errors during synthesis. In CI or automated builds, always review logs or avoid -q to catch issues early.",
    "tags": [
      "yosys",
      "logging",
      "ci"
    ]
  },
  {
    "id": "fpga-026",
    "pattern": "^iverilog\\s+.*-Wall.*",
    "cmd": "iverilog",
    "severity": "tip",
    "hint": "Enable -Wall to catch subtle Verilog coding issues.",
    "detail": "The -Wall flag turns on all warnings, helping you catch unused signals, implicit nets, and other common mistakes that can lead to simulation/synthesis mismatches.",
    "tags": [
      "iverilog",
      "warnings",
      "debugging"
    ]
  },
  {
    "id": "fpga-027",
    "pattern": "^openFPGALoader\\s+.*-b\\s+custom.*",
    "cmd": "openFPGALoader",
    "severity": "warn",
    "hint": "Verify custom board config; wrong settings may brick device.",
    "detail": "Using -b custom without a correct configuration file can misconfigure pinouts or voltage levels, potentially damaging the FPGA or making it unresponsive. Double-check all settings before flashing.",
    "tags": [
      "openFPGALoader",
      "board",
      "configuration"
    ]
  },
  {
    "id": "fpga-028",
    "pattern": "^vivado\\s+.*-nojournal.*",
    "cmd": "vivado",
    "severity": "warn",
    "hint": "Avoid -nojournal; journal files aid in debugging and recovery.",
    "detail": "The -nojournal flag disables creation of .jou files, which are useful for tracking command history and recovering from failed runs. Keep journals enabled for traceability.",
    "tags": [
      "vivado",
      "journal",
      "debugging"
    ]
  },
  {
    "id": "fpga-029",
    "pattern": "^yosys\\s+.*-p\\s+\".*read_vhdl.*\".*",
    "cmd": "yosys",
    "severity": "upgrade",
    "hint": "Use ghdl-yosys-plugin for full VHDL-2008 support in Yosys.",
    "detail": "The ghdl-yosys-plugin enables Yosys to synthesize VHDL-2008 designs natively, surpassing the limited built-in read_vhdl support. Install and use the plugin for modern VHDL workflows.",
    "tags": [
      "yosys",
      "ghdl",
      "vhdl"
    ]
  },
  {
    "id": "fpga-030",
    "pattern": "^modelsim\\s+.*-coverage.*",
    "cmd": "modelsim",
    "severity": "tip",
    "hint": "Enable -coverage for detailed code coverage metrics.",
    "detail": "The -coverage flag collects line, toggle, and FSM coverage during simulation, providing insights into testbench effectiveness and untested code paths. Use it to improve verification quality.",
    "tags": [
      "modelsim",
      "coverage",
      "verification"
    ]
  },
  {
    "id": "macos-001",
    "pattern": "^brew\\s+install\\s+--build-from-source\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use --build-bottle for reproducible builds, not just --build-from-sou...",
    "detail": "The --build-from-source flag compiles from source but doesn't create a Homebrew bottle, which can hinder reproducibility and sharing. Use --build-bottle to generate a relocatable binary package for consistent deployments.",
    "tags": [
      "brew",
      "build",
      "reproducibility"
    ]
  },
  {
    "id": "macos-003",
    "pattern": "^brew\\s+services\\s+restart\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use brew services list to check service status before restart.",
    "detail": "Restarting a service blindly may not address underlying issues. brew services list shows the status and user context, helping diagnose permission or configuration problems before restarting.",
    "tags": [
      "brew",
      "services",
      "troubleshooting"
    ]
  },
  {
    "id": "macos-004",
    "pattern": "^launchctl\\s+load\\s+",
    "cmd": "launchctl",
    "severity": "warn",
    "hint": "Use launchctl bootstrap instead of load on macOS 10.11+.",
    "detail": "launchctl load/unload are deprecated in favor of bootstrap/bootout, which provide more robust session management and error reporting. Using deprecated commands may silently fail or behave unexpectedly on newer macOS versions.",
    "tags": [
      "launchctl",
      "deprecation",
      "macos"
    ]
  },
  {
    "id": "macos-005",
    "pattern": "^launchctl\\s+asuser\\s+0\\s+",
    "cmd": "launchctl",
    "severity": "danger",
    "hint": "Never use asuser 0; it can break user launchd contexts.",
    "detail": "Running launchctl asuser 0 (root) can corrupt user launchd environments, causing login or service issues. Always specify the correct user ID to avoid breaking user-level agents and daemons.",
    "tags": [
      "launchctl",
      "root",
      "danger"
    ]
  },
  {
    "id": "macos-006",
    "pattern": "^defaults\\s+write\\s+[^\\s]+\\s+NSGlobalDomain\\s+",
    "cmd": "defaults",
    "severity": "warn",
    "hint": "Avoid writing directly to NSGlobalDomain; use -currentHost if possible.",
    "detail": "Writing to NSGlobalDomain affects all users and may override per-host settings. Use -currentHost to scope changes to the current machine, preventing unintended global configuration changes.",
    "tags": [
      "defaults",
      "scope",
      "configuration"
    ]
  },
  {
    "id": "macos-007",
    "pattern": "^defaults\\s+delete\\s+",
    "cmd": "defaults",
    "severity": "danger",
    "hint": "defaults delete removes all keys if no key is specified.",
    "detail": "Running defaults delete with only a domain argument deletes the entire domain, wiping all settings for that app. Always specify the key to avoid irreversible loss of configuration.",
    "tags": [
      "defaults",
      "danger",
      "data-loss"
    ]
  },
  {
    "id": "macos-008",
    "pattern": "^diskutil\\s+eraseDisk\\s+",
    "cmd": "diskutil",
    "severity": "danger",
    "hint": "eraseDisk is destructive; double-check disk identifier before running.",
    "detail": "diskutil eraseDisk wipes all partitions and data on the specified disk. Mistyping the disk identifier (e.g., disk0 instead of disk2) can result in total data loss, including the system volume.",
    "tags": [
      "diskutil",
      "erase",
      "data-loss"
    ]
  },
  {
    "id": "macos-009",
    "pattern": "^diskutil\\s+apfs\\s+deleteContainer\\s+",
    "cmd": "diskutil",
    "severity": "danger",
    "hint": "deleteContainer destroys all volumes in the APFS container.",
    "detail": "Deleting an APFS container removes all associated volumes irreversibly. Always verify the container identifier and back up critical data before proceeding.",
    "tags": [
      "diskutil",
      "apfs",
      "danger"
    ]
  },
  {
    "id": "macos-010",
    "pattern": "^security\\s+delete-generic-password\\s+",
    "cmd": "security",
    "severity": "danger",
    "hint": "delete-generic-password is irreversible; export credentials first.",
    "detail": "Deleting a generic password from the keychain cannot be undone, and credentials may be lost forever. Use security dump-keychain or security find-generic-password to export before deletion.",
    "tags": [
      "security",
      "keychain",
      "danger"
    ]
  },
  {
    "id": "macos-011",
    "pattern": "^security\\s+find-certificate\\s+",
    "cmd": "security",
    "severity": "tip",
    "hint": "Use -a to list all matching certificates, not just the first.",
    "detail": "By default, security find-certificate returns only the first match. Use the -a flag to display all matching certificates, which is essential for auditing and debugging multiple entries.",
    "tags": [
      "security",
      "certificate",
      "audit"
    ]
  },
  {
    "id": "macos-012",
    "pattern": "^osascript\\s+-e\\s+",
    "cmd": "osascript",
    "severity": "tip",
    "hint": "Use -l JavaScript to run JS scripts instead of AppleScript.",
    "detail": "osascript supports JavaScript for Automation (JXA) via the -l JavaScript flag, offering modern syntax and better integration with web APIs compared to legacy AppleScript.",
    "tags": [
      "osascript",
      "javascript",
      "modern"
    ]
  },
  {
    "id": "macos-013",
    "pattern": "^pbcopy(\\s+|$)",
    "cmd": "pbcopy",
    "severity": "tip",
    "hint": "Use LANG=C pbcopy to avoid encoding issues with non-UTF8 text.",
    "detail": "pbcopy may mishandle non-UTF8 input, resulting in garbled clipboard contents. Setting LANG=C ensures consistent encoding, especially when piping binary or legacy-encoded data.",
    "tags": [
      "pbcopy",
      "encoding",
      "clipboard"
    ]
  },
  {
    "id": "macos-014",
    "pattern": "^pbpaste(\\s+|$)",
    "cmd": "pbpaste",
    "severity": "tip",
    "hint": "Use pbpaste | tee file to save clipboard contents safely.",
    "detail": "pbpaste outputs clipboard contents to stdout, which can be redirected or piped. Using tee allows you to both view and save the clipboard data, avoiding accidental overwrites.",
    "tags": [
      "pbpaste",
      "clipboard",
      "safety"
    ]
  },
  {
    "id": "macos-015",
    "pattern": "^open\\s+.*\\.app(\\s+|$)",
    "cmd": "open",
    "severity": "tip",
    "hint": "Use -a to open apps by bundle name, not just path.",
    "detail": "open -a lets you launch applications by their bundle name (e.g., 'Safari'), regardless of their location. This is more robust than specifying the .app path, which may change across installations.",
    "tags": [
      "open",
      "applications",
      "robustness"
    ]
  },
  {
    "id": "macos-016",
    "pattern": "^open\\s+.*-g(\\s+|$)",
    "cmd": "open",
    "severity": "tip",
    "hint": "Use -g to open files/apps in background without focus.",
    "detail": "The -g flag opens the target without bringing it to the foreground, which is useful for scripting or launching background tasks without interrupting the user's workflow.",
    "tags": [
      "open",
      "background",
      "productivity"
    ]
  },
  {
    "id": "macos-017",
    "pattern": "^caffeinate(\\s+|$)",
    "cmd": "caffeinate",
    "severity": "tip",
    "hint": "Use -i to prevent idle sleep, or -d for display sleep only.",
    "detail": "caffeinate defaults to preventing system sleep. Use -i to prevent idle sleep (CPU), or -d to prevent only display sleep, tailoring the behavior to your needs for long-running processes.",
    "tags": [
      "caffeinate",
      "sleep",
      "performance"
    ]
  },
  {
    "id": "macos-018",
    "pattern": "^networksetup\\s+-setdnsservers\\s+",
    "cmd": "networksetup",
    "severity": "warn",
    "hint": "Always specify 'Empty' to clear DNS, not just blank.",
    "detail": "Passing an empty string to -setdnsservers does not clear DNS servers. You must explicitly use the word 'Empty' to reset DNS settings to default, or stale entries may persist.",
    "tags": [
      "networksetup",
      "dns",
      "configuration"
    ]
  },
  {
    "id": "macos-019",
    "pattern": "^networksetup\\s+-setairportpower\\s+.+\\s+on",
    "cmd": "networksetup",
    "severity": "tip",
    "hint": "Use -setairportpower with device name, not just 'Wi-Fi'.",
    "detail": "networksetup requires the exact device name (e.g., en0), not the friendly name ('Wi-Fi'). Use networksetup -listallhardwareports to find the correct device identifier.",
    "tags": [
      "networksetup",
      "wifi",
      "hardware"
    ]
  },
  {
    "id": "macos-020",
    "pattern": "^airport(\\s+|$)",
    "cmd": "airport",
    "severity": "upgrade",
    "hint": "Use /System/Library/PrivateFrameworks/Apple80211.framework/Versions/C...",
    "detail": "The airport utility is not in $PATH by default. Use the full path to access advanced Wi-Fi diagnostics and scanning features unavailable via GUI or networksetup.",
    "tags": [
      "airport",
      "wifi",
      "diagnostics"
    ]
  },
  {
    "id": "macos-021",
    "pattern": "^mdfind\\s+",
    "cmd": "mdfind",
    "severity": "tip",
    "hint": "Use -onlyin <dir> to limit search scope and speed up results.",
    "detail": "mdfind searches the entire Spotlight index by default, which can be slow. The -onlyin flag restricts the search to a specific directory, improving performance and relevance.",
    "tags": [
      "mdfind",
      "spotlight",
      "performance"
    ]
  },
  {
    "id": "macos-022",
    "pattern": "^mdfind\\s+-name\\s+",
    "cmd": "mdfind",
    "severity": "warn",
    "hint": "-name is not a valid mdfind flag; use quoted search terms.",
    "detail": "Unlike find, mdfind does not support a -name flag. Use quoted search terms to match filenames or metadata, or use kMDItemFSName for filename-specific queries.",
    "tags": [
      "mdfind",
      "search",
      "syntax"
    ]
  },
  {
    "id": "macos-023",
    "pattern": "^brew\\s+update(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Run brew upgrade after update to actually update installed packages.",
    "detail": "brew update only updates Homebrew's formulae and cask definitions. To upgrade installed packages, you must run brew upgrade separately; otherwise, your software remains outdated.",
    "tags": [
      "brew",
      "update",
      "upgrade"
    ]
  },
  {
    "id": "macos-025",
    "pattern": "^brew\\s+uninstall\\s+--force\\s+",
    "cmd": "brew",
    "severity": "danger",
    "hint": "--force removes all versions; use with caution.",
    "detail": "The --force flag with brew uninstall removes all installed versions of a formula, not just the current one. This can break dependencies or scripts relying on older versions.",
    "tags": [
      "brew",
      "uninstall",
      "danger"
    ]
  },
  {
    "id": "macos-026",
    "pattern": "^brew\\s+link\\s+--overwrite\\s+",
    "cmd": "brew",
    "severity": "warn",
    "hint": "--overwrite can clobber files from other packages.",
    "detail": "brew link --overwrite replaces conflicting files in /usr/local, which may belong to other packages or manual installs. This can lead to hard-to-debug issues or broken software.",
    "tags": [
      "brew",
      "link",
      "conflict"
    ]
  },
  {
    "id": "macos-027",
    "pattern": "^brew\\s+install\\s+python(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "brew installs python3 as 'python3', not 'python'.",
    "detail": "Homebrew installs Python 3 as python3 and does not symlink it to python by default. Scripts expecting 'python' may still invoke the system Python 2. Use brew info python for post-install caveats.",
    "tags": [
      "brew",
      "python",
      "compatibility"
    ]
  },
  {
    "id": "macos-028",
    "pattern": "^brew\\s+install\\s+--cask\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use --appdir to specify custom install location for casks.",
    "detail": "By default, casks are installed to /Applications. The --appdir flag lets you specify a different directory, which is useful for sandboxing or multi-user setups.",
    "tags": [
      "brew",
      "cask",
      "customization"
    ]
  },
  {
    "id": "macos-030",
    "pattern": "^launchctl\\s+unload\\s+",
    "cmd": "launchctl",
    "severity": "warn",
    "hint": "Use bootout instead of unload on macOS 10.11+ for reliability.",
    "detail": "launchctl unload is deprecated and may not fully remove agents or daemons on newer macOS versions. bootout provides better error handling and ensures complete removal from the launchd session.",
    "tags": [
      "launchctl",
      "unload",
      "deprecation"
    ]
  },
  {
    "id": "macos-031",
    "pattern": "^diskutil\\s+repairPermissions\\s+",
    "cmd": "diskutil",
    "severity": "upgrade",
    "hint": "repairPermissions is obsolete on macOS 10.11+; use SIP instead.",
    "detail": "Starting with El Capitan, System Integrity Protection (SIP) enforces permissions, making diskutil repairPermissions unnecessary and unsupported. Rely on SIP and system updates for permission integrity.",
    "tags": [
      "diskutil",
      "permissions",
      "obsolete"
    ]
  },
  {
    "id": "macos-032",
    "pattern": "^diskutil\\s+secureErase\\s+",
    "cmd": "diskutil",
    "severity": "warn",
    "hint": "secureErase is ineffective on SSDs; use FileVault for encryption.",
    "detail": "secureErase overwrites data, but SSDs may remap blocks, leaving data recoverable. FileVault provides full-disk encryption, which is more effective for SSD data security.",
    "tags": [
      "diskutil",
      "ssd",
      "encryption"
    ]
  },
  {
    "id": "macos-033",
    "pattern": "^security\\s+add-trusted-cert\\s+",
    "cmd": "security",
    "severity": "warn",
    "hint": "add-trusted-cert affects all users; use -k to specify keychain.",
    "detail": "By default, add-trusted-cert installs certificates into the system keychain, affecting all users. Use the -k flag to target a specific keychain, such as login.keychain, for user-scoped trust.",
    "tags": [
      "security",
      "certificate",
      "scope"
    ]
  },
  {
    "id": "macos-034",
    "pattern": "^osascript\\s+.*\\.js(\\s+|$)",
    "cmd": "osascript",
    "severity": "warn",
    "hint": "osascript does not auto-detect JavaScript; use -l JavaScript.",
    "detail": "osascript requires the -l JavaScript flag to interpret .js files as JXA scripts. Without it, scripts may fail or be interpreted as AppleScript, causing syntax errors.",
    "tags": [
      "osascript",
      "javascript",
      "syntax"
    ]
  },
  {
    "id": "macos-035",
    "pattern": "^brew\\s+tap\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use brew untap to remove unused taps and speed up updates.",
    "detail": "Extra taps slow down brew update and can introduce conflicting formulae. Regularly untap unused sources to streamline Homebrew operations and reduce maintenance overhead.",
    "tags": [
      "brew",
      "tap",
      "performance"
    ]
  },
  {
    "id": "macos-036",
    "pattern": "^brew\\s+search\\s+",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use brew search --desc <term> for description-based search.",
    "detail": "brew search defaults to formula and cask names only. The --desc flag enables searching by description, making it easier to discover relevant packages.",
    "tags": [
      "brew",
      "search",
      "discoverability"
    ]
  },
  {
    "id": "macos-037",
    "pattern": "^brew\\s+list\\s+--versions(\\s+|$)",
    "cmd": "brew",
    "severity": "tip",
    "hint": "Use --multiple to show all installed versions, not just latest.",
    "detail": "brew list --versions shows only the latest installed version by default. The --multiple flag lists all versions, which is useful for auditing and cleanup.",
    "tags": [
      "brew",
      "list",
      "versions"
    ]
  },
  {
    "id": "macos-038",
    "pattern": "^brew\\s+install\\s+coreutils(\\s+|$)",
    "cmd": "brew",
    "severity": "upgrade",
    "hint": "coreutils installs g-prefixed binaries; update PATH for GNU tools.",
    "detail": "Homebrew installs GNU coreutils with a 'g' prefix (e.g., gls, gcp). Update your PATH or use aliases to replace BSD utilities with GNU versions for script compatibility.",
    "tags": [
      "brew",
      "coreutils",
      "gnu"
    ]
  },
  {
    "id": "macos-039",
    "pattern": "^brew\\s+install\\s+findutils(\\s+|$)",
    "cmd": "brew",
    "severity": "upgrade",
    "hint": "findutils installs g-prefixed binaries; use gfind, not find.",
    "detail": "GNU findutils are installed as gfind, gxargs, etc., to avoid clashing with BSD versions. Update scripts or PATH if you require GNU behavior.",
    "tags": [
      "brew",
      "findutils",
      "gnu"
    ]
  },
  {
    "id": "macos-040",
    "pattern": "^brew\\s+install\\s+fd(\\s+|$)",
    "cmd": "brew",
    "severity": "upgrade",
    "hint": "fd is a modern replacement for find; use it for faster searches.",
    "detail": "fd offers a simpler syntax, colorized output, and parallel file system traversal, making it significantly faster and more user-friendly than traditional find for most use cases.",
    "tags": [
      "brew",
      "fd",
      "modern"
    ]
  }
]